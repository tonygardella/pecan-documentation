<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>11 Available Meteorological Drivers | The Predictive Ecosystem Analyzer</title>
  <meta name="description" content="11 Available Meteorological Drivers | The Predictive Ecosystem Analyzer">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="11 Available Meteorological Drivers | The Predictive Ecosystem Analyzer" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11 Available Meteorological Drivers | The Predictive Ecosystem Analyzer" />
  
  
  

<meta name="author" content="By: PEcAn Team">


<meta name="date" content="2019-04-29">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="pecan-models.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="project-overview.html"><a href="project-overview.html"><i class="fa fa-check"></i><b>1</b> Project Overview</a></li>
<li class="chapter" data-level="2" data-path="contributor-covenant-code-of-conduct.html"><a href="contributor-covenant-code-of-conduct.html"><i class="fa fa-check"></i><b>2</b> Contributor Covenant Code of Conduct</a></li>
<li class="chapter" data-level="3" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html"><i class="fa fa-check"></i><b>3</b> About the PEcAn Book</a><ul>
<li class="chapter" data-level="3.0.1" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html#general-feedbackcommentssuggestions"><i class="fa fa-check"></i><b>3.0.1</b> General Feedback/Comments/Suggestions</a></li>
<li class="chapter" data-level="3.1" data-path="about-the-pecan-book.html"><a href="about-the-pecan-book.html#bookediting"><i class="fa fa-check"></i><b>3.1</b> Editing this book</a></li>
</ul></li>
<li class="part"><span><b>II Tutorials,Demos and How To’s</b></span></li>
<li class="chapter" data-level="4" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html"><i class="fa fa-check"></i><b>4</b> Install PEcAn</a><ul>
<li class="chapter" data-level="4.1" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#pecanvm"><i class="fa fa-check"></i><b>4.1</b> PEcAn Virtual Machine</a><ul>
<li class="chapter" data-level="4.1.1" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#maintain-vm"><i class="fa fa-check"></i><b>4.1.1</b> Maintaining your PEcAn VM</a></li>
<li class="chapter" data-level="4.1.2" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#working-with-vm"><i class="fa fa-check"></i><b>4.1.2</b> Working with the VM</a></li>
<li class="chapter" data-level="4.1.3" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#awsvm"><i class="fa fa-check"></i><b>4.1.3</b> Using Amazon Web Services for a VM (AWS)</a></li>
<li class="chapter" data-level="4.1.4" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#createvm"><i class="fa fa-check"></i><b>4.1.4</b> Creating a Virtual Machine</a></li>
<li class="chapter" data-level="4.1.5" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#vm-dektop-conversion"><i class="fa fa-check"></i><b>4.1.5</b> VM Desktop Conversion</a></li>
<li class="chapter" data-level="4.1.6" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#aws-setup"><i class="fa fa-check"></i><b>4.1.6</b> AWS Setup</a></li>
<li class="chapter" data-level="4.1.7" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#porting-vm-to-aws"><i class="fa fa-check"></i><b>4.1.7</b> Porting VM to AWS</a></li>
<li class="chapter" data-level="4.1.8" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#set-up-multiple-instances-optional"><i class="fa fa-check"></i><b>4.1.8</b> Set up multiple instances (optional)</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#shiny-setup"><i class="fa fa-check"></i><b>4.2</b> Shiny Setup</a><ul>
<li class="chapter" data-level="4.2.1" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#install-the-shiny-r-package-and-shiny-server"><i class="fa fa-check"></i><b>4.2.1</b> Install the Shiny R package and Shiny server</a></li>
<li class="chapter" data-level="4.2.2" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#modify-the-shiny-configuration-file"><i class="fa fa-check"></i><b>4.2.2</b> Modify the shiny configuration file</a></li>
<li class="chapter" data-level="4.2.3" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#set-the-apache-proxy"><i class="fa fa-check"></i><b>4.2.3</b> Set the Apache proxy</a></li>
<li class="chapter" data-level="4.2.4" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#enable-and-start-the-shiny-server-and-restart-apache"><i class="fa fa-check"></i><b>4.2.4</b> Enable and start the shiny server, and restart apache</a></li>
<li class="chapter" data-level="4.2.5" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#troubleshooting"><i class="fa fa-check"></i><b>4.2.5</b> Troubleshooting</a></li>
<li class="chapter" data-level="4.2.6" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#further-reading"><i class="fa fa-check"></i><b>4.2.6</b> Further reading</a></li>
<li class="chapter" data-level="4.2.7" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#thredds-setup"><i class="fa fa-check"></i><b>4.2.7</b> Thredds Setup</a></li>
<li class="chapter" data-level="4.2.8" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#install-the-tomcat-8-and-thredds-webapp"><i class="fa fa-check"></i><b>4.2.8</b> Install the Tomcat 8 and Thredds webapp</a></li>
<li class="chapter" data-level="4.2.9" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#update-the-catalog"><i class="fa fa-check"></i><b>4.2.9</b> Update the catalog</a></li>
<li class="chapter" data-level="4.2.10" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#troubleshooting-1"><i class="fa fa-check"></i><b>4.2.10</b> Troubleshooting</a></li>
<li class="chapter" data-level="4.2.11" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#further-reading-1"><i class="fa fa-check"></i><b>4.2.11</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#docker-index"><i class="fa fa-check"></i><b>4.3</b> Docker</a><ul>
<li class="chapter" data-level="4.3.1" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#setup-pecan-using-docker-compose"><i class="fa fa-check"></i><b>4.3.1</b> Setup PEcAn using docker-compose</a></li>
<li class="chapter" data-level="4.3.2" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#pecan-docker-quickstart-init"><i class="fa fa-check"></i><b>4.3.2</b> Initialize PEcAn (first time only)</a></li>
<li class="chapter" data-level="4.3.3" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#docker-quickstart-troubleshooting"><i class="fa fa-check"></i><b>4.3.3</b> Troubleshooting</a></li>
<li class="chapter" data-level="4.3.4" data-path="pecan-manual-setup.html"><a href="pecan-manual-setup.html#osinstall"><i class="fa fa-check"></i><b>4.3.4</b> OS Specific Installations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="user-section.html"><a href="user-section.html"><i class="fa fa-check"></i><b>5</b> User Tutorial Section</a><ul>
<li class="chapter" data-level="5.0.1" data-path="user-section.html"><a href="user-section.html#demo-table"><i class="fa fa-check"></i><b>5.0.1</b> PEcAn Demos</a></li>
<li class="chapter" data-level="5.1" data-path="user-section.html"><a href="user-section.html#basic-web-wrokflow"><i class="fa fa-check"></i><b>5.1</b> Basic Web workflow</a><ul>
<li class="chapter" data-level="5.1.1" data-path="user-section.html"><a href="user-section.html#web-site-model"><i class="fa fa-check"></i><b>5.1.1</b> Site and model selection</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="user-section.html"><a href="user-section.html#intermediate-user"><i class="fa fa-check"></i><b>5.2</b> PEcAn Web Interface</a></li>
<li class="chapter" data-level="5.3" data-path="user-section.html"><a href="user-section.html#advanced-user"><i class="fa fa-check"></i><b>5.3</b> Advanced User Guide</a><ul>
<li class="chapter" data-level="5.3.1" data-path="user-section.html"><a href="user-section.html#adding-to-pecan"><i class="fa fa-check"></i><b>5.3.1</b> Adding to PEcAn</a></li>
<li class="chapter" data-level="5.3.2" data-path="user-section.html"><a href="user-section.html#web-curl-submission"><i class="fa fa-check"></i><b>5.3.2</b> Submitting Workflow from Command Line</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="developer-guide.html"><a href="developer-guide.html"><i class="fa fa-check"></i><b>6</b> Developer guide</a><ul>
<li class="chapter" data-level="6.1" data-path="developer-guide.html"><a href="developer-guide.html#updatebety"><i class="fa fa-check"></i><b>6.1</b> Updating PEcAn Code and Bety Database</a></li>
<li class="chapter" data-level="6.2" data-path="developer-guide.html"><a href="developer-guide.html#pecan-git"><i class="fa fa-check"></i><b>6.2</b> Git and GitHub Workflow</a><ul>
<li class="chapter" data-level="6.2.1" data-path="developer-guide.html"><a href="developer-guide.html#using-git"><i class="fa fa-check"></i><b>6.2.1</b> Using Git</a></li>
<li class="chapter" data-level="6.2.2" data-path="developer-guide.html"><a href="developer-guide.html#github-use-with-pecan"><i class="fa fa-check"></i><b>6.2.2</b> GitHub use with PEcAn</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="developer-guide.html"><a href="developer-guide.html#coding-practices"><i class="fa fa-check"></i><b>6.3</b> Coding Practices</a></li>
<li class="chapter" data-level="6.4" data-path="developer-guide.html"><a href="developer-guide.html#coding-style"><i class="fa fa-check"></i><b>6.4</b> Coding Style</a></li>
<li class="chapter" data-level="6.5" data-path="developer-guide.html"><a href="developer-guide.html#logging"><i class="fa fa-check"></i><b>6.5</b> Logging</a><ul>
<li class="chapter" data-level="6.5.1" data-path="developer-guide.html"><a href="developer-guide.html#pecan-logging-functions"><i class="fa fa-check"></i><b>6.5.1</b> PEcAn logging functions</a></li>
<li class="chapter" data-level="6.5.2" data-path="developer-guide.html"><a href="developer-guide.html#other-r-logging-packages"><i class="fa fa-check"></i><b>6.5.2</b> Other R logging packages</a></li>
<li class="chapter" data-level="6.5.3" data-path="developer-guide.html"><a href="developer-guide.html#example-usage"><i class="fa fa-check"></i><b>6.5.3</b> Example Usage</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="developer-guide.html"><a href="developer-guide.html#package-data"><i class="fa fa-check"></i><b>6.6</b> Package Data</a></li>
<li class="chapter" data-level="6.7" data-path="developer-guide.html"><a href="developer-guide.html#roxygen2-1"><i class="fa fa-check"></i><b>6.7</b> Roxygen2</a></li>
<li class="chapter" data-level="6.8" data-path="developer-guide.html"><a href="developer-guide.html#testing"><i class="fa fa-check"></i><b>6.8</b> Testing</a></li>
<li class="chapter" data-level="6.9" data-path="developer-guide.html"><a href="developer-guide.html#download-and-compile-pecan"><i class="fa fa-check"></i><b>6.9</b> Download and Compile PEcAn</a><ul>
<li class="chapter" data-level="6.9.1" data-path="developer-guide.html"><a href="developer-guide.html#pecan-testrun"><i class="fa fa-check"></i><b>6.9.1</b> PEcAn Testrun</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="developer-guide.html"><a href="developer-guide.html#directory-structure"><i class="fa fa-check"></i><b>6.10</b> Directory structure</a></li>
</ul></li>
<li class="part"><span><b>III Topical Pages</b></span></li>
<li class="chapter" data-level="7" data-path="pecan-standards.html"><a href="pecan-standards.html"><i class="fa fa-check"></i><b>7</b> PEcAn standard formats</a><ul>
<li class="chapter" data-level="7.1" data-path="pecan-standards.html"><a href="pecan-standards.html#defining-new-input-formats"><i class="fa fa-check"></i><b>7.1</b> Defining new input formats</a></li>
<li class="chapter" data-level="7.2" data-path="pecan-standards.html"><a href="pecan-standards.html#time-standard"><i class="fa fa-check"></i><b>7.2</b> Time Standard</a><ul>
<li class="chapter" data-level="7.2.1" data-path="pecan-standards.html"><a href="pecan-standards.html#input-standards"><i class="fa fa-check"></i><b>7.2.1</b> Input Standards</a></li>
<li class="chapter" data-level="7.2.2" data-path="pecan-standards.html"><a href="pecan-standards.html#soils-and-vegetation-inputs"><i class="fa fa-check"></i><b>7.2.2</b> Soils and Vegetation Inputs</a></li>
<li class="chapter" data-level="7.2.3" data-path="pecan-standards.html"><a href="pecan-standards.html#output-standards"><i class="fa fa-check"></i><b>7.2.3</b> Output Standards</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="pecanXML.html"><a href="pecanXML.html"><i class="fa fa-check"></i><b>8</b> The PEcAn XML</a><ul>
<li class="chapter" data-level="8.0.1" data-path="pecanXML.html"><a href="pecanXML.html#xml-core-config"><i class="fa fa-check"></i><b>8.0.1</b> Core configuration</a></li>
<li class="chapter" data-level="8.0.2" data-path="pecanXML.html"><a href="pecanXML.html#xml-outdir"><i class="fa fa-check"></i><b>8.0.2</b> <code>outdir</code>: Output directory</a></li>
<li class="chapter" data-level="8.0.3" data-path="pecanXML.html"><a href="pecanXML.html#xml-database"><i class="fa fa-check"></i><b>8.0.3</b> <code>database</code>: PEcAn database settings</a></li>
<li class="chapter" data-level="8.0.4" data-path="pecanXML.html"><a href="pecanXML.html#xml-pft"><i class="fa fa-check"></i><b>8.0.4</b> <code>pft</code>: Plant functional type selection</a></li>
<li class="chapter" data-level="8.0.5" data-path="pecanXML.html"><a href="pecanXML.html#xml-meta-analysis"><i class="fa fa-check"></i><b>8.0.5</b> <code>meta.analysis</code>: Trait Meta Analysis</a></li>
<li class="chapter" data-level="8.0.6" data-path="pecanXML.html"><a href="pecanXML.html#xml-model"><i class="fa fa-check"></i><b>8.0.6</b> <code>model</code>: Model configuration</a></li>
<li class="chapter" data-level="8.0.7" data-path="pecanXML.html"><a href="pecanXML.html#xml-run"><i class="fa fa-check"></i><b>8.0.7</b> <code>run</code>: Run Setup</a></li>
<li class="chapter" data-level="8.0.8" data-path="pecanXML.html"><a href="pecanXML.html#xml-host"><i class="fa fa-check"></i><b>8.0.8</b> <code>host</code>: Host information for remote execution</a></li>
<li class="chapter" data-level="8.0.9" data-path="pecanXML.html"><a href="pecanXML.html#xml-advanced"><i class="fa fa-check"></i><b>8.0.9</b> Advanced features</a></li>
<li class="chapter" data-level="8.0.10" data-path="pecanXML.html"><a href="pecanXML.html#xml-ensemble"><i class="fa fa-check"></i><b>8.0.10</b> <code>ensemble</code>: Ensemble Runs</a></li>
<li class="chapter" data-level="8.0.11" data-path="pecanXML.html"><a href="pecanXML.html#xml-sensitivity-analysis"><i class="fa fa-check"></i><b>8.0.11</b> <code>sensitivity.analysis</code>: Sensitivity analysis</a></li>
<li class="chapter" data-level="8.0.12" data-path="pecanXML.html"><a href="pecanXML.html#xml-parameter-data-assimilation"><i class="fa fa-check"></i><b>8.0.12</b> Parameter Data Assimilation</a></li>
<li class="chapter" data-level="8.0.13" data-path="pecanXML.html"><a href="pecanXML.html#xml-multi-settings"><i class="fa fa-check"></i><b>8.0.13</b> Multi-Settings</a></li>
<li class="chapter" data-level="8.0.14" data-path="pecanXML.html"><a href="pecanXML.html#xml-state-data-assimilation"><i class="fa fa-check"></i><b>8.0.14</b> (experimental) State Data Assimilation</a></li>
<li class="chapter" data-level="8.0.15" data-path="pecanXML.html"><a href="pecanXML.html#xml-browndog"><i class="fa fa-check"></i><b>8.0.15</b> (experimental) Brown Dog</a></li>
<li class="chapter" data-level="8.0.16" data-path="pecanXML.html"><a href="pecanXML.html#xml-benchmarking"><i class="fa fa-check"></i><b>8.0.16</b> (experimental) Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="workflow.html"><a href="workflow.html"><i class="fa fa-check"></i><b>9</b> PEcAn workflow (web/workflow.R)</a><ul>
<li class="chapter" data-level="9.0.1" data-path="workflow.html"><a href="workflow.html#workflow-readsettings"><i class="fa fa-check"></i><b>9.0.1</b> Read Settings</a></li>
<li class="chapter" data-level="9.0.2" data-path="workflow.html"><a href="workflow.html#workflow-input"><i class="fa fa-check"></i><b>9.0.2</b> Input Conversions</a></li>
<li class="chapter" data-level="9.0.3" data-path="workflow.html"><a href="workflow.html#workflow-input-data"><i class="fa fa-check"></i><b>9.0.3</b> Input Data</a></li>
<li class="chapter" data-level="9.0.4" data-path="workflow.html"><a href="workflow.html#workflow-input-initial"><i class="fa fa-check"></i><b>9.0.4</b> Initial Conditions</a></li>
<li class="chapter" data-level="9.0.5" data-path="workflow.html"><a href="workflow.html#workflow-met"><i class="fa fa-check"></i><b>9.0.5</b> Meteorological Data</a></li>
<li class="chapter" data-level="9.0.6" data-path="workflow.html"><a href="workflow.html#workflow-met-standard"><i class="fa fa-check"></i><b>9.0.6</b> Converting raw data to PEcAn standard</a></li>
<li class="chapter" data-level="9.0.7" data-path="workflow.html"><a href="workflow.html#workflow-met-downscale"><i class="fa fa-check"></i><b>9.0.7</b> Downscaling and gapfilling (optional)</a></li>
<li class="chapter" data-level="9.0.8" data-path="workflow.html"><a href="workflow.html#workflow-met-model"><i class="fa fa-check"></i><b>9.0.8</b> Converting from PEcAn standard to model-specific format</a></li>
<li class="chapter" data-level="9.0.9" data-path="workflow.html"><a href="workflow.html#workflow-traits"><i class="fa fa-check"></i><b>9.0.9</b> Traits</a></li>
<li class="chapter" data-level="9.0.10" data-path="workflow.html"><a href="workflow.html#workflow-metaanalysis"><i class="fa fa-check"></i><b>9.0.10</b> Meta Analysis</a></li>
<li class="chapter" data-level="9.0.11" data-path="workflow.html"><a href="workflow.html#workflow-modelconfig"><i class="fa fa-check"></i><b>9.0.11</b> Model Configuration</a></li>
<li class="chapter" data-level="9.0.12" data-path="workflow.html"><a href="workflow.html#workflow-modelrun"><i class="fa fa-check"></i><b>9.0.12</b> Run Execution</a></li>
<li class="chapter" data-level="9.0.13" data-path="workflow.html"><a href="workflow.html#workflow-postrun"><i class="fa fa-check"></i><b>9.0.13</b> Post Run Analysis</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pecan-models.html"><a href="pecan-models.html"><i class="fa fa-check"></i><b>10</b> PEcAn Models</a><ul>
<li class="chapter" data-level="10.0.1" data-path="pecan-models.html"><a href="pecan-models.html#models-biocro"><i class="fa fa-check"></i><b>10.0.1</b> BioCro</a></li>
<li class="chapter" data-level="10.0.2" data-path="pecan-models.html"><a href="pecan-models.html#models-clm"><i class="fa fa-check"></i><b>10.0.2</b> CLM</a></li>
<li class="chapter" data-level="10.0.3" data-path="pecan-models.html"><a href="pecan-models.html#models-dalec"><i class="fa fa-check"></i><b>10.0.3</b> DALEC</a></li>
<li class="chapter" data-level="10.0.4" data-path="pecan-models.html"><a href="pecan-models.html#models-ed"><i class="fa fa-check"></i><b>10.0.4</b> ED2</a></li>
<li class="chapter" data-level="10.0.5" data-path="pecan-models.html"><a href="pecan-models.html#installation-notes"><i class="fa fa-check"></i><b>10.0.5</b> Installation notes</a></li>
<li class="chapter" data-level="10.0.6" data-path="pecan-models.html"><a href="pecan-models.html#models-gday"><i class="fa fa-check"></i><b>10.0.6</b> GDAY</a></li>
<li class="chapter" data-level="10.0.7" data-path="pecan-models.html"><a href="pecan-models.html#models-linkages"><i class="fa fa-check"></i><b>10.0.7</b> LINKAGES</a></li>
<li class="chapter" data-level="10.0.8" data-path="pecan-models.html"><a href="pecan-models.html#models-lpjguess"><i class="fa fa-check"></i><b>10.0.8</b> LPJ-GUESS</a></li>
<li class="chapter" data-level="10.0.9" data-path="pecan-models.html"><a href="pecan-models.html#models-maespa"><i class="fa fa-check"></i><b>10.0.9</b> MAESPA</a></li>
<li class="chapter" data-level="10.0.10" data-path="pecan-models.html"><a href="pecan-models.html#models-preles"><i class="fa fa-check"></i><b>10.0.10</b> PRELES</a></li>
<li class="chapter" data-level="10.0.11" data-path="pecan-models.html"><a href="pecan-models.html#models-sipnet"><i class="fa fa-check"></i><b>10.0.11</b> SiPNET</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html"><i class="fa fa-check"></i><b>11</b> Available Meteorological Drivers</a><ul>
<li class="chapter" data-level="11.0.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#ameriflux"><i class="fa fa-check"></i><b>11.0.1</b> Ameriflux</a></li>
<li class="chapter" data-level="11.0.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#amerifluxlbl"><i class="fa fa-check"></i><b>11.0.2</b> AmerifluxLBL</a></li>
<li class="chapter" data-level="11.0.3" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#fluxnet2015"><i class="fa fa-check"></i><b>11.0.3</b> Fluxnet2015</a></li>
<li class="chapter" data-level="11.0.4" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#narr"><i class="fa fa-check"></i><b>11.0.4</b> NARR</a></li>
<li class="chapter" data-level="11.0.5" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#cruncep"><i class="fa fa-check"></i><b>11.0.5</b> CRUNCEP</a></li>
<li class="chapter" data-level="11.0.6" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#cmip5"><i class="fa fa-check"></i><b>11.0.6</b> CMIP5</a></li>
<li class="chapter" data-level="11.0.7" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#nldas"><i class="fa fa-check"></i><b>11.0.7</b> NLDAS</a></li>
<li class="chapter" data-level="11.0.8" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#gldas"><i class="fa fa-check"></i><b>11.0.8</b> GLDAS</a></li>
<li class="chapter" data-level="11.0.9" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#paleon"><i class="fa fa-check"></i><b>11.0.9</b> PalEON</a></li>
<li class="chapter" data-level="11.0.10" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#fluxnetlathuile"><i class="fa fa-check"></i><b>11.0.10</b> FluxnetLaThuile</a></li>
<li class="chapter" data-level="11.0.11" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#geostreams"><i class="fa fa-check"></i><b>11.0.11</b> Geostreams</a></li>
<li class="chapter" data-level="11.0.12" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#download-gfdl"><i class="fa fa-check"></i><b>11.0.12</b> Download GFDL</a></li>
<li class="chapter" data-level="11.0.13" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#cm3"><i class="fa fa-check"></i><b>11.0.13</b> CM3</a></li>
<li class="chapter" data-level="11.0.14" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#esm2m-esm2g"><i class="fa fa-check"></i><b>11.0.14</b> ESM2M &amp; ESM2G</a></li>
<li class="chapter" data-level="11.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#database-synchronization"><i class="fa fa-check"></i><b>11.1</b> Database synchronization</a><ul>
<li class="chapter" data-level="11.1.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#how-does-it-work"><i class="fa fa-check"></i><b>11.1.1</b> How does it work?</a></li>
<li class="chapter" data-level="11.1.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#set-up"><i class="fa fa-check"></i><b>11.1.2</b> Set up</a></li>
<li class="chapter" data-level="11.1.3" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#fetch-latest-data"><i class="fa fa-check"></i><b>11.1.3</b> Fetch latest data</a></li>
<li class="chapter" data-level="11.1.4" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#sharing-data"><i class="fa fa-check"></i><b>11.1.4</b> Sharing data</a></li>
<li class="chapter" data-level="11.1.5" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#automation"><i class="fa fa-check"></i><b>11.1.5</b> Automation</a></li>
<li class="chapter" data-level="11.1.6" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#database-maintentance"><i class="fa fa-check"></i><b>11.1.6</b> Database maintentance</a></li>
<li class="chapter" data-level="11.1.7" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#troubleshooting-3"><i class="fa fa-check"></i><b>11.1.7</b> Troubleshooting</a></li>
<li class="chapter" data-level="11.1.8" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#network-status-map"><i class="fa fa-check"></i><b>11.1.8</b> Network Status Map</a></li>
<li class="chapter" data-level="11.1.9" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#tasks"><i class="fa fa-check"></i><b>11.1.9</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#standalone-tools-modules"><i class="fa fa-check"></i><b>11.2</b> Standalone tools (modules)</a><ul>
<li class="chapter" data-level="11.2.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#LoadData"><i class="fa fa-check"></i><b>11.2.1</b> Loading Data in PEcAn</a></li>
<li class="chapter" data-level="11.2.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#function-load_data"><i class="fa fa-check"></i><b>11.2.2</b> Function <code>load_data</code></a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#using-the-pecan-download.file-function"><i class="fa fa-check"></i><b>11.3</b> Using the PEcAn download.file() function</a></li>
<li class="chapter" data-level="11.4" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#shiny"><i class="fa fa-check"></i><b>11.4</b> SHINY</a><ul>
<li class="chapter" data-level="11.4.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#debugging-shiny-apps"><i class="fa fa-check"></i><b>11.4.1</b> Debugging Shiny Apps</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#debugging"><i class="fa fa-check"></i><b>11.5</b> Debugging</a><ul>
<li class="chapter" data-level="11.5.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#using-testsworkflow.r"><i class="fa fa-check"></i><b>11.5.1</b> Using <code>tests/workflow.R</code></a></li>
<li class="chapter" data-level="11.5.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#useful-scripts"><i class="fa fa-check"></i><b>11.5.2</b> Useful scripts</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#troubleshooting-pecan"><i class="fa fa-check"></i><b>11.6</b> Troubleshooting PEcAn</a><ul>
<li class="chapter" data-level="11.6.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#cookies-and-pecan-web-pages"><i class="fa fa-check"></i><b>11.6.1</b> Cookies and pecan web pages</a></li>
<li class="chapter" data-level="11.6.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#warning-mkdir-function.mkdir-no-such-file-or-directory"><i class="fa fa-check"></i><b>11.6.2</b> <code>Warning: mkdir() [function.mkdir]: No such file or directory</code></a></li>
<li class="chapter" data-level="11.6.3" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#after-creating-a-new-pft-the-tag-for-pft-not-passed-to-config.xml-in-ed"><i class="fa fa-check"></i><b>11.6.3</b> After creating a new PFT the <num> tag for PFT not passed to config.xml in ED</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#pecan-project-use-to-teach-ecological-model-data-synthesis"><i class="fa fa-check"></i><b>11.7</b> PEcAn Project use to teach Ecological model-data synthesis</a><ul>
<li class="chapter" data-level="11.7.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#university-classes"><i class="fa fa-check"></i><b>11.7.1</b> University classes</a></li>
<li class="chapter" data-level="11.7.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#summer-courses-workshops"><i class="fa fa-check"></i><b>11.7.2</b> Summer Courses / Workshops</a></li>
<li class="chapter" data-level="11.7.3" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#selected-publications"><i class="fa fa-check"></i><b>11.7.3</b> Selected Publications</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#rabbitmq"><i class="fa fa-check"></i><b>11.8</b> RabbitMQ</a><ul>
<li class="chapter" data-level="11.8.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#rabbitmq-basics-sender"><i class="fa fa-check"></i><b>11.8.1</b> Producer – <code>sender.py</code></a></li>
<li class="chapter" data-level="11.8.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#rabbitmq-basics-receiver"><i class="fa fa-check"></i><b>11.8.2</b> Consumer – <code>receiver.py</code></a></li>
<li class="chapter" data-level="11.8.3" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#rabbitmq-web"><i class="fa fa-check"></i><b>11.8.3</b> RabbitMQ and the PEcAn web interface</a></li>
<li class="chapter" data-level="11.8.4" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#rabbitmq-xml"><i class="fa fa-check"></i><b>11.8.4</b> RabbitMQ in the PEcAn XML</a></li>
<li class="chapter" data-level="11.8.5" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#rabbitmq-dockerfile"><i class="fa fa-check"></i><b>11.8.5</b> RabbitMQ configuration in Dockerfiles</a></li>
<li class="chapter" data-level="11.8.6" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#rabbitmq-case-study"><i class="fa fa-check"></i><b>11.8.6</b> Case study: PEcAn web interface</a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#database"><i class="fa fa-check"></i><b>11.9</b> BETY Database Administration</a><ul>
<li class="chapter" data-level="11.9.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#database-setup"><i class="fa fa-check"></i><b>11.9.1</b> Best practices</a></li>
<li class="chapter" data-level="11.9.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#backup-of-bety-database"><i class="fa fa-check"></i><b>11.9.2</b> Backup of BETY database</a></li>
<li class="chapter" data-level="11.9.3" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#restore-of-bety-database"><i class="fa fa-check"></i><b>11.9.3</b> Restore of BETY database</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#workflow-modules"><i class="fa fa-check"></i><b>11.10</b> Workflow modules</a><ul>
<li class="chapter" data-level="11.10.1" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#overview"><i class="fa fa-check"></i><b>11.10.1</b> Overview</a></li>
<li class="chapter" data-level="11.10.2" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#load-settings"><i class="fa fa-check"></i><b>11.10.2</b> Load Settings:</a></li>
<li class="chapter" data-level="11.10.3" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#query-database"><i class="fa fa-check"></i><b>11.10.3</b> Query Database:</a></li>
<li class="chapter" data-level="11.10.4" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#meta-analysis"><i class="fa fa-check"></i><b>11.10.4</b> Meta Analysis:</a></li>
<li class="chapter" data-level="11.10.5" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#write-configuration-files"><i class="fa fa-check"></i><b>11.10.5</b> Write Configuration Files</a></li>
<li class="chapter" data-level="11.10.6" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#start-runs"><i class="fa fa-check"></i><b>11.10.6</b> Start Runs:</a></li>
<li class="chapter" data-level="11.10.7" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#get-model-output"><i class="fa fa-check"></i><b>11.10.7</b> Get Model Output</a></li>
<li class="chapter" data-level="11.10.8" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#ensemble-analysis"><i class="fa fa-check"></i><b>11.10.8</b> Ensemble Analysis</a></li>
<li class="chapter" data-level="11.10.9" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#sensitivity-analysis-variance-decomposition"><i class="fa fa-check"></i><b>11.10.9</b> Sensitivity Analysis, Variance Decomposition</a></li>
<li class="chapter" data-level="11.10.10" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#glossary"><i class="fa fa-check"></i><b>11.10.10</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="11.11" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#data-assimilation-with-dart"><i class="fa fa-check"></i><b>11.11</b> Data assimilation with DART</a></li>
</ul></li>
<li class="part"><span><b>IV Appendix</b></span><ul>
<li class="chapter" data-level="11.12" data-path="03_topical_pages/05_data/01_meteorology.html"><a href="#todo"><i class="fa fa-check"></i><b>11.12</b> TODO:</a></li>
<li class="chapter" data-level="11.13" data-path="available-meteorological-drivers.html"><a href="available-meteorological-drivers.html#faq"><i class="fa fa-check"></i><b>11.13</b> FAQ</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Predictive Ecosystem Analyzer</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="available-meteorological-drivers" class="section level1">
<h1><span class="header-section-number">11</span> Available Meteorological Drivers</h1>
<div id="ameriflux" class="section level3">
<h3><span class="header-section-number">11.0.1</span> Ameriflux</h3>
<p>Scale: site</p>
<p>Resolution: 30 or 60 min</p>
<p>Availability: varies by site <a href="http:\/\/ameriflux.lbl.gov\/data\/data-availability\/" class="uri">http:\/\/ameriflux.lbl.gov\/data\/data-availability\/</a></p>
<p>Notes: Old ORNL server, use is deprecated</p>
</div>
<div id="amerifluxlbl" class="section level3">
<h3><span class="header-section-number">11.0.2</span> AmerifluxLBL</h3>
<p>Scale: site</p>
<p>Resolution: 30 or 60 min</p>
<p>Availability: varies by site <a href="http:\/\/ameriflux.lbl.gov\/data\/data-availability\/" class="uri">http:\/\/ameriflux.lbl.gov\/data\/data-availability\/</a></p>
<p>Notes: new Lawrence Berkeley Lab server</p>
</div>
<div id="fluxnet2015" class="section level3">
<h3><span class="header-section-number">11.0.3</span> Fluxnet2015</h3>
<p>Scale: site</p>
<p>Resolution: 30 or 60 min</p>
<p>Availability: varies by site <a href="http://fluxnet.fluxdata.org/sites/site-list-and-pages/">http://fluxnet.fluxdata.org/sites/site-list-and-pages</a></p>
<p>Notes: Fluxnet 2015 synthesis product. Does not cover all FLUXNET sites</p>
</div>
<div id="narr" class="section level3">
<h3><span class="header-section-number">11.0.4</span> NARR</h3>
<p>Scale: North America</p>
<p>Resolution: 3 hr, approx. 32km <span class="math inline">\(Lambert conical projection\)</span></p>
<p>Availability: 1979-present</p>
</div>
<div id="cruncep" class="section level3">
<h3><span class="header-section-number">11.0.5</span> CRUNCEP</h3>
<p>Scale: global</p>
<p>Resolution: 6hr, 0.5 degree</p>
<p>Availability: 1901-2010</p>
</div>
<div id="cmip5" class="section level3">
<h3><span class="header-section-number">11.0.6</span> CMIP5</h3>
<p>Scale: varies by model</p>
<p>Resolution: 3 hr</p>
<p>Availability: 2006-2100</p>
<p>Currently only GFDL available. Different scenerios and ensemble members can be set via Advanced Edit.</p>
</div>
<div id="nldas" class="section level3">
<h3><span class="header-section-number">11.0.7</span> NLDAS</h3>
<p>Scale: Lower 48 + buffer,</p>
<p>Resolution: 1 hour, .125 degree</p>
<p>Availability: 1980-present</p>
</div>
<div id="gldas" class="section level3">
<h3><span class="header-section-number">11.0.8</span> GLDAS</h3>
<p>Scale: Global</p>
<p>Resolution: 3hr, 1 degree</p>
<p>Availability: 1948-2010</p>
</div>
<div id="paleon" class="section level3">
<h3><span class="header-section-number">11.0.9</span> PalEON</h3>
<p>Scale: -100 to -60 W Lon, 35 to 50 N Latitude <span class="math inline">\(US northern hardwoods + buffer\)</span></p>
<p>Resolution: 6hr, 0.5 degree</p>
<p>Availability: 850-2010</p>
</div>
<div id="fluxnetlathuile" class="section level3">
<h3><span class="header-section-number">11.0.10</span> FluxnetLaThuile</h3>
<p>Scale: site</p>
<p>Resolution: 30 or 60 min</p>
<p>Availability: varies by site <a href="http:\/\/www.fluxdata.org\/DataInfo\/Dataset%20Doc%20Lib\/SynthDataSummary.aspx">http:\/\/www.fluxdata.org\/DataInfo\/Dataset%20Doc%20Lib\/SynthDataSummary.aspx</a></p>
<p>Notes: 2007 synthesis. Fluxnet2015 supercedes this for sites that have been updated</p>
</div>
<div id="geostreams" class="section level3">
<h3><span class="header-section-number">11.0.11</span> Geostreams</h3>
<p>Scale: site</p>
<p>Resolution: varies</p>
<p>Availability: varies by site</p>
<p>Notes: This is a protocol, not a single archive. The PEcAn functions currently default to querying [<a href="https://terraref.ncsa.illinois.edu/clowder/api/geostreams" class="uri">https://terraref.ncsa.illinois.edu/clowder/api/geostreams</a>], which requires login and contains data from only two sites (Urbana IL and Maricopa AZ). However the interface can be used with any server that supports the <a href="https://opensource.ncsa.illinois.edu/confluence/display/CATS/Geostreams+API">Geostreams API</a>.</p>

</div>
<div id="download-gfdl" class="section level3">
<h3><span class="header-section-number">11.0.12</span> Download GFDL</h3>
<p>The Downlad.GFDL function assimilates 3 hour frequency CMIP5 outputs generated by multiple GFDL models. GFDL developed several distinct modeling streams on the timescale of CMIP5 and AR5. These models include CM3, ESM2M and ESM2G with a spatial resolution of 2 degrees latitude by 2.5 degrees longitude. Each model has future outputs for the AR5 Representative Concentration Pathways ranging from 2006-2100.</p>
</div>
<div id="cm3" class="section level3">
<h3><span class="header-section-number">11.0.13</span> CM3</h3>
<p>GFDL’s CMIP5 experiments with CM3 included many of the integrations found in the long-term CMIP5 experimental design. The focus of this physical climate model is on the role of aerosols, aerosol-cloud interactions, and atmospheric chemistry in climate variability and climate change.</p>
</div>
<div id="esm2m-esm2g" class="section level3">
<h3><span class="header-section-number">11.0.14</span> ESM2M &amp; ESM2G</h3>
<p>Two new models representing ocean physics with alternative numerical frameworks to explore the implications of some of the fundamental assumptions embedded in these models. Both ESM2M and ESM2G utilize a more advanced land model, LM3, than was available in ESM2.1 including a variety of enhancements (Milly et al., in prep). GFDL’s CMIP5 experiments with Earth System Models included many of the integrations found in the long-term CMIP5 experimental design. The ESMs, by design, close the carbon cycle and are used to study the impact of climate change on ecosystems, ecosystem changes on climate and human activities on ecosystems.</p>
<p>For more information please navigate <a href="https://gfdl.noaa.gov/cmip">here</a></p>
<table width=100%>
<th>
</th>
<th>
CM#
</th>
<th>
ESM2M
</th>
<th>
ESM2G
</th>
<tr>
<td>
rcp26
</td>
<td>
</td>
<td>
r1i1p1
</td>
<td>
r1i1p1
</td>
</tr>
<tr>
<td>
rcp45
</td>
<td>
r1i1p1, r3i1p1,r5i1p1
</td>
<td>
r1i1p1
</td>
<td>
r1i1p1
</td>
</tr>
<tr>
<td>
rcp60
</td>
<td>
</td>
<td>
r1i1p1
</td>
<td>
r1i1p1
</td>
</tr>
<tr>
<td>
rcp85
</td>
<td>
r1i1p1
</td>
<td>
r1i1p1
</td>
<td>
r1i1p1
</td>
</tr>

<div id="pecan-api" class="section level4">
<h4><span class="header-section-number">11.0.14.1</span> The PEcAn Docker API</h4>
<p>If you have a running instance of Dockerized PEcAn (or other setup where PEcAn workflows are submitted via <a href="available-meteorological-drivers.html#rabbitmq">RabbitMQ</a>),
you have the option of running and managing PEcAn workflows using the <code>pecanapi</code> package.</p>
<p>For more details, see the <code>pecanapi</code> <a href="#pecanapi-vignette">package vignette</a> and function-level documentation.
What follows is a lightning introduction.</p>
</div>
<div id="installation" class="section level4">
<h4><span class="header-section-number">11.0.14.2</span> Installation</h4>
<p>The package can be installed directly from GitHub via <code>devtools::install_github</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">devtools<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;pecanproject/pecan/api@develop&quot;</span>)</code></pre>
</div>
<div id="creating-and-submitting-a-workflow" class="section level4">
<h4><span class="header-section-number">11.0.14.3</span> Creating and submitting a workflow</h4>
<p>With <code>pecanapi</code>, creating a workflow, submitting it to RabbitMQ, monitoring its progress, and processing its output can all be accomplished via an R script.</p>
<p>Start by loading the package (and the <code>magrittr</code> package, for the <code>%&gt;%</code> pipe operator).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pecanapi)
<span class="kw">library</span>(magrittr)</code></pre>
<p>Set your PEcAn database user ID, and create a database connection object, which will be used for database operations throughout the workflow.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="dt">pecanapi.user_id =</span> <span class="dv">99000000002</span>)
con &lt;-<span class="st"> </span>DBI<span class="op">::</span><span class="kw">dbConnect</span>(
  RPostgres<span class="op">::</span><span class="kw">Postgres</span>(),
  <span class="dt">user =</span> <span class="st">&quot;bety&quot;</span>,
  <span class="dt">password =</span> <span class="st">&quot;bety&quot;</span>,
  <span class="dt">host =</span> <span class="st">&quot;localhost&quot;</span>,
  <span class="dt">port =</span> <span class="dv">5432</span>
)</code></pre>
<p>Find model and site IDs for the site and model you want to run.</p>
<pre class="sourceCode r"><code class="sourceCode r">model_id &lt;-<span class="st"> </span><span class="kw">get_model_id</span>(con, <span class="st">&quot;SIPNET&quot;</span>, <span class="st">&quot;136&quot;</span>)
all_umbs &lt;-<span class="st"> </span><span class="kw">search_sites</span>(con, <span class="st">&quot;umbs%disturbance&quot;</span>)
site_id &lt;-<span class="st"> </span><span class="kw">subset</span>(all_umbs, <span class="op">!</span><span class="kw">is.na</span>(mat))[[<span class="st">&quot;id&quot;</span>]]</code></pre>
<p>Insert a new workflow into the PEcAn database, and extract its ID.</p>
<pre class="sourceCode r"><code class="sourceCode r">workflow &lt;-<span class="st"> </span><span class="kw">insert_new_workflow</span>(con, site_id, model_id,
                                <span class="dt">start_date =</span> <span class="st">&quot;2004-01-01&quot;</span>,
                                <span class="dt">end_date =</span> <span class="st">&quot;2004-12-31&quot;</span>)
workflow_id &lt;-<span class="st"> </span>workflow[[<span class="st">&quot;id&quot;</span>]]</code></pre>
<p>Pull all of this information together into a settings list object.</p>
<pre class="sourceCode r"><code class="sourceCode r">settings &lt;-<span class="st"> </span><span class="kw">list</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_workflow</span>(workflow) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_database</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_pft</span>(<span class="st">&quot;temperate.deciduous&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_rabbitmq</span>(<span class="dt">con =</span> con) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">modifyList</span>(<span class="kw">list</span>(
    <span class="dt">meta.analysis =</span> <span class="kw">list</span>(<span class="dt">iter =</span> <span class="dv">3000</span>, <span class="dt">random.effects =</span> <span class="ot">FALSE</span>),
    <span class="dt">run =</span> <span class="kw">list</span>(<span class="dt">inputs =</span> <span class="kw">list</span>(<span class="dt">met =</span> <span class="kw">list</span>(<span class="dt">source =</span> <span class="st">&quot;CRUNCEP&quot;</span>, <span class="dt">output =</span> <span class="st">&quot;SIPNET&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;ncss&quot;</span>))),
    <span class="dt">ensemble =</span> <span class="kw">list</span>(<span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">variable =</span> <span class="st">&quot;NPP&quot;</span>)
  ))</code></pre>
<p>Submit the workflow via RabbitMQ, and monitor its progress in the R process.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">submit_workflow</span>(settings)
<span class="kw">watch_workflow</span>(workflow_id)</code></pre>
<p>Use THREDDS to access and analyze the output.</p>
<pre class="sourceCode r"><code class="sourceCode r">sipnet_out &lt;-<span class="st"> </span>ncdf4<span class="op">::</span><span class="kw">nc_open</span>(<span class="kw">run_dap</span>(workflow_id, <span class="st">&quot;2004.nc&quot;</span>))
gpp &lt;-<span class="st"> </span>ncdf4<span class="op">::</span><span class="kw">ncvar_get</span>(sipnet_out, <span class="st">&quot;GPP&quot;</span>)
time &lt;-<span class="st"> </span>ncdf4<span class="op">::</span><span class="kw">ncvar_get</span>(sipnet_out, <span class="st">&quot;time&quot;</span>)
ncdf4<span class="op">::</span><span class="kw">nc_close</span>(sipnet_out)
<span class="kw">plot</span>(time, gpp, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</code></pre>

</div>
</div>
<div id="database-synchronization" class="section level2">
<h2><span class="header-section-number">11.1</span> Database synchronization</h2>
<p>The database synchronization consists of 2 parts:
- Getting the data from the remote servers to your server
- Sharing your data with everybody else</p>
<div id="how-does-it-work" class="section level3">
<h3><span class="header-section-number">11.1.1</span> How does it work?</h3>
<p>Each server that runs the BETY database will have a unique machine_id and a sequence of ID’s associated. Whenever the user creates a new row in BETY it will receive an ID in the sequence. This allows us to uniquely identify where a row came from. This is information is crucial for the code that works with the synchronization since we can now copy those rows that have an ID in the sequence specified. If you have not asked for a unique ID your ID will be 99.</p>
<p>The synchronization code itself is split into two parts, loading data with the <code>load.bety.sh</code> script and exporting data using <code>dump.bety.sh</code>. If you do not plan to share data, you only need to use <code>load.bety.sh</code> to update your database.</p>
</div>
<div id="set-up" class="section level3">
<h3><span class="header-section-number">11.1.2</span> Set up</h3>
<p>Requests for new machine ID’s is currently handled manually. To request a machine ID contact Rob Kooper <a href="mailto:kooper@illinois.edu">kooper@illinois.edu</a>. In the examples below this ID is referred to as ‘my siteid’.</p>
<p>To setup the database to use this ID you need to call load.bety in ‘CREATE’ mode (replacing <my siteid> with the ID if your site)</p>
<pre><code>sudo -u postgres {$PECAN}/scripts/load.bety.sh -c -u -m &lt;my siteid&gt; </code></pre>
<p>WARNING: At the moment running CREATE deletes all current records in the database. If you are running from the VM this includes both all runs you have done and all information that the database is prepopulated with (e.g. input and model records). Remote records can be fetched (see below), but local records will be lost (we’re working on improving this!)</p>
</div>
<div id="fetch-latest-data" class="section level3">
<h3><span class="header-section-number">11.1.3</span> Fetch latest data</h3>
<p>When logged into the machine you can fetch the latest data using the load.bety.sh script. The script will check what site you want to get the data for and will remove all data in the database associated with that id. It will then reinsert all the data from the remote database.</p>
<p>The script is configured using environment variables. The following variables are recognized:
- DATABASE: the database where the script should write the results. The default is <code>bety</code>.
- OWNER: the owner of the database (if it is to be created). The default is <code>bety</code>.
- PG_OPT: additional options to be added to psql (default is nothing).
- MYSITE: the (numerical) ID of your site. If you have not requested an ID, use 99; this is used for all sites that do not want to share their data (i.e. VM). 99 is in fact the default.
- REMOTESITE: the ID of the site you want to fetch the data from. The default is 0 (EBI).
- CREATE: If ‘YES’, this indicates that the existing database (<code>bety</code>, or the one specified by DATABASE) should be removed. Set to YES (in caps) to remove the database. <strong>THIS WILL REMOVE ALL DATA</strong> in DATABASE. The default is NO.
- KEEPTMP: indicates whether the downloaded file should be preserved. Set to YES (in caps) to keep downloaded files; the default is NO.
- USERS: determines if default users should be created. Set to YES (in caps) to create default users with default passwords. The default is NO.</p>
<p>All of these variables can be specified as command line arguments as well, to see the options use -h.</p>
<pre><code>load.bety.sh -h
./scripts/load.bety.sh [-c YES|NO] [-d database] [-h] [-m my siteid] [-o owner] [-p psql options] [-r remote siteid] [-t YES|NO] [-u YES|NO]
 -c create database, THIS WILL ERASE THE CURRENT DATABASE, default is NO
 -d database, default is bety
 -h this help page
 -m site id, default is 99 (VM)
 -o owner of the database, default is bety
 -p additional psql command line options, default is empty
 -r remote site id, default is 0 (EBI)
 -t keep temp folder, default is NO
 -u create carya users, this will create some default users

dump.bety.sh -h
./scripts/dump.bety.sh [-a YES|NO] [-d database] [-h] [-l 0,1,2,3,4] [-m my siteid] [-o folder] [-p psql options] [-u YES|NO]
 -a use anonymous user, default is YES
 -d database, default is bety
 -h this help page
 -l level of data that can be dumped, default is 3
 -m site id, default is 99 (VM)
 -o output folder where dumped data is written, default is dump
 -p additional psql command line options, default is -U bety
 -u should unchecked data be dumped, default is NO</code></pre>
</div>
<div id="sharing-data" class="section level3">
<h3><span class="header-section-number">11.1.4</span> Sharing data</h3>
<p>Sharing your data requires a few steps. First, before entering any data, you will need to request an ID from the PEcAn developers. Simply open an issue at github and we will generate an ID for you. If possible, add the URL of your data host.</p>
<p>You will now need to synchronize the database again and use your ID. For example if you are given ID=42 you can use the following command: <code>MYID=42 REMOTEID=0 ./scripts/load.bety.sh</code>. This will load the EBI database and set the ID’s such that any data you insert will have the right ID.</p>
<p>To share your data you can now run the dump.bey.sh. The script is configured using environment variables, the following variables are recognized:
- DATABASE: the database where the script should write the results. The default is <code>bety</code>.
- PG_OPT: additional options to be added to psql (default is nothing).
- MYSITE: the ID of your site. If you have not requested an ID, use 99, which is used for all sites that do not want to share their data (i.e. VM). 99 is the default.
- LEVEL: the minimum access-protection level of the data to be dumped (0=private, 1=restricted, 2=internal collaborators, 3=external collaborators, 4=public). The default level for exported data is level 3.
- note that currently only the traits and yields tables have restrictions on sharing. If you share data, records from other (meta-data) tables will be shared. If you wish to extend the access_level to other tables please <a href="https://github.com/pecanproject/bety/issues/new">submit a feature request</a>.
- UNCHECKED: specifies whether unchecked traits and yields be dumped. Set to YES (all caps) to dump unchecked data. The default is NO.
- ANONYMOUS: specifies whether all users be anonymized. Set to YES (all caps) to keep the original users (<strong>INCLUDING PASSWORD</strong>) in the dump file. The default is NO.
- OUTPUT: the location of where on disk to write the result file. The default is <code>${PWD}/dump</code>.</p>
<p>NOTE: If you want your dumps to be accessible to other PEcAn servers you need to perform the following additional steps</p>
<ol style="list-style-type: decimal">
<li>Open pecan/scripts/load.bety.sh</li>
<li>In the DUMPURL section of the code add a new record indicating where you are dumping your data. Below is the example for SITE number 1 (Boston University)</li>
</ol>
<pre><code> elif [ &quot;${REMOTESITE}&quot; == &quot;1&quot; ]; then
 DUMPURL=&quot;http://psql-pecan.bu.edu/sync/dump/bety.tar.gz&quot;</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Check your Apache settings to make sure this location is public</li>
<li>Commit this code and submit a Pull Request</li>
<li>From the URL in the Pull Request, PEcAn administrators will update the machines table, the status map, and notify other users to update their cron jobs (see Automation below)</li>
</ol>
<p>Plans to simplify this process are in the works</p>
</div>
<div id="automation" class="section level3">
<h3><span class="header-section-number">11.1.5</span> Automation</h3>
<p>Below is an example of a script to synchronize PEcAn database instances across the network.</p>
<p>db.sync.sh</p>
<pre><code>#!/bin/bash 
## make sure psql is in PATH
export PATH=/usr/pgsql-9.3/bin/:$PATH 
## move to export directory
cd /fs/data3/sync 
## Dump Data
MYSITE=1 /home/dietze/pecan/scripts/dump.bety.sh 
## Load Data from other sites
MYSITE=1 REMOTESITE=2 /home/dietze/pecan/scripts/load.bety.sh 
MYSITE=1 REMOTESITE=5 /home/dietze/pecan/scripts/load.bety.sh 
MYSITE=1 REMOTESITE=0 /home/dietze/pecan/scripts/load.bety.sh 
## Timestamp sync log
echo $(date +%c) &gt;&gt; /home/dietze/db.sync.log</code></pre>
<p>Typically such a script is set up to run as a cron job. Make sure to schedule this job (<code>crontab -e</code>) as the user that has database privileges (typically postgres). The example below is a cron table that runs the sync every hour at 12 min after the hour.</p>
<pre><code>MAILTO=user@yourUniversity.edu
12 * * * * /home/dietze/db.sync.sh</code></pre>
</div>
<div id="database-maintentance" class="section level3">
<h3><span class="header-section-number">11.1.6</span> Database maintentance</h3>
<p>All databases need maintenance performed on them. Depending upon the database type this can happen automatically, or it needs to be run through a scheduler or manually. The BETYdb database is Postgresql and it needs to be reindexed and vacuumed on a regular basis. Reindexing introduces efficiencies back into the database by reorganizing the indexes. Vacuuming the database frees up resources to the database by rearranging and compacting the database. Both of these operations are necessary and safe. As always if there’s a concern, a backup of the database should be made ahead of time. While running the reindexing and vacuuming commands, users will notice a slowdown at times. Therefore it’s better to run these maintenance tasks during off hours.</p>
<div id="reindexing-the-database" class="section level4">
<h4><span class="header-section-number">11.1.6.1</span> Reindexing the database</h4>
<p>As mentioned above, reindexing allows the database to become more efficient. Over time as data gets updated and deleted, the indexes become less efficient. This has a negative inpact on executed statements. Reindexing makes the indexes efficient again (at least for a while) allowing faster statement execution and reducing the overall load on the database.</p>
<p>The reindex.bety.sh script is provided to simplify reindexing the database.</p>
<pre><code>reindex.bety.sh -h
./reindex.bety.sh [-c datalog] [-d database] [-h] [-i table names] [-p psql options] [-q] [-s] [-t tablename]
 -c catalog, database catalog name used to search for tables, default is bety
 -d database, default is bety
 -h this help page
 -i table names, list of space-separated table names to skip over when reindexing
 -p additional psql command line options, default is -U bety
 -q the reindexing should be quiet
 -s reindex the database after reindexing the tables (this should be done sparingly)
 -t tablename, the name of the one table to reindex</code></pre>
<p>If the database is small enough it’s reasonable to reindex the entire database at one time. To do this manually run or schedule the REINDEX statement. For example:</p>
<pre><code>reindex.bety.sh -s</code></pre>
<p>For larger databases it may be desireable to reindex entire tables at a time. An efficient way to do this is to reindex the larger tables and then the entire database. For example:</p>
<pre><code>reindex.bety.sh -t traits; reindex.bety.sh -t yields;
reindex.bety.sh -s</code></pre>
<p>For very large databases it may be desirable to reindex one or more individual indexes before reindexing tables and the databases. In this case running specific psql commands to reindex those specific indexes, followed by reindexing the table is a possible approach. For example:</p>
<pre><code>psql -U bety -c &quot;REINDEX INDEX index_yields_on_citation_id; REINDEX INDEX index_yields_on_cultivar_id;&quot;
reindex.bety.sh -t yields;</code></pre>
<p>Splitting up the indexing commands over time allows the database to operate efficiently with minimal impact on users. One approach is to schedule the reindexing of large, complex tables at a spcific off-time during the week, followed by a general reindexing and excluding those large tables on a weekend night.</p>
<p>Please refere to the Automation section above for information on using cron to schedule reindexing commands.</p>
</div>
<div id="vacuuming-the-database" class="section level4">
<h4><span class="header-section-number">11.1.6.2</span> Vacuuming the database</h4>
<p>Vacuuming the BETYdb Postgresql database reduces the amount of resources it uses and introduces its own efficiencies.</p>
<p>Over time, modified and deleted records leave ‘holes’ in the storage of the database. This is a common feature for most databases. Each database has its own way of handing this, in Postgresql it’s the VACUUM command. The VACUUM command performs two main operations: cleaning up tables to make memory use more efficient, and analyze tables for optimum statement execution. The use of the keyword ANALYZE indicates the second operation should take place.</p>
<p>The vacuum.bety.sh script is provided to simplify vacuuming the database.</p>
<pre><code>vacuum.bety.db -h
./vacuum.bety.sh [-c datalog] [-d database] [-f] [-h] [-i table names] [-n] [-p psql options] [-q] [-s] [-t tablename] [-z]
 -c catalog, database catalog name used to search for tables, default is bety
 -d database, default is bety
 -f perform a full vacuum to return resources to the system. Specify rarely, if ever
 -h this help page
 -i table names, list of space-separated table names to skip over when vacuuming
 -n only vacuum the tables and do not analyze, default is to first vacuum and then analyze
 -p additional psql command line options, default is -U bety
 -q the export should be quiet
 -s skip vacuuming the database after vacuuming the tables
 -t tablename, the name of the one table to vacuum
 -z only perform analyze, do not perform a regular vacuum, overrides -n and -f, sets -s</code></pre>
<p>For small databases with light loads it may be possible to set aside a time for a complete vacuum. During this time, commands executed against the database might fail (a temporary condition as the database gets cleaned up). The following commands can be used to perform all the vaccum operations in one go.</p>
<pre><code>vacuum.bety.sh -f</code></pre>
<p>Generally it’s not desireable to have down time. If the system running the database doesn’t need resources that the database is using returned to it, a FULL vacuum can be avoided. This is the default behavior of the script</p>
<pre><code>vacuum.bety.sh</code></pre>
<p>In larger databases, vacuuming the entire database can take a long time causing a negative impact on users. This means that individual tables need to be vacuumed. How often a vacuum needs to be performed is dependent upon a table’s activity. The more frequently updates and deletes occur on a table, the more frequent the vaccum should be. For large tables it may be desireable to separate the table cleanup from the analysis. An example for completely vacuuming and analyzing a table is:</p>
<pre><code>psql -U bety -c &quot;VACUUM traits; VACUUM ANALYZE traits;&quot;</code></pre>
<p>Similar to indexes, vacuuming the most active tables followed by general database vacuuming and vacuum analyze may be a desireable approach.</p>
<p>Also note that it isn’t necessary to run VACUUM ANALYZE for each vacuum performed. Separating the commands and performing a VACUUM ANALYZE after several regular vacuums may be sufficient, with less load on the database.</p>
<p>If the BETYdb database is running on a system with limited resources, or with resources that have become limited, the VACCUM command can return resources to the system from the database. The normal vacuuming process releases resources back to the database for reuse, but not to the system; generally this isn’t a problem. Postgresql has a VACUUM keyword FULL that returns resources back to the system. Requesting a FULL vacuum will lock the table being vacuumed while it is being re-written preventing any statements from being executed against it. If performing VECUUM FULL against the entire database, only the table being actively worked on is locked.</p>
<p>To minimize the impact a VACUUM FULL has on users, it’s best to perform a normal vacuum before a FULL vacuum. If this approach is taken, there sould be a minimal time gap between the normal VACUUM and the VACUUM FULL commands. A normal vacuum allows changes to be made thus requiring the full vacuum to handle those changes, extending it’s run time. Reducing the time between the two commands lessens the work VACUUM FULL needs to do.</p>
<pre><code>psql -U bety -c &quot;VACUUM yields; VACUUM FULL yields; VACUUM ANALYZE yields;&quot;</code></pre>
<p>Give its impact, it’s typically not desireable to perform a VACUUM FULL after every normal vacuum; it should be done on an “as needed” basis or infrequently.</p>
</div>
</div>
<div id="troubleshooting-3" class="section level3">
<h3><span class="header-section-number">11.1.7</span> Troubleshooting</h3>
<p>There are several possibilities if a scheduled cron job apepars to be running but isn’t producing the expected results. The following are suggestions on what to try to resolve the issue.</p>
<div id="username-and-password" class="section level5">
<h5><span class="header-section-number">11.1.7.0.1</span> Username and password</h5>
<p>The user that scheduled a cron job may not have access permissions to the database. This can be easily confirmed by running the command line from the cron job while logged in as the user that scheduled the job. An error message will be shown if the user doesn’t have permissions.</p>
<p>To resolve this, be sure to include a valid database user (not a BETYdb user) with their credentials on the command in crontab.</p>
</div>
<div id="db_hba.conf-file" class="section level5">
<h5><span class="header-section-number">11.1.7.0.2</span> db_hba.conf file</h5>
<p>Iit’s possible that the machine hosting the docker image of the database doesn’t have permissions to access the database. This may due to the cron job running on a machine that is not the docker instance of the database.</p>
<p>It may be necessary to look at the loga on the hosting machine to determine if database access permissions are causing a problem. Logs are stored in different locations depending upon the Operating System of the host and upon other environmental factors. This document doesn’t provide information on where to find the logs.</p>
<p>To begin, it’s best to look at the contents of the relevent database configuration file. The following command will display the contents of the db_hba.conf file.</p>
<pre><code>psql -U postgres -qAt -c &quot;show hba_file&quot; | xargs grep -v -E &#39;^[[:space:]]*#&#39;</code></pre>
<p>This command should return a series of text lines. For each row except those begining with ‘local’, the fourth item describes the machines that can access the database. In some cases an IP mask is specified in the fifth that further restricts the machines that have access. The special work ‘all’ in the fourth column grants permissions to all machines. The last column on each line contains the authentication option for the machine(s) specified in the fourth column (with a possible fifth column IP mask modifier).</p>
<p>Ensure that the host machine is listed under the fourth column (machine addresse range, or ‘all’), is also included in the IP mask if one was specified, and finally that any authentication option are not set to ‘reject’. If the host machine is not included the db_hba.conf file will need to be updated to allow access.</p>
</div>
</div>
<div id="network-status-map" class="section level3">
<h3><span class="header-section-number">11.1.8</span> Network Status Map</h3>
<p><a href="https://pecan2.bu.edu/pecan/status.php" class="uri">https://pecan2.bu.edu/pecan/status.php</a></p>
<p>Nodes: red = down, yellow = out-of-date schema, green = good</p>
<p>Edges: red = fail, yellow = out-of-date sync, green = good</p>
</div>
<div id="tasks" class="section level3">
<h3><span class="header-section-number">11.1.9</span> Tasks</h3>
<p>Following is a list of tasks we plan on working on to improve these scripts:
- <a href="https://github.com/PecanProject/bety/issues/368">pecanproject/bety#368</a> allow site-specific customization of information and UI elements including title, contacts, logo, color scheme.</p>

</div>
</div>
<div id="standalone-tools-modules" class="section level2">
<h2><span class="header-section-number">11.2</span> Standalone tools (modules)</h2>
<ul>
<li>Radiative transfer modeling and remote sensing (<a href="https://pecanproject.github.io/modules/rtm/docs/index.html"><code>modules/rtm</code></a>); <a href="https://pecanproject.github.io/modules/rtm/docs/articles/pecanrtm.vignette.html">vignette</a></li>
<li>Photosynthesis (<a href="https://pecanproject.github.io/modules/photosynthesis/docs/index.html"><code>modules/photosynthesis</code></a>); <a href="https://pecanproject.github.io/modules/photosynthesis/docs/articles/ResponseCurves.html">vignette</a></li>
<li>Allometry (<a href="https://pecanproject.github.io/modules/allometry/docs/index.html"><code>modules/allometry</code></a>); <a href="https://pecanproject.github.io/modules/allometry/docs/articles/AllomVignette.html">vignette</a></li>
<li>Load data (<a href="https://pecanproject.github.io/modules/benchmark/docs/index.html"><code>modules/benchmark</code></a> – <code>PEcAn.benchmark::load_data</code>)</li>
</ul>
<div id="LoadData" class="section level3">
<h3><span class="header-section-number">11.2.1</span> Loading Data in PEcAn</h3>
<p>If you are loading data in to PEcAn for benchmarking, using the Benchmarking shiny app [provide link?] is recommended.</p>
<p>Data can be loaded manually using the <code>load_data</code> function which in turn requires providing data format information using <code>query.format.vars</code> and the path to the data using <code>query.file.path</code>.</p>
<p>Below is a description of the <code>load_data</code> function an a simple example of loading data manually.</p>
</div>
<div id="function-load_data" class="section level3">
<h3><span class="header-section-number">11.2.2</span> Function <code>load_data</code></h3>
<div id="inputs-2" class="section level4">
<h4><span class="header-section-number">11.2.2.1</span> Inputs</h4>
<p>Required</p>
<ul>
<li><code>data.path</code>: path to the data that is the output of the function <code>query.file.path</code> (see example below)</li>
<li><code>format</code>: R list object that is the output of the function <code>query.format.vars</code> (see example below)</li>
</ul>
<p>Optional</p>
<ul>
<li><code>start_year = NA</code>:</li>
<li><code>end_year = NA</code>:</li>
<li><code>site = NA</code></li>
<li><p><code>vars.used.index=NULL</code>
### Output</p></li>
<li><p>R data frame containing the requested variables converted in to PEcAn standard name and units and time steps in <code>POSIX</code> format.</p></li>
</ul>
</div>
<div id="example-1" class="section level4">
<h4><span class="header-section-number">11.2.2.2</span> Example</h4>
<p>The data for this example has already been entered in to the database. To add new data go to <a href="user-section.html#NewInput">new data documentation</a>.</p>
<p>To load the Ameriflux data for the Harvard Forest (US-Ha1) site.</p>
<ol style="list-style-type: decimal">
<li>Create a connection to the BETY database. This can be done using R function</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">bety =<span class="st"> </span>PEcAn.DB<span class="op">::</span><span class="kw">betyConnect</span>(<span class="dt">php.config =</span> <span class="st">&quot;pecan/web/config.php&quot;</span>)</code></pre>
<p>where the complete path to the <code>config.php</code> is specified. See <a href="https://github.com/PecanProject/pecan/blob/master/web/config.example.php">here</a> for an example <code>config.php</code> file.</p>
<ol start="2" style="list-style-type: decimal">
<li>Look up the inputs record for the data in BETY.</li>
</ol>
<p><img src="04_advanced_user_guide/images/Input_ID_name.png" width="50%" height="50%" style="display: block; margin: auto;" /></p>
<p>To find the input ID, either look at</p>
<ul>
<li><p>The url of the record (see image above)</p>
<ul>
<li>In R run</li>
</ul></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
input_name =<span class="st"> &quot;AmerifluxLBL_site_0-758&quot;</span> <span class="co">#copied directly from online</span>
input.id =<span class="st"> </span><span class="kw">tbl</span>(bety,<span class="st">&quot;inputs&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(name <span class="op">==</span><span class="st"> </span>input_name) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(id)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>Additional arguments to <code>query.format.vars</code> are optional</p>
<ol style="list-style-type: decimal">
<li>If you only want to load a subset of dates in the data, specify start and end year, otherwise all data will be loaded.</li>
<li>If you only want to load a select list of variables from the data, look up their IDs in BETY, otherwise all variables will be loaded.</li>
</ol></li>
<li><p>In R run</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">   format =<span class="st"> </span>PEcAn.DB<span class="op">::</span><span class="kw">query.format.vars</span>(bety, input.id)</code></pre>
<p>Examine the resulting R list object to make sure it returned the correct information.</p>
<p>The example format contains the following objects:</p>
<pre class="sourceCode r"><code class="sourceCode r">   <span class="op">$</span>file_name
   [<span class="dv">1</span>] <span class="st">&quot;AMERIFLUX_BASE_HH&quot;</span>

   <span class="op">$</span>mimetype
   [<span class="dv">1</span>] <span class="st">&quot;csv&quot;</span>

   <span class="op">$</span>skip
   [<span class="dv">1</span>] <span class="dv">2</span>

   <span class="op">$</span>header
   [<span class="dv">1</span>] <span class="dv">1</span>

   <span class="op">$</span>na.strings
   [<span class="dv">1</span>] <span class="st">&quot;-9999&quot;</span> <span class="st">&quot;-6999&quot;</span> <span class="st">&quot;9999&quot;</span>  <span class="st">&quot;NA&quot;</span>   

   <span class="op">$</span>time.row
   [<span class="dv">1</span>] <span class="dv">4</span>

   <span class="op">$</span>site
   [<span class="dv">1</span>] <span class="dv">758</span>

   <span class="op">$</span>lat
   [<span class="dv">1</span>] <span class="fl">42.5378</span>

   <span class="op">$</span>lon
   [<span class="dv">1</span>] <span class="fl">-72.1715</span>

   <span class="op">$</span>time_zone
   [<span class="dv">1</span>] <span class="st">&quot;America/New_York&quot;</span></code></pre>
<p>The first 4 rows of the table <code>format$vars</code> looks like this:</p>
<table style="width:100%;">
<colgroup>
<col width="9%" />
<col width="8%" />
<col width="11%" />
<col width="8%" />
<col width="9%" />
<col width="9%" />
<col width="7%" />
<col width="8%" />
<col width="10%" />
<col width="7%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th>bety_name</th>
<th>variable_id</th>
<th>input_name</th>
<th>input_units</th>
<th>storage_type</th>
<th>column_number</th>
<th>bety_units</th>
<th>mstmip_name</th>
<th>mstmip_units</th>
<th>pecan_name</th>
<th>pecan_units</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>air_pressure</td>
<td>554</td>
<td>PA</td>
<td>kPa</td>
<td></td>
<td>19</td>
<td>Pa</td>
<td>Psurf</td>
<td>Pa</td>
<td>Psurf</td>
<td>Pa</td>
</tr>
<tr class="even">
<td>airT</td>
<td>86</td>
<td>TA</td>
<td>celsius</td>
<td></td>
<td>4</td>
<td>degrees C</td>
<td>Tair</td>
<td>K</td>
<td>Tair</td>
<td>K</td>
</tr>
<tr class="odd">
<td>co2atm</td>
<td>135</td>
<td>CO2_1</td>
<td>umol mol-1</td>
<td></td>
<td>20</td>
<td>umol mol-1</td>
<td>CO2air</td>
<td>micromol mol-1</td>
<td>CO2air</td>
<td>micromol mol-1</td>
</tr>
<tr class="even">
<td>datetime</td>
<td>5000000001</td>
<td>TIMESTAMP_START</td>
<td>ymd_hms</td>
<td>%Y%m%d%H%M</td>
<td>1</td>
<td>ymd_hms</td>
<td>NA</td>
<td>NA</td>
<td>datetime</td>
<td>ymd_hms</td>
</tr>
</tbody>
</table>
<ol start="5" style="list-style-type: decimal">
<li>Get the path to the data</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">   data.path =<span class="st"> </span>PEcAn.DB<span class="op">::</span><span class="kw">query.file.path</span>(
     <span class="dt">input.id =</span> input.id, 
     <span class="dt">host_name =</span> PEcAn.remote<span class="op">::</span><span class="kw">fqdn</span>(), 
     <span class="dt">con =</span> bety<span class="op">$</span>con)</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>Load the data</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">   data =<span class="st"> </span>PEcAn.benchmark<span class="op">::</span><span class="kw">load_data</span>(<span class="dt">data.path =</span> data.path, <span class="dt">format =</span> format)</code></pre>

</div>
</div>
</div>
<div id="using-the-pecan-download.file-function" class="section level2">
<h2><span class="header-section-number">11.3</span> Using the PEcAn download.file() function</h2>
<p>download.file(url, destination_file, method) <br>
<br></p>
<p>This custom PEcAn function works together with the base R function download.file (<a href="https://stat.ethz.ch/R-manual/R-devel/library/utils/html/download.file.html" class="uri">https://stat.ethz.ch/R-manual/R-devel/library/utils/html/download.file.html</a>). However, it provides expanded functionality to generalize the use for a broad range of environments. This is because some computing environments are behind a firewall or proxy, including FTP firewalls. This may require the use of a custom FTP program and/or initial proxy server authentication to retrieve the files needed by PEcAn (e.g. meteorology drivers, other inputs) to run certain model simulations or tools. For example, the Brookhaven National Laboratory (BNL) requires an initial connection to a FTP proxy before downloading files via FTP protocol. As a result, the computers running PEcAn behind the BNL firewall (e.g. <a href="https://modex.bnl.gov" class="uri">https://modex.bnl.gov</a>) use the ncftp cleint (<a href="http://www.ncftp.com/" class="uri">http://www.ncftp.com/</a>) to download files for PEcAn because the base options with R::base download.file() such as curl, libcurl which don’t have the functionality to provide credentials for a proxy or even those such as wget which do but don’t easily allow for connecting through a proxy server before downloading files. The current option for use in these instances is <strong>ncftp</strong>, specifically <strong>ncftpget</strong></p>
<p><br></p>
<p>Examples: <br>
<em>HTTP</em> <br></p>
<pre><code>download.file(&quot;http://lib.stat.cmu.edu/datasets/csb/ch11b.txt&quot;,&quot;~/test.download.txt&quot;) </code></pre>
<p><em>FTP</em></p>
<pre><code>download.file(&quot;ftp://ftp.cdc.noaa.gov/Datasets/NARR/monolevel/pres.sfc.2000.nc&quot;, &quot;~/pres.sfc.2000.nc&quot;)</code></pre>
<p><em>customizing to use ncftp when running behind an FTP firewall (requires ncftp to be installed and availible)</em> <br></p>
<pre><code>download.file(&quot;ftp://ftp.cdc.noaa.gov/Datasets/NARR/monolevel/pres.sfc.2000.nc&quot;, &quot;~/pres.sfc.2000.nc&quot;, method=&quot;&quot;ncftpget&quot;)</code></pre>
<p><br></p>
<p>On modex.bnl.gov, the ncftp firewall configuration file (e.g. ~/.ncftp/firewall) is configured as:
firewall-type=1
firewall-host=ftpgateway.sec.bnl.local
firewall-port=21</p>
<p>which then allows for direct connection through the firewall using a command like:</p>
<pre><code>ncftpget ftp://ftp.unidata.ucar.edu/pub/netcdf/netcdf-fortran-4.4.4.tar.gz</code></pre>
<p>To allow the use of ncftpget from within the download.file() function you need to set your R profile download.ftp.method option in your options list. To see your current R options run options() from R cmd, which should look something like this:</p>
<pre><code>&gt; options()
$add.smooth
[1] TRUE

$bitmapType
[1] &quot;cairo&quot;

$browser
[1] &quot;/usr/bin/xdg-open&quot;

$browserNLdisabled
[1] FALSE

$CBoundsCheck
[1] FALSE

$check.bounds
[1] FALSE

$citation.bibtex.max
[1] 1

$continue
[1] &quot;+ &quot;

$contrasts
        unordered           ordered
&quot;contr.treatment&quot;      &quot;contr.poly&quot;</code></pre>
<p>In order to set your download.ftp.method option you need to add a line such as</p>
<pre><code># set default FTP
options(download.ftp.method = &quot;ncftpget&quot;)</code></pre>
<p>In your ~/.Rprofile. On modex at BNL we have set the global option in /usr/lib64/R/etc/Rprofile.site.</p>
<p>Once this is done you should be able to see the option set using this command in R:</p>
<pre><code>&gt; options(&quot;download.ftp.method&quot;)
$download.ftp.method
[1] &quot;ncftpget&quot;</code></pre>

</div>
<div id="shiny" class="section level2">
<h2><span class="header-section-number">11.4</span> SHINY</h2>
<div id="debugging-shiny-apps" class="section level3">
<h3><span class="header-section-number">11.4.1</span> Debugging Shiny Apps</h3>
<p>When developing shiny apps you can run the application from rstudio and place breakpoints int he code. To do this you will need to do the following steps first (already done on the VM) before starting rstudio:
- echo “options(shiny.port = 6438)” &gt;&gt; ${HOME}/.Rprofile
- echo “options(shiny.launch.browser = ‘FALSE’)” &gt;&gt; ${HOME}/.Rprofile</p>
<p>Next you will need to create a tunnel for port 6438 to the VM, which will be used to open the shiny app, the following command will creat this tunnel: <code>ssh -l carya -p 6422 -L 6438:localhost:6438 localhost</code>.</p>
<p>Now you can from rstudio run your application using <code>shiny::runApp()</code> and it will show the output from the application in your console. You can now place breakpoints and evaluate the output.</p>
<div id="checking-log-files" class="section level4">
<h4><span class="header-section-number">11.4.1.1</span> Checking Log Files</h4>
<p>To create Log files on the VM, execute the following:</p>
<pre><code>sudo -s
echo &quot;preserve_logs true;&quot; &gt;&gt; /etc/shiny-server/shiny-server.conf
service shiny-server restart</code></pre>
<p>Then within the directory <code>/var/log/shiny-server</code> you will see log files for your specific shiny apps.</p>

</div>
</div>
</div>
<div id="debugging" class="section level2">
<h2><span class="header-section-number">11.5</span> Debugging</h2>
<p>How to identify the source of a problem.</p>
<div id="using-testsworkflow.r" class="section level3">
<h3><span class="header-section-number">11.5.1</span> Using <code>tests/workflow.R</code></h3>
<p>This script, along with model-specific settings files in the <code>tests</code> folder, provide a working example. From inside the tests folder, <code>R CMD --vanilla -- --settings pecan.&lt;model&gt;.xml &lt; workflow.R</code> should work.</p>
<p>The next step is to add <code>debugonce(&lt;broken.function.name&gt;)</code> before running the test workflow.</p>
<p>This allows you can step through the function and evaluate the different objects as they are created and/or transformed.</p>
<p>See <a href="https://github.com/PecanProject/pecan/blob/master/tests/README.md">tests README</a> for more information.</p>
</div>
<div id="useful-scripts" class="section level3">
<h3><span class="header-section-number">11.5.2</span> Useful scripts</h3>
<p>The following scripts (in <code>qaqc/vignettes</code> identify, respectively:</p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/PecanProject/pecan/blob/master/qaqc/vignettes/function_relationships.Rmd">relationships among functions across packages</a></li>
<li><a href="https://github.com/PecanProject/pecan/blob/master/qaqc/vignettes/module_output.Rmd">function inputs and outputs</a> (e.g. that will identify which functions and outputs are used in a workflow).</li>
</ol>

</div>
</div>
<div id="troubleshooting-pecan" class="section level2">
<h2><span class="header-section-number">11.6</span> Troubleshooting PEcAn</h2>
<div id="cookies-and-pecan-web-pages" class="section level3">
<h3><span class="header-section-number">11.6.1</span> Cookies and pecan web pages</h3>
<p>You may need to disable cookies specifically for the pecan webserver in your browser. This shouldn’t be a problem running from the virtual machine, but your installation of php can include a ‘PHPSESSID’ that is quite long, and this can overflow the params field of the workflows table, depending on how long your hostname, model name, site name, etc are.</p>
</div>
<div id="warning-mkdir-function.mkdir-no-such-file-or-directory" class="section level3">
<h3><span class="header-section-number">11.6.2</span> <code>Warning: mkdir() [function.mkdir]: No such file or directory</code></h3>
<p>If you are seeing: <code>Warning: mkdir() [function.mkdir]: No such file or directory in /path/to/pecan/web/runpecan.php at line 169</code> it is because you have used a relative path for $output_folder in system.php.</p>
</div>
<div id="after-creating-a-new-pft-the-tag-for-pft-not-passed-to-config.xml-in-ed" class="section level3">
<h3><span class="header-section-number">11.6.3</span> After creating a new PFT the <num> tag for PFT not passed to config.xml in ED</h3>
<p>This is a result of the rather clunky way we currently have adding PFTs to PEcAn. This is happening because you need to edit the ./pecan/models/ed/data/pftmapping.csv file to include your new PFTs.</p>
<p>This is what the file looks like:</p>
<pre><code>PEcAn;ED
ebifarm.acru;11
ebifarm.acsa3;11
...</code></pre>
<p>You just need to edit this file (in a text editor, no Excel) and add your PFT names and associated number to the end of the file. Once you do this, recompile PEcAn and it should then work for you. We currently need to reference this file in order to properly set the PFT number and maintain internal consistency between PEcAn and ED2.</p>

</div>
</div>
<div id="pecan-project-use-to-teach-ecological-model-data-synthesis" class="section level2">
<h2><span class="header-section-number">11.7</span> PEcAn Project use to teach Ecological model-data synthesis</h2>
<div id="university-classes" class="section level3">
<h3><span class="header-section-number">11.7.1</span> University classes</h3>
<div id="ge-375---environmental-modeling---spring-2013-2014-mike-dietze-boston-university" class="section level4">
<h4><span class="header-section-number">11.7.1.1</span> GE 375 - Environmental Modeling - Spring 2013, 2014 (Mike Dietze, Boston University)</h4>
<p>The final “Case Study: Terrestrial Ecosystem Models” is a PEcAn-based hands-on activity. Each class has been 25 students.</p>
<p>GE 585 - Ecological forecasting Fall 2013 (Mike Dietze, Boston University)</p>
</div>
</div>
<div id="summer-courses-workshops" class="section level3">
<h3><span class="header-section-number">11.7.2</span> Summer Courses / Workshops</h3>
<div id="annual-summer-course-in-flux-measurement-and-advanced-modeling-mike-dietze-ankur-desai-niwot-ridge-co" class="section level4">
<h4><span class="header-section-number">11.7.2.1</span> Annual summer course in flux measurement and advanced modeling (Mike Dietze, Ankur Desai) Niwot Ridge, CO</h4>
<p>About 1/3 lecture, 2/3 hands-on (the syllabus is actually wrong as it list the other way around). Each class has 24 students.</p>
<p><a href="http://www.fluxcourse.org/files/SyllabusFluxcourse_2013.pdf">2013 Syllabus</a> see Tuesday Week 2 Data Assimilation lectures and PEcAn demo and the Class projects and presentations on Thursday and Friday. (Most students use PEcAn for their group projects. 2014 will be the third year that PEcAn has been used for this course.</p>
</div>
<div id="assimilating-long-term-data-into-ecosystem-models-paleo-ecological-observatory-network-paleon-project" class="section level4">
<h4><span class="header-section-number">11.7.2.2</span> Assimilating Long-Term Data into Ecosystem Models: Paleo-Ecological Observatory Network (PalEON) Project</h4>
<p>Here is a link to the course: <a href="https://www3.nd.edu/~paleolab/paleonproject/summer-course/" class="uri">https://www3.nd.edu/~paleolab/paleonproject/summer-course/</a></p>
<p>This course uses the same demo as above, including collecting data in the field and assimilating it (part 3)</p>
</div>
<div id="integrating-evidence-on-forest-response-to-climate-change-physiology-to-regional-abundance" class="section level4">
<h4><span class="header-section-number">11.7.2.3</span> Integrating Evidence on Forest Response to Climate Change: Physiology to Regional Abundance</h4>
<p><a href="http://blue.for.msu.edu/macrosystems/workshop" class="uri">http://blue.for.msu.edu/macrosystems/workshop</a></p>
<p>May 13-14, 2013</p>
<p>Session 4: Integrating Forest Data Into Ecosystem Models</p>
</div>
<div id="ecological-society-of-america-meetings" class="section level4">
<h4><span class="header-section-number">11.7.2.4</span> Ecological Society of America meetings</h4>
<p><a href="http://eco.confex.com/eco/2013/webprogram/Session9007.html">Workshop: Combining Field Measurements and Ecosystem Models</a></p>
</div>
</div>
<div id="selected-publications" class="section level3">
<h3><span class="header-section-number">11.7.3</span> Selected Publications</h3>
<ol style="list-style-type: decimal">
<li>Dietze, M.C., D.S LeBauer, R. Kooper (2013) <a href="https://github.com/PecanProject/pecan/blob/master/documentation/dietze2013oic.pdf?raw=true">On improving the communication between models and data</a>. Plant, Cell, &amp; Environment <a href="doi:10.1111/pce.12043" class="uri">doi:10.1111/pce.12043</a></li>
<li>LeBauer, D.S., D. Wang, K. Richter, C. Davidson, &amp; M.C. Dietze. (2013). <a href="https://github.com/PecanProject/pecan/blob/master/documentation/lebauer2013ffb.pdf?raw=true">Facilitating feedbacks between field measurements and ecosystem models</a>. Ecological Monographs. <a href="doi:10.1890/12-0137.1" class="uri">doi:10.1890/12-0137.1</a></li>
</ol>

</div>
</div>
<div id="rabbitmq" class="section level2">
<h2><span class="header-section-number">11.8</span> RabbitMQ</h2>
<p>This section provides additional details about how PEcAn uses RabbitMQ to manage communication between its Docker containers.</p>
<p>In PEcAn, we use the Python <a href="http://www.rabbitmq.com/tutorials/tutorial-one-python.html"><code>pika</code></a> client to post and retrieve messages from RabbitMQ.
As such, every Docker container that communicates with RabbitMQ contains two Python scripts: <code>sender.py</code> and <code>reciever.py</code>.
Both are located in the <code>docker</code> directory in the PEcAn source code root.</p>
<div id="rabbitmq-basics-sender" class="section level3">
<h3><span class="header-section-number">11.8.1</span> Producer – <code>sender.py</code></h3>
<p>The <code>sender.py</code> script is in charge of posting messages to RabbitMQ.
In the RabbitMQ documentation, it is known as a “producer”.
It runs once for every message posted to RabbitMQ, and then immediately exits (unlike the <code>receiver.py</code>, which runs continuously – see <a href="available-meteorological-drivers.html#rabbitmq-basics-receiver">below</a>).</p>
<p>Its usage is as follows:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">python3</span> sender.py <span class="op">&lt;</span>URI<span class="op">&gt;</span> <span class="op">&lt;</span>queue<span class="op">&gt;</span> <span class="op">&lt;</span>message<span class="op">&gt;</span></code></pre>
<p>The arguments are:</p>
<ul>
<li><p><code>&lt;URI&gt;</code> – The unique identifier of the RabbitMQ instance, similar to a URL.
The format is <code>amqp://username:password@host/vhost</code>.
By default, this is <code>amqp://guest:guest@rabbitmq/%2F</code> (the <code>%2F</code> here is the hexadecimal encoding for the <code>/</code> character).</p></li>
<li><p><code>&lt;queue&gt;</code> – The name of the queue on which to post the message.</p></li>
<li><p><code>&lt;message&gt;</code> – The contents of the message to post, in JSON format.
A typical message posted by PEcAn looks like the following:</p>
<pre class="sourceCode json"><code class="sourceCode json"><span class="fu">{</span> <span class="dt">&quot;folder&quot;</span> <span class="fu">:</span> <span class="st">&quot;/path/to/PEcAn_WORKFLOWID&quot;</span><span class="fu">,</span> <span class="dt">&quot;workflow&quot;</span> <span class="fu">:</span> <span class="st">&quot;WORKFLOWID&quot;</span> <span class="fu">}</span></code></pre></li>
</ul>
<p>The <code>PEcAn.remote::start_rabbitmq</code> function is a wrapper for this script that provides an easy way to post a <code>folder</code> message to RabbitMQ from R.</p>
</div>
<div id="rabbitmq-basics-receiver" class="section level3">
<h3><span class="header-section-number">11.8.2</span> Consumer – <code>receiver.py</code></h3>
<p>Unlike <code>sender.py</code>, <code>receiver.py</code> runs like a daemon, constantly listening for messages.
In the RabbitMQ documentation, it is known as a “consumer”.
In PEcAn, you can tell that it is ready to receive messages if the corresponding logs (e.g. <code>docker-compose logs executor</code>) show the following message:</p>
<pre><code>[*] Waiting for messages. To exit press CTRL+C.</code></pre>
<p>Our <code>reciever</code> is configured by three environment variables:</p>
<ul>
<li><p><code>RABBITMQ_URI</code> – This defines the URI where RabbitMQ is running.
See corresponding argument in the <a href="available-meteorological-drivers.html#rabbitmq-basics-sender">producer</a></p></li>
<li><p><code>RABBITMQ_QUEUE</code> – This is the name of the queue on which the consumer will listen for messages, just as in the <a href="available-meteorological-drivers.html#rabbitmq-basics-sender">producer</a>.</p></li>
<li><p><code>APPLICATION</code> – This specifies the name (including the path) of the default executable to run when receiving a message.
At the moment, it should be an executable that runs in the directory specified by the message’s <code>folder</code> variable.
In the case of PEcAn models, this is usually <code>./job.sh</code>, such that the <code>folder</code> corresponds to the <code>run</code> directory associated with a particular <code>runID</code> (i.e. where the <code>job.sh</code> is located).
For the PEcAn workflow itself, this is set to <code>R CMD BATCH workflow.R</code>, such that the <code>folder</code> is the root directory of the workflow (in the <code>executor</code> Docker container, something like <code>/data/workflows/PEcAn_&lt;workflowID&gt;</code>).
This default executable is <em>overridden</em> if the message contains a <code>custom_application</code> key.
If included, the string specified by the <code>custom_application</code> key will be run as a command exactly as is on the container, from the directory specified by <code>folder</code>.
For instance, in the example below, the container will print “Hello there!” instead of running its default application.</p>
<pre class="sourceCode json"><code class="sourceCode json"><span class="fu">{</span><span class="dt">&quot;custom_application&quot;</span><span class="fu">:</span> <span class="st">&quot;echo &#39;Hello there!&#39;&quot;</span><span class="fu">,</span> <span class="dt">&quot;folder&quot;</span><span class="fu">:</span> <span class="st">&quot;/path/to/my/dir&quot;</span><span class="fu">}</span></code></pre>
<p>NOTE that in RabbitMQ messages, the <code>folder</code> key is always required.</p></li>
</ul>
</div>
<div id="rabbitmq-web" class="section level3">
<h3><span class="header-section-number">11.8.3</span> RabbitMQ and the PEcAn web interface</h3>
<p>RabbitMQ is configured by the following variables in <code>config.php</code>:</p>
<ul>
<li><code>$rabbitmq_host</code> – The RabbitMQ server hostname (default: <code>rabbitmq</code>, because that is the name of the <code>rabbitmq</code> service in <code>docker-compose.yml</code>)</li>
<li><code>$rabbitmq_port</code> – The port on which RabbitMQ listens for messages (default: 5672)</li>
<li><code>$rabbitmq_vhost</code> – The path of the RabbitMQ <a href="https://www.rabbitmq.com/vhosts.html">Virtual Host</a> (default: <code>/</code>).</li>
<li><code>$rabbitmq_queue</code> – The name of the RabbitMQ queue associated with the PEcAn workflow (default: <code>pecan</code>)</li>
<li><code>$rabbitmq_username</code> – The RabbitMQ username (default: <code>guest</code>)</li>
<li><code>$rabbitmq_password</code> – The RabbitMQ password (default: <code>guest</code>)</li>
</ul>
<p>In addition, for running models via RabbitMQ, you will also need to add an entry like the following to the <code>config.php</code> <code>$hostlist</code>:</p>
<pre class="sourceCode php"><code class="sourceCode php"><span class="kw">$hostlist</span>=<span class="kw">array</span><span class="ot">(</span><span class="kw">$fqdn</span> =&gt; <span class="kw">array</span><span class="ot">(</span><span class="st">&quot;rabbitmq&quot;</span> =&gt; <span class="st">&quot;amqp://guest:guest@rabbitmq/%2F&quot;</span><span class="ot">),</span> <span class="st">...</span><span class="ot">)</span></code></pre>
<p>This will set the hostname to the name of the current machine (defined by the <code>$fqdn</code> variable earlier in the <code>config.php</code> file) to an array with one entry, whose key is <code>rabbitmq</code> and whose value is the RabbitMQ URI (<code>amqp://...</code>).</p>
<p>These values are converted into the appropriate entries in the <code>pecan.xml</code> in <code>web/04-runpecan.php</code>.</p>
</div>
<div id="rabbitmq-xml" class="section level3">
<h3><span class="header-section-number">11.8.4</span> RabbitMQ in the PEcAn XML</h3>
<p>RabbitMQ is a special case of remote execution, so it is configured by the <code>host</code> node.
An example RabbitMQ configuration is as follows:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;host&gt;</span>
  <span class="kw">&lt;rabbitmq&gt;</span>
    <span class="kw">&lt;uri&gt;</span>amqp://guest:guest@rabbitmq/%2F<span class="kw">&lt;/uri&gt;</span>
    <span class="kw">&lt;queue&gt;</span>sipnet_136<span class="kw">&lt;/queue&gt;</span>
  <span class="kw">&lt;/rabbitmq&gt;</span>
<span class="kw">&lt;/host&gt;</span></code></pre>
<p>Here, <code>uri</code> and <code>queue</code> have the same general meanings as described in <a href="available-meteorological-drivers.html#rabbitmq-basics-sender">“producer”</a>.
Note that <code>queue</code> here refers to the target model.
In PEcAn, RabbitMQ model queues are named as <code>MODELTYPE_REVISION</code>,
so the example above refers to the SIPNET model version 136.
Another example is <code>ED2_git</code>, referring to the latest <code>git</code> version of the ED2 model.</p>
</div>
<div id="rabbitmq-dockerfile" class="section level3">
<h3><span class="header-section-number">11.8.5</span> RabbitMQ configuration in Dockerfiles</h3>
<p>As described in the <a href="available-meteorological-drivers.html#rabbitmq-basics-receiver">“consumer”</a> section, our standard RabbitMQ receiver script is configured using three environment variables: <code>RABBITMQ_URI</code>, <code>RABBITMQ_QUEUE</code>, and <code>APPLICATION</code>.
Therefore, configuring a container to work with PEcAn’s RabbitMQ instance requires setting these three variables in the Dockerfile using an <a href="https://docs.docker.com/engine/reference/builder/#env"><code>ENV</code></a> statement.</p>
<p>For example, this excerpt from <code>docker/base/Dockerfile.executor</code> (for the <code>pecan/executor</code> image responsible for the PEcAn workflow) sets these variables as follows:</p>
<pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span class="kw">ENV</span> RABBITMQ_URI=<span class="st">&quot;amqp://guest:guest@rabbitmq/%2F&quot;</span> \
    RABBITMQ_QUEUE=<span class="st">&quot;pecan&quot;</span> \
    APPLICATION=<span class="st">&quot;R CMD BATCH workflow.R&quot;</span></code></pre>
<p>Similarly, this excerpt from <code>docker/models/Dockerfile.sipnet</code> (which builds the SIPNET model image) is a typical example for a model image.
Note the use of <a href="https://docs.docker.com/engine/reference/builder/#arg"><code>ARG</code></a> here to specify a default version model version of 136 while allowing this to be configurable (via <code>--build-arg MODEL_VERSION=X</code>) at build time:</p>
<pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span class="kw">ARG</span> MODEL_VERSION=136

<span class="kw">ENV</span> APPLICATION=<span class="st">&quot;./job.sh&quot;</span> \
    MODEL_TYPE=<span class="st">&quot;SIPNET&quot;</span> \
    MODEL_VERSION=<span class="st">&quot;${MODEL_VERSION}&quot;</span>

<span class="kw">ENV</span> RABBITMQ_QUEUE=<span class="st">&quot;${MODEL_TYPE}_${MODEL_VERSION}&quot;</span></code></pre>
<p><strong>WARNING</strong>: Dockerfile environment variables set via <code>ENV</code> are assigned <em>all at once</em>; <em>they do not evaluate successively, left to right</em>.
Consider the following block:</p>
<pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span class="co"># Don&#39;t do this!</span>
<span class="kw">ENV</span> MODEL_TYPE=<span class="st">&quot;SIPNET&quot;</span> \
    MODEL_VERSION=136 \
    RABBITMQ_QUEUE=${MODEL_TYPE}_${MODEL_VERSION}   <span class="co"># &lt;- Doesn&#39;t know about MODEL_TYPE or MODEL_VERSION!</span></code></pre>
<p>In this block, the expansion for setting <code>RABBITMQ_QUEUE</code> <em>is not aware</em> of the current values of <code>MODEL_TYPE</code> or <code>MODEL_VERSION</code>, and will therefore be set incorrectly to just <code>_</code> (unless they have been set previously, in which case it will be aware only of their earlier values).
As such, <strong>variables depending on other variables must be set in a separate, subsequent <code>ENV</code> statement than the variables they depend on</strong>.</p>
</div>
<div id="rabbitmq-case-study" class="section level3">
<h3><span class="header-section-number">11.8.6</span> Case study: PEcAn web interface</h3>
<p>The following describes in general terms what happens during a typical run of the PEcAn web interface with RabbitMQ.</p>
<ol style="list-style-type: decimal">
<li><p>The user initializes all containers with <code>docker-compose up</code>.
All the services that interact with RabbitMQ (<code>executor</code> and all models) run <code>receiver.py</code> in the foreground, waiting for messages to tell them what to do.</p></li>
<li><p>The user browses to <a href="http://localhost:8000/pecan/" class="uri">http://localhost:8000/pecan/</a> and steps through the web interface.
All the pages up to the <code>04-runpecan.php</code> run on the <code>web</code> container, and are primarily for setting up the <code>pecan.xml</code> file.</p></li>
<li><p>Once the user starts the PEcAn workflow at <code>04-runpecan.php</code>, the underlying PHP code connects to RabbitMQ (based on the URI provided in <code>config.php</code>) and posts the following message to the <code>pecan</code> queue:</p></li>
</ol>
<pre class="sourceCode json"><code class="sourceCode json">  <span class="fu">{</span><span class="dt">&quot;folder&quot;</span><span class="fu">:</span> <span class="st">&quot;/workflows/PEcAn_WORKFLOWID&quot;</span><span class="fu">,</span> <span class="dt">&quot;workflowid&quot;</span><span class="fu">:</span> <span class="st">&quot;WORKFLOWID&quot;</span><span class="fu">}</span></code></pre>
<ol start="4" style="list-style-type: decimal">
<li>The <code>executor</code> service, which is listening on the <code>pecan</code> queue, hears this message and executes its <code>APPLICATION</code> (<code>R CMD BATCH workflow.R</code>) in the working directory specified in the message’s <code>folder</code>.
The <code>executor</code> service then performs the pre-execution steps (e.g. trait meta-analysis, conversions) itself.
Then, to actually execute the model, <code>executor</code> posts the following message to the target model’s queue:</li>
</ol>
<pre class="sourceCode json"><code class="sourceCode json">  <span class="fu">{</span><span class="dt">&quot;folder&quot;</span><span class="fu">:</span> <span class="st">&quot;/workflows/PEcAn_WORKFLOWID/run/RUNID&quot;</span><span class="fu">}</span></code></pre>
<ol start="5" style="list-style-type: decimal">
<li><p>The target model service, which is listening on its dedicated queue, hears this message and runs its <code>APPLICATION</code>, which is <code>job.sh</code>, in the directory indicated by the message.
Upon exiting (normally), the model service writes its status into a file called <code>rabbitmq.out</code> in the same directory.</p></li>
<li><p>The <code>executor</code> container continuously looks for the <code>rabbitmq.out</code> file as an indication of the model run’s status.
Once it sees this file, it reads the status and proceeds with the post-execution parts of the workflow.
(NOTE that this isn’t perfect. If the model running process exits abnormally, the <code>rabbitmq.out</code> file may not be created, which can cause the <code>executor</code> container to hang. If this happens, the solution is to restart the <code>executor</code> container with <code>docker-compose restart executor</code>).</p></li>
</ol>

</div>
</div>
<div id="database" class="section level2">
<h2><span class="header-section-number">11.9</span> BETY Database Administration</h2>
<p>This section provides additional details about the BETY database used by PEcAn. It will discuss best practices for setting up the BETY database, how to backup the database and how to restore the database.</p>
<div id="database-setup" class="section level3">
<h3><span class="header-section-number">11.9.1</span> Best practices</h3>
<p>When using the BETY database in non testing mode, it is best not to use the default users. This is accomplished when running the initialize of the database. When the database is initally created the database will be created with some default users (best known is the carya user) as well as the guestuser that can be used in the BETY web application. To disable these users you will either need to disable the users from the web interface, or you can reinitialize the database and remove the <code>-u</code> flag from the command line (the <code>-u</code> flag will create the default users). To disable the guestuser as well you can remove the <code>-g</code> flag from the command line, or disable the account from BETY.</p>
<p>The default installation of BETY and PEcAn will assume there is a database called bety with a default username and password. The default installation will setup the database account to not have any superuser abilities. It is also best to limit access to the postgres database from trusted hosts, either by using firewalls, or configuring postgresql to only accept connections from a limited set of hosts.</p>
</div>
<div id="backup-of-bety-database" class="section level3">
<h3><span class="header-section-number">11.9.2</span> Backup of BETY database</h3>
<p>It is good practice to make sure you backup the BETY database. Just creating a copy of the files on disk is not enough to ensure you have a valid backup. Most likely if you do this you will end up with a corrupted backup of the database.</p>
<p>To backup the database you can use the <code>pg_dump</code> command, which will make sure the database id backed up in a consistent state. You can run <code>sudo -u postgres pg_dump -d bety -Z 9 -f bety.sql.gz</code>, this will create a compressed file that can be used to resotore the database.</p>
<p>In the PEcAn distribution in scripts folder there is a script called <code>backup.bety.sh</code>. This script will create the backup of the database. It will create multiple backups allowing you to restore the database from one of these copies. The database will be backed up to one of the following files:
- bety-d-X, daily backup, where X is the day of the month.
- bety-w-X, weekly backup, where X is the week number in the year
- bety-m-X, montly backup, where X is the month of the year
- bety-y-X, yearly backup, where X is the actual year.
Using this scheme, we can restore the database using any of the files generated.</p>
<p>It is recommeneded to run this script using a cronjob at midnight such that you have a daily backup of the database and do not have to remember to create these backups. When running this script (either cron or by hand) make sure to place the backups on a different machine than the machine that holds the database in case of a larger system failure.</p>
</div>
<div id="restore-of-bety-database" class="section level3">
<h3><span class="header-section-number">11.9.3</span> Restore of BETY database</h3>
<p>Hopefully this section will never need to be used. Following are 5 steps that have been used to restore the database. Before you start it is worth it to read up online a bit on restoring the database as well as join the slack channel and ask any of the people there for help.</p>
<ol style="list-style-type: decimal">
<li>stop apache (BETY/PEcAn web apps) <code>service httpd stop</code> or <code>service apache2 stop</code></li>
<li>backup database (you know just incase) <code>pg_dump -d bety &gt; baddb.sql</code></li>
<li>drop database <code>sudo -u postgres psql -c 'drop database bety'</code></li>
<li>create database <code>sudo -u postgres psql -c 'create database bety with owner bety'</code></li>
<li>load database (assuming dump is called bety.sql.gz) <code>zcat bety.sql.gz | grep -v  search_path |  sudo -u postgres psql -d bety</code></li>
<li>start apache again <code>service httpd start</code> or <code>service apache2 start</code></li>
</ol>
<p>If during step 5 there is a lot of errors, it is helpful to add <code>-v ON_ERROR_STOP=1</code> to the end of the command. This will stop the restore at the first error and will help with debugging the issue.</p>

</div>
</div>
<div id="workflow-modules" class="section level2">
<h2><span class="header-section-number">11.10</span> Workflow modules</h2>
<p>NOTE: As of PEcAn 1.2.6 – needs to be updated significantly</p>
<!--NEEDS TO BE UPDATED SIGNIFICANTLY-->
<div id="overview" class="section level3">
<h3><span class="header-section-number">11.10.1</span> Overview</h3>
<p>Workflow inputs and outputs (click to open in new page, then zoom). Code used to generate this image is provided in <a href="https://github.com/PecanProject/pecan/blob/master/qaqc/vignettes/module_output.Rmd">qaqc/vignettes/module_output.Rmd</a></p>
<p><a href="http://isda.ncsa.illinois.edu/~kooper/EBI/workflow.svg"><img src="http://isda.ncsa.illinois.edu/~kooper/EBI/workflow.svg" alt="PEcAn Workflow" /></a></p>
</div>
<div id="load-settings" class="section level3">
<h3><span class="header-section-number">11.10.2</span> Load Settings:</h3>
<div id="read.settingshomepecanpecan.xml" class="section level4">
<h4><span class="header-section-number">11.10.2.1</span> <code>read.settings(&quot;/home/pecan/pecan.xml&quot;)</code></h4>
<ul>
<li>loads settings</li>
<li>create directories</li>
<li>generates new xml, put in output folder</li>
</ul>
</div>
</div>
<div id="query-database" class="section level3">
<h3><span class="header-section-number">11.10.3</span> Query Database:</h3>
<div id="get.trait.data" class="section level4">
<h4><span class="header-section-number">11.10.3.1</span> <code>get.trait.data()</code></h4>
<p>Queries the database for both the trait data and prior distributions associated with the PFTs specified in the settings file. The list of variables that are queried is determined by what variables have priors associated with them in the definition of the pft. Likewise, the list of species that are associated with a PFT determines what subset of data is extracted out of all data matching a given variable name.</p>
</div>
</div>
<div id="meta-analysis" class="section level3">
<h3><span class="header-section-number">11.10.4</span> Meta Analysis:</h3>
<div id="run.meta.analysis" class="section level4">
<h4><span class="header-section-number">11.10.4.1</span> <code>run.meta.analysis()</code></h4>
<p>The meta-analysis code begins by distilling the trait.data to just the values needed for the meta-analysis statistical model, with this being stored in <code>madata.Rdata</code>. This reduced form includes the conversion of all error statistics into precision (1/variance), and the indexing of sites, treatments, and greenhouse. In reality, the core meta-analysis code can be run independent of the trait database as long as input data is correctly formatted into the form shown in <code>madata</code>.</p>
<p>The evaluation of the meta-analysis is done using a Bayesian statistical software package called JAGS that is called by the R code. For each trait, the R code will generate a [trait].model.bug file that is the JAGS code for the meta-analysis itself. This code is generated on the fly, with PEcAn adding or subtracting the site, treatment, and greenhouse terms depending upon the presence of these effects in the data itself.</p>
<p>Meta-analyses are run, and summary plots are produced.</p>
</div>
</div>
<div id="write-configuration-files" class="section level3">
<h3><span class="header-section-number">11.10.5</span> Write Configuration Files</h3>
<div id="write.configsmodel" class="section level4">
<h4><span class="header-section-number">11.10.5.1</span> <code>write.configs(model)</code></h4>
<ul>
<li>writes out a configuration file for each model run
** writes 500 configuration files for a 500 member ensemble
** for <em>n</em> traits, writes <code>6 * n + 1</code> files for running default Sensitivity Analysis (number can be changed in the pecan settings file)</li>
</ul>
</div>
</div>
<div id="start-runs" class="section level3">
<h3><span class="header-section-number">11.10.6</span> Start Runs:</h3>
<div id="start.runsmodel" class="section level4">
<h4><span class="header-section-number">11.10.6.1</span> <code>start.runs(model)</code></h4>
<p>This code starts the model runs using a model specific run function named start.runs.<a href="user-section.html#model">model</a>. If the ecosystem model is running on a remote server, this module also takes care of all of the communication with the remote server and its run queue. Each of your subdirectories should now have a [run.id].out file in it. One instance of the model is run for each configuration file generated by the previous write configs module.</p>
</div>
</div>
<div id="get-model-output" class="section level3">
<h3><span class="header-section-number">11.10.7</span> Get Model Output</h3>
<div id="get.model.outputmodel" class="section level4">
<h4><span class="header-section-number">11.10.7.1</span> <code>get.model.output(model)</code></h4>
<p>This code first uses a model-specific model2netcdf.<a href="user-section.html#model">model</a> function to convert the model output into a standard output format (<a href="http://nacp.ornl.gov/MsTMIP_variables.shtml">MsTMIP</a>). Then it extracts the data for requested variables specified in the settings file as <code>settings$ensemble$variable</code>, averages over the time-period specified as <code>start.date</code> and <code>end.date</code>, and stores the output in a file <code>output.Rdata</code>. The <code>output.Rdata</code> file contains two objects, <code>sensitivity.output</code> and <code>ensemble.output</code>, that is the model prediction for the parameter sets specified in <code>sa.samples</code> and <code>ensemble.samples</code>. In order to save bandwidth, if the model output is stored on a remote system PEcAn will perform these operations on the remote host and only return the <code>output.Rdata</code> object.</p>
</div>
</div>
<div id="ensemble-analysis" class="section level3">
<h3><span class="header-section-number">11.10.8</span> Ensemble Analysis</h3>
<div id="run.ensemble.analysis" class="section level4">
<h4><span class="header-section-number">11.10.8.1</span> <code>run.ensemble.analysis()</code></h4>
<p>This module makes some simple graphs of the ensemble output. Open ensemble.analysis.pdf to view the ensemble prediction as both a histogram and a boxplot. ensemble.ts.pdf provides a timeseries plot of the ensemble mean, meadian, and 95% CI</p>
</div>
</div>
<div id="sensitivity-analysis-variance-decomposition" class="section level3">
<h3><span class="header-section-number">11.10.9</span> Sensitivity Analysis, Variance Decomposition</h3>
<div id="run.sensitivity.analysis" class="section level4">
<h4><span class="header-section-number">11.10.9.1</span> <code>run.sensitivity.analysis()</code></h4>
<p>This function processes the output of the previous module into sensitivity analysis plots, <code>sensitivityanalysis.pdf</code>, and a variance decomposition plot, <code>variancedecomposition.pdf</code> . In the sensitivity plots you will see the parameter values on the x-axis, the model output on the Y, with the dots being the model evaluations and the line being the spline fit.</p>
<p>The variance decomposition plot is discussed more below. For your reference, the R list object, sensitivity.results, stored in sensitivity.results.Rdata, contains all the components of the variance decomposition table, as well as the the input parameter space and splines from the sensitivity analysis (reminder: the output parameter space from the sensitivity analysis was in outputs.R).</p>
<p>The variance decomposition plot contains three columns, the coefficient of variation (normalized posterior variance), the elasticity (normalized sensitivity), and the partial standard deviation of each model parameter. This graph is sorted by the variable explaining the largest amount of variability in the model output (right hand column). From this graph identify the top-tier parameters that you would target for future constraint.</p>
</div>
</div>
<div id="glossary" class="section level3">
<h3><span class="header-section-number">11.10.10</span> Glossary</h3>
<ul>
<li>Inputs: data sets that are used, and file paths leading to them</li>
<li>Parameters: e.g. info set in settings file</li>
<li>Outputs: data sets that are dropped, and the file paths leading to them</li>
</ul>

</div>
</div>
<div id="data-assimilation-with-dart" class="section level2">
<h2><span class="header-section-number">11.11</span> Data assimilation with DART</h2>
<p>In addition to the state assimilation routines found in the assim.sequential module, another approach for state data assimilation in PEcAn is through the DART workflow created by the DARES group in NCAR.</p>
<p>This section gives a straight-forward explanation how to implement DART, focused on the technical aspects of the implementation. If there are any questions, feel free to send @Viskari an email (<code>tt.viskari@gmail.com</code>) or contacting DART support as they are quite awesome in helping people with problems. Also, if there are any suggestions on how to improve the wiki, please let me know.</p>
<p><strong>Running with current folders in PEcAn</strong></p>
<p>Currently the DART folders in PEcAn are that you can simply copy the structure there over a downloaded DART workflow and it should replace/add relevant files and folders. The most important step after that is to check and change the run paths in the following files:
Path_name files in the work folders
T_ED2IN file, as it indicates where the run results be written.
advance_model.csh, as it indicates where to copy files from/to.</p>
<p>Second thing is setting the state vector size. This is explained in more detail below, but essentially this is governed by the variable model_size in model_mod.f90. In addition to this, it should be changed in utils/F2R.f90 and R2F.f90 programs, which are responsible for reading and writing state variable information for the different ensembles. This also will be expanded below. Finally, the new state vector size should be updated for any other executable that runs it.</p>
<p>Third thing needed are the initial condition and observation sequence files. They will always follow the same format and are explained in more detail below.</p>
<p>Finally the ensemble size, which is the easiest to change. In the work subfolder, there is a file named input.nml. Simply changing the ensemble size there will set it for the run itself. Also remember that initial conditions file should have the equal amount of state vectors as there are ensemble members.</p>
<p><strong>Adjusting the workflow</strong></p>
<p>The central file for the actual workflow is advance_model.csh. It is a script DART calls to determine how the state vector changes between the two observation times and is essentially the only file one needs to change when changing state models or observations operators. The file itself should be commented to give a good idea of the flow, but beneath is a crude order of events.
1. Create a temporary folder to run the model in and copy/link required files in to it.
2. Read in the state vector values and times from DART. Here it is important to note that the values will be in binary format, which need to be read in by a Fortran program. In my system, there is a program called F2R which reads in the binary values and writes out in ascii form the state vector values as well as which ED2 history files it needs to copy based on the time stamps.
3. Run the observation operator, which writes the state vector state in to the history files and adjusts them if necessary.
4. Run the program.
5. Read the new state vector values from output files.
6. Convert the state vector values to the binary. In my system, this is done by the program R2F.</p>
<p><strong>Initial conditions file</strong></p>
<p>The initial conditions file, commonly named filter_ics although you can set it to something else in input.nml, is relatively simple in structure. It has one sequence repeating over the number of ensemble members.
First line contains two times: Seconds and days. Just use one of them in this situation, but it has to match the starting time given in input.nml.
After that each line should contain a value from the state vector in the order you want to treat them.
R functions filter_ics.R and B_filter_ics.R in the R folder give good examples of how to create these.</p>
<p><strong>Observations files</strong></p>
<p>The file which contains the observations is commonly known as obs_seq.out, although again the name of the file can be changed in input.nml. The structure of the file is relatively straight-forward and the R function ObsSeq.R in the R subfolder has the write structure for this. Instead of writing it out here, I want to focus on a few really important details in this file.
Each observations will have a time, a value, an uncertainty, a location and a kind. The first four are self-explanatory, but the kind is really important, but also unfortunately really easy to misunderstand. In this file, the kind does not refer to a unit or a type of observation, but which member of the state vector is this observation of. So if the kind was, for example, 5, it would mean that it was of the fifth member of the state vector. However, if the kind value is positive, the system assumes that there is some sort of an operator change in comparing the observation and state vector value which is specified in a subprogram in model_mod.f90.</p>
<p>So for an direct identity comparison between the observation and the state vector value, the kind needs to be negative number of the state vector component. Thus, again if the observation is of the fifth state vector value, the kind should be set as -5. Thus it is recommendable that the state vector values have already been altered to be comparable with the observations.</p>
<p>As for location, there are many ways to set in DART and the method needs to be chosen when compiling the code by giving the program which of the location mods it is to use. In our examples we used a 1-dimensional location vector with scaled values between 0 and 1. For future it makes sense to switch to a 2 dimensional long- and lat-scale, but for the time being the location does not impact the system a lot. The main impact will be if the covariances will be localized, as that will be decided on their locations.</p>
<p><strong>State variable vector in DART</strong></p>
<p>Creating/adjusting a state variable vector in DART is relatively straight-forward. Below are listed the steps to specify a state variable vector in DART.</p>
<p>I. For each specific model, there should be an own folder within the DART root models folder. In this folder there is a model_mod.f90, which contains the model specific subroutines necessary for a DART run.</p>
<p>At the beginning of this file there should be the following line:</p>
<p>integer, parameter :: model_size = [number]</p>
<p>The number here should be the number of variables in the vector. So for example if there were three state variables, then the line should look like this:</p>
<p>integer, parameter :: model_size = 3</p>
<p>This number should also be changed to match with any of the other executables called during the run as indicated by the list above.</p>
<ol start="2" style="list-style-type: upper-roman">
<li>In the DART root, there should be a folder named obs_kind, which contains a file called DEFAULT_obs_kind_mod.F90. It is important to note that all changes should be done to this file instead of obs_kind_mod.f90, as during compilation DART creates obs_kind_mod.f90 from DEFAULT_obs_kind_mod.F90.
This program file contains all the defined observation types used by DART and numbers them for easier reference later. Different types are classified according to observation instrument or relevant observation phenomenon. Adding a new type only requires finding an unused number and starting a new identifying line with the following:</li>
</ol>
<p>integer, parameter, public :: &amp;
KIND_…</p>
<p>Note that the observation kind should always be easy to understand, so avoid using unnecessary acronyms. For example, when adding an observation type for Leaf Area Index, it would look like below:</p>
<p>integer, parameter, public :: &amp;
KIND_LEAF_AREA_INDEX = [number]</p>
<ol start="3" style="list-style-type: upper-roman">
<li>In the DART root, there should be a folder named obs_def, which contains several files starting with obs_def_. There files contain the different available observation kinds classified either according to observation instrument or observable system. Each file starts with the line</li>
</ol>
<p>! BEGIN DART PREPROCESS KIND LIST</p>
<p>And end with line</p>
<p>! END DART PREPROCESS KIND LIST</p>
<p>The lines between these two should contain</p>
<p>! The desired observation reference, the observation type, COMMON_CODE.</p>
<p>For example, for observations relating to phenology, I have created a file called obs_def_phen_mod.f90. In this file I define the Leaf Area Index observations in the following way.</p>
<p>! BEGIN DART PREPROCESS KIND LIST
! LAI, TYPE_LEAF_AREA_INDEX, COMMON_CODE
! END DART PREPROCESS KIND LIST</p>
<p>Note that the exclamation marks are necessary for the file.</p>
<ol start="4" style="list-style-type: upper-roman">
<li>In the model specific folder, in the work subfolder there is a namelist file input.nml. This contains all the run specific information for DART. In it, there is a subtitle &amp;preprocess, under which there is a line</li>
</ol>
<p>input_files = ‘….’</p>
<p>This input_files sections must be set to refer to the obs_def file created in step III. The input files can contain references to multiple obs_def files if necessary.</p>
<p>As an example, the reference to the obs_def_phen_mod.f90 would look like
input_files = ‘../../../obs_def/obs_def_phen_mod.f90’</p>
<p>V. Finally, as an optional step, the different values in state vector can be typed. In model_mod, referred to in step I, there is a subroutine get_state_meta_data. In it, there is an input variable index_in, which refers to the vector component. So for instance for the second component of the vector index_in would be 2. If this is done, the variable kind has to be also included at the beginning of the model_mod.f90 file, at the section which begins</p>
<p>use obs_kind_mod, only ::</p>
<p>The location of the variable can be set, but for a 0-dimensional model we are discussing here, this is not necessary.</p>
<p>Here, though, it is possible to set the variable types by including the following line</p>
<p>if(index_in .eq. [number]) var_type = [One of the variable kinds set in step II]</p>
<ol start="6" style="list-style-type: upper-roman">
<li>If the length of the state vector is changed, it is important that the script ran with DART produces a vector of that length. Change appropriately if necessary.</li>
</ol>
<p>After these steps, DART should be able to run with the state vector of interest.</p>

</div>
</div>



<h2><span class="header-section-number">11.12</span> TODO:</h2>
<ul>
<li>Add list of developers</li>
</ul>

</div>
<div id="faq" class="section level2">
<h2><span class="header-section-number">11.13</span> FAQ</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pecan-models.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tonygardella/pecan/edit/release/vtonydoc/book_source/03_topical_pages/05_data/01_meteorology.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
