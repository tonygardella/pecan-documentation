<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>2 Tutorials,Demos and How To’s | The Predictive Ecosystem Analyzer</title>
  <meta name="description" content="2 Tutorials,Demos and How To’s | The Predictive Ecosystem Analyzer">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="2 Tutorials,Demos and How To’s | The Predictive Ecosystem Analyzer" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Tutorials,Demos and How To’s | The Predictive Ecosystem Analyzer" />
  
  
  

<meta name="author" content="By: PEcAn Team">


<meta name="date" content="2019-02-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction.html">
<link rel="next" href="topical.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.5/datatables.js"></script>
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
<link href="libs/dt-ext-fixedcolumns-1.10.16/css/fixedColumns.dataTables.min.css" rel="stylesheet" />
<script src="libs/dt-ext-fixedcolumns-1.10.16/js/dataTables.fixedColumns.min.js"></script>
<script src="libs/jszip-1.10.16/jszip.min.js"></script>
<script src="libs/pdfmake-1.10.16/pdfmake.min.js"></script>
<script src="libs/pdfmake-1.10.16/vfs_fonts.js"></script>
<link href="libs/dt-ext-buttons-1.10.16/css/buttons.dataTables.min.css" rel="stylesheet" />
<script src="libs/dt-ext-buttons-1.10.16/js/dataTables.buttons.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.flash.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.html5.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.colVis.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.print.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#project-overview"><i class="fa fa-check"></i><b>1.1</b> Project Overview</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#contributor-covenant-code-of-conduct"><i class="fa fa-check"></i><b>1.2</b> Contributor Covenant Code of Conduct</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#about-the-pecan-book"><i class="fa fa-check"></i><b>1.3</b> About the PEcAn Book</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#general-feedbackcommentssuggestions"><i class="fa fa-check"></i><b>1.3.1</b> General Feedback/Comments/Suggestions</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#bookediting"><i class="fa fa-check"></i><b>1.4</b> Editing this book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html"><i class="fa fa-check"></i><b>2</b> Tutorials,Demos and How To’s</a><ul>
<li class="chapter" data-level="2.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-manual-setup"><i class="fa fa-check"></i><b>2.1</b> Install PEcAn</a><ul>
<li class="chapter" data-level="2.1.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecanvm"><i class="fa fa-check"></i><b>2.1.1</b> PEcAn Virtual Machine</a></li>
<li class="chapter" data-level="2.1.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#docker-index"><i class="fa fa-check"></i><b>2.1.2</b> Docker</a></li>
<li class="chapter" data-level="2.1.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#osinstall"><i class="fa fa-check"></i><b>2.1.3</b> OS Specific Installations</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#user-tut"><i class="fa fa-check"></i><b>2.2</b> User Tutorial Section</a><ul>
<li class="chapter" data-level="2.2.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#demo-table"><i class="fa fa-check"></i><b>2.2.1</b> PEcAn Demos</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#web-workflow"><i class="fa fa-check"></i><b>2.3</b> Web workflow</a><ul>
<li class="chapter" data-level="2.3.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#web-site-model"><i class="fa fa-check"></i><b>2.3.1</b> Site and model selection</a></li>
<li class="chapter" data-level="2.3.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#selecting-a-site"><i class="fa fa-check"></i><b>2.3.2</b> Selecting a site</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#web-model-config"><i class="fa fa-check"></i><b>2.4</b> Model configuration</a><ul>
<li class="chapter" data-level="2.4.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#choosing-meteorology"><i class="fa fa-check"></i><b>2.4.1</b> Choosing meteorology</a></li>
<li class="chapter" data-level="2.4.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#selecting-plant-functional-types-pfts-and-other-parameter-groupings."><i class="fa fa-check"></i><b>2.4.2</b> Selecting Plant Functional Types (PFTs) and other parameter groupings.</a></li>
<li class="chapter" data-level="2.4.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#choosing-initial-vegetation"><i class="fa fa-check"></i><b>2.4.3</b> Choosing initial vegetation</a></li>
<li class="chapter" data-level="2.4.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#spin-up"><i class="fa fa-check"></i><b>2.4.4</b> Spin up</a></li>
<li class="chapter" data-level="2.4.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#selecting-a-soils-product"><i class="fa fa-check"></i><b>2.4.5</b> Selecting a soils product</a></li>
<li class="chapter" data-level="2.4.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#other-model-inputs"><i class="fa fa-check"></i><b>2.4.6</b> Other model inputs</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#intermediate-user"><i class="fa fa-check"></i><b>2.5</b> Intermediate user guide</a><ul>
<li class="chapter" data-level="2.5.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#additional-web-configuration"><i class="fa fa-check"></i><b>2.5.1</b> Additional web configuration</a></li>
<li class="chapter" data-level="2.5.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#brown-dog"><i class="fa fa-check"></i><b>2.5.2</b> Brown Dog</a></li>
<li class="chapter" data-level="2.5.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#basic-setups"><i class="fa fa-check"></i><b>2.5.3</b> Basic Setups</a></li>
<li class="chapter" data-level="2.5.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#advanced-setup"><i class="fa fa-check"></i><b>2.5.4</b> Advanced Setup</a></li>
<li class="chapter" data-level="2.5.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#editing-model-configurations"><i class="fa fa-check"></i><b>2.5.5</b> Editing model configurations</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#settings-configured-analyses"><i class="fa fa-check"></i><b>2.6</b> Settings-configured analyses</a><ul>
<li class="chapter" data-level="2.6.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pda"><i class="fa fa-check"></i><b>2.6.1</b> Parameter data assimilation (PDA)</a></li>
<li class="chapter" data-level="2.6.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#sda"><i class="fa fa-check"></i><b>2.6.2</b> State data assimilation (SDA)</a></li>
<li class="chapter" data-level="2.6.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#model-specific-functions-for-sda-workflow"><i class="fa fa-check"></i><b>2.6.3</b> Model Specific Functions for SDA Workflow</a></li>
<li class="chapter" data-level="2.6.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#analysis-options"><i class="fa fa-check"></i><b>2.6.4</b> Analysis Options</a></li>
<li class="chapter" data-level="2.6.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#the-generalized-ensemble-filter"><i class="fa fa-check"></i><b>2.6.5</b> The Generalized Ensemble Filter</a></li>
<li class="chapter" data-level="2.6.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#multi-site-state-data-assimilation."><i class="fa fa-check"></i><b>2.6.6</b> Multi-site State data assimilation.</a></li>
<li class="chapter" data-level="2.6.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#data-products"><i class="fa fa-check"></i><b>2.6.7</b> Data Products</a></li>
<li class="chapter" data-level="2.6.8" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#current-models"><i class="fa fa-check"></i><b>2.6.8</b> Current Models</a></li>
<li class="chapter" data-level="2.6.9" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#model-calibration"><i class="fa fa-check"></i><b>2.6.9</b> Model Calibration</a></li>
<li class="chapter" data-level="2.6.10" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#initial-conditions"><i class="fa fa-check"></i><b>2.6.10</b> Initial Conditions</a></li>
<li class="chapter" data-level="2.6.11" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#drivers"><i class="fa fa-check"></i><b>2.6.11</b> Drivers</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#sequential-state-data-assimilation"><i class="fa fa-check"></i><b>2.7</b> Sequential State Data Assimilation</a><ul>
<li class="chapter" data-level="2.7.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#general-description"><i class="fa fa-check"></i><b>2.7.1</b> General Description</a></li>
<li class="chapter" data-level="2.7.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#enkf"><i class="fa fa-check"></i><b>2.7.2</b> EnKF</a></li>
<li class="chapter" data-level="2.7.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#generalized-ensemble-filter"><i class="fa fa-check"></i><b>2.7.3</b> Generalized Ensemble Filter</a></li>
<li class="chapter" data-level="2.7.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#ensemble-adjustment"><i class="fa fa-check"></i><b>2.7.4</b> Ensemble Adjustment</a></li>
<li class="chapter" data-level="2.7.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#diagnostics"><i class="fa fa-check"></i><b>2.7.5</b> Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#Benchmarking"><i class="fa fa-check"></i><b>2.8</b> Benchmarking</a><ul>
<li class="chapter" data-level="2.8.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#data-preparation"><i class="fa fa-check"></i><b>2.8.1</b> Data Preparation</a></li>
<li class="chapter" data-level="2.8.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#model-runs"><i class="fa fa-check"></i><b>2.8.2</b> Model Runs</a></li>
<li class="chapter" data-level="2.8.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#the-benchmarking-shiny-app"><i class="fa fa-check"></i><b>2.8.3</b> The Benchmarking Shiny App</a></li>
<li class="chapter" data-level="2.8.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#benchmarking-in-pecan.xml"><i class="fa fa-check"></i><b>2.8.4</b> Benchmarking in pecan.xml</a></li>
<li class="chapter" data-level="2.8.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-remote"><i class="fa fa-check"></i><b>2.8.5</b> Remote execution with PEcAn</a></li>
<li class="chapter" data-level="2.8.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#ssh-tunnels-and-pecan"><i class="fa fa-check"></i><b>2.8.6</b> SSH tunnels and PEcAn</a></li>
<li class="chapter" data-level="2.8.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#basic-remote-execute-functions"><i class="fa fa-check"></i><b>2.8.7</b> Basic remote execute functions</a></li>
<li class="chapter" data-level="2.8.8" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#remote-model-execution-with-pecan"><i class="fa fa-check"></i><b>2.8.8</b> Remote model execution with PEcAn</a></li>
<li class="chapter" data-level="2.8.9" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#xml-configuration"><i class="fa fa-check"></i><b>2.8.9</b> XML configuration</a></li>
<li class="chapter" data-level="2.8.10" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#configuration-for-pecan-web-interface"><i class="fa fa-check"></i><b>2.8.10</b> Configuration for PEcAn web interface</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-api"><i class="fa fa-check"></i><b>2.9</b> The PEcAn Docker API</a><ul>
<li class="chapter" data-level="2.9.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#installation"><i class="fa fa-check"></i><b>2.9.1</b> Installation</a></li>
<li class="chapter" data-level="2.9.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#creating-and-submitting-a-workflow"><i class="fa fa-check"></i><b>2.9.2</b> Creating and submitting a workflow</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#advanced-user"><i class="fa fa-check"></i><b>2.10</b> Advanced User Guide</a><ul>
<li class="chapter" data-level="2.10.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#adding-to-pecan"><i class="fa fa-check"></i><b>2.10.1</b> Adding to PEcAn</a></li>
<li class="chapter" data-level="2.10.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#adding-model"><i class="fa fa-check"></i><b>2.10.2</b> Adding An Ecosystem Model</a></li>
<li class="chapter" data-level="2.10.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-database"><i class="fa fa-check"></i><b>2.10.3</b> PEcAn Database</a></li>
<li class="chapter" data-level="2.10.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#define-model_type"><i class="fa fa-check"></i><b>2.10.4</b> Define MODEL_TYPE</a></li>
<li class="chapter" data-level="2.10.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#machine"><i class="fa fa-check"></i><b>2.10.5</b> MACHINE</a></li>
<li class="chapter" data-level="2.10.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#model"><i class="fa fa-check"></i><b>2.10.6</b> MODEL</a></li>
<li class="chapter" data-level="2.10.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#formats"><i class="fa fa-check"></i><b>2.10.7</b> FORMATS</a></li>
<li class="chapter" data-level="2.10.8" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#model_type---formats"><i class="fa fa-check"></i><b>2.10.8</b> MODEL_TYPE -&gt; Formats</a></li>
<li class="chapter" data-level="2.10.9" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#inputs"><i class="fa fa-check"></i><b>2.10.9</b> INPUTS</a></li>
<li class="chapter" data-level="2.10.10" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pfts-plant-functional-types"><i class="fa fa-check"></i><b>2.10.10</b> PFTS (Plant Functional Types)</a></li>
<li class="chapter" data-level="2.10.11" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#priors"><i class="fa fa-check"></i><b>2.10.11</b> PRIORS</a></li>
<li class="chapter" data-level="2.10.12" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#interface-modules"><i class="fa fa-check"></i><b>2.10.12</b> Interface Modules</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#NewInput"><i class="fa fa-check"></i><b>2.11</b> Adding input data</a><ul>
<li class="chapter" data-level="2.11.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#input-records-in-bety"><i class="fa fa-check"></i><b>2.11.1</b> Input records in BETY</a></li>
<li class="chapter" data-level="2.11.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#create-a-database-file-record-for-the-input-data"><i class="fa fa-check"></i><b>2.11.2</b> Create a database file record for the input data</a></li>
<li class="chapter" data-level="2.11.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#creating-a-new-input-record-in-bety"><i class="fa fa-check"></i><b>2.11.3</b> Creating a new Input record in BETY</a></li>
<li class="chapter" data-level="2.11.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#InputConversions"><i class="fa fa-check"></i><b>2.11.4</b> Adding a new input converter</a></li>
<li class="chapter" data-level="2.11.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#adding-data-web"><i class="fa fa-check"></i><b>2.11.5</b> Pecan Data Ingest via Web Interface</a></li>
<li class="chapter" data-level="2.11.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#NewFormat"><i class="fa fa-check"></i><b>2.11.6</b> Creating a new format</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#NewBenchmark"><i class="fa fa-check"></i><b>2.12</b> Creating a new benchmark reference run</a></li>
<li class="chapter" data-level="2.13" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#editing-records"><i class="fa fa-check"></i><b>2.13</b> Editing records</a></li>
<li class="chapter" data-level="2.14" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#submitting-workflow-from-command-line"><i class="fa fa-check"></i><b>2.14</b> Submitting Workflow from Command Line</a></li>
<li class="chapter" data-level="2.15" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#developer-guide"><i class="fa fa-check"></i><b>2.15</b> Developer user guide</a><ul>
<li class="chapter" data-level="2.15.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#aws-setup"><i class="fa fa-check"></i><b>2.15.1</b> AWS Setup</a></li>
<li class="chapter" data-level="2.15.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#porting-vm-to-aws"><i class="fa fa-check"></i><b>2.15.2</b> Porting VM to AWS</a></li>
<li class="chapter" data-level="2.15.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#set-up-multiple-instances-optional"><i class="fa fa-check"></i><b>2.15.3</b> Set up multiple instances (optional)</a></li>
<li class="chapter" data-level="2.15.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#shiny-setup"><i class="fa fa-check"></i><b>2.15.4</b> Shiny Setup</a></li>
<li class="chapter" data-level="2.15.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#thredds-setup"><i class="fa fa-check"></i><b>2.15.5</b> Thredds Setup</a></li>
</ul></li>
<li class="chapter" data-level="2.16" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#updatepecan"><i class="fa fa-check"></i><b>2.16</b> Updating PEcAn Code and Bety Database</a><ul>
<li class="chapter" data-level="2.16.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#updating-pecan"><i class="fa fa-check"></i><b>2.16.1</b> Updating PEcAn</a></li>
</ul></li>
<li class="chapter" data-level="2.17" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#updating-bety"><i class="fa fa-check"></i><b>2.17</b> Updating BETY</a></li>
<li class="chapter" data-level="2.18" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#git-and-github-workflow"><i class="fa fa-check"></i><b>2.18</b> Git and GitHub Workflow</a></li>
<li class="chapter" data-level="2.19" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#using-git"><i class="fa fa-check"></i><b>2.19</b> Using Git</a><ul>
<li class="chapter" data-level="2.19.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#git"><i class="fa fa-check"></i><b>2.19.1</b> Git</a></li>
<li class="chapter" data-level="2.19.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-project-and-github"><i class="fa fa-check"></i><b>2.19.2</b> PEcAn Project and Github</a></li>
<li class="chapter" data-level="2.19.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-project-branches"><i class="fa fa-check"></i><b>2.19.3</b> PEcAn Project Branches</a></li>
<li class="chapter" data-level="2.19.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#quick-and-easy"><i class="fa fa-check"></i><b>2.19.4</b> Quick and Easy</a></li>
<li class="chapter" data-level="2.19.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#recommended-git-workflow"><i class="fa fa-check"></i><b>2.19.5</b> Recommended Git Workflow</a></li>
<li class="chapter" data-level="2.19.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#before-any-work-is-done"><i class="fa fa-check"></i><b>2.19.6</b> Before any work is done</a></li>
<li class="chapter" data-level="2.19.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#during-development"><i class="fa fa-check"></i><b>2.19.7</b> During development:</a></li>
<li class="chapter" data-level="2.19.8" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#basic-workflow"><i class="fa fa-check"></i><b>2.19.8</b> Basic Workflow</a></li>
<li class="chapter" data-level="2.19.9" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#recommended-workflow-a-new-branch-for-each-change"><i class="fa fa-check"></i><b>2.19.9</b> Recommended Workflow: A new branch for each change</a></li>
<li class="chapter" data-level="2.19.10" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#git-rstudio"><i class="fa fa-check"></i><b>2.19.10</b> Git + Rstudio</a></li>
<li class="chapter" data-level="2.19.11" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#for-development"><i class="fa fa-check"></i><b>2.19.11</b> For development:</a></li>
<li class="chapter" data-level="2.19.12" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#references"><i class="fa fa-check"></i><b>2.19.12</b> References</a></li>
</ul></li>
<li class="chapter" data-level="2.20" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#github-use-with-pecan"><i class="fa fa-check"></i><b>2.20</b> GitHub use with PEcAn</a><ul>
<li class="chapter" data-level="2.20.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#bugs-issues-features-etc."><i class="fa fa-check"></i><b>2.20.1</b> Bugs, Issues, Features, etc.</a></li>
<li class="chapter" data-level="2.20.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#requesting-a-feature"><i class="fa fa-check"></i><b>2.20.2</b> Requesting a feature</a></li>
<li class="chapter" data-level="2.20.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#closing-an-issue"><i class="fa fa-check"></i><b>2.20.3</b> Closing an issue</a></li>
<li class="chapter" data-level="2.20.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#when-to-submit-an-issue"><i class="fa fa-check"></i><b>2.20.4</b> When to submit an issue?</a></li>
</ul></li>
<li class="chapter" data-level="2.21" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#coding-practices"><i class="fa fa-check"></i><b>2.21</b> Coding Practices</a></li>
<li class="chapter" data-level="2.22" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#coding-style"><i class="fa fa-check"></i><b>2.22</b> Coding Style</a><ul>
<li class="chapter" data-level="2.22.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#use-roxygen2-documentation"><i class="fa fa-check"></i><b>2.22.1</b> Use Roxygen2 documentation</a></li>
<li class="chapter" data-level="2.22.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#write-your-name-at-the-top"><i class="fa fa-check"></i><b>2.22.2</b> Write your name at the top</a></li>
<li class="chapter" data-level="2.22.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#use-testthat-testing-package"><i class="fa fa-check"></i><b>2.22.3</b> Use testthat testing package</a></li>
<li class="chapter" data-level="2.22.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#dont-use-shortcuts"><i class="fa fa-check"></i><b>2.22.4</b> Don’t use shortcuts</a></li>
<li class="chapter" data-level="2.22.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#package-dependencies"><i class="fa fa-check"></i><b>2.22.5</b> Package Dependencies:</a></li>
</ul></li>
<li class="chapter" data-level="2.23" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#logging"><i class="fa fa-check"></i><b>2.23</b> Logging</a><ul>
<li class="chapter" data-level="2.23.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-logging-functions"><i class="fa fa-check"></i><b>2.23.1</b> PEcAn logging functions</a></li>
<li class="chapter" data-level="2.23.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#other-r-logging-packages"><i class="fa fa-check"></i><b>2.23.2</b> Other R logging packages</a></li>
<li class="chapter" data-level="2.23.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#example-usage"><i class="fa fa-check"></i><b>2.23.3</b> Example Usage</a></li>
</ul></li>
<li class="chapter" data-level="2.24" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#package-data"><i class="fa fa-check"></i><b>2.24</b> Package Data</a><ul>
<li class="chapter" data-level="2.24.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#summary"><i class="fa fa-check"></i><b>2.24.1</b> Summary:</a></li>
<li class="chapter" data-level="2.24.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#accessing-data"><i class="fa fa-check"></i><b>2.24.2</b> Accessing data</a></li>
</ul></li>
<li class="chapter" data-level="2.25" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#packages-used-in-development"><i class="fa fa-check"></i><b>2.25</b> Packages used in development</a></li>
<li class="chapter" data-level="2.26" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#roxygen2-1"><i class="fa fa-check"></i><b>2.26</b> Roxygen2</a><ul>
<li class="chapter" data-level="2.26.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#canonical-references"><i class="fa fa-check"></i><b>2.26.1</b> Canonical references:</a></li>
<li class="chapter" data-level="2.26.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#basic-roxygen2-instructions"><i class="fa fa-check"></i><b>2.26.2</b> Basic Roxygen2 instructions:</a></li>
<li class="chapter" data-level="2.26.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#example"><i class="fa fa-check"></i><b>2.26.3</b> Example</a></li>
<li class="chapter" data-level="2.26.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#updating-documentation"><i class="fa fa-check"></i><b>2.26.4</b> Updating documentation</a></li>
</ul></li>
<li class="chapter" data-level="2.27" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#testing"><i class="fa fa-check"></i><b>2.27</b> Testing</a><ul>
<li class="chapter" data-level="2.27.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#rationale"><i class="fa fa-check"></i><b>2.27.1</b> Rationale</a></li>
<li class="chapter" data-level="2.27.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#tests-makes-development-easier-and-less-error-prone"><i class="fa fa-check"></i><b>2.27.2</b> Tests makes development easier and less error prone</a></li>
<li class="chapter" data-level="2.27.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#quick-start"><i class="fa fa-check"></i><b>2.27.3</b> Quick Start:</a></li>
<li class="chapter" data-level="2.27.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#test-files"><i class="fa fa-check"></i><b>2.27.4</b> Test files</a></li>
<li class="chapter" data-level="2.27.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#testing-the-shiny-server"><i class="fa fa-check"></i><b>2.27.5</b> Testing the Shiny Server</a></li>
<li class="chapter" data-level="2.27.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#download-and-compile-pecan"><i class="fa fa-check"></i><b>2.27.6</b> Download and Compile PEcAn</a></li>
<li class="chapter" data-level="2.27.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-testrun"><i class="fa fa-check"></i><b>2.27.7</b> PEcAn Testrun</a></li>
</ul></li>
<li class="chapter" data-level="2.28" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#directory-structure"><i class="fa fa-check"></i><b>2.28</b> Directory structure</a></li>
<li class="chapter" data-level="2.29" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#overview-of-pecan-repository-as-of-pecan-1.5.3"><i class="fa fa-check"></i><b>2.29</b> Overview of PEcAn repository as of PEcAn 1.5.3</a></li>
<li class="chapter" data-level="2.30" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#generic-r-package-structure"><i class="fa fa-check"></i><b>2.30</b> Generic R package structure:</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="topical.html"><a href="topical.html"><i class="fa fa-check"></i><b>3</b> Topical Pages</a><ul>
<li class="chapter" data-level="3.1" data-path="topical.html"><a href="topical.html#pecan-standard-formats"><i class="fa fa-check"></i><b>3.1</b> PEcAn standard formats</a><ul>
<li class="chapter" data-level="3.1.1" data-path="topical.html"><a href="topical.html#defining-new-input-formats"><i class="fa fa-check"></i><b>3.1.1</b> Defining new input formats</a></li>
<li class="chapter" data-level="3.1.2" data-path="topical.html"><a href="topical.html#input-standards"><i class="fa fa-check"></i><b>3.1.2</b> Input Standards</a></li>
<li class="chapter" data-level="3.1.3" data-path="topical.html"><a href="topical.html#output-standards"><i class="fa fa-check"></i><b>3.1.3</b> Output Standards</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="topical.html"><a href="topical.html#pecanXML"><i class="fa fa-check"></i><b>3.2</b> The PEcAn XML</a><ul>
<li class="chapter" data-level="3.2.1" data-path="topical.html"><a href="topical.html#xml-core-config"><i class="fa fa-check"></i><b>3.2.1</b> Core configuration</a></li>
<li class="chapter" data-level="3.2.2" data-path="topical.html"><a href="topical.html#xml-outdir"><i class="fa fa-check"></i><b>3.2.2</b> <code>outdir</code>: Output directory</a></li>
<li class="chapter" data-level="3.2.3" data-path="topical.html"><a href="topical.html#xml-database"><i class="fa fa-check"></i><b>3.2.3</b> <code>database</code>: PEcAn database settings</a></li>
<li class="chapter" data-level="3.2.4" data-path="topical.html"><a href="topical.html#xml-pft"><i class="fa fa-check"></i><b>3.2.4</b> <code>pft</code>: Plant functional type selection</a></li>
<li class="chapter" data-level="3.2.5" data-path="topical.html"><a href="topical.html#xml-meta-analysis"><i class="fa fa-check"></i><b>3.2.5</b> <code>meta.analysis</code>: Trait Meta Analysis</a></li>
<li class="chapter" data-level="3.2.6" data-path="topical.html"><a href="topical.html#xml-model"><i class="fa fa-check"></i><b>3.2.6</b> <code>model</code>: Model configuration</a></li>
<li class="chapter" data-level="3.2.7" data-path="topical.html"><a href="topical.html#xml-run"><i class="fa fa-check"></i><b>3.2.7</b> <code>run</code>: Run Setup</a></li>
<li class="chapter" data-level="3.2.8" data-path="topical.html"><a href="topical.html#xml-host"><i class="fa fa-check"></i><b>3.2.8</b> <code>host</code>: Host information for remote execution</a></li>
<li class="chapter" data-level="3.2.9" data-path="topical.html"><a href="topical.html#xml-advanced"><i class="fa fa-check"></i><b>3.2.9</b> Advanced features</a></li>
<li class="chapter" data-level="3.2.10" data-path="topical.html"><a href="topical.html#xml-ensemble"><i class="fa fa-check"></i><b>3.2.10</b> <code>ensemble</code>: Ensemble Runs</a></li>
<li class="chapter" data-level="3.2.11" data-path="topical.html"><a href="topical.html#xml-sensitivity-analysis"><i class="fa fa-check"></i><b>3.2.11</b> <code>sensitivity.analysis</code>: Sensitivity analysis</a></li>
<li class="chapter" data-level="3.2.12" data-path="topical.html"><a href="topical.html#xml-parameter-data-assimilation"><i class="fa fa-check"></i><b>3.2.12</b> Parameter Data Assimilation</a></li>
<li class="chapter" data-level="3.2.13" data-path="topical.html"><a href="topical.html#xml-multi-settings"><i class="fa fa-check"></i><b>3.2.13</b> Multi-Settings</a></li>
<li class="chapter" data-level="3.2.14" data-path="topical.html"><a href="topical.html#xml-state-data-assimilation"><i class="fa fa-check"></i><b>3.2.14</b> (experimental) State Data Assimilation</a></li>
<li class="chapter" data-level="3.2.15" data-path="topical.html"><a href="topical.html#xml-browndog"><i class="fa fa-check"></i><b>3.2.15</b> (experimental) Brown Dog</a></li>
<li class="chapter" data-level="3.2.16" data-path="topical.html"><a href="topical.html#xml-benchmarking"><i class="fa fa-check"></i><b>3.2.16</b> (experimental) Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="topical.html"><a href="topical.html#workflow"><i class="fa fa-check"></i><b>3.3</b> PEcAn workflow (web/workflow.R)</a><ul>
<li class="chapter" data-level="3.3.1" data-path="topical.html"><a href="topical.html#workflow-readsettings"><i class="fa fa-check"></i><b>3.3.1</b> Read Settings</a></li>
<li class="chapter" data-level="3.3.2" data-path="topical.html"><a href="topical.html#workflow-input"><i class="fa fa-check"></i><b>3.3.2</b> Input Conversions</a></li>
<li class="chapter" data-level="3.3.3" data-path="topical.html"><a href="topical.html#workflow-input-data"><i class="fa fa-check"></i><b>3.3.3</b> Input Data</a></li>
<li class="chapter" data-level="3.3.4" data-path="topical.html"><a href="topical.html#workflow-input-initial"><i class="fa fa-check"></i><b>3.3.4</b> Initial Conditions</a></li>
<li class="chapter" data-level="3.3.5" data-path="topical.html"><a href="topical.html#workflow-met"><i class="fa fa-check"></i><b>3.3.5</b> Meteorological Data</a></li>
<li class="chapter" data-level="3.3.6" data-path="topical.html"><a href="topical.html#workflow-met-standard"><i class="fa fa-check"></i><b>3.3.6</b> Converting raw data to PEcAn standard</a></li>
<li class="chapter" data-level="3.3.7" data-path="topical.html"><a href="topical.html#workflow-met-downscale"><i class="fa fa-check"></i><b>3.3.7</b> Downscaling and gapfilling (optional)</a></li>
<li class="chapter" data-level="3.3.8" data-path="topical.html"><a href="topical.html#workflow-met-model"><i class="fa fa-check"></i><b>3.3.8</b> Converting from PEcAn standard to model-specific format</a></li>
<li class="chapter" data-level="3.3.9" data-path="topical.html"><a href="topical.html#workflow-traits"><i class="fa fa-check"></i><b>3.3.9</b> Traits</a></li>
<li class="chapter" data-level="3.3.10" data-path="topical.html"><a href="topical.html#workflow-metaanalysis"><i class="fa fa-check"></i><b>3.3.10</b> Meta Analysis</a></li>
<li class="chapter" data-level="3.3.11" data-path="topical.html"><a href="topical.html#workflow-modelconfig"><i class="fa fa-check"></i><b>3.3.11</b> Model Configuration</a></li>
<li class="chapter" data-level="3.3.12" data-path="topical.html"><a href="topical.html#workflow-modelrun"><i class="fa fa-check"></i><b>3.3.12</b> Run Execution</a></li>
<li class="chapter" data-level="3.3.13" data-path="topical.html"><a href="topical.html#workflow-postrun"><i class="fa fa-check"></i><b>3.3.13</b> Post Run Analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="topical.html"><a href="topical.html#pecan-models"><i class="fa fa-check"></i><b>3.4</b> PEcAn Models</a><ul>
<li class="chapter" data-level="3.4.1" data-path="topical.html"><a href="topical.html#models-biocro"><i class="fa fa-check"></i><b>3.4.1</b> BioCro</a></li>
<li class="chapter" data-level="3.4.2" data-path="topical.html"><a href="topical.html#models-clm"><i class="fa fa-check"></i><b>3.4.2</b> CLM</a></li>
<li class="chapter" data-level="3.4.3" data-path="topical.html"><a href="topical.html#models-dalec"><i class="fa fa-check"></i><b>3.4.3</b> DALEC</a></li>
<li class="chapter" data-level="3.4.4" data-path="topical.html"><a href="topical.html#models-ed"><i class="fa fa-check"></i><b>3.4.4</b> ED2</a></li>
<li class="chapter" data-level="3.4.5" data-path="topical.html"><a href="topical.html#introduction-1"><i class="fa fa-check"></i><b>3.4.5</b> Introduction</a></li>
<li class="chapter" data-level="3.4.6" data-path="topical.html"><a href="topical.html#pecan-configuration-file-additions"><i class="fa fa-check"></i><b>3.4.6</b> PEcAn configuration file additions</a></li>
<li class="chapter" data-level="3.4.7" data-path="topical.html"><a href="topical.html#models-ed-pft-configuration"><i class="fa fa-check"></i><b>3.4.7</b> PFT configuration in ED2</a></li>
<li class="chapter" data-level="3.4.8" data-path="topical.html"><a href="topical.html#model-specific-input-files"><i class="fa fa-check"></i><b>3.4.8</b> Model specific input files</a></li>
<li class="chapter" data-level="3.4.9" data-path="topical.html"><a href="topical.html#model-configuration-files"><i class="fa fa-check"></i><b>3.4.9</b> Model configuration files</a></li>
<li class="chapter" data-level="3.4.10" data-path="topical.html"><a href="topical.html#installation-notes"><i class="fa fa-check"></i><b>3.4.10</b> Installation notes</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="topical.html"><a href="topical.html#models-gday"><i class="fa fa-check"></i><b>3.5</b> GDAY</a><ul>
<li class="chapter" data-level="3.5.1" data-path="topical.html"><a href="topical.html#models-linkages"><i class="fa fa-check"></i><b>3.5.1</b> LINKAGES</a></li>
<li class="chapter" data-level="3.5.2" data-path="topical.html"><a href="topical.html#models-lpjguess"><i class="fa fa-check"></i><b>3.5.2</b> LPJ-GUESS</a></li>
<li class="chapter" data-level="3.5.3" data-path="topical.html"><a href="topical.html#models-maespa"><i class="fa fa-check"></i><b>3.5.3</b> MAESPA</a></li>
<li class="chapter" data-level="3.5.4" data-path="topical.html"><a href="topical.html#models-preles"><i class="fa fa-check"></i><b>3.5.4</b> PRELES</a></li>
<li class="chapter" data-level="3.5.5" data-path="topical.html"><a href="topical.html#models-sipnet"><i class="fa fa-check"></i><b>3.5.5</b> SiPNET</a></li>
<li class="chapter" data-level="3.5.6" data-path="topical.html"><a href="topical.html#download-gfdl"><i class="fa fa-check"></i><b>3.5.6</b> Download GFDL</a></li>
<li class="chapter" data-level="3.5.7" data-path="topical.html"><a href="topical.html#cm3"><i class="fa fa-check"></i><b>3.5.7</b> CM3</a></li>
<li class="chapter" data-level="3.5.8" data-path="topical.html"><a href="topical.html#esm2m-esm2g"><i class="fa fa-check"></i><b>3.5.8</b> ESM2M &amp; ESM2G</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="topical.html"><a href="topical.html#available-meteorological-drivers"><i class="fa fa-check"></i><b>3.6</b> Available Meteorological Drivers</a><ul>
<li class="chapter" data-level="3.6.1" data-path="topical.html"><a href="topical.html#ameriflux"><i class="fa fa-check"></i><b>3.6.1</b> Ameriflux</a></li>
<li class="chapter" data-level="3.6.2" data-path="topical.html"><a href="topical.html#amerifluxlbl"><i class="fa fa-check"></i><b>3.6.2</b> AmerifluxLBL</a></li>
<li class="chapter" data-level="3.6.3" data-path="topical.html"><a href="topical.html#fluxnet2015"><i class="fa fa-check"></i><b>3.6.3</b> Fluxnet2015</a></li>
<li class="chapter" data-level="3.6.4" data-path="topical.html"><a href="topical.html#narr"><i class="fa fa-check"></i><b>3.6.4</b> NARR</a></li>
<li class="chapter" data-level="3.6.5" data-path="topical.html"><a href="topical.html#cruncep"><i class="fa fa-check"></i><b>3.6.5</b> CRUNCEP</a></li>
<li class="chapter" data-level="3.6.6" data-path="topical.html"><a href="topical.html#cmip5"><i class="fa fa-check"></i><b>3.6.6</b> CMIP5</a></li>
<li class="chapter" data-level="3.6.7" data-path="topical.html"><a href="topical.html#nldas"><i class="fa fa-check"></i><b>3.6.7</b> NLDAS</a></li>
<li class="chapter" data-level="3.6.8" data-path="topical.html"><a href="topical.html#gldas"><i class="fa fa-check"></i><b>3.6.8</b> GLDAS</a></li>
<li class="chapter" data-level="3.6.9" data-path="topical.html"><a href="topical.html#paleon"><i class="fa fa-check"></i><b>3.6.9</b> PalEON</a></li>
<li class="chapter" data-level="3.6.10" data-path="topical.html"><a href="topical.html#fluxnetlathuile"><i class="fa fa-check"></i><b>3.6.10</b> FluxnetLaThuile</a></li>
<li class="chapter" data-level="3.6.11" data-path="topical.html"><a href="topical.html#geostreams"><i class="fa fa-check"></i><b>3.6.11</b> Geostreams</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="topical.html"><a href="topical.html#database-synchronization"><i class="fa fa-check"></i><b>3.7</b> Database synchronization</a><ul>
<li class="chapter" data-level="3.7.1" data-path="topical.html"><a href="topical.html#how-does-it-work"><i class="fa fa-check"></i><b>3.7.1</b> How does it work?</a></li>
<li class="chapter" data-level="3.7.2" data-path="topical.html"><a href="topical.html#set-up"><i class="fa fa-check"></i><b>3.7.2</b> Set up</a></li>
<li class="chapter" data-level="3.7.3" data-path="topical.html"><a href="topical.html#fetch-latest-data"><i class="fa fa-check"></i><b>3.7.3</b> Fetch latest data</a></li>
<li class="chapter" data-level="3.7.4" data-path="topical.html"><a href="topical.html#sharing-data"><i class="fa fa-check"></i><b>3.7.4</b> Sharing data</a></li>
<li class="chapter" data-level="3.7.5" data-path="topical.html"><a href="topical.html#automation"><i class="fa fa-check"></i><b>3.7.5</b> Automation</a></li>
<li class="chapter" data-level="3.7.6" data-path="topical.html"><a href="topical.html#database-maintentance"><i class="fa fa-check"></i><b>3.7.6</b> Database maintentance</a></li>
<li class="chapter" data-level="3.7.7" data-path="topical.html"><a href="topical.html#troubleshooting-3"><i class="fa fa-check"></i><b>3.7.7</b> Troubleshooting</a></li>
<li class="chapter" data-level="3.7.8" data-path="topical.html"><a href="topical.html#network-status-map"><i class="fa fa-check"></i><b>3.7.8</b> Network Status Map</a></li>
<li class="chapter" data-level="3.7.9" data-path="topical.html"><a href="topical.html#tasks"><i class="fa fa-check"></i><b>3.7.9</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="topical.html"><a href="topical.html#standalone-tools-modules"><i class="fa fa-check"></i><b>3.8</b> Standalone tools (modules)</a><ul>
<li class="chapter" data-level="3.8.1" data-path="topical.html"><a href="topical.html#LoadData"><i class="fa fa-check"></i><b>3.8.1</b> Loading Data in PEcAn</a></li>
<li class="chapter" data-level="3.8.2" data-path="topical.html"><a href="topical.html#function-load_data"><i class="fa fa-check"></i><b>3.8.2</b> Function <code>load_data</code></a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="topical.html"><a href="topical.html#using-the-pecan-download.file-function"><i class="fa fa-check"></i><b>3.9</b> Using the PEcAn download.file() function</a></li>
<li class="chapter" data-level="3.10" data-path="topical.html"><a href="topical.html#shiny"><i class="fa fa-check"></i><b>3.10</b> SHINY</a><ul>
<li class="chapter" data-level="3.10.1" data-path="topical.html"><a href="topical.html#debugging-shiny-apps"><i class="fa fa-check"></i><b>3.10.1</b> Debugging Shiny Apps</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="topical.html"><a href="topical.html#debugging"><i class="fa fa-check"></i><b>3.11</b> Debugging</a><ul>
<li class="chapter" data-level="3.11.1" data-path="topical.html"><a href="topical.html#using-testsworkflow.r"><i class="fa fa-check"></i><b>3.11.1</b> Using <code>tests/workflow.R</code></a></li>
<li class="chapter" data-level="3.11.2" data-path="topical.html"><a href="topical.html#useful-scripts"><i class="fa fa-check"></i><b>3.11.2</b> Useful scripts</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="topical.html"><a href="topical.html#troubleshooting-pecan"><i class="fa fa-check"></i><b>3.12</b> Troubleshooting PEcAn</a><ul>
<li class="chapter" data-level="3.12.1" data-path="topical.html"><a href="topical.html#cookies-and-pecan-web-pages"><i class="fa fa-check"></i><b>3.12.1</b> Cookies and pecan web pages</a></li>
<li class="chapter" data-level="3.12.2" data-path="topical.html"><a href="topical.html#warning-mkdir-function.mkdir-no-such-file-or-directory"><i class="fa fa-check"></i><b>3.12.2</b> <code>Warning: mkdir() [function.mkdir]: No such file or directory</code></a></li>
<li class="chapter" data-level="3.12.3" data-path="topical.html"><a href="topical.html#after-creating-a-new-pft-the-tag-for-pft-not-passed-to-config.xml-in-ed"><i class="fa fa-check"></i><b>3.12.3</b> After creating a new PFT the <num> tag for PFT not passed to config.xml in ED</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="topical.html"><a href="topical.html#pecan-project-use-to-teach-ecological-model-data-synthesis"><i class="fa fa-check"></i><b>3.13</b> PEcAn Project use to teach Ecological model-data synthesis</a><ul>
<li class="chapter" data-level="3.13.1" data-path="topical.html"><a href="topical.html#university-classes"><i class="fa fa-check"></i><b>3.13.1</b> University classes</a></li>
<li class="chapter" data-level="3.13.2" data-path="topical.html"><a href="topical.html#summer-courses-workshops"><i class="fa fa-check"></i><b>3.13.2</b> Summer Courses / Workshops</a></li>
<li class="chapter" data-level="3.13.3" data-path="topical.html"><a href="topical.html#selected-publications"><i class="fa fa-check"></i><b>3.13.3</b> Selected Publications</a></li>
</ul></li>
<li class="chapter" data-level="3.14" data-path="topical.html"><a href="topical.html#rabbitmq"><i class="fa fa-check"></i><b>3.14</b> RabbitMQ</a><ul>
<li class="chapter" data-level="3.14.1" data-path="topical.html"><a href="topical.html#rabbitmq-basics-sender"><i class="fa fa-check"></i><b>3.14.1</b> Producer – <code>sender.py</code></a></li>
<li class="chapter" data-level="3.14.2" data-path="topical.html"><a href="topical.html#rabbitmq-basics-receiver"><i class="fa fa-check"></i><b>3.14.2</b> Consumer – <code>receiver.py</code></a></li>
<li class="chapter" data-level="3.14.3" data-path="topical.html"><a href="topical.html#rabbitmq-web"><i class="fa fa-check"></i><b>3.14.3</b> RabbitMQ and the PEcAn web interface</a></li>
<li class="chapter" data-level="3.14.4" data-path="topical.html"><a href="topical.html#rabbitmq-xml"><i class="fa fa-check"></i><b>3.14.4</b> RabbitMQ in the PEcAn XML</a></li>
<li class="chapter" data-level="3.14.5" data-path="topical.html"><a href="topical.html#rabbitmq-dockerfile"><i class="fa fa-check"></i><b>3.14.5</b> RabbitMQ configuration in Dockerfiles</a></li>
<li class="chapter" data-level="3.14.6" data-path="topical.html"><a href="topical.html#rabbitmq-case-study"><i class="fa fa-check"></i><b>3.14.6</b> Case study: PEcAn web interface</a></li>
</ul></li>
<li class="chapter" data-level="3.15" data-path="topical.html"><a href="topical.html#database"><i class="fa fa-check"></i><b>3.15</b> BETY Database Administration</a><ul>
<li class="chapter" data-level="3.15.1" data-path="topical.html"><a href="topical.html#database-setup"><i class="fa fa-check"></i><b>3.15.1</b> Best practices</a></li>
<li class="chapter" data-level="3.15.2" data-path="topical.html"><a href="topical.html#backup-of-bety-database"><i class="fa fa-check"></i><b>3.15.2</b> Backup of BETY database</a></li>
<li class="chapter" data-level="3.15.3" data-path="topical.html"><a href="topical.html#restore-of-bety-database"><i class="fa fa-check"></i><b>3.15.3</b> Restore of BETY database</a></li>
</ul></li>
<li class="chapter" data-level="3.16" data-path="topical.html"><a href="topical.html#workflow-modules"><i class="fa fa-check"></i><b>3.16</b> Workflow modules</a><ul>
<li class="chapter" data-level="3.16.1" data-path="topical.html"><a href="topical.html#overview"><i class="fa fa-check"></i><b>3.16.1</b> Overview</a></li>
<li class="chapter" data-level="3.16.2" data-path="topical.html"><a href="topical.html#load-settings"><i class="fa fa-check"></i><b>3.16.2</b> Load Settings:</a></li>
<li class="chapter" data-level="3.16.3" data-path="topical.html"><a href="topical.html#query-database"><i class="fa fa-check"></i><b>3.16.3</b> Query Database:</a></li>
<li class="chapter" data-level="3.16.4" data-path="topical.html"><a href="topical.html#meta-analysis"><i class="fa fa-check"></i><b>3.16.4</b> Meta Analysis:</a></li>
<li class="chapter" data-level="3.16.5" data-path="topical.html"><a href="topical.html#write-configuration-files"><i class="fa fa-check"></i><b>3.16.5</b> Write Configuration Files</a></li>
<li class="chapter" data-level="3.16.6" data-path="topical.html"><a href="topical.html#start-runs"><i class="fa fa-check"></i><b>3.16.6</b> Start Runs:</a></li>
<li class="chapter" data-level="3.16.7" data-path="topical.html"><a href="topical.html#get-model-output"><i class="fa fa-check"></i><b>3.16.7</b> Get Model Output</a></li>
<li class="chapter" data-level="3.16.8" data-path="topical.html"><a href="topical.html#ensemble-analysis"><i class="fa fa-check"></i><b>3.16.8</b> Ensemble Analysis</a></li>
<li class="chapter" data-level="3.16.9" data-path="topical.html"><a href="topical.html#sensitivity-analysis-variance-decomposition"><i class="fa fa-check"></i><b>3.16.9</b> Sensitivity Analysis, Variance Decomposition</a></li>
<li class="chapter" data-level="3.16.10" data-path="topical.html"><a href="topical.html#glossary"><i class="fa fa-check"></i><b>3.16.10</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="3.17" data-path="topical.html"><a href="topical.html#data-assimilation-with-dart"><i class="fa fa-check"></i><b>3.17</b> Data assimilation with DART</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>4</b> Appendix</a><ul>
<li class="chapter" data-level="4.1" data-path="appendix.html"><a href="appendix.html#faq"><i class="fa fa-check"></i><b>4.1</b> FAQ</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Predictive Ecosystem Analyzer</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tutorialsdemos-and-how-tos" class="section level1">
<h1><span class="header-section-number">2</span> Tutorials,Demos and How To’s</h1>

<div id="pecan-manual-setup" class="section level2">
<h2><span class="header-section-number">2.1</span> Install PEcAn</h2>
<p>These instructions are provided to document how to install and setup PEcAn. It includes:</p>
<ul>
<li><a href="tutorialsdemos-and-how-tos.html#pecanvm">Installing and maintaining the PEcAn VM</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#docker-index">PEcAn Docker</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#osinstall">PEcAn OS specific installation</a></li>
</ul>
<p>The PEcAn code and necessary infrastructure can be obtained and compiled in different ways. This set of instructions will help facilitate your path and the steps necessary to move forward to have a fully a functioning PEcAn environment.</p>

<div id="pecanvm" class="section level3">
<h3><span class="header-section-number">2.1.1</span> PEcAn Virtual Machine</h3>
<p>This section includes the following VM related documentation:
<a href="tutorialsdemos-and-how-tos.html#maintain-vm">Maintaining your PEcAn VM</a>
<a href="tutorialsdemos-and-how-tos.html#ssh-vm">Connecting to the VM via SSH</a>
<a href="tutorialsdemos-and-how-tos.html#ssh-vm-bety">Connecting to bety on the VM via SSh</a>
<a href="tutorialsdemos-and-how-tos.html#awsvm">Using Amazon Web Services for a VM (AWS)</a>
<a href="tutorialsdemos-and-how-tos.html#createvm">Creating a Virtual Machine</a>
<a href="tutorialsdemos-and-how-tos.html#vm-dektop-conversion">VM Desktop Conversion</a>
<a href="tutorialsdemos-and-how-tos.html#install-rstudio">Install RStudio Desktop</a></p>
<p>The PEcAn virtual machine consists of all of PEcAn pre-compiled within a Linux operating system and saved in a “virtual machine” (VM). Virtual machines allow for running consistent set-ups without worrying about differences between operating systems, library dependencies, compiling the code, etc.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Install VirtualBox</strong> This is the software that runs the virtual machine. You can find the download link and instructions at <a href="http://www.virtualbox.org" class="uri">http://www.virtualbox.org</a>. <em>NOTE: On Windows you may see a warning about Logo testing, it is okay to ignore the warning.</em></p></li>
<li><p><strong>Download the PEcAn VM</strong> You can find the download link at <a href="http://opensource.ncsa.illinois.edu/projects/artifacts.php?key=PECAN" class="uri">http://opensource.ncsa.illinois.edu/projects/artifacts.php?key=PECAN</a>, under the “<strong>Files</strong>” header. Click the “.ova” file to begin the download. Note that the file is ~7 GB, so this download can take several minutes to hours depending on your connection speed. Also, the VM requires &gt;4 GB of RAM to operate correctly. Please check current usage of RAM and shutdown processes as needed.</p></li>
<li><p><strong>Import the VM</strong> Once the download is complete, open VirtualBox. In the VirtualBox menus, go to “File” → “Import Appliance” and locate the downloaded “.ova” file.</p></li>
</ol>
<p>For Virtualbox version 5.x: In the Appliance Import Settings, make sure you select “Reinitialize the MAC address of all network cards” (picture below). This is not selected by default and can result in networking issues since multiple machines might claim to have the same network MAC Address.</p>
<p><img src="figures/pic1.jpg" width="259" style="display: block; margin: auto;" /></p>
<p>For Virtualbox versions starting with 6.0, there is a slightly different interface (see figure). Select “Generate new MAC addresses for all network adapters” from the MAC Address Policy:</p>
<p><img src="figures/pic1v2.png" width="510" style="display: block; margin: auto;" /></p>
<p>NOTE: If you experience network connection difficulties in the VM with this enabled, try re-importing the VM without this setting selected).</p>
<p>Finally, click “Import” to build the Virtual Machine from its image.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Launch PEcAn</strong> Double click the icon for the PEcAn VM. A terminal window will pop up showing the machine booting up which may take a minute. It is done booting when you get to the <code>pecan login:</code> prompt. You do not need to login as the VM behaves like a server that we will be accessing through you web browser. Feel free to minimize the VM window.</li>
</ol>
<ul>
<li>If you <em>do</em> want to login to the VM, the credentials are as follows: <code>username: carya</code>, <code>password: illinois</code> (after the pecan tree, [Carya illinoinensis][pecan-wikipedia]).</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li><strong>Open the PEcAn web interface</strong> With the VM running in the background, open any web browser on the same machine and navigate to <code>localhost:6480/pecan/</code> to start the PEcAn workflow. (NOTE: The trailing backslash may be necessary depending on your browser)</li>
</ol>
<ul>
<li>To ssh into the VM, open up a terminal on your machine and execute <code>ssh -l carya -p 6422 localhost</code>. Username and password are the same as when you log into the machine.</li>
</ul>
<div id="maintain-vm" class="section level4">
<h4><span class="header-section-number">2.1.1.1</span> Maintaining your PEcAn VM</h4>
<p>The PEcAn VM is distributed with specific versions of PEcAn compiled. However, you do not need to constantly download the VM in order to update your code and verion of BETY. To update and maintain your code you can follow the steps found in the Developer section in <span id="updatepecan">Updating PecAn and Code and BETY Database</span></p>
</div>
<div id="working-with-vm" class="section level4">
<h4><span class="header-section-number">2.1.1.2</span> Working with the VM</h4>
</div>
<div id="ssh-vm" class="section level4">
<h4><span class="header-section-number">2.1.1.3</span> Connecting to the VM via SSH</h4>
<p>Once the VM is running anywhere on your machine, you can connect to it from a separate terminal via SSH as follows:</p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">ssh</span> -p 6422 carya@localhost</code></pre>
<p>You will be prompted for a password. Like everywhere else in PEcAn, the username is <code>carya</code> and the password is <code>illinois</code>. The same password is used for any system maintenance you wish to do on the VM via <code>sudo</code>.</p>
<p>As a shortcut, you can add the following to your <code>~/.ssh/config</code> file (or create one if it does not exist).</p>
<pre><code>Host pecan-vm
    Hostname localhost
    Port 6422
    user carya
    ForwardX11Trusted yes</code></pre>
<p>This will allow you to SSH into the VM with the simplified command, <code>ssh pecan-vm</code>.</p>
</div>
<div id="ssh-vm-bety" class="section level4">
<h4><span class="header-section-number">2.1.1.4</span> Connecting to bety on the VM via SSh</h4>
<p>Sometimes, you may want to develop code locally but connect to an instance of Bety on the VM.
To do this, first open a new terminal and connect to the VM while enabling port forwarding (with the <code>-L</code> flag) and setting XXXX to any available port (more or less any 4 digit number – a reasonable choice is 3333).</p>
<pre><code>ssh -L XXXX:localhost:5432 carya@localhost:6422</code></pre>
<p>This makes port XXXX on the local machine match port 5432 on the VM.
This means that connecting to <code>localhost:XXXX</code> will give you access to Bety on the VM.</p>
<p>To test this on the command line, try the following command, which, if successful, will drop you into the <code>psql</code> console.</p>
<pre><code>psql -d bety -U bety -h localhost -p XXXX</code></pre>
<p>To test this in R, open a Postgres using the analogous parameters:</p>
<pre><code>library(RPostgres)
con &lt;- dbConnect(
  Postgres(),
  user = &quot;bety&quot;,
  password = &quot;bety&quot;,
  dbname = &quot;bety&quot;,
  host = &quot;localhost&quot;,
  port = XXXX
  )
dbListTables(con)   # This should return a vector of bety tables</code></pre>
<p>Note that the same general approach will work on any Bety server where port forwarding is enabled.</p>
</div>
<div id="awsvm" class="section level4">
<h4><span class="header-section-number">2.1.1.5</span> Using Amazon Web Services for a VM (AWS)</h4>
<p>Login to <a href="http://console.aws.amazon.com/">Amazon Web Services (AWS)</a> and select the EC2 Dashboard. If this is your first time using AWS you will need to set up an account before you are able to access the EC2 Dashboard. Important: You will need a credit card number and access to a phone to be able to verify AWS account registration. AWS is free for one year.</p>
<ol style="list-style-type: decimal">
<li>Choose AMI</li>
</ol>
<ul>
<li>On the top right next to your name, make sure the location setting is on U.S. East (N. Virginia), not U.S. West (Oregon)</li>
<li>On the left click, click on EC2 (Virtual servers), then click on “AMIs”, also on the left</li>
<li>In the search window toggle to change “Owned by me” to “Public images”</li>
<li>Type “pecan” into the search window</li>
<li>Click on the toggle button on the left next to PEcAn1.4.6</li>
<li>Click on the “Launch” button at the top</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Choose an Instance Type</li>
</ol>
<ul>
<li>Select what type of machine you want to run. For this demo the default, t2.micro, will be adequate. Be aware that different machine types incur very different costs, from 1.3 cents/hour to over $5/hr <a href="https://aws.amazon.com/ec2/pricing/" class="uri">https://aws.amazon.com/ec2/pricing/</a><br />
</li>
<li>Select t2.micro, then click “Next: Configure Instance Details”</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Configure Instance Details</li>
</ol>
<ul>
<li>The defaults are OK. Click “Next: Add Storage”</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Add Storage</li>
</ol>
<ul>
<li>The defaults are OK. Click “Next: Tag Instance”</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Tag Instance</li>
</ol>
<ul>
<li>You can name your instance if you want. Click “Next: Configure Security Group”</li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>Configure Security Group</li>
</ol>
<ul>
<li>You will need to add two new rules:</li>
<li>Click “Add Rule” then select “HTTP” from the pull down menu. This rule allows you to access the webserver on PEcAn.</li>
<li>Click “Add Rule”, leave the pull down on “Custom TCP Rule”, and then change the Port Range from 0 to 8787. Set “Source” to Anywhere. This rule allows you to access RStudio Server on PEcAn.</li>
<li>Click “Review and Launch” . You will then see this pop-up:</li>
</ul>
<p><img src="figures/pic2.jpg" width="343" style="display: block; margin: auto;" /></p>
<p>Select the default drive volume type and click Next</p>
<ol start="7" style="list-style-type: decimal">
<li>Review and Launch</li>
</ol>
<ul>
<li>Review the settings and then click “Launch”, which will pop up a select/create Key Pair window.</li>
</ul>
<ol start="8" style="list-style-type: decimal">
<li>Key Pair</li>
</ol>
<ul>
<li>Select “Create a new key pair” and give it a name. You won’t actually need this key unless you need to SSH into your PEcAn server, but AWS requires you to create one. Click on “Download Key Pair” then on “Launch Instances”. Next click on “View Instances” at the bottom of the following page.</li>
</ul>
<p><img src="figures/pic3.jpg" width="682" style="display: block; margin: auto;" /></p>
<ol start="9" style="list-style-type: decimal">
<li>Instances</li>
</ol>
<ul>
<li>You will see the status of your PEcAn VM, which will take a minute to boot up. Wait until the Instance State reads “running”. The most important piece of information here is the Public IP, which is the URL you will need in order to access your PEcAn instance from within your web browser (see Demo 1 below).</li>
<li>Be aware that it often takes ~1 hr for AWS instances to become fully operational, so if you get an error when you put the Public IP in you web browser, most of the time you just need to wait a bit longer.
Congratulations! You just started a PEcAn server in the “cloud”!</li>
</ul>
<ol start="10" style="list-style-type: decimal">
<li>When you are done using PEcAn, you will want to return to the “Instances” menu to turn off your VM.</li>
</ol>
<ul>
<li>To STOP the instance (which will turn the machine off but keep your work), select your PEcAn instance and click Actions &gt; Instance state &gt; Stop. Be aware that a stopped instance will still accrue a small storage cost on AWS. To restart this instance at any point in the future you do not want to repeat all the steps above, but instead you just need to select your instance and then click Actions &gt; Instance state &gt; Start</li>
<li>To TERMINATE the instance (which will DELETE your PEcAn machine), select your instance and click Actions &gt; Instance state &gt; Terminate. Terminated instances will not incur costs. In most cases you will also want to go to the Volumes menu and delete the storage associated with your PEcAn VM.Remember, AWS is free for one year, but will automatically charge a fee in second year if account is not cancelled.</li>
</ul>
</div>
<div id="createvm" class="section level4">
<h4><span class="header-section-number">2.1.1.6</span> Creating a Virtual Machine</h4>
<p>First create virtual machine</p>
<pre><code># ----------------------------------------------------------------------
# CREATE VM USING FOLLOWING:
# - VM NAME  = PEcAn
# - CPU      = 2
# - MEMORY   = 2GB 
# - DISK     = 100GB
# - HOSTNAME = pecan
# - FULLNAME = PEcAn Demo User
# - USERNAME = xxxxxxx
# - PASSWORD = yyyyyyy
# - PACKAGE  = openssh
# ----------------------------------------------------------------------</code></pre>
<p>To enable tunnels run the following on the host machine:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">VBoxManage</span> modifyvm <span class="st">&quot;PEcAn&quot;</span> --natpf1 <span class="st">&quot;ssh,tcp,,6422,,22&quot;</span>
<span class="ex">VBoxManage</span> modifyvm <span class="st">&quot;PEcAn&quot;</span> --natpf1 <span class="st">&quot;www,tcp,,6480,,80&quot;</span></code></pre>
<p>Make sure machine is up to date.</p>
<p>UBUNTU</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> apt-get update
<span class="fu">sudo</span> apt-get -y dist-upgrade
<span class="fu">sudo</span> reboot</code></pre>
<p>CENTOS/REDHAT</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> yum -y update
<span class="fu">sudo</span> reboot</code></pre>
<p>Install compiler and other packages needed and install the tools.</p>
<p>UBUNTU</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> apt-get -y install build-essential linux-headers-server dkms</code></pre>
<p>CENTOS/REDHAT</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> yum -y groupinstall <span class="st">&quot;Development Tools&quot;</span>
<span class="fu">sudo</span> yum -y install wget</code></pre>
<p>Install Virtual Box additions for better integration</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> mount /dev/cdrom /mnt
<span class="fu">sudo</span> /mnt/VBoxLinuxAdditions.run
<span class="fu">sudo</span> umount /mnt
<span class="fu">sudo</span> usermod -a -G vboxsf carya</code></pre>
<p><strong>Finishing up the machine</strong></p>
<p><strong>Add a message to the login:</strong></p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> -s
<span class="bu">export</span> <span class="va">PORT=$(</span> <span class="fu">hostname</span> <span class="kw">|</span> <span class="fu">sed</span> <span class="st">&#39;s/pecan//&#39;</span> <span class="va">)</span>
<span class="fu">cat</span> <span class="op">&gt;</span> /etc/motd <span class="op">&lt;&lt; EOF</span>
PEcAn version 1.4.3

For more information about:
Pecan    - http://pecanproject.org
BETY     - http://www.betydb.org

For a list of all models currently navigate [here](../users_guide/basic_users_guide/models_table.md)


You can access this system using a webbrowser at
 http://&lt;hosting machine&gt;:<span class="va">${PORT}</span>80/
or using SSH at
 ssh -l carya -p <span class="va">${PORT}</span>22 &lt;hosting machine&gt;
where &lt;hosting machine&gt; is the machine where the VM runs on.
<span class="op">EOF</span>
<span class="bu">exit</span></code></pre>
<p><strong>Finishing up</strong></p>
<p>Script to clean the VM and remove as much as possible history <a href="http://isda.ncsa.uiuc.edu/~kooper/EBI/cleanvm.sh">cleanvm.sh</a></p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">wget</span> -O ~/cleanvm.sh http://isda.ncsa.uiuc.edu/~kooper/EBI/cleanvm.sh
<span class="fu">chmod</span> 755 ~/cleanvm.sh</code></pre>
<p>Make sure machine has SSH keys <a href="http://isda.ncsa.illinois.edu/~kooper/EBI/rc.local">rc.local</a></p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> wget -O /etc/rc.local http://isda.ncsa.illinois.edu/~kooper/EBI/rc.local</code></pre>
<p>Change the resolution of the console</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> sed -i -e <span class="st">&#39;s/#GRUB_GFXMODE=640x480/GRUB_GFXMODE=1024x768/&#39;</span> /etc/default/grub
<span class="fu">sudo</span> update-grub</code></pre>
<p>Once all done, stop the virtual machine</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">history</span> -c <span class="kw">&amp;&amp;</span> <span class="va">${HOME}</span><span class="ex">/cleanvm.sh</span></code></pre>
</div>
<div id="vm-dektop-conversion" class="section level4">
<h4><span class="header-section-number">2.1.1.7</span> VM Desktop Conversion</h4>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> apt-get update
<span class="fu">sudo</span> apt-get install xfce4 xorg</code></pre>
<p>For a more refined desktop environment, try</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> apt-get install --no-install-recommends xubuntu-desktop </code></pre>
<ul>
<li>replace <code>xubuntu-</code> with <code>ubuntu-</code>, <code>lubuntu-</code>, or other preferred desktop enviornment</li>
<li>the <code>--no-install-recommends</code> eliminates additional applications, removing it will add a word processor, a browser, and lots of other applications included in the default operating system.</li>
</ul>
<p>Reinstall Virtual Box additions for better integration adding X/mouse support</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> mount /dev/cdrom /mnt
<span class="fu">sudo</span> /mnt/VBoxLinuxAdditions.run
<span class="fu">sudo</span> umount /mnt</code></pre>
</div>
<div id="install-rstudio" class="section level4">
<h4><span class="header-section-number">2.1.1.8</span> Install RStudio Desktop</h4>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">wget</span> http://download1.rstudio.org/rstudio-0.97.551-amd64.deb
<span class="ex">apt-get</span> install libjpeg621
<span class="ex">dpkg</span> -i rstudio-*
<span class="fu">rm</span> rstudio-*</code></pre>

</div>
</div>
<div id="docker-index" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Docker</h3>
<p>This chapter describes the PEcAn Docker container infrastructure.
It contains the following sections:</p>
<ul>
<li><a href="tutorialsdemos-and-how-tos.html#docker-intro">Introduction to Docker</a> – Brief introduction to Docker and <code>docker-compose</code></li>
<li><a href="tutorialsdemos-and-how-tos.html#docker-quickstart">Docker quickstart</a> – Brief tutorial for setting up a Docker-based PEcAn instance</li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-docker">PEcAn Docker Architecture</a> – Detailed description of the containers comprising the PEcAn Docker-based infrastructure</li>
<li><a href="tutorialsdemos-and-how-tos.html#model-docker">Dockerfiles for models</a> – General guide for writing Dockerfiles for new models</li>
<li><a href="tutorialsdemos-and-how-tos.html#docker-build-images">Building and modifying images</a></li>
<li><span id="docker-troubleshooting">Troubleshooting Docker</span></li>
<li><a href="tutorialsdemos-and-how-tos.html#docker-migrate">Migrating from VM to Docker</a> – Steps to migrate from running PEcAn on a VM to a docker.</li>
</ul>

<div id="docker-intro" class="section level4">
<h4><span class="header-section-number">2.1.2.1</span> Introduction to Docker?</h4>
<p><a href="tutorialsdemos-and-how-tos.html#what-is-docker">What is Docker</a>
<a href="tutorialsdemos-and-how-tos.html#working-with-docker">Working with Docker</a>
<span id="docker-compose"><code>docker-compose</code></span></p>
</div>
<div id="what-is-docker" class="section level4">
<h4><span class="header-section-number">2.1.2.2</span> What is Docker?</h4>
<p>For a quick and accessible introduction to Docker, we suggest this YouTube video: <a href="https://www.youtube.com/watch?v=YFl2mCHdv24">Learn Docker in 12 Minutes</a>.</p>
<p>For more comprehensive Docker documentation, we refer you to the <a href="https://docs.docker.com/">Docker documentation website</a>.</p>
<p>For a useful analogy for Docker containerization, we refer you to the webcomic <a href="https://xkcd.com/1988/">xkcd</a>.</p>
<p>Docker is a technology for encapsulating software in “containers”, somewhat similarly to virtual machines.
Like virtual machines, Docker containers facilitate software distribution by bundling the software with all of its dependencies in a single location.
Unlike virtual machines, Docker containers are meant to only run a single service or process and are build on top of existing services provided by the host OS (such as disk access, networking, memory management etc.).</p>
<p>In Docker, an <strong>image</strong> refers to a binary snapshot of a piece of software and all of its dependencies.
A <strong>container</strong> refers to a running instance of a particular image.
A good rule of thumb is that each container should be responsible for no more than one running process.
A software <strong>stack</strong> refers to a collection of containers, each responsible for its own process, working together to power a particular application.
Docker makes it easy to run multiple software stacks at the same time in parallel on the same machine.
Stacks can be given a unique name, which is passed along as a prefix to all their containers.
Inside these stacks, containers can communicate using generic names not prefixed with the stack name, making it easy to deploy multiple stacks with the same internal configuration.
Containers within the same stack communicate with each other via a common <strong>network</strong>.
Like virtual machines or system processes, Docker stacks can also be instructed to open specific ports to facilitate communication with the host and other machines.</p>
<p>The PEcAn database BETY provides an instructive case-study.
BETY is comprised of two core processes – a PostgreSQL database, and a web-based front-end to that database (Apache web server with Ruby on Rails).
Running BETY as a “Dockerized” application therefore involves two containers – one for the PostgreSQL database, and one for the web server.
We could build these containers ourselves by starting from a container with nothing but the essentials of a particular operating system, but we can save some time and effort by starting with an <a href="https://hub.docker.com/_/postgres/">existing image for PostgreSQL</a> from Docker Hub.
When starting a Dockerized BETY, we start the PostgreSQL container first, then start the BETY container telling it how to communicate with the PostgreSQL container.
To upgrade an existing BETY instance, we stop the BETY container, download the latest version, tell it to upgrade the database, and re-start the BETY container.
There is no need to install new dependencies for BETY since they are all shipped as part of the container.</p>
<p>The PEcAn Docker architecture is designed to facilitate installation and maintenance on a variety of systems by eliminating the need to install and maintain complex system dependencies (such as PostgreSQL, Apache web server, and Shiny server).
Furthermore, using separate Docker containers for each ecosystem model helps avoid clashes between different software version requirements of different models (e.g. some models require GCC &lt;5.0, while others may require GCC &gt;=5.0).</p>
<p>The full PEcAn Docker stack is described in more detail in the <a href="tutorialsdemos-and-how-tos.html#pecan-docker">next section</a>.</p>
</div>
<div id="working-with-docker" class="section level4">
<h4><span class="header-section-number">2.1.2.3</span> Working with Docker</h4>
<p>To run an image, you can use the Docker command line interface.
For example, the following runs a PostgreSQL image based on the <a href="https://hub.docker.com/r/mdillon/postgis/">pre-existing PostGIS image</a> by <code>mdillon</code>:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> run \
    --detach \
    --rm \
    --name postgresql \
    --network pecan \
    --publish 9876:5432 \
    --volume <span class="va">${PWD}</span>/postgres:/var/lib/postgresql/data \
    mdillon/postgis:9.6-alpine</code></pre>
<p>This will start the PostgreSQL+PostGIS container.
The following options were used:</p>
<ul>
<li><code>--detach</code> makes the container run in the background.</li>
<li><code>--rm</code> removes the container when it is finished (make sure to use the volume below).</li>
<li><code>--name</code> the name of the container, also the hostname of the container which can be used by other docker containers in the same network inside docker.</li>
<li><code>--network pecan</code> the network that the container should be running in, this leverages of network isolation in docker and allows this container to be connected to by others using the postgresql hostname.</li>
<li><code>--publish</code> exposes the port to the outside world, this is like ssh, and maps port 9876 to port 5432 in the docker container</li>
<li><code>--volume</code> maps a folder on your local machine to the machine in the container. This allows you to save data on your local machine.</li>
<li><code>mdillon/postgis:9.6-alpine</code> is the actual image that will be run, in this case it comes from the group/person mdillon, the container is postgis and the version 9.6-alpine (version 9.6 build on alpine linux).</li>
</ul>
<p>Other options that might be used:</p>
<ul>
<li><code>--tty</code> allocate a pseudo-TTY to send stdout and stderr back to the console.</li>
<li><code>--interactive</code> keeps stdin open so the user can interact with the application running.</li>
<li><code>--env</code> sets environment variables, these are often used to change the behavior of the docker container.</li>
</ul>
<p>To see a list of all running containers you can use the following command:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> ps</code></pre>
<p>To see the log files of this container you use the following command (you can either use their name or id as returned by <code>docker ps</code>). The <code>-f</code> flag will follow the <code>stdout</code>/<code>stderr</code> from the container, use <code>Ctrl-C</code> to stop following the <code>stdout</code>/<code>stderr</code>.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> logs -f postgresql</code></pre>
<p>To stop a running container use:</p>
<pre><code>docker stop postgresql</code></pre>
<p>Containers that are running in the foreground (without the <code>--detach</code>) can be stopped by pressing <code>Ctrl-C</code>. Any containers running in the background (with <code>--detach</code>) will continue running until the machine is restarted or the container is stopped using <code>docker stop</code>.</p>
</div>
<div id="docker-compose" class="section level4">
<h4><span class="header-section-number">2.1.2.4</span> <code>docker-compose</code></h4>
<p>For a quick introduction to <code>docker-compose</code>, we recommend the following YouTube video: <a href="https://www.youtube.com/watch?v=Qw9zlE3t8Ko">Docker Compose in 12 Minutes</a>.</p>
<p>The complete <code>docker-compose</code> references can be found on the <a href="https://docs.docker.com/compose/">Docker documentation website</a>.</p>
<p><code>docker-compose</code> provides a convenient way to configure and run a multi-container Docker stack.
Basically, a <code>docker-compose</code> setup consists of a list of containers and their configuration parameters, which are then internally converted into a bunch of <code>docker</code> commands.
To configure BETY as described above, we can use a <code>docker-compose.yml</code> file like the following:</p>
<pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="fu">version:</span><span class="at"> </span><span class="st">&quot;3&quot;</span>
<span class="fu">services:</span>
  <span class="fu">postgres:</span>
    <span class="fu">image:</span><span class="at"> mdillon/postgis:9.5</span>
  <span class="fu">bety:</span>
    <span class="fu">image:</span><span class="at"> pecan/bety</span>
    <span class="fu">depends_on:</span>
      <span class="kw">-</span> postgres</code></pre>
<p>This simple file allows us to bring up a full BETY application with both database and BETY application. The BETY app will not be brought up until the database container has started.</p>
<p>You can now start this application by changing into the same directory as the <code>docker-compose.yml</code> file (<code>cd /path/to/file</code>) and then running:</p>
<pre><code>docker-compose up</code></pre>
<p>This will start the application, and you will see the log files for the 2 different containers.</p>

</div>
<div id="docker-quickstart" class="section level4">
<h4><span class="header-section-number">2.1.2.5</span> Quickstart for Docker and PEcAn</h4>
<p>This is a short documentation on how to start with Docker and PEcAn. This will not go into much detail about about how to use docker.</p>
<p><a href="tutorialsdemos-and-how-tos.html#install-docker">Install Docker</a>
<a href="tutorialsdemos-and-how-tos.html#curl-model-runs">Start model runs using curl</a>
<a href="tutorialsdemos-and-how-tos.html#pecan-setup-compose">Setup PEcAn using docker-compose</a>
<a href="tutorialsdemos-and-how-tos.html#pecan-docker-quickstart-init">Initialize the PEcAn database (first time only)</a>
<a href="tutorialsdemos-and-how-tos.html#start-pecan">Start PEcAn</a></p>
</div>
<div id="install-docker" class="section level4">
<h4><span class="header-section-number">2.1.2.6</span> Install Docker</h4>
<p>You will need to install docker first. See <a href="https://www.docker.com/community-edition#/download" class="uri">https://www.docker.com/community-edition#/download</a></p>
<p>Once Docker is installed, make sure it is running.
To test that Docker is installed and running, open a terminal and run the following commands:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> run hello-world</code></pre>
<p>If successful, this should return a message starting with <code>&quot;Hello from Docker!&quot;</code>.
If this doesn’t work, there is something wrong with your configuration.
Refer to the Docker documentation for debugging.</p>
<p>NOTE: Depending on how Docker is installed and configured, you may have to run this command as <code>sudo</code>.
Try running the command without <code>sudo</code> first.
If that fails, but running as <code>sudo</code> succeeds, see <a href="https://docs.docker.com/install/linux/linux-postinstall/">these instructions</a> for steps to use Docker as a non-root user.</p>
</div>
<div id="pecan-setup-compose" class="section level4">
<h4><span class="header-section-number">2.1.2.7</span> Setup PEcAn using docker-compose</h4>
<p>The PEcAn Docker stack is configured using a <code>docker-compose.yml</code> file (see also <a href="tutorialsdemos-and-how-tos.html#docker-compose"><code>docker-compose</code></a>).
If you cloned the PEcAn source from GitHub, you can find this file in the root directory of the repository.
Alternatively, if you do not want to clone the PEcAn source, you can download just this file directly from GitHub <a href="https://github.com/PecanProject/pecan/blob/develop/docker-compose.yml">here</a>. (NOTE that this is the latest, <code>develop</code> branch version. If you want a specific release, you should change the branch accordingly.).</p>
<p>The following instructions assume you are in the same directory as the file (if not, <code>cd</code> into it) and that the file is called <code>docker-compose.yml</code>.
The <code>docker-compose</code> commands assume this.
If you want to explicitly point <code>docker-compose</code> to a specific file, you can do so by calling all commands as <code>docker-compose -f /path/to/my-docker-compose.yml ...other options...</code>.
(NOTE that this <code>-f</code> option must go <em>immediately</em> after <code>docker-compose</code>. More generally, <code>docker-compose</code> options are very sensitive to their location relative to other commands in the same line – that is, <code>docker-compose -f /my/docker-compose.yml -p pecan up -d postgres</code> is <em>not</em> the same as <code>docker-compose -d postgres -p pecan up -f /my/docker-compose.yml</code>. If expected ever don’t seem to be working, check that the arguments are in the right order.)</p>
</div>
<div id="pecan-docker-quickstart-init" class="section level4">
<h4><span class="header-section-number">2.1.2.8</span> Initialize the PEcAn database (first time only)</h4>
<p>The commands described in this section will set up the PEcAn database (BETY) and pre-load it with some common “default” data.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker-compose</span> -p pecan up -d postgres

<span class="co"># If you have a custom docker-compose file:</span>
<span class="co"># docker-compose -f /path/to/my-docker-compose.yml -p pecan up -d postgres</span></code></pre>
<p>The breakdown of this command is as follows:</p>
<ul>
<li><code>-p pecan</code> – This tells <code>docker-compose</code> to do all of this as part of a “project” <code>-p</code> we’ll call <code>pecan</code>. By default, the project name is set to the name of the current working directory. The project name will be used as a prefix to all containers started by this <code>docker-compose</code> instance (so, if we have a service called <code>postgres</code>, this will create a container called <code>pecan_postgres</code>).</li>
<li><code>up -d</code> – <code>up</code> is a command that initializes the containers. Initialization involves downloading and building the target containers and any containers they depend on, and then running them. Normally, this happens in the foreground, printing logs directly to <code>stderr</code>/<code>stdout</code> (meaning you would have to interrupt it with Ctrl-C), but the <code>-d</code> flag forces this to happen more quietly and in the background.</li>
<li><code>postgres</code> – This indicates that we only want to initialize the service called <code>postgres</code> (and its dependencies). If we omitted this, <code>docker-compose</code> would initialize all containers in the stack.</li>
</ul>
<p>The end result of this command is to initialize a “blank” PostGIS container that will run in the background.
This container is not connected to any data (yet), and is basically analogous to just installing and starting PostgreSQL to your system.
As a side effect, the above command will also create blank data <a href="https://docs.docker.com/storage/volumes/">“volumes”</a> and a <a href="https://docs.docker.com/network/">“network”</a> that containers will use to communicate with each other.
Because our project is called <code>pecan</code> and <code>docker-compose.yml</code> describes a network called <code>pecan</code>, the resulting network is called <code>pecan_pecan</code>.
This is relevant to the following commands, which will actually initialize and populate the BETY database.</p>
<p>Assuming the above ran successfully, next run the following:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> run -ti --rm --network pecan_pecan pecan/bety:latest initialize</code></pre>
<p>The breakdown of this command is as follows: {#docker-run-init}</p>
<ul>
<li><code>docker run</code> – This says we will be running a specific command inside the target Docker container. See <code>docker run --help</code> and the <a href="https://docs.docker.com/engine/reference/run/">Docker run reference</a> for more information.</li>
<li><code>-ti</code> – This is actually two flags, <code>-t</code> to allocate a pseudo-tty and <code>-i</code> to keep STDIN open even if detached. <code>-t</code> is necessary to ensure lower-level script commands run correctly. <code>-i</code> makes sure that the command output (<code>stdin</code>) is displayed.</li>
<li><code>--rm</code> – This automatically removes the resulting container once the specified command exits, as well as any volumes associated with the container. This is useful as a general “clean-up” flag for one-off commands (like this one) to make sure you don’t leave any “zombie” containers or volumes around at the end.</li>
<li><code>--network pecan_pecan</code> – This indicates that the container will use the existing <code>pecan_pecan</code> network. This network is what ensures communication between the <code>postgres</code> container (which, recall, is <em>just</em> a PostGIS installation, and has no data inside it) and the “volumes” where the actual data are persistently stored.</li>
<li><code>pecan/bety:latest</code> – This is the name of the image in which to run the specified command, in the form <code>repository/image:version</code>. This is interpreted as follows:
<ul>
<li>First, it sees if there are any images called <code>pecan/bety:latest</code> available on your local machine. If there are, it uses that one.</li>
<li>If that image version is <em>not</em> available locally, it will next try to find the image online. By default, it searches <a href="https://hub.docker.com/">Docker Hub</a>, such that <code>pecan/bety</code> gets expanded to the container at <code>https://hub.docker.com/r/pecan/bety</code>. For custom repositories, a full name can be given, such as <code>hub.ncsa.illinois.edu/pecan/bety:latest</code>.</li>
<li>If <code>:version</code> is omitted, Docker assumes <code>:latest</code>. NOTE that while online containers <em>should</em> have a <code>:latest</code> version, not all of them do, and if a <code>:latest</code> version does not exist, Docker will be unable to find the image and will throw an error.</li>
</ul></li>
<li>Everything after the image name (here, <code>pecan/bety:latest</code>) is interpreted as an argument to the image’s specified <a href="https://docs.docker.com/engine/reference/builder/#entrypoint">entrypoint</a>. For the <code>pecan/bety</code> image, the entrypoint is the script <a href="https://github.com/PecanProject/bety/blob/master/docker/entrypoint.sh"><code>docker/entrypoint.sh</code></a> located in the BETY repository. Here, the <code>initialize</code> argument is parsed to mean “Create a new database”, which first runs <code>psql</code> commands to create the <code>bety</code> role and database and then runs the <code>load.bety.sh</code> script.
<ul>
<li>NOTE: The entrypoint script that is used is the one copied into the Docker container at the time it was built, which, depending on the indicated image version and how often images are built on Docker Hub relative to updates to the source, may be older than whatever is in the source code.</li>
<li>NOTE: The <code>load.bety.sh</code> script is, somewhat confusingly, located in the <em>PEcAn</em> GitHub repository (<a href="https://github.com/PecanProject/pecan/blob/develop/scripts/load.bety.sh"><code>scripts/load.bety.sh</code></a>), <em>not</em> in the BETY repository. As part of its build process, the BETY image downloads the latest <code>develop</code> version of <code>load.bety.sh</code> from the PEcAn repository and stores it in the root folder of the image. The relevant parts of the Dockerfile are <a href="https://github.com/PecanProject/bety/blob/master/Dockerfile#L33-L36">here</a>. As with <code>entrypoint.sh</code>, note that this script is only updated when the image is re-built, and because the origin is in a different repository, new versions are not built whenever <code>load.bety.sh</code> is updated. This is a <a href="https://github.com/PecanProject/bety/issues/597">known issue</a>.</li>
</ul></li>
</ul>
<p>The above command should produce a bunch of output, some of which may look like errors.
Some of these errors are normal and should not stop the command from completing successfully.
You will know you have encountered more serious errors if the command exits or hangs with output resembling the following:</p>
<pre><code>LINE 1: SELECT count(*) FROM formats WHERE ...
                             ^
Error: Relation `formats` does not exist</code></pre>
<p><strong>If the above command fails</strong>, you can try to fix things interactively by first opening a shell inside the container…</p>
<pre><code>docker run -ti --rm --network pecan_pecan pecan/bety:latest /bin/bash</code></pre>
<p>…and then running the following commands, which emulate the functionality of the <code>entrypoint.sh</code> with the <code>initialize</code> argument.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># Create the bety role in the postgresql database</span>
<span class="ex">psql</span> -h postgres -p 5432 -U postgres -c <span class="st">&quot;CREATE ROLE bety WITH LOGIN CREATEDB NOSUPERUSER NOCREATEROLE PASSWORD &#39;bety&#39;&quot;</span>

<span class="co"># Initialize the bety database itself, and set to be owned by role bety</span>
<span class="ex">psql</span> -h postgres -p 5432 -U postgres -c <span class="st">&quot;CREATE DATABASE bety WITH OWNER bety&quot;</span>

<span class="co"># If either of these fail with a &quot;role/database bety already exists&quot;,</span>
<span class="co"># that&#39;s fine. You can safely proceed to the next command.</span>

<span class="co"># Load the actual bety database tables and values</span>
<span class="ex">./load.bety.sh</span> -a <span class="st">&quot;postgres&quot;</span> -d <span class="st">&quot;bety&quot;</span> -p <span class="st">&quot;-h postgres -p 5432&quot;</span> -o bety -c -u -g -m <span class="va">${LOCAL_SERVER}</span> -r 0 -w https://ebi-forecast.igb.illinois.edu/pecan/dump/all/bety.tar.gz</code></pre>
<p>Note that this command may throw a bunch of errors related to functions and/or operators already existing.
This is normal – it just means that the PostGIS extension to PostgreSQL is already installed.
The important thing is that you see output near the end like:</p>
<pre><code>CREATED SCHEMA
Loading  schema_migrations         : ADDED 61
Started psql (pid=507)
Updated  formats                   :     35 (+35)
Fixed    formats                   : 46
Updated  machines                  :     23 (+23)
Fixed    machines                  : 24
Updated  mimetypes                 :    419 (+419)
Fixed    mimetypes                 : 1095
...
...
...
Added carya41 with access_level=4 and page_access_level=1 with id=323
Added carya42 with access_level=4 and page_access_level=2 with id=325
Added carya43 with access_level=4 and page_access_level=3 with id=327
Added carya44 with access_level=4 and page_access_level=4 with id=329
Added guestuser with access_level=4 and page_access_level=4 with id=331</code></pre>
<p>Once the command has finished successfully, proceed with the next step:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> run -ti --rm --network pecan_pecan --volume pecan_pecan:/data pecan/data:develop</code></pre>
<p>The breakdown of this command is as follows:</p>
<ul>
<li><code>docker run -ti --rm --network pecan_pecan</code> – Same as <a href="#docker-run-init">above</a>.</li>
<li><code>--volume pecan_pecan:/data</code> – This mounts the data from the subsequent container (<code>pecan/data:develop</code>) onto the current project volume, called <code>pecan_pecan</code> (as with the network, the project name <code>pecan</code> is the prefix, and the volume name also happens to be <code>pecan</code> as specified in the <code>docker-compose.yml</code> file).</li>
<li><code>pecan/data:develop</code> – As above, this is the target image to run. Since there is no argument after the image name, this command will run the default command (<a href="https://docs.docker.com/engine/reference/builder/#cmd"><code>CMD</code></a>) specified for this docker container. In this case, it is the <a href="https://github.com/PecanProject/pecan/blob/develop/docker/add-data.sh"><code>docker/add_data.sh</code></a> script from the PEcAn repository.</li>
</ul>
<p>Under the hood, this container runs the <code>docker/add-data.sh</code> script, which downloads a bunch of input files and registers them with the PEcAn database.</p>
<p>Successful execution of this command should take some time because it involves downloading and copying reasonably large amounts of data and performing a number of database operations.</p>
</div>
<div id="start-pecan" class="section level4">
<h4><span class="header-section-number">2.1.2.9</span> Start PEcAn</h4>
<p>If you already completed the above steps, you can start the full stack by just running the following:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker-compose</span> -p pecan up -d</code></pre>
<p>This will build and start all containers required to run PEcAn.
With the <code>-d</code> flag, this will run all of these containers quietly in the background, and show a nice architecture diagram with the name and status of each container while they are starting.
Once this is done you have a working instance of PEcAn.</p>
<p>If all of the containers started successfully, you should be able to access the various components from a browser via the following URLs:</p>
<ul>
<li>PEcAn web interface (running models) – <a href="http://localhost:8000/pecan/" class="uri">http://localhost:8000/pecan/</a> (NOTE: The trailing backslash is necessary.)</li>
<li>PEcAn documentation and home page – <a href="http://localhost:8000/" class="uri">http://localhost:8000/</a></li>
<li>BETY web interface – <a href="http://localhost:8000/bety/" class="uri">http://localhost:8000/bety/</a></li>
<li>File browser (minio) – <a href="http://localhost:8000/minio/" class="uri">http://localhost:8000/minio/</a></li>
<li>RabbitMQ management console (for managing queued processes) – <a href="http://localhost:8000/rabbitmq/" class="uri">http://localhost:8000/rabbitmq/</a></li>
<li>Traefik, webserver showing maps from URLs onto their respective containers – <a href="http://localhost:8001/" class="uri">http://localhost:8001/</a></li>
<li>Monitor, service that monitors models and shows all models that are online as well as how many instances are online and the number of jobs waiting. The output is in JSON – <a href="http://localhost:8000/monitor/" class="uri">http://localhost:8000/monitor/</a></li>
</ul>
</div>
<div id="curl-model-runs" class="section level4">
<h4><span class="header-section-number">2.1.2.10</span> Start model runs using curl</h4>
<p>To test PEcAn you can use the following <code>curl</code> statement, or use the webpage to submit a request:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">curl</span> -v -X POST \
    -F <span class="st">&#39;hostname=docker&#39;</span> \
    -F <span class="st">&#39;modelid=5000000002&#39;</span> \
    -F <span class="st">&#39;sitegroupid=1&#39;</span> \
    -F <span class="st">&#39;siteid=772&#39;</span> \
    -F <span class="st">&#39;sitename=Niwot Ridge Forest/LTER NWT1 (US-NR1)&#39;</span> \
    -F <span class="st">&#39;pft[]=temperate.coniferous&#39;</span> \
    -F <span class="st">&#39;start=2004/01/01&#39;</span> \
    -F <span class="st">&#39;end=2004/12/31&#39;</span> \
    -F <span class="st">&#39;input_met=5000000005&#39;</span> \
    -F <span class="st">&#39;email=&#39;</span> \
    -F <span class="st">&#39;notes=&#39;</span> \
    <span class="st">&#39;http://localhost:8000/pecan/04-runpecan.php&#39;</span></code></pre>
<p>This should return some text with in there <code>Location:</code> this is shows the workflow id, you can prepend <a href="http://localhost:8000/pecan/" class="uri">http://localhost:8000/pecan/</a> to the front of this, for example: <a href="http://localhost:8000/pecan/05-running.php?workflowid=99000000001" class="uri">http://localhost:8000/pecan/05-running.php?workflowid=99000000001</a>. Here you will be able to see the progress of the workflow.</p>
<p>To see what is happening behind the scenes you can use look at the log file of the specific docker containers, once of interest are <code>pecan_executor_1</code> this is the container that will execute a single workflow and <code>pecan_sipnet_1</code> which executes the sipnet mode. To see the logs you use <code>docker logs pecan_executor_1</code> Following is an example output:</p>
<pre><code>2018-06-13 15:50:37,903 [MainThread     ] INFO    : pika.adapters.base_connection - Connecting to 172.18.0.2:5672
2018-06-13 15:50:37,924 [MainThread     ] INFO    : pika.adapters.blocking_connection - Created channel=1
2018-06-13 15:50:37,941 [MainThread     ] INFO    : root -  [*] Waiting for messages. To exit press CTRL+C
2018-06-13 19:44:49,523 [MainThread     ] INFO    : root - b&#39;{&quot;folder&quot;: &quot;/data/workflows/PEcAn_99000000001&quot;, &quot;workflowid&quot;: &quot;99000000001&quot;}&#39;
2018-06-13 19:44:49,524 [MainThread     ] INFO    : root - Starting job in /data/workflows/PEcAn_99000000001.
2018-06-13 19:45:15,555 [MainThread     ] INFO    : root - Finished running job.</code></pre>
<p>This shows that the executor connects to RabbitMQ, waits for messages. Once it picks up a message it will print the message, and execute the workflow in the folder passed in with the message. Once the workflow (including any model executions) is finished it will print Finished. The log file for <code>pecan_sipnet_1</code> is very similar, in this case it runs the <code>job.sh</code> in the run folder.</p>
<p>To run multiple executors in parallel you can duplicate the executor section in the docker-compose file and just rename it from executor to executor1 and executor2 for example. The same can be done for the models. To make this easier it helps to deploy the containers using Kubernetes allowing to easily scale up and down the containers.</p>

</div>
<div id="pecan-docker" class="section level4">
<h4><span class="header-section-number">2.1.2.11</span> PEcAn Docker Architecture</h4>
<p><a href="tutorialsdemos-and-how-tos.html#pecan-docker-overview">Overview</a>
<a href="tutorialsdemos-and-how-tos.html#pecan-docker-compose">PEcAn’s <code>docker-compose</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-structure">Top-level structure</a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-traefik"><code>traefik</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-portainer"><code>portainer</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-minio"><code>minio</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-thredds"><code>thredds</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-postgres"><code>postgres</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-rabbitmq"><code>rabbitmq</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-bety"><code>bety</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-docs"><code>docs</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-web"><code>web</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-executor"><code>executor</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-monitor"><code>monitor</code></a>
<a href="tutorialsdemos-and-how-tos.html#pecan-dc-models">Model-specific containers</a></p>
</div>
<div id="pecan-docker-overview" class="section level4">
<h4><span class="header-section-number">2.1.2.12</span> Overview</h4>
<p>The PEcAn docker architecture consists of many containers (see figure below) that will communicate with each other. The goal of this architecture is to easily expand the PEcAn system by deploying new model containers and registering them with PEcAn. Once this is done the user can now use these new models in their work. The PEcAn framework will setup the configurations for the models, and send a message to the model containers to start execution. Once the execution is finished the PEcAn framework will continue. This is exactly as if the model is running on a HPC machine. Models can be executed in parallel by launching multiple model containers.</p>
<p><img src="06_reference/04_docker/pecan-docker.png" width="50%" height="50%" style="display: block; margin: auto;" /></p>
<p>As can be seen in the figure the architecture leverages of two standard containers (in orange). The first container is postgresql with postgis (<a href="https://hub.docker.com/r/mdillon/postgis/">mdillon/postgis</a>) which is used to store the database used by both BETY and PEcAn. The second containers is a messagebus, more specifically RabbitMQ (<a href="https://hub.docker.com/_/rabbitmq/">rabbitmq</a>).</p>
<p>The BETY app container (<a href="https://hub.docker.com/r/pecan/bety/">pecan/bety</a>) is the front end to the BETY database and is connected to the postgresql container. A http server can be put in front of this container for SSL termination as well to allow for load balancing (by using multiple BETY app containers).</p>
<p>The PEcAn framework containers consist of multiple unique ways to interact with the PEcAn system (none of these containers will have any models installed):</p>
<ul>
<li>PEcAn shiny hosts the shiny applications developed and will interact with the database to get all information necessary to display</li>
<li>PEcAn rstudio is a rstudio environment with the PEcAn libraries preloaded. This allows for prototyping of new algorithms that can be used as part of the PEcAn framework later.</li>
<li>PEcAn web allows the user to create a new PEcAn workflow. The workflow is stored in the database, and the models are executed by the model containers.</li>
<li>PEcAn cli will allow the user to give a pecan.xml file that will be executed by the PEcAn framework. The workflow created from the XML file is stored in the database, and the models are executed by the model containers.</li>
</ul>
<p>The model containers contain the actual models that are executed as well as small wrappers to make them work in the PEcAn framework. The containers will run the model based on the parameters received from the message bus and convert the outputs back to the standard PEcAn output format. Once the container is finished processing a message it will immediatly get the next message and start processing it.</p>
</div>
<div id="pecan-docker-compose" class="section level4">
<h4><span class="header-section-number">2.1.2.13</span> PEcAn’s <code>docker-compose</code></h4>
<p>The PEcAn Docker architecture is described in full by the PEcAn <code>docker-compose.yml</code> file.
For full <code>docker-compose</code> syntax, see the <a href="https://docs.docker.com/compose/">official documentation</a>.</p>
<p>This section describes the <a href="tutorialsdemos-and-how-tos.html#pecan-dc-structure">top-level structure</a> and each of the services, which are as follows:</p>
<ul>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-traefik"><code>traefik</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-portainer"><code>portainer</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-minio"><code>minio</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-thredds"><code>thredds</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-postgres"><code>postgres</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-rabbitmq"><code>rabbitmq</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-bety"><code>bety</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-docs"><code>docs</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-web"><code>web</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-executor"><code>executor</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-monitor"><code>monitor</code></a></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-dc-models">Model-specific services</a></li>
</ul>
<p>For reference, the complete <code>docker-compose</code> file is as follows:</p>
<pre><code>version: &#39;3&#39;
services:
  traefik:
    image: traefik:latest
    command:
    - --loglevel=INFO
    - --api
    - --defaultentrypoints=https,http
    - --entryPoints=Name:http Address::${TRAEFIK_HTTP_PORT:-8000} ${TRAEFIK_HTTP_REDIRECT:-&quot;&quot;}
    - --entryPoints=Name:https Address::${TRAEFIK_HTTPS_PORT:-8443} ${TRAEFIK_HTTPS_OPTIONS:-TLS}
    - --acme=${TRAEFIK_ACME_ENABLE:-false}
    - --acme.email=${TRAEFIK_ACME_EMAIL:-&quot;&quot;}
    - --acme.entrypoint=https
    - --acme.onhostrule=true
    - --acme.storage=/config/acme.json
    - --acme.httpchallenge.entrypoint=http
    - --acme.storage=/config/acme.json
    - --acme.acmelogging=true
    - --docker=true
    - --docker.endpoint=unix:///var/run/docker.sock
    - --docker.exposedbydefault=false
    - --docker.watch=true
    restart: unless-stopped
    networks: pecan
    ports:
    - ${TRAEFIK_HTTP_PORT-8000}:${TRAEFIK_HTTP_PORT:-8000}
    - ${TRAEFIK_HTTPS_PORT-8443}:${TRAEFIK_HTTPS_PORT:-8443}
    labels:
    - traefik.enable=true
    - traefik.backend=traefik
    - traefik.port=8080
    - &#39;traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefixStrip: /traefik&#39;
    - traefik.website.frontend.whiteList.sourceRange=${TRAEFIK_IPFILTER:-172.16.0.0/12}
    volumes:
    - /var/run/docker.sock:/var/run/docker.sock:ro
    - traefik:/config
  portainer:
    image: portainer/portainer:latest
    command:
    - --admin-password=${PORTAINER_PASSWORD:-}
    - --host=unix:///var/run/docker.sock
    restart: unless-stopped
    networks: pecan
    labels:
    - traefik.enable=true
    - traefik.backend=portainer
    - &#39;traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefixStrip: /portainer&#39;
    - traefik.website.frontend.whiteList.sourceRange=${TRAEFIK_IPFILTER:-172.16.0.0/12}
    volumes:
    - /var/run/docker.sock:/var/run/docker.sock
    - portainer:/data
  minio:
    image: minio/minio:latest
    command: server /data
    restart: unless-stopped
    networks: pecan
    environment:
    - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-carya}
    - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-illinois}
    labels:
    - traefik.enable=true
    - traefik.backend=minio
    - traefik.port=9000
    - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/minio/
    volumes: pecan:/data
  thredds:
    image: pecan/thredds:${PECAN_VERSION:-latest}
    restart: unless-stopped
    networks: pecan
    volumes: pecan:/data
    labels:
    - traefik.enable=true
    - traefik.port=8080
    - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/thredds
    - traefik.backend=thredds
  rabbitmq:
    image: rabbitmq:management
    restart: unless-stopped
    networks: pecan
    environment:
    - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbitmq_management path_prefix &quot;/rabbitmq&quot;
    - RABBITMQ_DEFAULT_USER=${RABBITMQ_DEFAULT_USER:-guest}
    - RABBITMQ_DEFAULT_PASS=${RABBITMQ_DEFAULT_PASS:-guest}
    labels:
    - traefik.enable=true
    - traefik.backend=rabbitmq
    - traefik.port=15672
    - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/rabbitmq
    - traefik.website.frontend.whiteList.sourceRange=${TRAEFIK_IPFILTER:-172.16.0.0/12}
    volumes: rabbitmq:/var/lib/rabbitmq
  postgres:
    image: mdillon/postgis:9.5
    restart: unless-stopped
    networks: pecan
    volumes: postgres:/var/lib/postgresql/data
  bety:
    image: pecan/bety:${BETY_VERSION:-latest}
    restart: unless-stopped
    networks: pecan
    environment:
    - UNICORN_WORKER_PROCESSES=1
    - SECRET_KEY_BASE=${BETY_SECRET_KEY:-notasecret}
    - RAILS_RELATIVE_URL_ROOT=/bety
    - LOCAL_SERVER=${BETY_LOCAL_SERVER:-99}
    depends_on: postgres
    labels:
    - traefik.enable=true
    - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/bety/
    - traefik.backend=bety
  docs:
    image: pecan/docs:${PECAN_VERSION:-latest}
    restart: unless-stopped
    networks: pecan
    labels:
    - traefik.enable=true
    - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/
    - traefik.backend=docs
  web:
    image: pecan/web:${PECAN_VERSION:-latest}
    restart: unless-stopped
    networks: pecan
    environment:
    - RABBITMQ_URI=${RABBITMQ_URI:-amqp://guest:guest@rabbitmq/%2F}
    - FQDN=${PECAN_FQDN:-docker}
    - NAME=${PECAN_NAME:-docker}
    depends_on:
    - postgres
    - rabbitmq
    labels:
    - traefik.enable=true
    - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/pecan/
    - traefik.backend=pecan
    volumes:
    - pecan:/data
    - pecan:/var/www/html/pecan/data
  monitor:
    image: pecan/monitor:${PECAN_VERSION:-latest}
    restart: unless-stopped
    networks: pecan
    ports: 9999:9999
    environment:
    - RABBITMQ_URI=${RABBITMQ_URI:-amqp://guest:guest@rabbitmq/%2F}
    - FQDN=${PECAN_FQDN:-docker}
    depends_on: rabbitmq
    labels:
    - traefik.enable=true
    - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefixStrip:/monitor/
    - traefik.backend=monitor
    volumes: pecan:/data
  executor:
    image: pecan/executor:${PECAN_VERSION:-latest}
    restart: unless-stopped
    networks: pecan
    environment:
    - RABBITMQ_URI=${RABBITMQ_URI:-amqp://guest:guest@rabbitmq/%2F}
    - FQDN=${PECAN_FQDN:-docker}
    depends_on:
    - postgres
    - rabbitmq
    volumes: pecan:/data
  sipnet:
    image: pecan/model-sipnet-136:${PECAN_VERSION:-latest}
    restart: unless-stopped
    networks: pecan
    environment: RABBITMQ_URI=${RABBITMQ_URI:-amqp://guest:guest@rabbitmq/%2F}
    depends_on: rabbitmq
    volumes: pecan:/data
  ed2:
    image: pecan/model-ed2-git:${PECAN_VERSION:-latest}
    restart: unless-stopped
    networks: pecan
    environment: RABBITMQ_URI=${RABBITMQ_URI:-amqp://guest:guest@rabbitmq/%2F}
    depends_on: rabbitmq
    volumes: pecan:/data
networks:
  pecan: ~
volumes:
  traefik: ~
  postgres: ~
  rabbitmq: ~
  pecan: ~
  portainer: ~</code></pre>
<p>There are two ways you can override different values in the docker-compose.yml file. The first method is to create a file called <code>.env</code> that is placed in the same folder as the docker-compose.yml file. This file can override some of configuration variables used by docker-compose. For example the following is an example of the env file</p>
<pre><code># This file will override the configation options in the docker-compose
# file. Copy this file to the same folder as docker-compose as .env

# ----------------------------------------------------------------------
# GENERAL CONFIGURATION
# ----------------------------------------------------------------------

# Folder to store all data
DATA_DIR=/home/kooper/pecan

# ----------------------------------------------------------------------
# TRAEFIK CONFIGURATION
# ----------------------------------------------------------------------

# hostname of server
TRAEFIK_HOST=Host:pecan-docker.ncsa.illinois.edu;

# only allow access from localhost and NCSA
TRAEFIK_IPFILTER=172.16.0.0/12, 141.142.0.0/16

# Run traffik on port 80 (http) and port 443 (https)
TRAEFIK_HTTP_PORT=80
TRAEFIK_HTTPS_PORT=443
TRAEFIK_HTTPS_OPTIONS=TLS

# enable SSL cerificate generation
TRAEFIK_ACME_ENABLE=true

# Use you real email address here to be notified if cert expires
TRAEFIK_ACME_EMAIL=pecanproj@gmail.com

# Always use https, trafic to http is redirected to https
TRAEFIK_HTTP_REDIRECT=Redirect.EntryPoint:https

# ----------------------------------------------------------------------
# PEcAn CONFIGURATION
# ----------------------------------------------------------------------

# what version of pecan to use
PECAN_VERSION=develop

# the fully qualified hostname used for this server
PECAN_FQDN=pecan-docker.ncsa.illinois.edu

# short name shown in the menu
PECAN_FQDN=pecan-docker

# ----------------------------------------------------------------------
# BETY CONFIGURATION
# ----------------------------------------------------------------------

# what version of BETY to use
BETY_VERSION=latest

# what is our server number, 99=vm, 98=docker
BETY_LOCAL_SERVER=98

# secret used to encrypt cookies in BETY
BETY_SECRET_KEY=1208q7493e8wfhdsohfo9ewhrfiouaho908ruq30oiewfdjspadosuf08q345uwrasdy98t7q243

# ----------------------------------------------------------------------
# MINIO CONFIGURATION
# ----------------------------------------------------------------------

# minio username and password
MINIO_ACCESS_KEY=carya
MINIO_SECRET_KEY=illinois

# ----------------------------------------------------------------------
# PORTAINER CONFIGURATION
# ----------------------------------------------------------------------

# password for portainer admin account
# use docker run --rm httpd:2.4-alpine htpasswd -nbB admin &lt;password&gt; | cut -d &quot;:&quot; -f 2
PORTAINER_PASSWORD=$2y$05$5meDPBtS3NNxyGhBpYceVOxmFhiiC3uY5KEy2m0YRbWghhBr2EVn2

# ----------------------------------------------------------------------
# RABBITMQ CONFIGURATION
# ----------------------------------------------------------------------

# RabbitMQ username and password
RABBITMQ_DEFAULT_USER=carya
RABBITMQ_DEFAULT_PASS=illinois

# create the correct URI with above username and password
RABBITMQ_URI=amqp://carya:illinois@rabbitmq/%2F</code></pre>
<p>You can also extend the <code>docker-compose.yml</code> file with a <code>docker-compose.override.yml</code> file (in the same directory), allowing you to add more services, or for example to change where the volumes are stored (see <a href="https://docs.docker.com/compose/extends/">official documentation</a>). For example the following will change the volume for postgres to be stored in your home directory:</p>
<pre><code>version: &quot;3&quot;

volumes:
  postgres:
    driver_opts:
      type: none
      device: ${HOME}/postgres
      o: bind</code></pre>
</div>
<div id="pecan-dc-structure" class="section level4">
<h4><span class="header-section-number">2.1.2.14</span> Top-level structure</h4>
<p>The root of the <code>docker-compose.yml</code> file contains three sections:</p>
<ul>
<li><p><code>services</code> – This is a list of services provided by the application, with each service corresponding to a container.
When communicating with each other internally, the hostnames of containers correspond to their names in this section.
For instance, regardless of the “project” name passed to <code>docker-compose up</code>, the hostname for connecting to the PostgreSQL database of any given container is <em>always</em> going to be <code>postgres</code> (e.g. you should be able to access the PostgreSQL database by calling the following from inside the container: <code>psql -d bety -U bety -h postgres</code>).
The services comprising the PEcAn application are described below.</p></li>
<li><p><code>networks</code> – This is a list of networks used by the application.
Containers can only communicate with each other (via ports and hostnames) if they are on the same Docker network, and containers on different networks can only communicate through ports exposed by the host machine.
We just provide the network name (<code>pecan</code>) and resort to Docker’s default network configuration.
Note that the services we want connected to this network include a <code>networks: ... - pecan</code> tag.
For more details on Docker networks, see the <a href="https://docs.docker.com/network/">official documentation</a>.</p></li>
<li><p><code>volumes</code> – Similarly to <code>networks</code>, this just contains a list of volume names we want.
Briefly, in Docker, volumes are directories containing files that are meant to be shared across containers.
Each volume corresponds to a directory, which can be mounted at a specific location by different containers.
For example, syntax like <code>volumes: ... - pecan:/data</code> in a service definition means to mount the <code>pecan</code> “volume” (including its contents) in the <code>/data</code> directory of that container.
Volumes also allow data to persist on containers between restarts, as normally, any data created by a container during its execution is lost when the container is re-launched.
For example, using a volume for the database allows data to be saved between different runs of the database container.
Without volumes, we would start with a blank database every time we restart the containers.
For more details on Docker volumes, see the <a href="https://docs.docker.com/storage/volumes/">official documentation</a>.
Here, we define three volumes:</p>
<ul>
<li><p><code>postgres</code> – This contains the data files underlying the PEcAn PostgreSQL database (BETY).
Notice that it is mounted by the <code>postgres</code> container to <code>/var/lib/postgresql/data</code>.
This is the data that we pre-populate when we run the Docker commands to <a href="tutorialsdemos-and-how-tos.html#pecan-docker-quickstart-init">initialize the PEcAn database</a>.
Note that these are the values stored <em>directly in the PostgreSQL database</em>.
The default files to which the database points (i.e. <code>dbfiles</code>) are stored in the <code>pecan</code> volume, described below.</p></li>
<li><p><code>rabbitmq</code> – This volume contains persistent data for RabbitMQ.
It is only used by the <code>rabbitmq</code> service.</p></li>
<li><p><code>pecan</code> – This volume contains PEcAn’s <code>dbfiles</code>, which include downloaded and converted model inputs, processed configuration files, and outputs.
It is used by almost all of the services in the PEcAn stack, and is typically mounted to <code>/data</code>.</p></li>
</ul></li>
</ul>
</div>
<div id="pecan-dc-traefik" class="section level4">
<h4><span class="header-section-number">2.1.2.15</span> <code>traefik</code></h4>
<p><a href="https://traefik.io/">Traefik</a> manages communication among the different PEcAn services and between PEcAn and the web.
Among other things, <code>traefik</code> facilitates the setup of web access to each PEcAn service via common and easy-to-remember URLs.
For instance, the following lines in the <code>web</code> service configure access to the PEcAn web interface via the URL <a href="http://localhost:8000/pecan/" class="uri">http://localhost:8000/pecan/</a> :</p>
<pre><code>labels:
- traefik.enable=true
- traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/pecan/
- traefik.backend=pecan</code></pre>
<p>(Further details in the works…)</p>
<p>The traefik service configuration looks like this:</p>
<pre><code>traefik:
  image: traefik:latest
  command:
  - --loglevel=INFO
  - --api
  - --defaultentrypoints=https,http
  - --entryPoints=Name:http Address::${TRAEFIK_HTTP_PORT:-8000} ${TRAEFIK_HTTP_REDIRECT:-&quot;&quot;}
  - --entryPoints=Name:https Address::${TRAEFIK_HTTPS_PORT:-8443} ${TRAEFIK_HTTPS_OPTIONS:-TLS}
  - --acme=${TRAEFIK_ACME_ENABLE:-false}
  - --acme.email=${TRAEFIK_ACME_EMAIL:-&quot;&quot;}
  - --acme.entrypoint=https
  - --acme.onhostrule=true
  - --acme.storage=/config/acme.json
  - --acme.httpchallenge.entrypoint=http
  - --acme.storage=/config/acme.json
  - --acme.acmelogging=true
  - --docker=true
  - --docker.endpoint=unix:///var/run/docker.sock
  - --docker.exposedbydefault=false
  - --docker.watch=true
  restart: unless-stopped
  networks: pecan
  ports:
  - ${TRAEFIK_HTTP_PORT-8000}:${TRAEFIK_HTTP_PORT:-8000}
  - ${TRAEFIK_HTTPS_PORT-8443}:${TRAEFIK_HTTPS_PORT:-8443}
  labels:
  - traefik.enable=true
  - traefik.backend=traefik
  - traefik.port=8080
  - &#39;traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefixStrip: /traefik&#39;
  - traefik.website.frontend.whiteList.sourceRange=${TRAEFIK_IPFILTER:-172.16.0.0/12}
  volumes:
  - /var/run/docker.sock:/var/run/docker.sock:ro
  - traefik:/config</code></pre>
</div>
<div id="pecan-dc-portainer" class="section level4">
<h4><span class="header-section-number">2.1.2.16</span> <code>portainer</code></h4>
<p><a href="https://portainer.io/">portainer</a> is lightweight management UI that allows you to manage the docker host (or swarm). You can use this service to monitor the different containers, see the logfiles, and start and stop containers.</p>
<p>The portainer service configuration looks like this:</p>
<pre><code>portainer:
  image: portainer/portainer:latest
  command:
  - --admin-password=${PORTAINER_PASSWORD:-}
  - --host=unix:///var/run/docker.sock
  restart: unless-stopped
  networks: pecan
  labels:
  - traefik.enable=true
  - traefik.backend=portainer
  - &#39;traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefixStrip: /portainer&#39;
  - traefik.website.frontend.whiteList.sourceRange=${TRAEFIK_IPFILTER:-172.16.0.0/12}
  volumes:
  - /var/run/docker.sock:/var/run/docker.sock
  - portainer:/data</code></pre>
<p>Portainer is accessible by browsing to <code>localhost:8000/portainer/</code>. You can either set the password in the <code>.env</code> file (for an example see env.example) or you can use the web browser and go to the portainer url. If this is the first time it will ask for your password.</p>
</div>
<div id="pecan-dc-minio" class="section level4">
<h4><span class="header-section-number">2.1.2.17</span> <code>minio</code></h4>
<p><a href="https://github.com/minio/minio">Minio</a> is a service that provides access to the a folder on disk through a variety of protocols, including S3 buckets and web-based access.
We mainly use Minio to facilitate access to PEcAn data using a web browser without the need for CLI tools.</p>
<p>Our current configuration is as follows:</p>
<pre><code>minio:
  image: minio/minio:latest
  command: server /data
  restart: unless-stopped
  networks: pecan
  environment:
  - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-carya}
  - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-illinois}
  labels:
  - traefik.enable=true
  - traefik.backend=minio
  - traefik.port=9000
  - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/minio/
  volumes: pecan:/data</code></pre>
<p>The Minio interface is accessible by browsing to <code>localhost:8000/minio/</code>.
From there, you can browse directories and download files.
You can also upload files by clicking the red “+” in the bottom-right corner.</p>
<p>Note that it is currently impossible to create or upload directories using the Minio interface (except in the <code>/data</code> root directory – those folders are called “buckets” in Minio).
Therefore, the recommended way to perform any file management tasks other than individual file uploads is through the command line, e.g.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> run -it --rm --volumes pecan_pecan:/data --volumes /path/to/local/directory:/localdir ubuntu

<span class="co"># Now, you can move files between `/data` and `/localdir`, create new directories, etc.</span></code></pre>
</div>
<div id="pecan-dc-thredds" class="section level4">
<h4><span class="header-section-number">2.1.2.18</span> <code>thredds</code></h4>
<p>This service allows PEcAn model outputs to be accessible via the <a href="https://www.unidata.ucar.edu/software/thredds/current/tds/">THREDDS data server (TDS)</a>.
When the PEcAn stack is running, the catalog can be explored in a web browser at <a href="http://localhost:8000/thredds/catalog.html" class="uri">http://localhost:8000/thredds/catalog.html</a>.
Specific output files can also be accessed from the command line via commands like the following:</p>
<pre class="sourceCode r"><code class="sourceCode r">nc &lt;-<span class="st"> </span>ncdf4<span class="op">::</span><span class="kw">nc_open</span>(<span class="st">&quot;http://localhost:8000/thredds/dodsC/outputs/PEcAn_&lt;workflow_id&gt;/out/&lt;run_id&gt;/&lt;year&gt;.nc&quot;</span>)</code></pre>
<p>Note that everything after <code>outputs/</code> exactly matches the directory structure of the <code>workflows</code> directory.</p>
<p>Which files are served, which subsetting services are available, and other aspects of the data server’s behavior are configured in the <code>docker/thredds_catalog.xml</code> file.
Specifically, this XML tells the data server to use the <code>datasetScan</code> tool to serve all files within the <code>/data/workflows</code> directory, with the additional <code>filter</code> that only files ending in <code>.nc</code> are served.
For additional information about the syntax of this file, see the extensive <a href="https://www.unidata.ucar.edu/software/thredds/current/tds/reference/index.html">THREDDS documentation</a>.</p>
<p>Our current configuration is as follows:</p>
<pre><code>thredds:
  image: pecan/thredds:${PECAN_VERSION:-latest}
  restart: unless-stopped
  networks: pecan
  volumes: pecan:/data
  labels:
  - traefik.enable=true
  - traefik.port=8080
  - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/thredds
  - traefik.backend=thredds</code></pre>
</div>
<div id="pecan-dc-postgres" class="section level4">
<h4><span class="header-section-number">2.1.2.19</span> <code>postgres</code></h4>
<p>This service provides a working PostGIS database.
Our configuration is fairly straightforward:</p>
<pre><code>postgres:
  image: mdillon/postgis:9.5
  restart: unless-stopped
  networks: pecan
  volumes: postgres:/var/lib/postgresql/data</code></pre>
<p>Some additional details about our configuration:</p>
<ul>
<li><p><code>image</code> – This pulls a container with PostgreSQL + PostGIS pre-installed.
Note that by default, we use PostgreSQL version 9.5.
To experiment with other versions, you can change <code>9.5</code> accordingly.</p></li>
<li><p><code>networks</code> – This allows PostgreSQL to communicate with other containers on the <code>pecan</code> network.
As mentioned above, the hostname of this service is just its name, i.e. <code>postgres</code>, so to connect to the database from inside a running container, use a command like the following: <code>psql -d bety -U bety -h postgres</code></p></li>
<li><p><code>volumes</code> – Note that the PostgreSQL data files (which store the values in the SQL database) are stored on a <em>volume</em> called <code>postgres</code> (which is <em>not</em> the same as the <code>postgres</code> <em>service</em>, even though they share the same name).</p></li>
</ul>
</div>
<div id="pecan-dc-rabbitmq" class="section level4">
<h4><span class="header-section-number">2.1.2.20</span> <code>rabbitmq</code></h4>
<p><a href="https://www.rabbitmq.com/">RabbitMQ</a> is a message broker service.
In PEcAn, RabbitMQ functions as a task manager and scheduler, coordinating the execution of different tasks (such as running models and analyzing results) associated with the PEcAn workflow.</p>
<p>Our configuration is as follows:</p>
<pre><code>rabbitmq:
  image: rabbitmq:management
  restart: unless-stopped
  networks: pecan
  environment:
  - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbitmq_management path_prefix &quot;/rabbitmq&quot;
  - RABBITMQ_DEFAULT_USER=${RABBITMQ_DEFAULT_USER:-guest}
  - RABBITMQ_DEFAULT_PASS=${RABBITMQ_DEFAULT_PASS:-guest}
  labels:
  - traefik.enable=true
  - traefik.backend=rabbitmq
  - traefik.port=15672
  - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/rabbitmq
  - traefik.website.frontend.whiteList.sourceRange=${TRAEFIK_IPFILTER:-172.16.0.0/12}
  volumes: rabbitmq:/var/lib/rabbitmq</code></pre>
<p>Note that the <code>traefik.frontend.rule</code> indicates that browsing to <a href="http://localhost:8000/rabbitmq/" class="uri">http://localhost:8000/rabbitmq/</a> leads to the RabbitMQ management console.</p>
<p>By default, the RabbitMQ management console has username/password <code>guest/guest</code>, which is highly insecure.
For production instances of PEcAn, we highly recommend changing these credentials to something more secure, and removing access to the RabbitMQ management console via Traefik.</p>
</div>
<div id="pecan-dc-bety" class="section level4">
<h4><span class="header-section-number">2.1.2.21</span> <code>bety</code></h4>
<p>This service operates the BETY web interface, which is effectively a web-based front-end to the PostgreSQL database.
Unlike the <code>postgres</code> service, which contains all the data needed to run PEcAn models, this service is not essential to the PEcAn workflow.
However, note that certain features of the PEcAn web interface do link to the BETY web interface and will not work if this container is not running.</p>
<p>Our configuration is as follows:</p>
<pre><code>bety:
  image: pecan/bety:${BETY_VERSION:-latest}
  restart: unless-stopped
  networks: pecan
  environment:
  - UNICORN_WORKER_PROCESSES=1
  - SECRET_KEY_BASE=${BETY_SECRET_KEY:-notasecret}
  - RAILS_RELATIVE_URL_ROOT=/bety
  - LOCAL_SERVER=${BETY_LOCAL_SERVER:-99}
  depends_on: postgres
  labels:
  - traefik.enable=true
  - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/bety/
  - traefik.backend=bety</code></pre>
<p>The BETY container Dockerfile is located in the root directory of the <a href="https://github.com/pecan/bety">BETY GitHub repository</a> (<a href="https://github.com/PecanProject/bety/blob/master/Dockerfile">direct link</a>).</p>
</div>
<div id="pecan-dc-docs" class="section level4">
<h4><span class="header-section-number">2.1.2.22</span> <code>docs</code></h4>
<p>This service will show the documentation for the version of PEcAn running as well as a homepage with links to all relevant endpoints. You can access this at <a href="http://localhost:8000/" class="uri">http://localhost:8000/</a>. You can find the documentation for PEcAn at <a href="http://localhost:8000/docs/pecan/" class="uri">http://localhost:8000/docs/pecan/</a>.</p>
<p>Our current configuration is as follows:</p>
<pre><code>docs:
  image: pecan/docs:${PECAN_VERSION:-latest}
  restart: unless-stopped
  networks: pecan
  labels:
  - traefik.enable=true
  - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/
  - traefik.backend=docs</code></pre>
</div>
<div id="pecan-dc-web" class="section level4">
<h4><span class="header-section-number">2.1.2.23</span> <code>web</code></h4>
<p>This service runs the PEcAn web interface.
It is effectively a thin wrapper around a standard Apache web server container from Docker Hub that installs some additional dependencies and copies over the necessary files from the PEcAn source code.</p>
<p>Our configuration is as follows:</p>
<pre><code>web:
  image: pecan/web:${PECAN_VERSION:-latest}
  restart: unless-stopped
  networks: pecan
  environment:
  - RABBITMQ_URI=${RABBITMQ_URI:-amqp://guest:guest@rabbitmq/%2F}
  - FQDN=${PECAN_FQDN:-docker}
  - NAME=${PECAN_NAME:-docker}
  depends_on:
  - postgres
  - rabbitmq
  labels:
  - traefik.enable=true
  - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefix:/pecan/
  - traefik.backend=pecan
  volumes:
  - pecan:/data
  - pecan:/var/www/html/pecan/data</code></pre>
<p>Its Dockerfile ships with the PEcAn source code, in <a href="https://github.com/PecanProject/pecan/blob/develop/docker/base/Dockerfile.web"><code>docker/base/Dockerfile.web</code></a>.</p>
<p>In terms of <a href="#pecan-docker-develop">actively developing PEcAn using Docker</a>, this is the service to modify when making changes to the web interface (i.e. PHP, HTML, and JavaScript code located in the PEcAn <code>web</code> directory).</p>
</div>
<div id="pecan-dc-executor" class="section level4">
<h4><span class="header-section-number">2.1.2.24</span> <code>executor</code></h4>
<p>This service is in charge of running the R code underlying the core PEcAn workflow.
However, it is <em>not</em> in charge of executing the models themselves – model binaries are located on their <a href="tutorialsdemos-and-how-tos.html#pecan-dc-models">own dedicated Docker containers</a>, and model execution is coordinated by RabbitMQ.</p>
<p>Our configuration is as follows:</p>
<pre><code>executor:
  image: pecan/executor:${PECAN_VERSION:-latest}
  restart: unless-stopped
  networks: pecan
  environment:
  - RABBITMQ_URI=${RABBITMQ_URI:-amqp://guest:guest@rabbitmq/%2F}
  - FQDN=${PECAN_FQDN:-docker}
  depends_on:
  - postgres
  - rabbitmq
  volumes: pecan:/data</code></pre>
<p>Its Dockerfile is ships with the PEcAn source code, in <a href="https://github.com/PecanProject/pecan/blob/develop/docker/base/Dockerfile.executor"><code>docker/base/Dockerfile.executor</code></a>.
Its image is built on top of the <code>pecan/base</code> image (<a href="https://github.com/PecanProject/pecan/blob/develop/docker/base/Dockerfile.base"><code>docker/base/Dockerfile.base</code></a>), which contains the actual PEcAn source.
To facilitate caching, the <code>pecan/base</code> image is itself built on top of the <code>pecan/depends</code> image (<a href="https://github.com/PecanProject/pecan/blob/develop/docker/base/Dockerfile.depends"><code>docker/base/Dockerfile.depends</code></a>), a large image that contains an R installation and PEcAn’s many system and R package dependencies (which usually take ~30 minutes or longer to install from scratch).</p>
<p>In terms of <a href="#pecan-docker-develop">actively developing PEcAn using Docker</a>, this is the service to modify when making changes to the PEcAn R source code.
Note that, unlike changes to the <code>web</code> image’s PHP code, changes to the R source code do not immediately propagate to the PEcAn container; instead, you have to re-compile the code by running <code>make</code> inside the container.</p>
</div>
<div id="pecan-dc-monitor" class="section level4">
<h4><span class="header-section-number">2.1.2.25</span> <code>monitor</code></h4>
<p>This service will show all models that are currently running <a href="http://localhost:8000/monitor/" class="uri">http://localhost:8000/monitor/</a>. This list returned is JSON and shows all models (grouped by type and version) that are currently running, or where seen in the past. This list will also contain a list of all current active containers, as well as how many jobs are waiting to be processed.</p>
<p>This service is also responsible for registering any new models with PEcAn so users can select it and execute the model from the web interface.</p>
<p>Our current configuration is as follows:</p>
<pre><code>monitor:
  image: pecan/monitor:${PECAN_VERSION:-latest}
  restart: unless-stopped
  networks: pecan
  ports: 9999:9999
  environment:
  - RABBITMQ_URI=${RABBITMQ_URI:-amqp://guest:guest@rabbitmq/%2F}
  - FQDN=${PECAN_FQDN:-docker}
  depends_on: rabbitmq
  labels:
  - traefik.enable=true
  - traefik.frontend.rule=${TRAEFIK_FRONTEND_RULE:-}PathPrefixStrip:/monitor/
  - traefik.backend=monitor
  volumes: pecan:/data</code></pre>
</div>
<div id="pecan-dc-models" class="section level4">
<h4><span class="header-section-number">2.1.2.26</span> Model-specific containers</h4>
<p>Additional models are added as additional services.
In general, their configuration should be similar to the following configuration for SIPNET, which ships with PEcAn:</p>
<pre><code>sipnet:
  image: pecan/model-sipnet-136:${PECAN_VERSION:-latest}
  restart: unless-stopped
  networks: pecan
  environment: RABBITMQ_URI=${RABBITMQ_URI:-amqp://guest:guest@rabbitmq/%2F}
  depends_on: rabbitmq
  volumes: pecan:/data</code></pre>
<p>The PEcAn source contains Dockerfiles for ED2 (<a href="https://github.com/PecanProject/pecan/blob/develop/docker/models/Dockerfile.ed2"><code>docker/models/Dockerfile.ed2</code></a>) and SIPNET (<a href="https://github.com/PecanProject/pecan/blob/develop/docker/models/Dockerfile.sipnet"><code>docker/models/Dockerfile.sipnet</code></a>) that can serve as references.
For additional tips on constructing a Dockerfile for your model, see <a href="tutorialsdemos-and-how-tos.html#model-docker">Dockerfiles for Models</a>.</p>

</div>
<div id="model-docker" class="section level4">
<h4><span class="header-section-number">2.1.2.27</span> Models using Docker</h4>
<p>This section will discuss how to add new models to PEcAn docker. To be able to add a new model to PEcAn when using docker is as simple as starting a new container. The model will come online and let the PEcAn framework know there is a new model available, there is no need to go through the process of registering this model with PEcAn. Users will be able to select this new model from web interface and run with this model selected.</p>
<p>For this process to work a docker image of the model will need to be created as well as small json file that is used to announce this new model. A separate service in PEcAn (<a href="tutorialsdemos-and-how-tos.html#pecan-dc-monitor"><code>monitor</code></a>) will use this json file to keep track of all models available as well as register these models with PEcAn.</p>
<p><a href="tutorialsdemos-and-how-tos.html#model-docker-json-file">Model information</a>
<a href="tutorialsdemos-and-how-tos.html#model-docker-Dockerfile">Model build</a>
<a href="tutorialsdemos-and-how-tos.html#common-docker-problems">Common problems</a></p>
</div>
<div id="model-docker-json-file" class="section level4">
<h4><span class="header-section-number">2.1.2.28</span> Model information</h4>
<p>Each model will have a small json file called model_info.json that is used to describe the model and to used by the monitor service to register the model with PEcAn. This file will contain information about the model that is send as part of the heartbeat of the container to the monitor service. Below is an example of this file for the ED model. The required fields are <code>name</code>, <code>type</code>, <code>version</code> and <code>binary</code>. There are 2 special values that can be used, <code>@VERSION@</code> which will be replaced by the version that is passed in when building the container, and <code>@BINARY@</code> which will be replaced by the binary when building the docker image.</p>
<pre class="sourceCode json"><code class="sourceCode json"><span class="fu">{</span>
  <span class="dt">&quot;name&quot;</span><span class="fu">:</span> <span class="st">&quot;ED2.2&quot;</span><span class="fu">,</span>
  <span class="dt">&quot;type&quot;</span><span class="fu">:</span> <span class="st">&quot;ED2&quot;</span><span class="fu">,</span>
  <span class="dt">&quot;version&quot;</span><span class="fu">:</span> <span class="st">&quot;@VERSION@&quot;</span><span class="fu">,</span>
  <span class="dt">&quot;binary&quot;</span><span class="fu">:</span> <span class="st">&quot;@BINARY@&quot;</span><span class="fu">,</span>
  <span class="dt">&quot;description&quot;</span><span class="fu">:</span> <span class="st">&quot;The Ecosystem Demography Biosphere Model (ED2) is an integrated terrestrial biosphere model incorporating hydrology, land-surface biophysics, vegetation dynamics, and soil carbon and nitrogen biogeochemistry&quot;</span><span class="fu">,</span>
  <span class="dt">&quot;author&quot;</span><span class="fu">:</span> <span class="st">&quot;Mike Dietze&quot;</span><span class="fu">,</span>
  <span class="dt">&quot;contributors&quot;</span><span class="fu">:</span> <span class="ot">[</span><span class="st">&quot;David LeBauer&quot;</span><span class="ot">,</span> <span class="st">&quot;Xiaohui Feng&quot;</span><span class="ot">,</span> <span class="st">&quot;Dan Wang&quot;</span><span class="ot">,</span> <span class="st">&quot;Carl Davidson&quot;</span><span class="ot">,</span> <span class="st">&quot;Rob Kooper&quot;</span><span class="ot">,</span> <span class="st">&quot;Shawn Serbin&quot;</span><span class="ot">,</span> <span class="st">&quot;Alexey Shiklomanov&quot;</span><span class="ot">]</span><span class="fu">,</span>
  <span class="dt">&quot;links&quot;</span><span class="fu">:</span> <span class="fu">{</span>
    <span class="dt">&quot;source&quot;</span><span class="fu">:</span> <span class="st">&quot;https://github.com/EDmodel/ED2&quot;</span><span class="fu">,</span>
    <span class="dt">&quot;issues&quot;</span><span class="fu">:</span> <span class="st">&quot;https://github.com/EDmodel/ED2/issues&quot;</span>
  <span class="fu">},</span>
  <span class="dt">&quot;inputs&quot;</span><span class="fu">:</span> <span class="fu">{},</span>
  <span class="dt">&quot;citation&quot;</span><span class="fu">:</span> <span class="ot">[</span><span class="st">&quot;Medvigy D., Wofsy S. C., Munger J. W., Hollinger D. Y., Moorcroft P. R. 2009. Mechanistic scaling of ecosystem function and dynamics in space and time: Ecosystem Demography model version 2. J. Geophys. Res. 114 (doi:10.1029/2008JG000812)&quot;</span><span class="ot">]</span>
<span class="fu">}</span></code></pre>
<p>Other fields that are recommended, but currently not used yet, are:
- <code>description</code> : a longer description of the model.
- <code>creator</code> : contact person about this docker image.
- <code>contribuor</code> : other people that have contributed to this docker image.
- <code>links</code> : addtional links to help people when using this docker image, for example values that can be used are <code>source</code> to link to the source code, <code>issues</code> to link to issue tracking system, and <code>documentation</code> to link to model specific documentation.
- <code>citation</code> : how the model should be cited in publications.</p>
</div>
<div id="model-docker-Dockerfile" class="section level4">
<h4><span class="header-section-number">2.1.2.29</span> Model build</h4>
<p>In general we try to minimize the size of the images. To be able to do this we split the process of creating the building of the model images into two pieces (or leverage of an image that exists from the original model developers). If you look at the example Dockerfile you will see that there are 2 sections, the first section will build the model binary, the second section will build the actual PEcAn model, which copies the binary from the first section.</p>
<p>This is an example of how the ED2 model is build. This will install all the packages needed to build ED2 model, gets the latest version from GitHub and builds the model.</p>
<p>The second section will create the actual model runner. This will leverage the PEcAn model image that has PEcAn already installed as well as the python code to listen for messages and run the actual model code. This will install some additional packages needed by the model binary (more about that below), copy the model_info.json file and change the <code>@VERSION@</code> and <code>@BINARY@</code> placeholders.</p>
<p>It is important values for <code>type</code> and <code>version</code> are set correct. The PEcAn code will use these to register the model with the BETY database, which is then used by PEcAn to send out a message to a specfic worker queue, if you do not set these variables correctly your model executor will pick up messages for the wrong model.</p>
<p>To build the docker image, we use a Dockerfile (see example below) and run the following command. This command will expect the Dockerfile to live in the model specific folder and the command is executed in the root pecan folder. It will copy the content of the pecan folder and make it available to the build process (in this example we do not need any additional files).</p>
<p>Since we can have multiple different versions of a model be available for PEcAn we ar using the following naming schema <code>pecan/model-&lt;modeltype&gt;-&lt;version&gt;:&lt;pecan version</code>. For example the image below will be named pecan/model-ed2-git, since we do not specify the exact version it will be atomically be named <code>pecan/model-ed2-git:latest</code>.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> build \
    --tag pecan/model-ed2-git \
    --file models/ed/Dockerfile \
    .</code></pre>
<p>Example of a Dockerfile, in this case to build the ED2 model.</p>
<pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span class="co"># ----------------------------------------------------------------------</span>
<span class="co"># BUILD MODEL BINARY</span>
<span class="co"># ----------------------------------------------------------------------</span>
<span class="kw">FROM</span> debian:stretch as model-binary

<span class="co"># Some variables that can be used to set control the docker build</span>
<span class="kw">ARG</span> MODEL_VERSION=git

<span class="co"># install dependencies</span>
<span class="kw">RUN</span> apt-get update \
    &amp;&amp; apt-get install -y --no-install-recommends \
       build-essential \
       curl \
       gfortran \
       git \
       libhdf5-dev \
       libopenmpi-dev \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

<span class="co"># download, unzip and build ed2</span>
<span class="kw">WORKDIR</span> /src
<span class="kw">RUN</span> git -c http.sslVerify=false clone https://github.com/EDmodel/ED2.git \
    &amp;&amp; cd ED2/ED/build \
    &amp;&amp; curl -o make/include.mk.VM http://isda.ncsa.illinois.edu/~kooper/EBI/include.mk.opt.Linux \
    &amp;&amp; if [ <span class="st">&quot;${MODEL_VERSION}&quot;</span> != <span class="st">&quot;git&quot;</span> ]; then git checkout ${MODEL_VERSION}; fi \
    &amp;&amp; ./install.sh -g -p VM

<span class="co">########################################################################</span>

<span class="co"># ----------------------------------------------------------------------</span>
<span class="co"># BUILD PECAN FOR MODEL</span>
<span class="co"># ----------------------------------------------------------------------</span>
<span class="kw">FROM</span> pecan/models:latest

<span class="co"># ----------------------------------------------------------------------</span>
<span class="co"># INSTALL MODEL SPECIFIC PIECES</span>
<span class="co"># ----------------------------------------------------------------------</span>

<span class="kw">RUN</span> apt-get update \
    &amp;&amp; apt-get install -y --no-install-recommends \
       libgfortran3 \
       libopenmpi2 \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

<span class="co"># ----------------------------------------------------------------------</span>
<span class="co"># SETUP FOR SPECIFIC MODEL</span>
<span class="co"># ----------------------------------------------------------------------</span>

<span class="co"># Some variables that can be used to set control the docker build</span>
<span class="kw">ARG</span> MODEL_VERSION=git

<span class="co"># Setup model_info file</span>
<span class="kw">COPY</span> models/ed/model_info.json /work/model.json
<span class="kw">RUN</span> sed -i -e <span class="st">&quot;s/@VERSION@/${MODEL_VERSION}/g&quot;</span> \
           -e <span class="st">&quot;s#@BINARY@#/usr/local/bin/ed2.${MODEL_VERSION}#g&quot;</span> /work/model.json

<span class="co"># COPY model binary</span>
<span class="kw">COPY</span> --from=model-binary /src/ED2/ED/build/ed_2.1-opt /usr/local/bin/ed2.${MODEL_VERSION}</code></pre>
<p><strong>WARNING</strong>: Dockerfile environment variables set via <code>ENV</code> are assigned <em>all at once</em>; <em>they do not evaluate successively, left to right</em>.
Consider the following block:</p>
<pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span class="co"># Don&#39;t do this!</span>
<span class="kw">ENV</span> MODEL_TYPE=<span class="st">&quot;SIPNET&quot;</span> \
    MODEL_VERSION=136 \
    MODEL_TYPE_VERSION=${MODEL_TYPE}_${MODEL_VERSION}   <span class="co"># &lt;- Doesn&#39;t know about MODEL_TYPE or MODEL_VERSION!</span></code></pre>
<p>In this block, the expansion for setting <code>MODEL_TYPE_VERSION</code> <em>is not aware</em> of the current values of <code>MODEL_TYPE</code> or <code>MODEL_VERSION</code>, and will therefore be set incorrectly to just <code>_</code> (unless they have been set previously, in which case it will be aware only of their earlier values).
As such, <strong>variables depending on other variables must be set in a separate, subsequent <code>ENV</code> statement than the variables they depend on</strong>.</p>
<p>Once the model has build and is working we can add it to the PEcAn stack and be able to use this model in the web interface. There are two methods to start this new model. First, we can add it to the <code>docker-compose.yml</code> file and start the container using <code>docker-compose -p pecan -d up</code>.</p>
<pre class="sourceCode yaml"><code class="sourceCode yaml">  <span class="fu">sipnet:</span>
    <span class="fu">image:</span><span class="at"> pecan/model-ed2-git</span>
    <span class="fu">networks:</span>
      <span class="kw">-</span> pecan
    <span class="fu">volumes:</span>
      <span class="kw">-</span> <span class="fu">pecan:</span><span class="at">/data</span>
    <span class="fu">depends_on:</span>
       <span class="kw">-</span> rabbitmq
    <span class="fu">restart:</span><span class="at"> unless-stopped</span></code></pre>
<p>Alternatively we can start the container manually using the following command.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> run \
    --detach \
    --rm \
    --name pecan-ed2-git \
    --networks pecan_pecan \
    --volume pecan_pecan:/data
    <span class="ex">pecan/model-ed2-git</span></code></pre>
</div>
<div id="common-docker-problems" class="section level4">
<h4><span class="header-section-number">2.1.2.30</span> Common problems</h4>
<p>Following are some solutions for common problems that you might encounter when building the docker images for a model.</p>
</div>
<div id="debugging-missing-libraries" class="section level4">
<h4><span class="header-section-number">2.1.2.31</span> Debugging missing libraries</h4>
<p>When building the model binary it might require specific libraries to be installed. In the second stage the model binary is copied into a new image, which could result in the binary missing specific libraries. In the case of the ED2 model the following was used to find the libraries that are needed to be installed (libgfortran5 and libopenmpi3).</p>
<p>The first step is to build the model using the Dockerfile (in this case the ap-get install was missing in the second stage).</p>
<pre><code>Step 5/9 : RUN git clone https://github.com/EDmodel/ED2.git     &amp;&amp; cd ED2/ED/build     &amp;&amp; curl -o make/include.mk.VM http://isda.ncsa.illinois.edu/~kooper/EBI/include.mk.opt.`uname -s`     &amp;&amp; if [ &quot;${MODEL_VERSION}&quot; != &quot;git&quot; ]; then git checkout ${MODEL_VERSION}; fi     &amp;&amp; ./install.sh -g -p VM
... LOTS OF OUTPUT ...
make[1]: Leaving directory &#39;/src/ED2/ED/build/bin-opt-E&#39;
Installation Complete.
Removing intermediate container a53eba9a8fc1
 ---&gt; 7f23c6302130
Step 6/9 : FROM pecan/executor:latest
 ---&gt; f19d81b739f5
... MORE OUTPUT ...
Step 9/9 : COPY --from=model-binary /src/ED2/ED/build/ed_2.1-opt /usr/local/bin/ed2.${MODEL_VERSION}
 ---&gt; 07ac841be457
Successfully built 07ac841be457
Successfully tagged pecan/pecan-ed2:latest</code></pre>
<p>At this point we have created a docker image with the binary and all PEcAn code that is needed to run the model. Some models (especially those build as native code) might be missing additional packages that need to be installed in the docker image. To see if all libraries are installed for the binary.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="op">&gt;</span> <span class="ex">docker</span> run -ti --rm pecan/pecan-ed2 /bin/bash
<span class="ex">root@8a95ee8b6b47</span>:/work# ldd /usr/local/bin/ed2.git  <span class="kw">|</span> <span class="fu">grep</span> <span class="st">&quot;not found&quot;</span>
    <span class="ex">libmpi_usempif08.so.40</span> =<span class="op">&gt;</span> not found
    <span class="ex">libmpi_usempi_ignore_tkr.so.40</span> =<span class="op">&gt;</span> not found
    <span class="ex">libmpi_mpifh.so.40</span> =<span class="op">&gt;</span> not found
    <span class="ex">libmpi.so.40</span> =<span class="op">&gt;</span> not found
    <span class="ex">libgfortran.so.5</span> =<span class="op">&gt;</span> not found</code></pre>
<p>Start the build container again (this is the number before the line FROM pecan/executor:latest, 7f23c6302130 in the example), and find the missing libraries listed above (for example libmpi_usempif08.so.40):</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="op">&gt;</span> <span class="ex">docker</span> run --rm -ti 7f23c6302130
<span class="ex">root@e716c63c031f</span>:/src# dpkg -S libmpi_usempif08.so.40
<span class="ex">libopenmpi3</span>:amd64: /usr/lib/x86_64-linux-gnu/openmpi/lib/libmpi_usempif08.so.40.10.1
<span class="ex">libopenmpi3</span>:amd64: /usr/lib/x86_64-linux-gnu/libmpi_usempif08.so.40.10.1
<span class="ex">libopenmpi3</span>:amd64: /usr/lib/x86_64-linux-gnu/libmpi_usempif08.so.40</code></pre>
<p>This shows the pages is libopenmpi3 that needs to be installed, do this for all missing packages, modify the Dockerfile and rebuild. Next time you run the ldd command there should be no more packages being listed.</p>

</div>
<div id="docker-build-images" class="section level4">
<h4><span class="header-section-number">2.1.2.32</span> Building and modifying images</h4>
<p>The only other section on this page is:
<a href="tutorialsdemos-and-how-tos.html#docker-local-devel">Local development and testing with Docker</a></p>
<p>For general use, it is sufficient to use the pre-built PEcAn images hosted on <a href="https://hub.docker.com/r/pecan/">Docker Hub</a> (see <a href="tutorialsdemos-and-how-tos.html#docker-quickstart">Docker quickstart</a>).
However, there are cases where it makes sense to re-build the Docker images locally.
The following is a list of PEcAn-specific images and reasons why you would want to rebuild them locally:</p>
<ul>
<li><code>pecan/depends</code> – Rebuild if:
<ul>
<li>You modify the <code>docker/base/Dockerfile.depends</code></li>
<li>You introduce new system dependencies (i.e. things that need to be installed with <code>apt-get</code>)</li>
<li>You introduce new R package dependencies, and you want those R package installations to be cached during future builds. For packages with fast build times, it may be fine to let them be installed as part of PEcAn’s standard build process (i.e. <code>make</code>).</li>
</ul></li>
<li><code>pecan/base</code> – Rebuild if:
<ul>
<li>You built a new version of <code>pecan/depends</code> (on which <code>pecan/base</code> depends)</li>
<li>You modify the <code>docker/base/Dockerfile.base</code></li>
<li>You made changes to the PEcAn R package source code, the Makefile, or <code>web/workflow.R</code>.
<ul>
<li>NOTE that changes to the web interface code affect <code>pecan/web</code>, <em>not</em> <code>pecan/base</code></li>
</ul></li>
</ul></li>
<li><code>pecan/executor</code> – Rebuild if:
<ul>
<li>You built a new version of <code>pecan/base</code> (on which <code>pecan/executor</code> depends) and/or, <code>pecan/depends</code> (on which <code>pecan/base</code> depends)</li>
<li>You modified the <code>docker/base/Dockerfile.executor</code></li>
<li>You modified the RabbitMQ Python scripts (e.g. <code>docker/receiver.py</code>, <code>docker/sender.py</code>)</li>
</ul></li>
<li><code>pecan/web</code> – Rebuild if you modified any of the following:
<ul>
<li><code>docker/base/Dockerfile.web</code></li>
<li>The PHP/HTML/JavaScript code for the PEcAn web interface in <code>web/</code> (<em>except</em> <code>web/workflow.R</code> – that goes in <code>pecan/base</code>)</li>
<li><code>docker/config.docker.php</code> (the <code>config.php</code> file for Docker web instances)</li>
<li><code>documentation/index_vm.html</code> (the documentation HTML website)</li>
<li>NOTE: Because changes to this code are applied instantly (i.e. do not require compilation or installation), a more effective way to do local development may be to mount the <code>web/</code> or other relevant folders as a volume onto the <code>pecan/web</code> container.</li>
</ul></li>
</ul>
<p>The easiest way to quickly re-build all of the images is using the <code>docker.sh</code> script in the PEcAn source code root directory.
This script will build all of the docker images locally on your machine, and tag them as <code>latest</code>.
This will not build the <code>pecan/depends</code> image by default because that takes considerably longer.
However, you can force the script to build <code>pecan/depends</code> as well by setting the <code>DEPEND</code> environment variable to 1 (i.e. <code>DEPEND=1 ./docker.sh</code>).
The following instructions provide details on how to build each image individually.</p>
<p>To build an image locally, use the <code>docker build</code> command as described below.
For more details, see <code>docker build --help</code> or the <a href="https://docs.docker.com/engine/reference/commandline/build/">online Docker build documentation</a>.</p>
<p>First, in a terminal window, navigate (<code>cd</code>) into the PEcAn source code root directory.
From there, the general syntax for building an image looks like the following:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> build -t pecan/<span class="op">&lt;</span>image name<span class="op">&gt;</span>:<span class="op">&lt;</span>image version<span class="op">&gt;</span> -f docker/base/Dockerfile.<span class="op">&lt;</span>image name<span class="op">&gt;</span> .</code></pre>
<p>For instance, to build a local version of the <code>pecan/depends:latest</code> image, you would run:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">docker</span> build -t pecan/depends:latest -f docker/base/Dockerfile.depends .</code></pre>
<p>The breakdown of this command is as follows:</p>
<ul>
<li><p><code>docker build</code> – This is the core command.
The standard syntax is <code>docker build [OPTIONS] &lt;PATH&gt;</code>, where <code>&lt;PATH&gt;</code> refers to the directory to be used as the “build context”.
The “build context” is the working directory assumed by the Dockerfiles.
In PEcAn, this is always the PEcAn source code root directory, which allows Dockerfiles to use instructions such as <code>COPY web/workflow.R /work/</code>.
In this example, the <code>&lt;PATH&gt;</code> is set to the current working directory, i.e. <code>.</code> because we are already in the PEcAn root directory.
If you were located in a different directory, you would have to provide a path to the PEcAn source code root directory.
Also, by default, <code>docker build</code> will look for a Dockerfile located at <code>&lt;PATH&gt;/Dockerfile</code>, but this is modified by the <code>-f</code> option described below.</p></li>
<li><code>-t pecan/depends:latest</code> – The <code>-t/--tag</code> option specifies how the image will be labeled.
By default, Docker only defines unique image IDs, which are hexidecimal strings that are unintuitive and hard to remember.
Tags are useful for referring to specific images in a human-readable way.
Note that the same unique image can have multiple tags associated with it, so it is possible for, e.g. <code>pecan/depends:latest</code>, <code>pecan/depends:custom</code>, and even <code>mypecan/somethingelse:20.0</code> to refer to the same exact image.
To see a table of all local images, including their tags and IDs, run <code>docker image ls</code>.
<ul>
<li><strong>NOTE</strong>: PEcAn’s <code>docker-compose.yml</code> can be configured via the <code>PECAN</code> environment variable to point at different versions of PEcAn images.
By default, it points to the <code>:latest</code> versions of all images.
However, if you wanted to, for instance, build <code>:local</code> images corresponding to your local source code and then run that version of PEcAn, you would run:</li>
</ul>
<pre><code>PECAN=local docker-compose -p pecan up -d</code></pre>
<p>This is an effective way to do local development and testing of different PEcAn versions, as described <a href="tutorialsdemos-and-how-tos.html#docker-local-devel">below</a>.</p></li>
<li><p><code>-f docker/base/Dockerfile.depends</code> – The <code>-f/--file</code> tag is used to provide an alternative location and file name for the Dockerfile.
The convention in PEcAn is to put Dockerfiles for core PEcAn functionality in <code>docker/base/</code> and for specific models in <code>docker/models/</code>, and to name these files <code>Dockerfile.&lt;image name&gt;</code>.</p></li>
</ul>
</div>
<div id="docker-local-devel" class="section level4">
<h4><span class="header-section-number">2.1.2.33</span> Local development and testing with Docker</h4>
<p>The following is an example of one possible workflow for developing and testing PEcAn using local Docker images.
The basic idea is to mount a local version of the PEcAn source code onto a running <code>pecan/executor</code> image, and then send a special “rebuild” RabbitMQ message to the container to trigger the rebuild whenever you make changes.
NOTE: All commands assume you are working from the PEcAn source code root directory.</p>
<ol style="list-style-type: decimal">
<li><p>In the PEcAn source code directory, create a <code>docker-compose.override.yml</code> file with the following contents.:</p>
<pre class="sourceCode yml"><code class="sourceCode yaml"><span class="fu">version:</span><span class="at"> </span><span class="st">&quot;3&quot;</span>
<span class="fu">services:</span>
  <span class="fu">executor:</span>
    <span class="fu">volumes:</span>
      <span class="kw">-</span> <span class="fu">.:</span><span class="at">/pecan</span></code></pre>
<p>This will mount the current directory <code>.</code> to the <code>/pecan</code> directory in the <code>executor</code> container.
The special <code>docker-compose.override.yml</code> file is read automatically by <code>docker-compose</code> and overrides or extends any instructions set in the original <code>docker-compose.yml</code> file.
It provides a convenient way to host server-specific configurations without having to modify the project-wide (and version-controlled) default configuration.
For more details, see the <a href="https://docs.docker.com/compose/extends/">Docker Compose documentation</a>.</p></li>
<li><p>Update your PEcAn Docker stack with <code>docker-compose up -d</code>.
If the stack is already running, this should only restart your <code>executor</code> instance while leaving the remaining containers running.</p></li>
<li><p>To update to the latest local code, run <code>./scripts/docker_rebuild.sh</code>.
Under the hood, this uses <code>curl</code> to post a RabbitMQ message to a running Docker instance.
By default, the scripts assumes that username and password are both <code>guest</code> and that the RabbitMQ URL is <code>http://localhost:8000/rabbitmq</code>.
All of these can be customized by setting the environment variables <code>RABBITMQ_USER</code>, <code>RABBITMQ_PASSWORD</code>, and <code>RABBITMQ_URL</code>, respectively (or running the script prefixed with those variables, e.g. <code>RABBITMQ_USER=carya RABBITMQ_PASSWORD=illinois ./scripts/docker_rebuild.sh</code>).
This step can be repeated whenever you want to trigger a rebuild of the local code.</p></li>
</ol>
<p>NOTE: The updates with this workflow are <em>specific to the running container session</em>; restarting the <code>executor</code> container will revert to the previous versions of the installed packages.
To make persistent changes, you should re-build the <code>pecan/base</code> and <code>pecan/executor</code> containers against the current version of the source code.</p>
<p>NOTE: The mounted PEcAn source code directory includes <em>everything</em> in your local source directory, <em>including installation artifacts used by make</em>.
This can lead to two common issues:
- Any previous make cache files (stuff in the <code>.install</code>, <code>.docs</code>, etc. directories) persist across container instances, even though the installed packages may not. To ensure a complete build, it’s a good idea to run <code>make clean</code> on the host machine to remove these artifacts.
- Similarly, any installation artifacts from local builds will be carried over to the build. In particular, be wary of packages with compiled code, such as <code>modules/rtm</code> (<code>PEcAnRTM</code>) – the compiled <code>.o</code>, <code>.so</code>, <code>.mod</code>, etc. files from compilation of such packages will carry over into the build, which can cause conflicts if the package was also built locally.</p>
<p>The <code>docker-compose.override.yml</code> is useful for some other local modifications.
For instance, the following adds a custom ED2 “develop” model container.</p>
<pre class="sourceCode yml"><code class="sourceCode yaml"><span class="fu">services:</span>
  <span class="co"># ...</span>
  <span class="fu">ed2devel:</span>
    <span class="fu">image:</span><span class="at"> pecan/model-ed2-develop:latest</span>
    <span class="fu">build:</span>
      <span class="fu">context:</span><span class="at"> ../ED2  </span><span class="co"># Or wherever ED2 source code is found</span>
    <span class="fu">networks:</span>
      <span class="kw">-</span> pecan
    <span class="fu">depends_on:</span>
      <span class="kw">-</span> rabbitmq
    <span class="fu">volumes:</span>
      <span class="kw">-</span> <span class="fu">pecan:</span><span class="at">/data</span>
    <span class="fu">restart:</span><span class="at"> unless-stopped</span></code></pre>
<p>Similarly, this snippet modifies the <code>pecan</code> network to use a custom IP subnet mask.
This is required on the PNNL cluster because its servers’ IP addresses often clash with Docker’s default IP mask.</p>
<pre class="sourceCode yml"><code class="sourceCode yaml"><span class="fu">networks:</span>
  <span class="fu">pecan:</span>
    <span class="fu">ipam:</span>
      <span class="fu">config:</span>
        <span class="kw">-</span> <span class="fu">subnet:</span><span class="at"> 10.17.1.0/24</span></code></pre>

</div>
<div id="docker-troubleshooting" class="section level4">
<h4><span class="header-section-number">2.1.2.34</span> Troubleshooting Docker</h4>
</div>
<div id="package-not-available-while-building-images" class="section level4">
<h4><span class="header-section-number">2.1.2.35</span> “Package not available” while building images</h4>
<p><strong>PROBLEM</strong>: Packages fail to install while building <code>pecan/depends</code> and/or <code>pecan/base</code> with an error like the following:</p>
<pre><code>Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)
Warning: unable to access index for repository https://mran.microsoft.com/snapshot/2018-09-01/src/contrib:
 cannot open URL &#39;https://mran.microsoft.com/snapshot/2018-09-01/src/contrib/PACKAGES&#39;
Warning message:
package ‘&lt;PACKAGE&gt;’ is not available (for R version 3.5.1)</code></pre>
<p><strong>CAUSE</strong>: This can sometimes happen if there are problems with Microsoft’s CRAN snapshots, which are the default repository for the <code>rocker/tidyverse</code> containers.
See GitHub issues <a href="https://github.com/rocker-org/rocker-versioned/issues/102">rocker-org/rocker-versioned#102</a> and <a href="https://github.com/rocker-org/rocker-versioned/issues/58">#58</a>.</p>
<p><strong>SOLUTION</strong>: Add the following line to the <code>depends</code> and/or <code>base</code> Dockerfiles <em>before</em> (i.e. above) any commands that install R packages (e.g. <code>Rscript -e &quot;install.packages(...)&quot;</code>):</p>
<pre><code>RUN echo &quot;options(repos = c(CRAN = &#39;https://cran.rstudio.org&#39;))&quot; &gt;&gt; /usr/local/lib/R/etc/Rprofile.site</code></pre>
<p>This will set the default repository to the more reliable (albeit, more up-to-date; beware of breaking package changes!) RStudio CRAN mirror.
Then, build the image as usual.</p>

</div>
<div id="docker-migrate" class="section level4">
<h4><span class="header-section-number">2.1.2.36</span> Migrating PEcAn from VM to Docker</h4>
<p>This document assumes you have read through the <a href="tutorialsdemos-and-how-tos.html#docker-intro">Introduction to Docker</a> as well as <a href="tutorialsdemos-and-how-tos.html#docker-quickstart">Docker quickstart</a> and have docker running on the VM.</p>
<p>This document will slowly replace each of the components with the appropriate docker images. At then end of this document you should be able to use the docker-compose command to bring up the full docker stack as if you had started with this origianally.</p>
</div>
<div id="running-bety-as-a-docker-container" class="section level4">
<h4><span class="header-section-number">2.1.2.37</span> Running BETY as a docker container</h4>
<p>This will replace the BETY application running on the machine with a docker image. This will assume you still have the database running on the local machine and the only thing we replace is the BETY application.</p>
<p>If you are running systemd (Ubuntu 16.04 or Centos 7) you can copy the following file to /etc/systemd/system/bety.service (replace LOCAL_SERVER=99 with your actual server). If you have postgres running on another server replace 127.0.0.1 with the actual ip address of the postgres server.</p>
<pre><code>[Unit]
Description=BETY container
After=docker.service

[Service]
Restart=always
ExecStart=/usr/bin/docker run -t --rm --name bety --add-host=postgres:127.0.0.1 --network=host --env RAILS_RELATIVE_URL_ROOT=/bety --env LOCAL_SERVER=99 pecan/bety
ExecStop=/usr/bin/docker stop -t 2 bety

[Install]
WantedBy=local.target</code></pre>
<p>At this point we can enable the bety service (this only needs to be done once). First we need to tell systemd a new service is available using <code>systemctl daemon-reload</code>. Next we enable the BETY service so it will restart automatically when the machine reboots, using <code>systemctl enable bety</code>. Finally we can start the BETY service using <code>systemctl start bety</code>. At this point BETY is running as a docker container on port 8000. You can see the log messages using <code>journalctl -u bety</code>.</p>
<p>Next we need to modify apache configuration files. The file /etc/apache2/conf-enabled/bety.conf will be replaced with the following content:</p>
<pre><code>ProxyPass                /bety/ http://localhost:8000/bety/
ProxyPassReverse         /bety/ http://localhost:8000/bety/
RedirectMatch permanent ^/bety$ /bety/</code></pre>
<p>Once this modified we can restart apache using <code>systemctl restart apache2</code>. At this point BETY is running in a container and is accessable trough the webserver at <a href="http://server/bety/" class="uri">http://server/bety/</a>.</p>
<p>To upgrade to a new version of BETY you can now use the docker commands. You can use the following commands to stop BETY, pull the latest image down, migrate the database (you made a backup correct?) and start BETY again.</p>
<pre><code>systemctl stop bety
docker pull pecan/bety:latest
docker run -ti --rm --add-host=postgres:127.0.0.1 --network=host --env LOCAL_SERVER=99 pecan/bety migrate
systemctl start bety</code></pre>
<p>Once you are satisfied with the migration of BETY you can remove the bety folder as well as any ruby binaries you have installed.</p>

</div>
</div>
<div id="osinstall" class="section level3">
<h3><span class="header-section-number">2.1.3</span> OS Specific Installations</h3>
<ul>
<li><a href="tutorialsdemos-and-how-tos.html#ubuntu">Ubuntu</a></li>
<li><a href="#centos/redhat">CentOS</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#macosx">OSX</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#install-bety">Install BETY</a> THIS PAGE IS DEPRECATED</li>
<li><a href="tutorialsdemos-and-how-tos.html#install-models">Install Models</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#install-data">Install Data</a></li>
</ul>

<div id="ubuntu" class="section level4">
<h4><span class="header-section-number">2.1.3.1</span> Ubuntu</h4>
<p>These are specific notes for installing PEcAn on Ubuntu (14.04) and will be referenced from the main <a href="Installing-PEcAn">installing PEcAn</a> page. You will at least need to install the build environment and Postgres sections. If you want to access the database/PEcAn using a web browser you will need to install Apache. To access the database using the BETY interface, you will need to have Ruby installed.</p>
<p>This document also contains information on how to install the Rstudio server edition as well as any other packages that can be helpful.</p>
<div id="install-build-environment" class="section level5">
<h5><span class="header-section-number">2.1.3.1.1</span> Install build environment</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> -s

<span class="co"># point to latest R</span>
<span class="bu">echo</span> <span class="st">&quot;deb http://cran.rstudio.com/bin/linux/ubuntu </span><span class="kw">`</span><span class="ex">lsb_release</span> -s -c<span class="kw">`</span><span class="st">/&quot;</span> <span class="op">&gt;</span> /etc/apt/sources.list.d/R.list
<span class="ex">apt-key</span> adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9

<span class="co"># update package list</span>
<span class="ex">apt-get</span> -y update

<span class="co"># install packages needed for PEcAn</span>
<span class="ex">apt-get</span> -y install build-essential gfortran git r-base-core r-base-dev jags liblapack-dev libnetcdf-dev netcdf-bin bc libcurl4-gnutls-dev curl udunits-bin libudunits2-dev libgmp-dev python-dev libgdal1-dev libproj-dev expect

<span class="co"># install packages needed for ED2</span>
<span class="ex">apt-get</span> -y install openmpi-bin libopenmpi-dev

<span class="co"># install requirements for DALEC</span>
<span class="ex">apt-get</span> -y install libgsl0-dev

<span class="co"># install packages for webserver</span>
<span class="ex">apt-get</span> -y install apache2 libapache2-mod-php5 php5

<span class="co"># install packages to compile docs</span>
<span class="ex">apt-get</span> -y install texinfo texlive-latex-base texlive-latex-extra texlive-fonts-recommended

<span class="co"># install devtools</span>
<span class="bu">echo</span> <span class="st">&#39;install.packages(&quot;devtools&quot;, repos=&quot;http://cran.rstudio.com/&quot;)&#39;</span> <span class="kw">|</span> <span class="ex">R</span> --vanilla

<span class="co"># done as root</span>
<span class="bu">exit</span></code></pre>
</div>
<div id="install-postgres" class="section level5">
<h5><span class="header-section-number">2.1.3.1.2</span> Install Postgres</h5>
<p>Documentation: <a href="http://trac.osgeo.org/postgis/wiki/UsersWikiPostGIS21UbuntuPGSQL93Apt" class="uri">http://trac.osgeo.org/postgis/wiki/UsersWikiPostGIS21UbuntuPGSQL93Apt</a></p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> -s

<span class="co"># point to latest PostgreSQL</span>
<span class="bu">echo</span> <span class="st">&quot;deb http://apt.postgresql.org/pub/repos/apt </span><span class="kw">`</span><span class="ex">lsb_release</span> -s -c<span class="kw">`</span><span class="st">-pgdg main&quot;</span> <span class="op">&gt;</span> /etc/apt/sources.list.d/pgdg.list
<span class="fu">wget</span> --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc <span class="kw">|</span> <span class="ex">apt-key</span> add -

<span class="co"># update package list</span>
<span class="ex">apt-get</span> -y update

<span class="co"># install packages for postgresql (using a newer version than default)</span>
<span class="ex">apt-get</span> -y install libdbd-pgsql postgresql postgresql-client libpq-dev postgresql-9.4-postgis-2.1 postgresql-9.4-postgis-2.1-scripts

<span class="co"># install following if you want to run pecan through the web</span>
<span class="ex">apt-get</span> -y install php5-pgsql

<span class="co"># enable bety user to login with trust by adding the following lines after</span>
<span class="co"># the ability of postgres user to login in /etc/postgresql/9.4/main/pg_hba.conf</span>
<span class="bu">local</span>   <span class="va">all</span>             <span class="va">bety</span>                                    <span class="va">trust</span>
<span class="ex">host</span>    all             bety            127.0.0.1/32            trust
<span class="ex">host</span>    all             bety            ::1/128                 trust

<span class="co"># Once done restart postgresql</span>
<span class="ex">/etc/init.d/postgresql</span> restart

<span class="bu">exit</span></code></pre>
<p>To install the BETYdb database ..
##### Apache Configuration PEcAn</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># become root</span>
<span class="fu">sudo</span> -s

<span class="co"># get index page</span>
<span class="fu">rm</span> /var/www/html/index.html
<span class="fu">ln</span> -s <span class="va">${HOME}</span>/pecan/documentation/index_vm.html /var/www/html/index.html

<span class="co"># setup a redirect</span>
<span class="fu">cat</span> <span class="op">&gt;</span> /etc/apache2/conf-available/pecan.conf <span class="op">&lt;&lt; EOF</span>
Alias /pecan <span class="va">${HOME}</span>/pecan/web
&lt;Directory <span class="va">${HOME}</span>/pecan/web&gt;
  DirectoryIndex index.php
  Options +ExecCGI
  Require all granted
&lt;/Directory&gt;
<span class="op">EOF</span>
<span class="ex">a2enconf</span> pecan
<span class="ex">/etc/init.d/apache2</span> restart

<span class="co"># done as root</span>
<span class="bu">exit</span></code></pre>
</div>
<div id="apache-configuration-bety" class="section level5">
<h5><span class="header-section-number">2.1.3.1.3</span> Apache Configuration BETY</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> -s

<span class="co"># install all ruby related packages</span>
<span class="ex">apt-get</span> -y install ruby2.0 ruby2.0-dev libapache2-mod-passenger 

<span class="co"># link static content</span>
<span class="fu">ln</span> -s <span class="va">${HOME}</span>/bety/public /var/www/html/bety

<span class="co"># setup a redirect</span>
<span class="fu">cat</span> <span class="op">&gt;</span> /etc/apache2/conf-available/bety.conf <span class="op">&lt;&lt; EOF</span>
RailsEnv production
RailsBaseURI /bety
PassengerRuby /usr/bin/ruby2.0
&lt;Directory /var/www/html/bety&gt;
  Options +FollowSymLinks
  Require all granted
&lt;/Directory&gt;
<span class="op">EOF</span>
<span class="ex">a2enconf</span> bety
<span class="ex">/etc/init.d/apache2</span> restart</code></pre>
</div>
<div id="rstudio-server" class="section level5">
<h5><span class="header-section-number">2.1.3.1.4</span> Rstudio-server</h5>
<p><em>NOTE This will allow anybody to login to the machine through the rstudio interface and run any arbitrary code. The login used however is the same as the system login/password.</em></p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">wget</span> http://download2.rstudio.org/rstudio-server-0.98.1103-amd64.deb</code></pre>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># bceome root</span>
<span class="fu">sudo</span> -s

<span class="co"># install required packages</span>
<span class="ex">apt-get</span> -y install libapparmor1 apparmor-utils libssl0.9.8

<span class="co"># install rstudio</span>
<span class="ex">dpkg</span> -i rstudio-server-*
<span class="fu">rm</span> rstudio-server-*
<span class="bu">echo</span> <span class="st">&quot;www-address=127.0.0.1&quot;</span> <span class="op">&gt;&gt;</span> /etc/rstudio/rserver.conf
<span class="bu">echo</span> <span class="st">&quot;r-libs-user=~/R/library&quot;</span> <span class="op">&gt;&gt;</span> /etc/rstudio/rsession.conf
<span class="ex">rstudio-server</span> restart

<span class="co"># setup rstudio forwarding in apache</span>
<span class="ex">a2enmod</span> proxy_http
<span class="fu">cat</span> <span class="op">&gt;</span> /etc/apache2/conf-available/rstudio.conf <span class="op">&lt;&lt; EOF</span>
ProxyPass        /rstudio/ http://localhost:8787/
ProxyPassReverse /rstudio/ http://localhost:8787/
RedirectMatch permanent ^/rstudio$ /rstudio/
<span class="op">EOF</span>
<span class="ex">a2enconf</span> rstudio
<span class="ex">/etc/init.d/apache2</span> restart

<span class="co"># all done, exit root</span>
<span class="bu">exit</span></code></pre>
</div>
<div id="additional-packages" class="section level5">
<h5><span class="header-section-number">2.1.3.1.5</span> Additional packages</h5>
<p>HDF5 Tools, netcdf, GDB and emacs</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> apt-get -y install hdf5-tools cdo nco netcdf-bin ncview gdb emacs ess nedit</code></pre>

</div>
</div>
<div id="centosredhat-centosredhat" class="section level4">
<h4><span class="header-section-number">2.1.3.2</span> CentOS/RedHat {#centos/redhat}</h4>
<p>These are specific notes for installing PEcAn on CentOS (7) and will be referenced from the main <a href="Installing-PEcAn">installing PEcAn</a> page. You will at least need to install the build environment and Postgres sections. If you want to access the database/PEcAn using a web browser you will need to install Apache. To access the database using the BETY interface, you will need to have Ruby installed.</p>
<p>This document also contains information on how to install the Rstudio server edition as well as any other packages that can be helpful.</p>
<div id="install-build-environment-1" class="section level5">
<h5><span class="header-section-number">2.1.3.2.1</span> Install build environment</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> -s

<span class="co"># install packages needed for PEcAn</span>
<span class="ex">yum</span> -y groupinstall <span class="st">&#39;Development Tools&#39;</span> 
<span class="ex">yum</span> -y install git netcdf-fortran-openmpi-devel R bc curl libxml2-devel openssl-devel ed  udunits2 udunits2-devel netcdf netcdf-devel gmp-devel python-devel gdal-devel proj-devel proj-epsg expect

<span class="co"># jags</span>
<span class="ex">yum</span> -y install http://download.opensuse.org/repositories/home:/cornell_vrdc/CentOS_7/x86_64/jags3-3.4.0-54.1.x86_64.rpm
<span class="ex">yum</span> -y install http://download.opensuse.org/repositories/home:/cornell_vrdc/CentOS_7/x86_64/jags3-devel-3.4.0-54.1.x86_64.rpm

<span class="co"># fix include folder for udunits2</span>
<span class="fu">ln</span> -s /usr/include/udunits2/* /usr/include/

<span class="co"># install packages needed for ED2</span>
<span class="ex">yum</span> -y install environment-modules openmpi-bin libopenmpi-dev

<span class="co"># install requirements for DALEC</span>
<span class="ex">yum</span> -y install gsl-devel

<span class="co"># install packages for webserver</span>
<span class="ex">yum</span> -y install httpd php
<span class="ex">systemctl</span> enable httpd
<span class="ex">systemctl</span> start httpd
<span class="ex">firewall-cmd</span> --zone=public --add-port=80/tcp --permanent
<span class="ex">firewall-cmd</span> --reload

<span class="co"># install packages to compile docs</span>
<span class="co">#apt-get -y install texinfo texlive-latex-base texlive-latex-extra texlive-fonts-recommended</span>

<span class="co"># install devtools</span>
<span class="bu">echo</span> <span class="st">&#39;install.packages(&quot;devtools&quot;, repos=&quot;http://cran.rstudio.com/&quot;)&#39;</span> <span class="kw">|</span> <span class="ex">R</span> --vanilla

<span class="co"># done as root</span>
<span class="bu">exit</span>

<span class="bu">echo</span> <span class="st">&quot;module load mpi&quot;</span> <span class="op">&gt;&gt;</span> ~/.bashrc
<span class="ex">module</span> load mpi</code></pre>
<div id="install-and-configure-postgresql-udunits2-netcdf" class="section level6">
<h6><span class="header-section-number">2.1.3.2.1.1</span> Install and configure PostgreSQL, udunits2, NetCDF</h6>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> -s

<span class="co"># point to latest PostgreSQL</span>
<span class="ex">yum</span> install -y epel-release 
<span class="ex">yum</span> -y install http://yum.postgresql.org/9.4/redhat/rhel-7-x86_64/pgdg-centos94-9.4-1.noarch.rpm

<span class="co"># install packages for postgresql (using a newer version than default)</span>
<span class="ex">yum</span> -y install postgresql94-server postgresql94-contrib postgis2_94 postgresql94-devel udunits2 netcdf

<span class="co"># install following if you want to run pecan through the web</span>
<span class="ex">yum</span> -y install php-pgsql

<span class="co"># enable bety user to login with trust by adding the following lines after</span>
<span class="co"># the ability of postgres user to login in /var/lib/pgsql/9.4/data/pg_hba.conf</span>
<span class="bu">local</span>   <span class="va">all</span>             <span class="va">bety</span>                                    <span class="va">trust</span>
<span class="ex">host</span>    all             bety            127.0.0.1/32            trust
<span class="ex">host</span>    all             bety            ::1/128                 trust

<span class="co"># Create database</span>
<span class="ex">/usr/pgsql-9.4/bin/postgresql94-setup</span> initdb

<span class="co"># Enable postgres</span>
<span class="ex">systemctl</span> enable postgresql-9.4
<span class="ex">systemctl</span> start postgresql-9.4

<span class="bu">exit</span></code></pre>
</div>
</div>
<div id="apache-configuration-pecan" class="section level5">
<h5><span class="header-section-number">2.1.3.2.2</span> Apache Configuration PEcAn</h5>
<p>Install and Start Apache</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">yum</span> -y install httpd
<span class="ex">systemctl</span> enable httpd
<span class="ex">systemctl</span> start httpd</code></pre>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># become root</span>
<span class="fu">sudo</span> -s

<span class="co"># get index page</span>
<span class="fu">rm</span> /var/www/html/index.html
<span class="fu">ln</span> -s /home/carya/pecan/documentation/index_vm.html /var/www/html/index.html

<span class="co"># fix selinux context (does this need to be done after PEcAn is installed?)</span>
<span class="ex">chcon</span> -R -t httpd_sys_content_t /home/carya/pecan /home/carya/output

<span class="co"># setup a redirect</span>
<span class="fu">cat</span> <span class="op">&gt;</span> /etc/httpd/conf.d/pecan.conf <span class="op">&lt;&lt; EOF</span>
Alias /pecan /home/carya/pecan/web
&lt;Directory /home/carya/pecan/web&gt;
  DirectoryIndex index.php
  Options +ExecCGI
  Require all granted
&lt;/Directory&gt;
<span class="op">EOF</span>
<span class="ex">a2enconf</span> pecan
<span class="ex">/etc/init.d/apache2</span> restart

<span class="co"># done as root</span>
<span class="bu">exit</span></code></pre>
</div>
<div id="apache-configuration-bety-1" class="section level5">
<h5><span class="header-section-number">2.1.3.2.3</span> Apache Configuration BETY</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> -s

<span class="co"># install all ruby related packages</span>
<span class="fu">sudo</span> curl --fail -sSLo /etc/yum.repos.d/passenger.repo https://oss-binaries.phusionpassenger.com/yum/definitions/el-passenger.repo
<span class="ex">yum</span> -y install ruby ruby-devel mod_passenger

<span class="co"># link static content</span>
<span class="fu">ln</span> -s /home/carya/bety/public /var/www/html/bety

<span class="co"># fix GemFile</span>
<span class="bu">echo</span> <span class="st">&#39;gem &quot;test-unit&quot;&#39;</span> <span class="op">&gt;&gt;</span> bety/Gemlile

<span class="co"># fix selinux context (does this need to be done after bety is installed?)</span>
<span class="ex">chcon</span> -R -t httpd_sys_content_t /home/carya/bety

<span class="co"># setup a redirect</span>
<span class="fu">cat</span> <span class="op">&gt;</span> /etc/httpd/conf.d/bety.conf <span class="op">&lt;&lt; EOF</span>
RailsEnv production
RailsBaseURI /bety
PassengerRuby /usr/bin/ruby
&lt;Directory /var/www/html/bety&gt;
  Options +FollowSymLinks
  Require all granted
&lt;/Directory&gt;
<span class="op">EOF</span>
<span class="ex">systemctl</span> restart httpd</code></pre>
</div>
<div id="rstudio-server-1" class="section level5">
<h5><span class="header-section-number">2.1.3.2.4</span> Rstudio-server</h5>
<p>NEED FIXING</p>
<p><em>NOTE This will allow anybody to login to the machine through the rstudio interface and run any arbitrary code. The login used however is the same as the system login/password.</em></p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">wget</span> http://download2.rstudio.org/rstudio-server-0.98.1103-amd64.deb</code></pre>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># bceome root</span>
<span class="fu">sudo</span> -s

<span class="co"># install required packages</span>
<span class="ex">apt-get</span> -y install libapparmor1 apparmor-utils libssl0.9.8

<span class="co"># install rstudio</span>
<span class="ex">dpkg</span> -i rstudio-server-*
<span class="fu">rm</span> rstudio-server-*
<span class="bu">echo</span> <span class="st">&quot;www-address=127.0.0.1&quot;</span> <span class="op">&gt;&gt;</span> /etc/rstudio/rserver.conf
<span class="bu">echo</span> <span class="st">&quot;r-libs-user=~/R/library&quot;</span> <span class="op">&gt;&gt;</span> /etc/rstudio/rsession.conf
<span class="ex">rstudio-server</span> restart

<span class="co"># setup rstudio forwarding in apache</span>
<span class="ex">a2enmod</span> proxy_http
<span class="fu">cat</span> <span class="op">&gt;</span> /etc/apache2/conf-available/rstudio.conf <span class="op">&lt;&lt; EOF</span>
ProxyPass        /rstudio/ http://localhost:8787/
ProxyPassReverse /rstudio/ http://localhost:8787/
RedirectMatch permanent ^/rstudio$ /rstudio/
<span class="op">EOF</span>
<span class="ex">a2enconf</span> rstudio
<span class="ex">/etc/init.d/apache2</span> restart

<span class="co"># all done, exit root</span>
<span class="bu">exit</span></code></pre>
<p><em>Alternative Rstudio instructions</em></p>
</div>
<div id="install-and-configure-rstudio-server" class="section level5">
<h5><span class="header-section-number">2.1.3.2.5</span> Install and configure Rstudio-server</h5>
<p>Install RStudio Server by following the <a href="https://www.rstudio.com/products/rstudio/download-server/">official documentation</a> for your platform.
Then, proceed with the following:</p>
<ul>
<li>add <code>PATH=$PATH:/usr/sbin:/sbin</code> to <code>/etc/profile</code></li>
</ul>
<pre class="sourceCode bash"><code class="sourceCode bash">   <span class="fu">cat</span> <span class="st">&quot;PATH=</span><span class="va">$PATH</span><span class="st">:/usr/sbin:/sbin; export PATH&quot;</span> <span class="op">&gt;&gt;</span> /etc/profile</code></pre>
<ul>
<li>add <a href="https://gist.github.com/dlebauer/6921889">rstudio.conf</a> to /etc/httpd/conf.d/</li>
</ul>
<pre class="sourceCode bash"><code class="sourceCode bash">   <span class="fu">wget</span> https://gist.github.com/dlebauer/6921889/raw/d1e0f945228e5519afa6223d6f49d6e0617262bd/rstudio.conf
   <span class="fu">sudo</span> mv rstudio.conf /httpd/conf.d/</code></pre>
<ul>
<li>restart the Apache server: <code>sudo httpd restart</code></li>
<li>now you should be able to access <code>http://&lt;server&gt;/rstudio</code></li>
</ul>
<div id="install-ruby-netcdf-gem" class="section level6">
<h6><span class="header-section-number">2.1.3.2.5.1</span> Install ruby-netcdf gem</h6>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span> <span class="va">$RUBY_APPLICATION_HOME</span>
<span class="bu">export</span> <span class="va">$NETCDF_URL=</span>http://www.gfd-dennou.org/arch/ruby/products/ruby-netcdf/release/ruby-netcdf-0.6.6.tar.gz
<span class="bu">export</span> <span class="va">$NETCDF_DIR=</span>/usr/local/netcdf
<span class="ex">gem</span> install narray
<span class="bu">export</span> <span class="va">NARRAY_DIR=</span><span class="st">&quot;</span><span class="va">$(</span><span class="fu">ls</span> <span class="va">$GEM_HOME</span>/gems <span class="kw">|</span> <span class="fu">grep</span> <span class="st">&#39;narray-&#39;</span><span class="va">)</span><span class="st">&quot;</span>
<span class="bu">export</span> <span class="va">NARRAY_PATH=</span><span class="st">&quot;</span><span class="va">$GEM_HOME</span><span class="st">/gems/</span><span class="va">$NARRAY_DIR</span><span class="st">&quot;</span>
<span class="bu">cd</span> <span class="va">$MY_RUBY_HOME</span>/bin
<span class="fu">wget</span> <span class="va">$NETCDF_URL</span> -O ruby-netcdf.tgz
<span class="fu">tar</span> zxf ruby-netcdf.tgz <span class="kw">&amp;&amp;</span> <span class="bu">cd</span> ruby-netcdf-0.6.6/
<span class="ex">ruby</span> -rubygems extconf.rb --with-narray-include=<span class="va">$NARRAY_PATH</span> --with-netcdf-dir=/usr/local/netcdf-4.3.0
<span class="fu">sed</span> -i <span class="st">&#39;s|rb/$|rb|&#39;</span> Makefile
<span class="fu">make</span>
<span class="fu">make</span> install
<span class="bu">cd</span> ../ <span class="kw">&amp;&amp;</span> <span class="fu">sudo</span> rm -rf ruby-netcdf*

<span class="bu">cd</span> <span class="va">$RUBY_APPLICATION</span>
<span class="ex">bundle</span> install --without development</code></pre>
</div>
</div>
<div id="additional-packages-1" class="section level5">
<h5><span class="header-section-number">2.1.3.2.6</span> Additional packages</h5>
<p>NEED FIXING</p>
<p>HDF5 Tools, netcdf, GDB and emacs</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> apt-get -y install hdf5-tools cdo nco netcdf-bin ncview gdb emacs ess nedit</code></pre>

</div>
</div>
<div id="macosx" class="section level4">
<h4><span class="header-section-number">2.1.3.3</span> Mac OSX</h4>
<p>These are specific notes for installing PEcAn on Mac OSX and will be referenced from the main <a href="Installing-PEcAn">installing PEcAn</a> page. You will at least need to install the build environment and Postgres sections. If you want to access the database/PEcAn using a web browser you will need to install Apache. To access the database using the BETY interface, you will need to have Ruby installed.</p>
<p>This document also contains information on how to install the Rstudio server edition as well as any other packages that can be helpful.</p>
<div id="install-build-environment-2" class="section level5">
<h5><span class="header-section-number">2.1.3.3.1</span> Install build environment</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># install R</span>
<span class="co"># download from http://cran.r-project.org/bin/macosx/</span>

<span class="co"># install gfortran </span>
<span class="co"># download from http://cran.r-project.org/bin/macosx/tools/</span>

<span class="co"># install OpenMPI</span>
<span class="ex">curl</span> -o openmpi-1.6.3.tar.gz http://www.open-mpi.org/software/ompi/v1.6/downloads/openmpi-1.6.3.tar.gz
<span class="fu">tar</span> zxf openmpi-1.6.3.tar.gz
<span class="bu">cd</span> openmpi-1.6.3
<span class="ex">./configure</span> --prefix=/usr/local
<span class="fu">make</span> all
<span class="fu">sudo</span> make install
<span class="bu">cd</span> ..

<span class="co"># install szip</span>
<span class="ex">curl</span> -o szip-2.1-MacOSX-intel.tar.gz ftp://ftp.hdfgroup.org/lib-external/szip/2.1/bin/szip-2.1-MacOSX-intel.tar.gz
<span class="fu">tar</span> zxf szip-2.1-MacOSX-intel.tar.gz
<span class="fu">sudo</span> mv szip-2.1-MacOSX-intel /usr/local/szip

<span class="co"># install HDF5</span>

<span class="ex">curl</span> -o hdf5-1.8.11.tar.gz http://www.hdfgroup.org/ftp/HDF5/current/src/hdf5-1.8.11.tar.gz
<span class="fu">tar</span> zxf hdf5-1.8.11.tar.gz
<span class="bu">cd</span> hdf5-1.8.11
<span class="fu">sed</span> -i -e <span class="st">&#39;s/-O3/-O0/g&#39;</span> config/gnu-flags 
<span class="ex">./configure</span> --prefix=/usr/local/hdf5 --enable-fortran --enable-cxx --with-szlib=/usr/local/szip
<span class="fu">make</span>
<span class="co"># make check</span>
<span class="fu">sudo</span> make install
<span class="co"># sudo make check-install</span>
<span class="bu">cd</span> ..</code></pre>
</div>
<div id="install-postgres-1" class="section level5">
<h5><span class="header-section-number">2.1.3.3.2</span> Install Postgres</h5>
<p>For those on a Mac I use the following app for postgresql which has
postgis already installed (<a href="http://postgresapp.com/" class="uri">http://postgresapp.com/</a>)</p>
<p>To get postgis run the following commands in psql:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">##### Enable PostGIS (includes raster)</span>
<span class="ex">CREATE</span> EXTENSION postgis<span class="kw">;</span>
<span class="co">##### Enable Topology</span>
<span class="ex">CREATE</span> EXTENSION postgis_topology<span class="kw">;</span>
<span class="co">##### fuzzy matching needed for Tiger</span>
<span class="ex">CREATE</span> EXTENSION fuzzystrmatch<span class="kw">;</span>
<span class="co">##### Enable US Tiger Geocoder</span>
<span class="ex">CREATE</span> EXTENSION postgis_tiger_geocoder<span class="kw">;</span></code></pre>
<p>To check your postgis run the following command again in psql: <code>SELECT PostGIS_full_version();</code></p>
</div>
<div id="additional-installs" class="section level5">
<h5><span class="header-section-number">2.1.3.3.3</span> Additional installs</h5>
<div id="install-jags" class="section level6">
<h6><span class="header-section-number">2.1.3.3.3.1</span> Install JAGS</h6>
<p>Download JAGS from <a href="http://sourceforge.net/projects/mcmc-jags/files/JAGS/3.x/Mac%20OS%20X/JAGS-Mavericks-3.4.0.dmg/download">http://sourceforge.net/projects/mcmc-jags/files/JAGS/3.x/Mac%20OS%20X/JAGS-Mavericks-3.4.0.dmg/download</a></p>
</div>
<div id="install-udunits" class="section level6">
<h6><span class="header-section-number">2.1.3.3.3.2</span> Install udunits</h6>
<p>Installing udunits-2 on MacOSX is done from source.</p>
<ul>
<li>download most recent <a href="http://www.unidata.ucar.edu/downloads/udunits/index.jsp">version of Udunits here</a></li>
<li>instructions for <a href="http://www.unidata.ucar.edu/software/udunits/udunits-2/udunits2.html#Obtain">compiling from source</a></li>
</ul>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">curl</span> -o udunits-2.1.24.tar.gz ftp://ftp.unidata.ucar.edu/pub/udunits/udunits-2.1.24.tar.gz
<span class="fu">tar</span> zxf udunits-2.1.24.tar.gz
<span class="bu">cd</span> udunits-2.1.24
<span class="ex">./configure</span>
<span class="fu">make</span>
<span class="fu">sudo</span> make install</code></pre>
</div>
</div>
<div id="apache-configuration" class="section level5">
<h5><span class="header-section-number">2.1.3.3.4</span> Apache Configuration</h5>
<p>Mac does not support pdo/postgresql by default. The easiest way to install is use: <a href="http://php-osx.liip.ch/" class="uri">http://php-osx.liip.ch/</a></p>
<p>To enable pecan to run from your webserver.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">cat</span> <span class="op">&gt;</span> /etc/apache2/others/pecan.conf <span class="op">&lt;&lt; EOF</span>
Alias /pecan <span class="va">${PWD}</span>/pecan/web
&lt;Directory <span class="va">${PWD}</span>/pecan/web&gt;
  DirectoryIndex index.php
  Options +All
  Require all granted
&lt;/Directory&gt;
<span class="op">EOF</span></code></pre>
</div>
<div id="ruby" class="section level5">
<h5><span class="header-section-number">2.1.3.3.5</span> Ruby</h5>
<p>The default version of ruby should work. Or use <a href="https://jewelrybox.unfiniti.com/">JewelryBox</a>.</p>
</div>
<div id="rstudio-server-2" class="section level5">
<h5><span class="header-section-number">2.1.3.3.6</span> Rstudio Server</h5>
<p>For the mac you can download <a href="http://www.rstudio.com/">Rstudio Desktop</a>.</p>

</div>
</div>
<div id="install-bety" class="section level4">
<h4><span class="header-section-number">2.1.3.4</span> Installing BETY</h4>
<p>**************THIS PAGE IS DEPRECATED*************</p>
<p>Official Instructions for BETY are maintained here: <a href="https://pecan.gitbook.io/betydb-documentation" class="uri">https://pecan.gitbook.io/betydb-documentation</a></p>
<p>If you would like to install the Docker Version of BETY, please consult the <a href="tutorialsdemos-and-how-tos.html#pecan-docker">PEcAn Docker</a> section.</p>
</div>
<div id="install-database-data" class="section level4">
<h4><span class="header-section-number">2.1.3.5</span> Install Database + Data</h4>
<ul>
<li><em>note</em> To install BETYdb without PEcAn, first download the <a href="https://raw.githubusercontent.com/PecanProject/pecan/master/scripts/load.bety.sh"><code>load.bety.sh</code> script</a></li>
</ul>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="co"># install database (code assumes password is bety)</span>
<span class="fu">sudo</span> -u postgres createuser -d -l -P -R -S bety
<span class="fu">sudo</span> -u postgres createdb -O bety bety
<span class="fu">sudo</span> -u postgres ./scripts/load.bety.sh -c YES -u YES -r 0
<span class="fu">sudo</span> -u postgres ./scripts/load.bety.sh -r 1
<span class="fu">sudo</span> -u postgres ./scripts/load.bety.sh -r 2

<span class="co"># configure for PEcAn web app (change password if needed)</span>
<span class="fu">cp</span> web/config.example.php web/config.php 

<span class="co"># add models to database (VM only)</span>
<span class="ex">./scripts/add.models.sh</span>

<span class="co"># add data to database</span>
<span class="ex">./scripts/add.data.sh</span>

<span class="co"># create outputs folder</span>
<span class="fu">mkdir</span> ~/output
<span class="fu">chmod</span> 777 ~/output</code></pre>
</div>
<div id="installing-betydb-web-application" class="section level4">
<h4><span class="header-section-number">2.1.3.6</span> Installing BETYdb Web Application</h4>
<p>There are two flavors of BETY, PHP and RUBY. The PHP version allows for a minimal interaction with the database while the RUBY version allows for full interaction with the database.</p>
<div id="php-version" class="section level5">
<h5><span class="header-section-number">2.1.3.6.1</span> PHP version</h5>
<p>The php version comes with PEcAn and is already configured.</p>
</div>
<div id="ruby-version" class="section level5">
<h5><span class="header-section-number">2.1.3.6.2</span> RUBY version</h5>
<p>The RUBY version requires a few extra packages to be installed first.</p>
<p>Next we install the web app.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># install bety</span>
<span class="bu">cd</span>
<span class="fu">git</span> clone https://github.com/PecanProject/bety.git

<span class="co"># install gems</span>
<span class="bu">cd</span> bety
<span class="fu">sudo</span> gem2.0 install bundler
<span class="ex">bundle</span> install --without development:test:javascript_testing:debug</code></pre>
<p>and configure BETY</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># create folders for upload folders</span>
<span class="fu">mkdir</span> paperclip/files paperclip/file_names
<span class="fu">chmod</span> 777 paperclip/files paperclip/file_names

<span class="co"># create folder for log files</span>
<span class="fu">mkdir</span> log
<span class="fu">touch</span> log/production.log
<span class="fu">chmod</span> 0666 log/production.log

<span class="co"># fix configuration for vm</span>
<span class="fu">cp</span> config/additional_environment_vm.rb config/additional_environment.rb
<span class="fu">chmod</span> go+w public/javascripts/cache/

<span class="co"># setup bety database configuration</span>
<span class="fu">cat</span> <span class="op">&gt;</span> config/database.yml <span class="op">&lt;&lt; EOF</span>
production:
  adapter: postgis
  encoding: utf-8
  reconnect: false
  database: bety
  pool: 5
  username: bety
  password: bety
<span class="op">EOF</span>

<span class="co"># setup login tokens</span>
<span class="fu">cat</span> <span class="op">&gt;</span> config/initializers/site_keys.rb <span class="op">&lt;&lt; EOF</span>
REST_AUTH_SITE_KEY         = &#39;thisisnotasecret&#39;
REST_AUTH_DIGEST_STRETCHES = 10
<span class="op">EOF</span></code></pre>

</div>
</div>
<div id="install-models" class="section level4">
<h4><span class="header-section-number">2.1.3.7</span> Install Models</h4>
<p>This page contains instructions on how to download and install ecosystem models that have been or are being coupled to PEcAn.
These instructions have been tested on the PEcAn unbuntu VM. Commands may vary on other operating systems.
Also, some model downloads require permissions before downloading, making them unavailable to the general public. Please contact the PEcAn team if you would like access to a model that is not already installed on the default PEcAn VM.</p>
<ul>
<li><a href="tutorialsdemos-and-how-tos.html#inst-biocro">BioCro</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#inst-clm45">CLM 4.5</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#inst-dalec">DALEC</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#inst-ed2">ED2</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#inst-fates">FATES</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#inst-gday">GDAY</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#inst-jules">JULES</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#inst-linkages">LINKAGES</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#inst-lpj-guess">LPJ-GUESS</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#inst-maespa">MAESPA</a></li>
<li><a href="#inst-sipnet">SIPNET</a></li>
</ul>

</div>
<div id="inst-biocro" class="section level4">
<h4><span class="header-section-number">2.1.3.8</span> BioCro</h4>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Public</span>
echo <span class="st">&#39;devtools::install_github(&quot;ebimodeling/biocro&quot;)&#39;</span> <span class="op">|</span><span class="st"> </span>R <span class="op">--</span>vanilla
<span class="co"># Development:</span>
echo <span class="st">&#39;devtools::install_github(&quot;ebimodeling/biocro-dev&quot;)&#39;</span> <span class="op">|</span><span class="st"> </span>R <span class="op">--</span>vanilla</code></pre>
<p><em>BioCro Developers:</em> request from <span class="citation">[@dlebauer on GitHub]</span>(<a href="https://github.com/dlebauer" class="uri">https://github.com/dlebauer</a>)</p>

</div>
<div id="inst-clm45" class="section level4">
<h4><span class="header-section-number">2.1.3.9</span> CLM 4.5</h4>
<p>The version of CLM installed on PEcAn is the ORNL branch provided by Dan Ricciuto. This version includes Dan’s point-level CLM processing scripts</p>
<p>Download the code (~300M compressed), input data (1.7GB compressed and expands to 14 GB), and a few misc inputs.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">mkdir</span> models
<span class="bu">cd</span> models
<span class="fu">wget</span> ftp://nacp.ornl.gov/synthesis/2008/firenze/site/clm4_5_1_r085.tar.gz
<span class="fu">wget</span> ftp://nacp.ornl.gov/synthesis/2008/firenze/site/clm/ccsm_inputdata.tar.gz
<span class="fu">tar</span> -xvzf clm4_5*
<span class="fu">tar</span> -xvzf ccsm_inputdata.tar.gz

<span class="co">#Parameter file:</span>
<span class="fu">mkdir</span> /home/carya/models/ccsm_inputdata/lnd/clm2/paramdata
<span class="bu">cd</span>  /home/carya/models/ccsm_inputdata/lnd/clm2/paramdata
<span class="fu">wget</span> ftp://nacp.ornl.gov/synthesis/2008/firenze/site/clm_params.c130821.nc
<span class="fu">wget</span> ftp://nacp.ornl.gov/synthesis/2008/firenze/site/clm_params.c140423.nc

<span class="co">#Domain file:</span>
<span class="bu">cd</span> /home/carya/models/ccsm_inputdata/share/domains/domain.clm/
<span class="fu">wget</span> ftp://nacp.ornl.gov/synthesis/2008/firenze/site/domain.lnd.1x1pt_US-UMB_navy.nc

<span class="co">#Aggregated met data file:</span>
<span class="bu">cd</span> /home/carya/models/ccsm_inputdata/atm/datm7/CLM1PT_data/1x1pt_US-UMB
<span class="fu">wget</span> ftp://nacp.ornl.gov/synthesis/2008/firenze/site/all_hourly.nc 

<span class="co">## lightning database</span>
<span class="bu">cd</span> /home/carya/models/ccsm_inputdata/atm/datm7/NASA_LIS/
<span class="fu">wget</span> ftp://nacp.ornl.gov/synthesis/2008/firenze/site/clmforc.Li_2012_climo1995-2011.T62.lnfm_Total_c140423.nc

<span class="co">## surface data</span>
<span class="bu">cd</span> /home/carya/models/ccsm_inputdata/lnd/clm2/surfdata
<span class="fu">wget</span> ftp://nacp.ornl.gov/synthesis/2008/firenze/site/clm/surfdata_360x720cru_simyr1850_c130927.nc
<span class="bu">cd</span> /home/carya/models/ccsm_inputdata/lnd/clm2/surfdata_map
<span class="fu">wget</span> ftp://nacp.ornl.gov/synthesis/2008/firenze/site/clm/surfdata_1x1pt_US-UMB_I1850CLM45CN_simyr1850.nc_new
<span class="fu">mv</span> surfdata_1x1pt_US-UMB_I1850CLM45CN_simyr1850.nc_new surfdata_1x1pt_US-UMB_I1850CLM45CN_simyr1850.nc</code></pre>
<p>Required libraries</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">sudo</span> apt-get install mercurial csh tcsh subversion cmake

<span class="fu">sudo</span> ln -s /usr/bin/make /usr/bin/gmake</code></pre>
<p>Compile and build default inputs</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span> ~/carya/models/clm4_5_1_r085/scripts
<span class="ex">python</span> runCLM.py --site US-UMB ––compset I1850CLM45CN --mach ubuntu --ccsm_input /home/carya/models/ccsm_inputdata --tstep 1 --nopointdata --coldstart --cpl_bypass --clean_build</code></pre>
<div id="clm-test-run" class="section level5">
<h5><span class="header-section-number">2.1.3.9.1</span> CLM Test Run</h5>
<p>You will see a new directory in scripts: US-UMB_I1850CLM45CN
Enter this directory and run (you shouldn’t have to do this normally, but there is a bug with the python script and doing this ensures all files get to the right place):</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">./US-UMB_I1850CLM45CN.build</span></code></pre>
<p>Next you are ready to go to the run directory:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">/home/carya/models/clm4_5_1_r085/run/US-UMB_I1850CLM45CN/run</span></code></pre>
<p>Open to edit file: datm.streams.txt.CLM1PT.CLM_USRDAT and check file paths such that all paths start with /home/carya/models/ccsm_inputdata</p>
<p>From this directory, launch the executable that resides in the bld directory:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">/home/carya/clm4_5_1_r085/run/US-UMB_I1850CLM45CN/bld/cesm.exe</span></code></pre>
<p>not sure this was the right location, but wherever the executable is</p>
<p>You should begin to see output files that look like this:
US-UMB_I1850CLM45CN.clm2.h0.yyyy-mm.nc (yyyy is year, mm is month)
These are netcdf files containing monthly averages of lots of variables.</p>
<p>The lnd_in file in the run directory can be modified to change the output file frequency and variables.</p>

</div>
</div>
<div id="inst-dalec" class="section level4">
<h4><span class="header-section-number">2.1.3.10</span> DALEC</h4>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span>
<span class="ex">curl</span> -o dalec_EnKF_pub.tgz http://isda.ncsa.illinois.edu/~kooper/EBI/dalec_EnKF_pub.tgz
<span class="fu">tar</span> zxf dalec_EnKF_pub.tgz
<span class="fu">rm</span> dalec_EnKF_pub.tgz

<span class="bu">cd</span> dalec_EnKF_pub
<span class="fu">make</span> dalec_EnKF
<span class="fu">make</span> dalec_seqMH
<span class="fu">sudo</span> cp dalec_EnKF dalec_seqMH /usr/local/bin</code></pre>

</div>
<div id="inst-ed2" class="section level4">
<h4><span class="header-section-number">2.1.3.11</span> ED2</h4>
<div id="ed2.2-r46-used-in-pecan-manuscript" class="section level5">
<h5><span class="header-section-number">2.1.3.11.1</span> ED2.2 r46 (used in PEcAn manuscript)</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># ----------------------------------------------------------------------</span>
<span class="co"># Get version r46 with a few patches for ubuntu</span>
<span class="bu">cd</span>
<span class="ex">curl</span> -o ED.r46.tgz http://isda.ncsa.illinois.edu/~kooper/EBI/ED.r46.tgz
<span class="fu">tar</span> zxf ED.r46.tgz
<span class="fu">rm</span> ED.r46.tgz
<span class="co"># ----------------------------------------------------------------------</span>
<span class="co"># configure and compile ed</span>
<span class="bu">cd</span> ~/ED.r46/ED/build/bin
<span class="ex">curl</span> -o include.mk.VM http://isda.ncsa.illinois.edu/~kooper/EBI/include.mk.opt.<span class="kw">`</span><span class="fu">uname</span> -s<span class="kw">`</span>
<span class="fu">make</span> OPT=VM
<span class="fu">sudo</span> cp ../ed_2.1-VM /usr/local/bin/ed2.r46</code></pre>
<p>Perform a test run using pre configured ED settings for ED2.2 r46</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># ----------------------------------------------------------------------</span>
<span class="co"># Create sample run</span>
<span class="bu">cd</span>
<span class="fu">mkdir</span> testrun.ed.r46
<span class="bu">cd</span> testrun.ed.r46
<span class="ex">curl</span> -o ED2IN http://isda.ncsa.illinois.edu/~kooper/EBI/ED2IN.r46
<span class="fu">sed</span> -i -e <span class="st">&quot;s#</span><span class="dt">\$</span><span class="st">HOME#</span><span class="va">$HOME</span><span class="st">#&quot;</span> ED2IN
<span class="ex">curl</span> -o config.xml  http://isda.ncsa.illinois.edu/~kooper/EBI/config.r46.xml
<span class="co"># execute test run</span>
<span class="bu">time</span> ed2.r46</code></pre>
</div>
<div id="ed-2.2-r82" class="section level5">
<h5><span class="header-section-number">2.1.3.11.2</span> ED 2.2 r82</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span>
<span class="ex">curl</span> -o ED.r82.tgz http://isda.ncsa.illinois.edu/~kooper/EBI/ED.r82.tgz
<span class="fu">tar</span> zxf ED.r82.tgz
<span class="fu">rm</span> ED.r82.tgz

<span class="bu">cd</span> ED.r82
<span class="ex">curl</span> -o ED.r82.patch http://isda.ncsa.illinois.edu/~kooper/EBI/ED.r82.patch
<span class="fu">patch</span> -p1 <span class="op">&lt;</span> ED.r82.patch
<span class="bu">cd</span> ED/build/bin
<span class="ex">curl</span> -o include.mk.VM http://isda.ncsa.illinois.edu/~kooper/EBI/include.mk.opt.<span class="kw">`</span><span class="fu">uname</span> -s<span class="kw">`</span>
<span class="fu">make</span> OPT=VM
<span class="fu">sudo</span> cp ../ed_2.1-VM /usr/local/bin/ed2.r82</code></pre>
<p>Perform a test run using pre configured ED settings for ED2.2 r82</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span>
<span class="fu">mkdir</span> testrun.ed.r82
<span class="bu">cd</span> testrun.ed.r82
<span class="ex">curl</span> -o ED2IN http://isda.ncsa.illinois.edu/~kooper/EBI/ED2IN.r82
<span class="fu">sed</span> -i -e <span class="st">&quot;s#</span><span class="dt">\$</span><span class="st">HOME#</span><span class="va">$HOME</span><span class="st">#&quot;</span> ED2IN
<span class="ex">curl</span> -o config.xml  http://isda.ncsa.illinois.edu/~kooper/EBI/config.r82.xml
<span class="co"># execute test run</span>
<span class="bu">time</span> ed2.r82</code></pre>
</div>
<div id="ed-2.2-bleeding-edge" class="section level5">
<h5><span class="header-section-number">2.1.3.11.3</span> ED 2.2 bleeding edge</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span>
<span class="fu">git</span> clone https://github.com/EDmodel/ED2.git

<span class="bu">cd</span> ED2/ED/build/bin
<span class="ex">curl</span> -o include.mk.VM http://isda.ncsa.illinois.edu/~kooper/EBI/include.mk.opt.<span class="kw">`</span><span class="fu">uname</span> -s<span class="kw">`</span>
<span class="ex">./generate_deps.sh</span>
<span class="fu">make</span> OPT=VM
<span class="fu">sudo</span> cp ../ed_2.1-VM /usr/local/bin/ed2.git</code></pre>

</div>
</div>
<div id="inst-fates" class="section level4">
<h4><span class="header-section-number">2.1.3.12</span> CLM-FATES</h4>
<p>Prerequisites</p>
<pre><code>sudo apt-get upgrade libnetcdf-dev
sudo apt-get install subversion
sudo apt-get install csh
sudo apt-get install cmake
sudo ln -s /usr/bin/make /usr/bin/gmake
sudo rm /bin/sh
sudo ln -s /bin/bash /bin/sh

wget https://github.com/Unidata/netcdf-fortran/archive/v4.4.4.tar.gz
cd netcdf-4.4.4
./configure
make
sudo make install</code></pre>
<p>you might need to mess around with installing netcdf and netcdf-fortran to get a version FATES likes…</p>
<p>Get code from Github (currently private) and go to cime/scripts directory</p>
<pre><code>git clone git@github.com:NGEET/ed-clm.git
cd ed-clm/cime/scripts/</code></pre>
<p>Within CLM-FATES, to be able to build an executable we need to create a reference run. We’ll also use this reference run to grab defaults from, so we’ll be registering the location of both the reference <strong>case</strong> (location of executable, scripts, etc) and the reference <strong>inputs</strong> with the PEcAn database. To begin, copy reference run script from pecan</p>
<pre><code>cp ~/pecan/models/fates/inst/create_1x1_ref_case.sh .</code></pre>
<p>Edit reference case script to set NETCDF_HOME, CROOT (reference run case), DIN_LOC_ROOT (reference run inputs). Also, make sure DIN_LOC_ROOT exists as FATES will not create it itself. Then run the script</p>
<pre><code>./create_1x1_ref_case.sh</code></pre>
<p>Be aware that this script WILL ask you for your password on the NCAR server to download the reference case input data (the guest password may work, haven’t tried this). If it gives an error at the pio stage check the log, but the most likely error is it being unable to find a version of netcdf it likes.</p>
<p>Once FATES is installed, set the whole reference case directory as the Model path (leave filename blank) and set the whole inputs directory as an Input with format clm_defaults.</p>

</div>
<div id="inst-gday" class="section level4">
<h4><span class="header-section-number">2.1.3.13</span> GDAY</h4>
<p>Navigate to a directory you would like to store GDAY and run the following:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">git</span> clone https://github.com/mdekauwe/GDAY.git

<span class="bu">cd</span> GDAY

<span class="bu">cd</span> src

<span class="fu">make</span></code></pre>
<p><code>gday</code> is your executable.</p>

</div>
<div id="inst-jules" class="section level4">
<h4><span class="header-section-number">2.1.3.14</span> JULES</h4>
<p>INSTALL STEPS:
1) Download JULES and FCM
JULES:
Model requires registration to download. Not to be put on PEcAn VM
Getting Started documentation: <a href="https://jules.jchmr.org/content/getting-started" class="uri">https://jules.jchmr.org/content/getting-started</a>
Registration: <a href="http://jules-lsm.github.io/access_req/JULES_access.html" class="uri">http://jules-lsm.github.io/access_req/JULES_access.html</a></p>
<p>FCM:</p>
<pre class="sourceCode bash"><code class="sourceCode bash">    <span class="ex">https</span>://github.com/metomi/fcm/
    <span class="fu">wget</span> https://github.com/metomi/fcm/archive/2015.05.0.tar.gz</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>edit makefile</li>
</ol>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">open</span> etc/fcm-make/make.cfg

<span class="kw">set</span> <span class="ex">JULES_NETCDF</span> = actual instead of dummy
<span class="kw">set</span> <span class="ex">path</span> (e.g. /usr/) <span class="ex">and</span> lib_path /lib64 to netCDF libraries</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>compile JULES</li>
</ol>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span> etc/fcm-make/
<span class="dt">{path.to.fcm}</span><span class="ex">/fcm</span> make -f etc/fcm-make/make.cfg --new</code></pre>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">UBUNTU</span> VERSION: installed without having to add any perl libraries
<span class="co">#perl stuff that I had to install on pecan2 not PEcAN VM</span>
<span class="fu">sudo</span> yum install perl-Digest-SHA
<span class="fu">sudo</span> yum install perl-Time-modules
<span class="fu">sudo</span> yum install cpan
<span class="ex">curl</span> -L http://cpanmin.us <span class="kw">|</span> <span class="fu">perl</span> - --sudo App::cpanminus
<span class="fu">sudo</span> cpanm Time/Piece.pm
<span class="fu">sudo</span> cpanm IO/Uncompress/Gunzip.pm</code></pre>
<p>Executable is under build/bin/jules.exe</p>
<p>Example rundir: examples/point_loobos</p>

</div>
<div id="inst-linkages" class="section level4">
<h4><span class="header-section-number">2.1.3.15</span> LINKAGES</h4>
<div id="r-installation" class="section level5">
<h5><span class="header-section-number">2.1.3.15.1</span> R Installation</h5>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Public</span>
echo <span class="st">&#39;devtools::install_github(&quot;araiho/linkages_package&quot;)&#39;</span> <span class="op">|</span><span class="st"> </span>R <span class="op">--</span>vanilla</code></pre>
</div>
<div id="fortran-version" class="section level5">
<h5><span class="header-section-number">2.1.3.15.2</span> FORTRAN VERSION</h5>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#FORTRAN VERSION</span>
cd
git clone https<span class="op">:</span><span class="er">//</span>github.com<span class="op">/</span>araiho<span class="op">/</span>Linkages.git
cd Linkages
gfortran <span class="op">-</span>o linkages linkages.f
sudo cp linkages <span class="op">/</span>usr<span class="op">/</span>local<span class="op">/</span>bin<span class="op">/</span>linkages.git</code></pre>

</div>
</div>
<div id="inst-lpj-guess" class="section level4">
<h4><span class="header-section-number">2.1.3.16</span> LPJ-GUESS</h4>
<p>Instructions to download source code</p>
<p>Go to <a href="http://web.nateko.lu.se/lpj-guess/download.html">LPJ-GUESS website</a> for instructions to access code.</p>

</div>
<div id="inst-maespa" class="section level4">
<h4><span class="header-section-number">2.1.3.17</span> MAESPA</h4>
<p>Navigate to a directory you would like store MAESPA and run the following:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">git</span> clone https://bitbucket.org/remkoduursma/maespa.git

<span class="bu">cd</span> maespa

<span class="fu">make</span></code></pre>
<p><code>maespa.out</code> is your executable. Example input files can be found in the <code>inpufiles</code> directory. Executing measpa.out from within one of the example directories will produce output.</p>
<p>MAESPA developers have also developed a wrapper package called Maeswrap. The usual R package installation method <code>install.packages</code> may present issues with downloading an unpacking a dependency package called <code>rgl</code>. Here are a couple of solutions:</p>
<div id="solution-1" class="section level5">
<h5><span class="header-section-number">2.1.3.17.1</span> Solution 1</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">### From the Command Line</span>
<span class="fu">sudo</span> apt-get install r-cran-rgl</code></pre>
<p>then from within R</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;Maeswrap&quot;</span>)</code></pre>
</div>
<div id="solution-2" class="section level5">
<h5><span class="header-section-number">2.1.3.17.2</span> Solution 2</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">### From the Command line </span>
<span class="fu">sudo</span> apt-get install libglu1-mesa-dev</code></pre>
<p>then from within R</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;Maeswrap&quot;</span>)</code></pre>

</div>
</div>
<div id="sipnet-inst-sipnet" class="section level4">
<h4><span class="header-section-number">2.1.3.18</span> SIPNET {inst-sipnet}</h4>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span>
<span class="ex">curl</span> -o sipnet_unk.tar.gz http://isda.ncsa.illinois.edu/~kooper/EBI/sipnet_unk.tar.gz
<span class="fu">tar</span> zxf sipnet_unk.tar.gz
<span class="fu">rm</span> sipnet_unk.tar.gz

<span class="bu">cd</span> sipnet_unk
<span class="fu">make</span>
<span class="fu">sudo</span> cp sipnet /usr/local/bin/sipnet.runk</code></pre>
<div id="sipnet-testrun" class="section level5">
<h5><span class="header-section-number">2.1.3.18.1</span> SIPNET testrun</h5>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span>
<span class="ex">curl</span> -o testrun.sipnet.tar.gz http://isda.ncsa.illinois.edu/~kooper/EBI/testrun.sipnet.tar.gz
<span class="fu">tar</span> zxf testrun.sipnet.tar.gz
<span class="fu">rm</span> testrun.sipnet.tar.gz
<span class="bu">cd</span> testrun.sipnet
<span class="ex">sipnet.runk</span></code></pre>

</div>
</div>
<div id="install-data" class="section level4">
<h4><span class="header-section-number">2.1.3.19</span> Installing data for PEcAn</h4>
<p>PEcAn assumes some of the data to be installed on the machine. This page will describe how to install this data.</p>
<div id="site-information" class="section level5">
<h5><span class="header-section-number">2.1.3.19.1</span> Site Information</h5>
<p>These are large-ish files that contain data used with ED2 and SIPNET</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">rm</span> -rf sites
<span class="ex">curl</span> -o sites.tgz http://isda.ncsa.illinois.edu/~kooper/EBI/sites.tgz
<span class="fu">tar</span> zxf sites.tgz
<span class="fu">sed</span> -i -e <span class="st">&quot;s#/home/kooper/Projects/EBI#</span><span class="va">${PWD}</span><span class="st">#&quot;</span> sites/*/ED_MET_DRIVER_HEADER
<span class="fu">rm</span> sites.tgz

<span class="fu">rm</span> -rf inputs
<span class="ex">curl</span> -o inputs.tgz http://isda.ncsa.illinois.edu/~kooper/EBI/inputs.tgz
<span class="fu">tar</span> zxf inputs.tgz
<span class="fu">rm</span> inputs.tgz</code></pre>
</div>
<div id="fia-database" class="section level5">
<h5><span class="header-section-number">2.1.3.19.2</span> FIA database</h5>
<p>FIA database is large and will add an extra 10GB to the installation.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># download and install database</span>
<span class="ex">curl</span> -o fia5data.psql.gz http://isda.ncsa.illinois.edu/~kooper/EBI/fia5data.psql.gz
<span class="ex">dropdb</span> --if-exists fia5data
<span class="ex">createdb</span> -O bety fia5data
<span class="fu">gunzip</span> fia5data.psql.gz
<span class="ex">psql</span> -U bety -d fia5data <span class="op">&lt;</span> fia5data.psql
<span class="fu">rm</span> fia5data.psql</code></pre>
</div>
<div id="flux-camp" class="section level5">
<h5><span class="header-section-number">2.1.3.19.3</span> Flux Camp</h5>
<p>Following will install the data for flux camp (as well as the demo script for PEcAn).</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span>
<span class="ex">curl</span> -o plot.tgz http://isda.ncsa.illinois.edu/~kooper/EBI/plot.tgz
<span class="fu">tar</span> zxf plot.tgz
<span class="fu">rm</span> plot.tgz</code></pre>
</div>
<div id="harvard-for-ed-tutorial" class="section level5">
<h5><span class="header-section-number">2.1.3.19.4</span> Harvard for ED tutorial</h5>
<p>Add datasets and runs</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">curl</span> -o Santarem_Km83.zip http://isda.ncsa.illinois.edu/~kooper/EBI/Santarem_Km83.zip
<span class="fu">unzip</span> -d sites Santarem_Km83.zip
<span class="fu">sed</span> -i -e <span class="st">&quot;s#/home/pecan#</span><span class="va">${HOME}</span><span class="st">#&quot;</span> sites/Santarem_Km83/ED_MET_DRIVER_HEADER
<span class="fu">rm</span> Santarem_Km83.zip

<span class="ex">curl</span> -o testrun.s83.zip http://isda.ncsa.illinois.edu/~kooper/EBI/testrun.s83.zip
<span class="fu">unzip</span> testrun.s83.zip
<span class="fu">sed</span> -i -e <span class="st">&quot;s#/home/pecan#</span><span class="va">${HOME}</span><span class="st">#&quot;</span> testrun.s83/ED2IN
<span class="fu">rm</span> testrun.s83.zip

<span class="ex">curl</span> -o ed2ws.harvard.tgz http://isda.ncsa.illinois.edu/~kooper/EBI/ed2ws.harvard.tgz
<span class="fu">tar</span> zxf ed2ws.harvard.tgz
<span class="fu">mkdir</span> ed2ws.harvard/analy ed2ws.harvard/histo
<span class="fu">sed</span> -i -e <span class="st">&quot;s#/home/pecan#</span><span class="va">${HOME}</span><span class="st">#g&quot;</span> ed2ws.harvard/input_harvard/met_driver/HF_MET_HEADER ed2ws.harvard/ED2IN ed2ws.harvard/*.r
<span class="fu">rm</span> ed2ws.harvard.tgz

<span class="ex">curl</span> -o testrun.PDG.zip http://isda.ncsa.illinois.edu/~kooper/EBI/testrun.PDG.zip
<span class="fu">unzip</span> testrun.PDG.zip
<span class="fu">sed</span> -i -e <span class="st">&quot;s#/home/pecan#</span><span class="va">${HOME}</span><span class="st">#&quot;</span> testrun.PDG/Met/PDG_MET_DRIVER testrun.PDG/Template/ED2IN
<span class="fu">sed</span> -i -e <span class="st">&#39;s#/n/scratch2/moorcroft_lab/kzhang/PDG/WFire_Pecan/##&#39;</span> testrun.PDG/Template/ED2IN
<span class="fu">rm</span> testrun.PDG.zip

<span class="ex">curl</span> -o create_met_driver.tar.gz http://isda.ncsa.illinois.edu/~kooper/EBI/create_met_driver.tar.gz
<span class="fu">tar</span> zxf create_met_driver.tar.gz
<span class="fu">rm</span> create_met_driver.tar.gz</code></pre>

</div>
</div>
</div>
</div>
<div id="user-tut" class="section level2">
<h2><span class="header-section-number">2.2</span> User Tutorial Section</h2>
<p>The following Tutorials assume you have installed PEcAn. If you have not, please consult the <a href="tutorialsdemos-and-how-tos.html#pecan-manual-setup">PEcAn Installation Section</a>.</p>
<div id="how-pecan-works-in-a-nutshell" class="section level4">
<h4><span class="header-section-number">2.2.0.1</span> How PEcAn Works in a nutshell</h4>
<p>PEcAn provides an interface to a variety of ecosystem models and attempts to standardize and automate the processes of model parameterization, execution, and analysis. First, you choose an ecosystem model, then the time and location of interest (a site), the plant community (or crop) that you are interested in simulating, and a source of atmospheric data from the BETY database (LeBauer et al, 2010). These are set in a “settings” file, commonly named <code>pecan.xml</code> which can be edited manually if desired. From here, PEcAn will take over and set up and execute the selected model using your settings. The key is that PEcAn uses models as-is, and all of the translation steps are done within PEcAn so no modifications are required of the model itself. Once the model is finished it will allow you to create graphs with the results of the simulation as well as download the results. It is also possible to see all past experiments and simulations.</p>
<p>There are two ways of using PEcAn, via the web interface and directly within R. Even for users familiar with R, using the web interface is a good place to start because it provides a high level overview of the PEcAn workflow. The quickest way to get started is to download the virtual machine or use an AWS instance.</p>
</div>
<div id="demo-table" class="section level3">
<h3><span class="header-section-number">2.2.1</span> PEcAn Demos</h3>
<p>Once you have a running version of PEcAn, we recommend working through some of the following demos and vignettes to explore PEcAn’s many capabilities:</p>
<table>
<thead>
<tr class="header">
<th align="center">Type</th>
<th align="center">Title</th>
<th align="center">Web Link</th>
<th align="center">Source Rmd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Demo</td>
<td align="center">Basic Run</td>
<td align="center"><a href="https://pecanproject.github.io/pecan-documentation/tutorials/Demo01.html">html</a></td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/develop/documentation/tutorials/01_Demo_Basic_Run/Demo01.Rmd">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Demo</td>
<td align="center">Uncertainty Analysis</td>
<td align="center"><a href="https://pecanproject.github.io/pecan-documentation/tutorials/Demo02.html">html</a></td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/master/documentation/tutorials/02_Demo_Uncertainty_Analysis">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Demo</td>
<td align="center">Output Analysis</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/develop/documentation/tutorials/AnalyzeOutput">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Demo</td>
<td align="center">MCMC</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/develop/documentation/tutorials/MCMC">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Demo</td>
<td align="center">Parameter Assimilation</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/develop/documentation/tutorials/ParameterAssimilation">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Demo</td>
<td align="center">State Assimilation</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/develop/documentation/tutorials/StateAssimilation">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Demo</td>
<td align="center">Sensitivity</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/develop/documentation/tutorials/sensitivity">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Vignette</td>
<td align="center">Allometries</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/allometry/vignettes/AllomVignette.Rmd">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Vignette</td>
<td align="center">MCMC</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/assim.batch/vignettes/AssimBatchVignette.Rmd">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Vignette</td>
<td align="center">Meteorological Data</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/tree/master/modules/data.atmosphere/vignettes">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Vignette</td>
<td align="center">Meta-Analysis</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/meta.analysis/vignettes/single.MA_demo.Rmd">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Vignette</td>
<td align="center">Photosynthetic Response Curves</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/photosynthesis/vignettes/ResponseCurves.Rmd">Rmd</a></td>
</tr>
<tr class="odd">
<td align="center">Vignette</td>
<td align="center">Priors</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/priors/vignettes/priors_demo.Rmd">Rmd</a></td>
</tr>
<tr class="even">
<td align="center">Vignette</td>
<td align="center">Leaf Spectra:PROSPECT inversion</td>
<td align="center">html</td>
<td align="center"><a href="https://github.com/PecanProject/pecan/blob/master/modules/rtm/vignettes/pecanrtm.vignette.Rmd">Rmd</a></td>
</tr>
</tbody>
</table>

</div>
</div>
<div id="web-workflow" class="section level2">
<h2><span class="header-section-number">2.3</span> Web workflow</h2>
<p>This chapter describes the major steps of the PEcAn web-based workflow, which are as follows:</p>
<ul>
<li><a href="tutorialsdemos-and-how-tos.html#web-site-model">Model and site selection</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#web-model-config">Model configuration</a></li>
<li>Run execution – TODO!</li>
<li>Results – TODO!</li>
<li>Interactive visualizations – TODO!</li>
</ul>
<p>We recommend that all new users begin with [PEcAn Hands-On Demo 01: Basic Run]. The documentation below assumes you are already familiar with how to navigate to PEcAn’s interactive web interface for running models.</p>
<div id="web-site-model" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Site and model selection</h3>
<p>This page is used to select the model to run and the site at which you would like to run that model.</p>
<p><strong>NOTE:</strong> If this page does not load for you, it may be related to a known Google Maps API key issue. See <a href="https://github.com/PecanProject/pecan/issues/1269">issue #1269</a> for a possible solution.</p>
<div id="selecting-a-model" class="section level4">
<h4><span class="header-section-number">2.3.1.1</span> Selecting a model</h4>
<ol style="list-style-type: decimal">
<li><p>On the <strong>Select Host</strong> webpage <strong>use the Host pull-down menu to select the server you want to run on</strong>. PEcAn is designed to allow models to be run both locally and on remote high-performance computing (HPC) resources (i.e. clusters). We recommend that users start with local runs. More information about connecting your PEcAn instance to a cluster can be found on the <a href="tutorialsdemos-and-how-tos.html#pecan-remote">Remote execution with PEcAn</a> page.</p></li>
<li><p>Next, <strong>select the model you want to run under the Model pull-down menu</strong>. The list of models currently supported by PEcAn, along with information about these models, is available on the <a href="topical.html#pecan-models">PEcAn Models</a> page.</p>
<ol style="list-style-type: lower-roman">
<li><p>If a PEcAn-supported model is not listed, this is most likely because the model has not been installed on the server. The PEcAn team does not have permissions to redistribute all of the models that are coupled to it, so you will have to install some PEcAn-compatible models yourself. Please consult the PEcAn model listing for information about obtaining and installing different models. Once the model is installed and you have added the location of the model executable to Bety (see <a href="tutorialsdemos-and-how-tos.html#adding-model">Adding An Ecosystem Model</a>), your model should appear on the PEcAn <strong>Select Host</strong> page after your refresh the page.</p></li>
<li><p>If you would like to add a new model to PEcAn please consult our guide for <a href="tutorialsdemos-and-how-tos.html#adding-model">Adding an Ecosystem Model</a> and contact the PEcAn team for assistance.</p></li>
</ol></li>
<li><p>If selecting your model causes your <strong>site to disappear</strong> from the Google Map, that means the site exists but there are no drivers for that model-site combination registered in the database.</p>
<ol style="list-style-type: lower-roman">
<li><p>Click the “Conversion” checkbox. If your site reappears, that means PEcAn should be able to automatically generate the required inputs for this site by converting from existing input files in other formats.</p></li>
<li><p>If the site still does not reappear, that means there are required input files for that model-site combination that PEcAn cannot autogenerate. This may be because the model has unique input requirements or because it has not yet been fully coupled to the PEcAn input processing workflow. Go to the troubleshooting section under <a href="tutorialsdemos-and-how-tos.html#selecting-a-site">Selecting a site</a> for more information on diagnosing what drivers are missing.</p></li>
</ol></li>
</ol>
</div>
</div>
<div id="selecting-a-site" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Selecting a site</h3>
<div id="site-groups" class="section level4">
<h4><span class="header-section-number">2.3.2.1</span> Site Groups</h4>
<ol style="list-style-type: decimal">
<li><p>PEcAn provides the option of organizing sites into groups to make them easier to find and easier to run as a group. We have pre-loaded a number of common research networks (e.g., FLUXNET, LTER, NEON), but you are free to create new site groups through Bety.</p></li>
<li><p>If you are searching for a site that is not part of an existing site group, or you are unsure which site group it belongs to, select “All Sites” to see all sites in Bety. Note that this may take a while to render.</p></li>
</ol>
</div>
<div id="using-existing-sites" class="section level4">
<h4><span class="header-section-number">2.3.2.2</span> Using existing sites</h4>
<ol style="list-style-type: decimal">
<li><p><strong>Find the site on the map</strong> The simplest way of determining if a site exists in PEcAn is through the Google Map interface of the web-based workflow. You’ll want to make sure that the “Site Group” is set to “All Sites” and the “Model” is set to “All Models”.</p></li>
<li><p><strong>Find the site in BETY</strong> If the site is not on the map, it may still be in Bety but with insufficient geographic information. To locate the site in Bety, first login to your local version of the BETY database. If using the VM, navigate to <code>localhost:6480/bety</code> and login with username <code>bety</code> and password <code>illinois</code>. Then, navigate to <code>Data &gt; Sites</code> and use the “Search” box to search for your site. If you <strong>do</strong> find your site, click “Edit” and add geographic information so that the site will show up on the map. Also, note that the site ID number shows up in the URL for the “Show” or “Edit” pages. This ID is often useful to know, for example when editing a PEcAn settings file by hand. If you did not find you site, follow the instructions below to add a site.</p></li>
</ol>
</div>
<div id="adding-a-new-site" class="section level4">
<h4><span class="header-section-number">2.3.2.3</span> Adding a new site</h4>
<p>(TODO: Move most of this out)</p>
<ol style="list-style-type: decimal">
<li><p>Log into Bety as described above.</p></li>
<li><p><strong>Pick a citation for your site</strong> Each site requires an associated “citation” that must be added before the site itself is added. First, navigate to “Data &gt; Citations” and use the “Search” box to see if the relevant citation already exists. If it does, click the check mark under “Actions” to proceed to site creation.</p></li>
</ol>
<ul>
<li><p><strong>To create a new citation</strong>, click the <strong>New Citation</strong> button, fill in the fields, and then click “Create”. The “field URL” should contain the web address that takes you to this publication on the publisher’s website. The “PDF” field should be the full web address to a PDF for this citation.</p></li>
<li><p>Note that our definition of a citation is flexible, and a citation need not be a peer-reviewed publication. Most of the fields in “New Citation” can be left blank, but we recommend at least adding a descriptive title, such as “EBI Farm Field Data” and a relevant contact person as the “Author”.</p></li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li><p>Once the Citation is created or selected this should automatically take you to the Sites page and list any Sites already associated with this citation. To create a new site click the <strong>New Site</strong> button.</p></li>
<li><p>When creating a new site, the most important fields are the <strong>Site name</strong> and coordinates (<strong>latitude</strong> and <strong>longitude</strong>). The coordinates can be entered by hand or by clicking on the site location on the Google Map interface. All other information is optional, but can be useful for searching and indexing purposes.</p></li>
<li><p>When you are done click <strong>Create</strong>. At this point, once the PEcAn site-level page is refreshed, the site should automatically appear.</p></li>
</ol>
</div>
<div id="troubleshooting" class="section level4">
<h4><span class="header-section-number">2.3.2.4</span> Troubleshooting</h4>
<div id="my-site-shows-up-when-i-dont-have-any-model-selected-but-disappears-once-i-select-the-model-i-want-to-run" class="section level5">
<h5><span class="header-section-number">2.3.2.4.1</span> My site shows up when I don’t have any model selected, but disappears once I select the model I want to run</h5>
<p>Selecting a model will cause PEcAn to filter the available sites based on whether they possess the required Inputs for a given model (e.g. meteorology). To check what Inputs are missing for a site point your browser to the pecan/checksite.php webpage (e.g. localhost:6480/pecan/checksite.php). This page looks virtually identical to the site selection page, except that it has a <em>Check</em> button instead of <em>Prev</em> and <em>Next</em>. If you select a Machine, Model, and Site and then click <em>Check</em> the page should return a list of what Inputs are missing (listing both the name and the Format ID number). Don’t forget that its possible for PEcAn to have required Inputs in its database, but just not have them for the Machine where you want to run.</p>
<p>To see more about what Inputs a given model can accept, and which of those are required, take a look at the MODEL_TYPE table entry in the database (e.g. go to <code>localhost:6480/bety</code>; Select <code>Runs &gt; Model Type</code>; and then click on the model you want to run).</p>
<p>For information about loading missing Inputs into the database visit <a href="tutorialsdemos-and-how-tos.html#input-records-in-bety">Input records in BETY</a>, and also read the rest of the pages under this section, which will provide important information about the specific classes of Inputs (e.g. meteorology, vegetation, etc).</p>
<p>Finally, we are continually developing and refining workflows and standards for processing Input data in a model-agnostic way. The details about what Inputs can be processed automatically are discussed input-by-input in the sections below. For those looking to dive into the code or troubleshoot further, these conversions are ultimately handled under the <code>PEcAn.workflow::do_conversions</code> workflow module.</p>
</div>
</div>
</div>
</div>
<div id="web-model-config" class="section level2">
<h2><span class="header-section-number">2.4</span> Model configuration</h2>
<p>This page is used for basic model configuration, including when your model will run and what input data it will use.</p>
<div id="choosing-meteorology" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Choosing meteorology</h3>
<p>Once a Machine, Model, and Site have been selected, PEcAn will take you to the Input selection page. From this page you will select what Plant Functional Type (PFT) you want to run at a site, the start and end dates of the run, and various Input selections. The most common of these across all models is the need to specify meteorological forcing data. The exact name of the menu item for meteorology will vary by model because all of the Input requirements are generated individually for each model based on the MODEL_TYPE table. In general there are 3 possible cases for meteorology</p>
<ul>
<li>PEcAn already has driver files in its database</li>
<li>PEcAn does not have drivers, but can generate them from publicly available data</li>
<li>You need (or want) to upload your own drivers</li>
</ul>
<p>The first two cases will appear automatically in the the pull down menu. For meteorological files that already exist you will see the date range that’s available. By contrast, met that can be generated will appear as “Use <source>”, where <source> is the origin of the data (e.g. “Use Ameriflux” will use the micromet from an Ameriflux eddy covariance tower, if one is present at the site).</p>
<p>If you want to upload your own met data this can be done in three ways.</p>
<ol style="list-style-type: decimal">
<li><p>The default way to add met data is to incorporate it into the overall meteorological processing workflow. This is preferred if you are working with a common meteorological data product that is not yet in PEcAn’s workflow. This case can be divided into two special cases:</p>
<ol style="list-style-type: lower-roman">
<li><p>Data is in a common MIME-type that PEcAn already has a converter for (e.g. CSV). In this case you’ll want to create a new Format record for the meta-data so that the existing converter can process this data. See documentation for [Creating a new Format record in BETY] for more details.</p></li>
<li><p>Data is in a more complicated format or interactive database, but large/useful enough to warrent a custom conversion function. Details on creating custom met conversions is in the [Input Conversion], though at this stage you would also be strongly encouraged to contact the PEcAn development team.</p></li>
</ol></li>
<li><p>The second-best way is to upload data in PEcAn’s standard meteorological format (netCDF files, CF metadata). See [Input Conversion] for details about variables and units. From this standard, PEcAn can then convert the file to the model-specific format required by the model you have chosen. This approach is preferred for a rare or one-off meterological file format, because PEcAn will also be able to convert the file into the format required by any other model as well.</p></li>
<li><p>The last option for adding met data is to add it in a model-specific format, which is often easiest if you’ve already been running your model at a site and are just switching to using PEcAn.</p></li>
</ol>
<div id="met-workflow" class="section level4">
<h4><span class="header-section-number">2.4.1.1</span> Met workflow</h4>
<p>In a nutshell, the PEcAn met workflow is designed to reduce the problem of converting <em>n</em> possible met inputs into <em>m</em> possible model formats, which requires <em>n x m</em> conversion functions as well as numerous custom functions for downscaling, gap filling, etc. Instead, PEcAn works with a single met standard, and thus requires <em>n</em> conversion functions, one for converting each data source into the PEcAn standard, and then <em>m</em> conversion functions for converting from that standard to what an individual model requires. For a new model joining the PEcAn system the burden in particularly low – writing one conversion function provides access to <em>n</em> inputs. Similarly, PEcAn performs all other operations/manipulations (extracting a site, downscaling, gap filling, etc) within the PEcAn standard, which means these operations only need be implemented once.</p>
<p>Consider a generic met data product named MET for simplicity. PEcAn will use a function, download.MET, to pull data for the selected year from a public data source (e.g. Ameriflux, North American Regional Reanalysis, etc). Next, PEcAn will use a function, met2CF.MET, to convert the data into the PEcAn standard. If the data is already at the site scale it will then gapfill the data. If the data is a regional or global data product, PEcAn will then permute the data to allow easier site-level extraction, then it will extract data for the requested site and data range. Modules to address the temporal and spatial downscaling of meteorological data products, as well as their uncertainties, are in development but not yet part of the operational workflow. All of these functions are located within the data.atmosphere module.</p>
<p>Once data is in the standard format and processed, it will be converted to the model-specific format using a met2model.MODEL function (located in that MODEL’s module).</p>
<p>More detailed information on how PEcAn processes inputs can be found on our [Input Conversion] page.</p>
</div>
<div id="troubleshooting-meteorological-conversions" class="section level4">
<h4><span class="header-section-number">2.4.1.2</span> Troubleshooting meteorological conversions</h4>
<p>At the current moment, most of the issues below address possible errors that the Ameriflux meteorology workflow might report</p>
<div id="could-not-do-gapfill-the-following-variables-have-nas" class="section level5">
<h5><span class="header-section-number">2.4.1.2.1</span> Could not do gapfill … The following variables have NA’s</h5>
<p>This error message means that there were gaps in the downloaded data, for whatever variables that were listed, which were larger than the current algorithm could fill. Particularly common is missing radiation or PAR data, as Ameriflux frequently converts nighttime data to NULL, and work is in progress to detect this based on solar geometry. Also common are incomplete years (first or last year of tower operations).</p>
</div>
<div id="could-not-get-information-about-.-is-this-an-ameriflux-site" class="section level5">
<h5><span class="header-section-number">2.4.1.2.2</span> Could not get information about <site> . Is this an Ameriflux site?</h5>
<p>This message occurs when PEcAn believes that a site is part of Ameriflux (because it was listed on the Ameriflux or FLUXNET webpage and has a US-* site code), but no data is present on the Ameriflux server. The most common reasons for this is that you have selected a site that has not submitted data to Ameriflux yet (or that data hasn’t been processed yet), or you have selected a year that’s outside the tower’s operational period. Visit <a href="http://ameriflux.lbl.gov/sites/site-list-and-pages/">Ameriflux</a> and <a href="http://fluxnet.ornl.gov/site_status">FLUXNET</a> for lists of available site years.</p>
</div>
<div id="could-not-download-data-for-for-the-year" class="section level5">
<h5><span class="header-section-number">2.4.1.2.3</span> Could not download data for <site> for the year <YEAR></h5>
<p>This is similar to the previous error, but in this case PEcAn did find data for the site listed, but just not for the year requested. This can usually be fixed by just altering the years of the run to match those with available data.</p>
</div>
<div id="i-could-not-find-the-requested-var-or-dimvar-in-the-file" class="section level5">
<h5><span class="header-section-number">2.4.1.2.4</span> I could not find the requested var (or dimvar) in the file!</h5>
<p>PEcAn could not find a required variable within the downloaded file. Most likely this is due to that variable not being measured at this site. The most common cause of failure is the absence of atmospheric pressure data (PRESS), but since most models have a low sensitivity to this variable we are working on methods to estimate this from other sources.</p>
</div>
</div>
</div>
<div id="selecting-plant-functional-types-pfts-and-other-parameter-groupings." class="section level3">
<h3><span class="header-section-number">2.4.2</span> Selecting Plant Functional Types (PFTs) and other parameter groupings.</h3>
<div id="using-existing-pfts" class="section level4">
<h4><span class="header-section-number">2.4.2.1</span> Using existing PFTs</h4>
<p>PEcAn does not automatically know what vegetation types are present at your study site so you need to select the PFT.</p>
<p>Some models, such as ED2 and LINKAGES, support competition among multiple PFTs and thus you are encouraged to highlight multiple choices. Other models, such as SIPNET and DALEC, only support one PFT at a site.</p>
<p>Many models also have parameters that control non-vegetation processes (e.g. soil biogeochemistry and hydrology). PEcAn allows users to assign these parameters to functional groups as well (e.g. a <code>soils</code> PFT)</p>
</div>
<div id="creating-new-pfts" class="section level4">
<h4><span class="header-section-number">2.4.2.2</span> Creating new PFTs</h4>
<p>To modify or add a new Plant Functional Type (PFT), or to change a PFT’s priors, navigate
on the grey menu bar to Data &gt; PFTs</p>
<ol style="list-style-type: decimal">
<li><p>To add a new pft, click “new PFT” at the top and enter a name and description. (hint:
we’re trying to name PFTs based on model.biome.pft, ED2 is the default model if one
isn’t specified)</p></li>
<li><p>To add new species to a PFT click on [+] View Related Species and type the species,
genus, or family you are looking for into the Search box. Click on the + to add.</p></li>
<li><p>To remove a species from a PFT, click on [+] View Related Species and click on the X
of the species you want to remove from the PFT.</p></li>
<li><p>To remove a prior, click [-] View Related Prior and click on the X of the variable who’s
prior you want to remove. This will cause the parameter to be excluded from all
analyses (meta-analysis, sensitivity analysis, etc) and revert to its default value.</p></li>
<li><p>To add a prior, choose one from the white box of priors on the right to choose.</p></li>
<li><p>To view the specification of a prior, or to add a new prior, click BETY-DB &gt; Priors and
enter the information on the variable, distribution name, distribution parameters, etc. N
is the sample size underlying the prior specification (0 is ok for uninformative priors).</p></li>
<li><p>You can also got to Data &gt; Variables in order to use the search function to find an
existing variable (or create a new one). Please try not to create new variables
unnecessarily (e.g. changes of variable name or units to what your model uses is handled
internally, so you want to find the trait with the correct MEANING).</p></li>
</ol>
<p>Additional information on adding PFTs, Species, and Priors can be found in Adding An [Ecosystem Model].</p>
</div>
</div>
<div id="choosing-initial-vegetation" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Choosing initial vegetation</h3>
<p>On the Input Selection webpage, in addition to selecting PFTs, start &amp; end dates, and meteorology, many models also require some way of specifying the initial conditions for the vegetation, which may range from setting the aboveground biomass and LAI up to detailed inventory-like data on species composition and stand structure.</p>
<p>At the moment, PEcAn has three cases for initial conditions:</p>
<ol style="list-style-type: decimal">
<li><p>If files already exist in the database, they can simply be selected from the menu. For ED2, there are 3 different veg files (site, pss, css) and it is important that you select a complete set, not mix and match.</p></li>
<li><p>If files don’t exist they can be uploaded following the instructions in <a href="tutorialsdemos-and-how-tos.html#create-a-database-file-record-for-the-input-data">Create a database file record for the input data</a>.</p></li>
<li><p>Automated vegetation initial condition workflow</p></li>
</ol>
<p>As with meteorology, PEcAn is working to develop a model-agnostic workflow for converting various sources of vegetation data to common standards, developing common processing tools, and then writing out to model-specific formats. This process is in a much early stage than the meteorology workflow, as we are still researching what the options are for standard formats, but ultimately aims to be much more broad in scope, considering not just plot inventory data but also historical documentation, paleoecological proxies, satellite remote sensing (e.g. LANDSAT), airborne hyperspectral imagery, and active remote sensing (Lidar, Radar).</p>
<p>At the moment, what is functional is a prototype workflow that works for inventory-based vegetation data. This data can come from either files that have been registered with the BETY Inputs and Formats tables or can be queried from the USFS Forest Inventory and Analysis (FIA). For more information visit Section 13.1.2.2 Vegetation Data</p>
<div id="us-fia" class="section level4">
<h4><span class="header-section-number">2.4.3.1</span> US FIA</h4>
<p>This tool works with an internal copy of the FIA that is uploaded to a postGRES database along side BETY, however for space reasons this database does not ship with the PEcAn VM. To turn this feature on:</p>
<ol style="list-style-type: decimal">
<li>Download and Install the FIA database. Instructions in <a href="tutorialsdemos-and-how-tos.html#install-data">Installing data for PEcAn</a></li>
<li>For web-base runs, specify the database settings in the <a href="https://github.com/PecanProject/pecan/blob/master/web/config.example.php">config.php</a></li>
<li>For R-based runs, specify the database settings in the <a href="topical.html#pecanXML">THE PEcAn XML</a></li>
</ol>
<p>More detailed information on how PEcAn processes inputs can be found on our [Input Conversion]page.</p>
</div>
</div>
<div id="spin-up" class="section level3">
<h3><span class="header-section-number">2.4.4</span> Spin up</h3>
<p>A number of ecosystem models are typically initialized by spinning up to steady state. At the moment PEcAn doesn’t handle spin up automatically (e.g. looping met, checking for stability), but there are various ways to achieve a spin-up within the system.</p>
<p><strong>Option 1:</strong> If there are model-specific settings in a model’s settings/config file, then that file can be accessed by clicking on the <strong>Edit model config</strong> check box. If this box is selected then PEcAn will pause the site run workflow after it has generated your model config file, but before it runs the model, and give you an opportunity to edit the file by hand, allowing you to change any model-specific spin up settings (e.g met recycling, spin up length)</p>
<p><strong>Option 2:</strong> Set start_year very early and set the met drivers to be a long time series (e.g. PalEON, something custom uploaded to Inputs)</p>
<p><strong>Option 3:</strong> In the MODEL_TYPE table, add your model’s restart format as an optional input, modify the model specific write.config function to use that restart, and then load a previous spin-up to the Inputs table</p>
<p>Beyond these options, we hope to eventually develop more general, model-agnostic tools for spin up. In particular, we have started to explore the accelerated spin-up and semi-analytical techniques being developed by Yiqi Luo’s lab</p>
</div>
<div id="selecting-a-soils-product" class="section level3">
<h3><span class="header-section-number">2.4.5</span> Selecting a soils product</h3>
<p>Many models have requirements for soils information, which may include: site-specific soil texture and depth information; soil biogeochemical initial conditions (e.g. soil carbon and nitrogen pools); soil moisture initial conditions; and soil thermal initial conditions.</p>
<p>As with <a href="tutorialsdemos-and-how-tos.html#choosing-initial-vegetation">Choosing initial vegetation</a>, we eventually hope to develop data standards, soils workflows, and spin-up tools, but at the moment this workflow is in the early stages of development. Model requirements need to be met by<a href="tutorialsdemos-and-how-tos.html#creating-a-new-input-record-in-bety">Creating a new Input record in BETY</a> into the database or using files that have already been uploaded. Similar to met, we recommend that this file be in the PEcAn-standard netCDF described below, but model-specific files can also be registered.</p>
<div id="soil-texture-depth-and-physical-parameters" class="section level4">
<h4><span class="header-section-number">2.4.5.1</span> Soil texture, depth, and physical parameters</h4>
<p>A PEcAn-standard netCDF file format exists for soil texture, depth, and physical parameters, using PEcAn standard names that are largely a direct extention of the CF standard.</p>
<p>The easiest way to create this file is with the PEcAn R function <code>soil2netcdf</code> as described in the Soil Data section of the Advanced Users Guide.</p>
<p>A table of standard names and units can be listed using <code>PEcAn.data.land::soil.units()</code> with no arguments.</p>
<p>More detailed information on how PEcAn processes inputs can be found on our [Input Conversion] page.</p>
</div>
</div>
<div id="other-model-inputs" class="section level3">
<h3><span class="header-section-number">2.4.6</span> Other model inputs</h3>
<p>Finally, any other model-specific inputs (e.g. N deposition, land use history, etc), should be met by <a href="tutorialsdemos-and-how-tos.html#creating-a-new-input-record-in-bety">Creating a new Input record in BETY</a> or using files that have already been uploaded.</p>

</div>
</div>
<div id="intermediate-user" class="section level2">
<h2><span class="header-section-number">2.5</span> Intermediate user guide</h2>
<p>This section will provide information to those wanting to take advantage of PEcAn’s customizations from the web interface.</p>
<ul>
<li><a href="topical.html#pecanXML">The PEcAn XML</a> - A tour of the configuration file driving the PEcAn workflow</li>
<li><a href="tutorialsdemos-and-how-tos.html#additional-web-configuration">Additional web configuration</a> - Advanced options available from the web interface
<ul>
<li><a href="tutorialsdemos-and-how-tos.html#brown-dog">Brown Dog</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#advanced-setup">Sensitivity and ensemble analyses</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#editing-model-configurations">Editing model configurations</a></li>
</ul></li>
<li><a href="tutorialsdemos-and-how-tos.html#settings-configured-analyses">Settings-configured analyses</a> - Analyses only available by manually editing <code>pecan.xml</code>
<ul>
<li><a href="tutorialsdemos-and-how-tos.html#pda">Parameter data assimilation (PDA)</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#sda">State data assimilation (SDA)</a></li>
</ul></li>
<li><a href="tutorialsdemos-and-how-tos.html#pecan-remote">Remote execution with PEcAn</a> - Running analyses and generally working with external machines (HPC) in the context of PEcAn.</li>
</ul>

<div id="additional-web-configuration" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Additional web configuration</h3>
<p>Additional settings for web configuration:</p>
<ul>
<li><a href="tutorialsdemos-and-how-tos.html#brown-dog">Brown Dog</a></li>
<li>[Editing model configuration files]</li>
<li><a href="tutorialsdemos-and-how-tos.html#advanced-setup">Advanced setup</a>
<ul>
<li>[Sensitivity analysis]</li>
<li>[Uncertainty analysis]</li>
</ul></li>
</ul>
</div>
<div id="brown-dog" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Brown Dog</h3>
<p>The Browndog service provides PEcAn with access to large and diverse sets of data at the click of a button in the format that PEcAn needs. By clicking the checkbox you will be using the Browndog Service to process data.</p>
<p>For more information regarding meteorological data check out <a href="topical.html#available-meteorological-drivers">Available Meteorological Drivers</a></p>
<p>** <a href="http://browndog.ncsa.illinois.edu/">More Informatoin can be found at the Browndog website</a>**</p>
</div>
<div id="basic-setups" class="section level3">
<h3><span class="header-section-number">2.5.3</span> Basic Setups</h3>
<p>There are few options which you can change via web interface.</p>
<p>To visit the configuration page either you can just click on the setups link on the introduction page alternatively can type <code>&lt;host&gt;/setups/</code>.</p>
<p>The list of configuration available</p>
<ol style="list-style-type: decimal">
<li><p><strong>Database configuration</strong> : BETYdb(Biofuel Ecophysiological Traits and Yields database) configuration details, can be edited according to need.</p></li>
<li><p><strong>Browndog configuration</strong> : Browndog configuration details, Used to connect browndog. Its included by default in VM.</p></li>
<li><p><strong>FIA Database</strong> : FIA(Forest Inventory and Analysis) Database configuration details, Can be used to add additional data to models.</p></li>
<li><p><strong>Google MapKey</strong> : Google Map key, used to access the google map by PEcAn.</p></li>
<li><p><strong>Change Password</strong> : A small infomation to change the VM user password. (if using Docker image it won’t work)</p></li>
<li><p><strong>Automatic Sync</strong> : If ON then it will sync the database between local machine and the remote servers. <strong>Still unders testing part might be buggy</strong>.</p></li>
</ol>
<p>Still work on the adding other editing feature going on, this page will be updated as new configuration will be available.</p>
</div>
<div id="advanced-setup" class="section level3">
<h3><span class="header-section-number">2.5.4</span> Advanced Setup</h3>
<p>(TODO: Under construction…)</p>
</div>
<div id="editing-model-configurations" class="section level3">
<h3><span class="header-section-number">2.5.5</span> Editing model configurations</h3>
<p>(TODO: Under construction…)</p>

</div>
</div>
<div id="settings-configured-analyses" class="section level2">
<h2><span class="header-section-number">2.6</span> Settings-configured analyses</h2>
<p>These analyses can be run through the web interface, but lack graphical interfaces and currently can only be configured throughthe XML settings. To run these analyses use the <strong>Edit pecan.xml</strong> checkbox on the Input configuration page. Eventually, these modules will be integrated into the web user interface.</p>
<ul>
<li>Parameter Data Assimilation (PDA) {#pda}</li>
<li>State Data Assimilation (SDA) {#sda}</li>
<li>MultiSettings</li>
<li>Benchmarking</li>
</ul>
<p>(TODO: Add links)</p>
<div id="pda" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Parameter data assimilation (PDA)</h3>
<p>All functions pertaining to Parameter Data Assimilation are housed within: <strong>pecan/modules/assim.batch</strong>.</p>
<p>For a detailed usage of the module, please see the vignette under <strong>pecan/modules/assim.batch/vignettes</strong>.</p>
<div id="pda.mcmc.r" class="section level4">
<h4><span class="header-section-number">2.6.1.1</span> <strong>pda.mcmc.R</strong></h4>
<p>This is the main PDA code. It performs Bayesian MCMC on model parameters by proposing parameter values, running the model, calculating a likelihood (between model output and supplied observations), and accepting or rejecting the proposed parameters (Metropolis algorithm). Additional notes:</p>
<ul>
<li><p>The first argument is <em>settings</em>, followed by others that all default to <em>NULL.settings</em> is a list used throughout Pecan, which contains all the user options for whatever analyses are being done. The easiest thing to do is just pass that whole object all around the Pecan code and let different functions access whichever settings they need. That’s what a lot of the rest of the Pecan code does. But the flexibility to override most of the relevant settings in <em>settings</em> is there by providing them directly as arguments to the function.</p></li>
<li><p>The <em>if(FALSE)…</em> : If you’re trying to step through the function you probably will have the <em>settings</em> object around, but those other variables will be undefined. If you set them all to NULL then they’ll be ignored without causing errors. It is there for debugging purposes.</p></li>
<li><p>The next step calls pda.settings(), which is in the file pda.utils.R (see below). It checks whether any settings are being overridden by arguments, and in most cases supplies default values if it can’t find either.</p></li>
<li>In the MCMC setup section
<ul>
<li>The code is set up to allow you to start a new MCMC chain, or to continue a previous chain as specified in settings.</li>
<li>The code writes a simple text file of parameter samples at every iteration, which lets you get some results and even re-start an MCMC that fails for some reason.</li>
<li>The code has adaptive jump distributions. So you can see some initialization of the jump distributions and associated variables here.</li>
<li>Finally, note that after all this setup a new XML settings file is saved. The idea is that the original pecan.xml you create is preserved for provenance, and then periodically throughout the workflow the settings (likely containing new information) are re-saved with descriptive filenames.</li>
</ul></li>
<li>MCMC loop
<ul>
<li>Periodically adjust jump distribution to make acceptance rate closer to target</li>
<li>Propose new parameters one at a time. For each:
<ul>
<li>First, note that Pecan may be handling many more parameters than are actually being targeted by PDA. Pecan puts priors on any variables it has information for (in the BETY database), and then these get passed around throughout the analysis and every step (meta-, sensitivity, ensemble analyses, etc.). But for PDA, you specify a separate list of probably far fewer parameters to constrain with data. These are the ones that get looped over and varied here. The distinction between all parameters and only those dealt with in PDA is dealt with in the setup code above.</li>
<li>First a new value is proposed for the parameter of interest.</li>
<li>Then, a new model run is set up, identical to the previous except with the new proposed value for the one parameter being updated on this run.</li>
<li>The model run is started, and outputs collected after waiting for it to finish.</li>
<li>A new likelihood is calculated based on the model outputs and the observed dataset provided.</li>
<li>Standard Metropolis acceptance criteria is used to decide whether to keep the proposed parameter.</li>
<li>Periodically (at interval specified in settings), a diagnostic figure is saved to disk so you can check on progress.</li>
</ul></li>
<li>This works only for NEE currently</li>
</ul></li>
</ul>
</div>
<div id="pda.mcmc.bs.r" class="section level4">
<h4><span class="header-section-number">2.6.1.2</span> <strong>pda.mcmc.bs.R</strong></h4>
<p>This file is basically identical to pda.mcm.R, but rather than propose parameters one at a time, it proposes new values for all parameters at once (“bs” stands for “block sampling”). You choose which option to use by specifying settings<span class="math inline">\(assim.batch\)</span>method:
* “bruteforce” means sample parameters one at a time
* “bruteforce.bs” means use this version, sampling all parameters at once
* “emulator” means use the emulated-likelihood version</p>
</div>
<div id="pda.emulator" class="section level4">
<h4><span class="header-section-number">2.6.1.3</span> <strong>pda.emulator</strong></h4>
<p>This version of the PDA code again looks quite similar to the basic “bruteforce” one, but its mechanics are very different. The basic idea is, rather than running thousands of model iterations to explore parameter space via MCMC, run a relatively smaller number of runs that have been carefully chosen to give good coverage of parameter space. Then, basically interpolate the likelihood calculated for each of those runs (actually, fit a Gaussian process to it), to get a surface that “emulates” the true likelihood. Now, perform regular MCMC (just like the “bruteforce” approach), except instead of actually running the model on every iteration to get a likelihood, just get an approximation from the likelihood emulator. Since the latter step takes virtually no time, you can run as long of an MCMC as you need at little computational cost, once you have done the initial model runs to create the likelihood emulator.</p>
</div>
<div id="pda.mcmc.recover.r" class="section level4">
<h4><span class="header-section-number">2.6.1.4</span> <strong>pda.mcmc.recover.R</strong></h4>
<p>This function is for recovering a failed PDA MCMC run.</p>
</div>
<div id="pda.utils.r" class="section level4">
<h4><span class="header-section-number">2.6.1.5</span> <strong>pda.utils.R</strong></h4>
<p>This file contains most of the individual functions used by the main PDA functions (pda.mcmc.*.R).</p>
<ul>
<li><em>assim.batch</em> is the main function Pecan calls to do PDA. It checks which method is requested (bruteforce, bruteforce.bs, or emulator) and call the appropriate function described above.</li>
<li><em>pda.setting</em> handles settings. If a setting isn’t found, the code can usually supply a reasonable default.</li>
<li><em>pda.load.priors</em> is fairly self explanatory, except that it handles a lot of cases and gives different options priority over others. Basically, the priors to use for PDA parameters can come from either a Pecan prior.distns or post.distns object (the latter would be, e.g., the posteriors of a meta-analysis or previous PDA), or specified either by file path or BETY ID. If not told otherwise, the code tries to just find the most recent posterior in BETY, and use that as prior for PDA.</li>
<li><em>pda.create.ensemble</em> gets an ensemble ID for the PDA. All model runs associated with an individual PDA (any of the three methods) are considered part of a single ensemble. This function does is register a new ensemble in BETY, and return the ID that BETY gives it.</li>
<li><em>pda.define.prior.fn</em> creates R functions for all of the priors the PDA will use.</li>
<li><em>pda.init.params</em> sets up the parameter matrix for the run, which has one row per iteration, and one column per parameter. Columns include all Pecan parameters, not just the (probably small) subset that are being updated by PDA. This is for compatibility with other Pecan components. If starting a fresh run, the returned matrix is just a big empty matrix to fill in as the PDA runs. If continuing an existing MCMC, then it will be the previous params matrix, with a bunch of blank rows added on for filling in during this round of PDA.</li>
<li><em>pda.init.run</em> This is basically a big wrapper for Pecan’s write.config function (actually functions [plural], since every model in Pecan has its own version). For the bruteforce and bruteforce.bs methods this will be run once per iteration, whereas the emulator method knows about all its runs ahead of time and this will be a big batch of all runs at once.</li>
<li><em>pda.adjust.jumps</em> tweaks the jump distributions for the standard MCMC method, and <em>pda.adjust.jumps.bs</em> does the same for the block-sampled version.</li>
<li><em>pda.calc.llik</em> calculates the log-likelihood of the model given all datasets provided to compare it to.</li>
<li><em>pda.generate.knots</em> is for the emulator version of PDA. It uses a Latin hypercube design to sample a specified number of locations in parameter space. These locations are where the model will actually be run, and then the GP interpolates the likelihood surface in between.</li>
<li><em>pda.plot.params</em> provides basic MCMC diagnostics (trace and density) for parameters being sampled.</li>
<li><em>pda.postprocess</em> prepares the posteriors of the PDA, stores them to files and the database, and performs some other cleanup functions.</li>
<li><em>pda.load.data.r</em> This is the function that loads in data that will be used to constrain the PDA. It’s supposed to be eventually more integrated with Pecan, which will know how to load all kinds of data from all kinds of sources. For now, it can do NEE from Ameriflux.</li>
<li><em>pda.define.llik.r</em> A simple helper function that defines likelihood functions for different datasets. Probably in the future this should be queried from the database or something. For now, it is extremely limited. The original test case of NEE assimilation uses a heteroskedastic Laplacian distribution.</li>
<li><em>pda.get.model.output.R</em> Another function that will eventually grow to handle many more cases, or perhaps be replaced by a better system altogether. For now though, it again just handles Ameriflux NEE.</li>
</ul>
</div>
<div id="get.da.data..r-plot.da.r" class="section level4">
<h4><span class="header-section-number">2.6.1.6</span> <strong>get.da.data.*.R, plot.da.R</strong></h4>
<p>Old codes written by Carl Davidson. Defunct now, but may contain good ideas so currently left in.</p>
</div>
</div>
<div id="sda" class="section level3">
<h3><span class="header-section-number">2.6.2</span> State data assimilation (SDA)</h3>
<p><code>sda.enkf.R</code> is housed within: <code>/pecan/modules/assim.sequential/R</code></p>
<p>The tree ring tutorial is housed within: <code>/pecan/documentation/tutorials/StateAssimilation</code></p>
<p>More descriptive SDA methods can be found at: <code>/pecan/book_source/adve_user_guide_web/SDA_Methods.Rmd</code></p>
<div id="sda.enkf.r-description" class="section level4">
<h4><span class="header-section-number">2.6.2.1</span> <strong>sda.enkf.R Description</strong></h4>
<p>This is the main ensemble Kalman filter and generalized filter code. Originally, this was just ensemble Kalman filter code. Mike Dietze and Ann Raiho added a generalized ensemble filter to avoid filter divergence. The output of this function will be all the of run outputs, a PDF of diagnostics, and an Rdata object that includes three lists:</p>
<ul>
<li>FORECAST will be the ensemble forecasts for each year</li>
<li>ANALYSIS will be the updated ensemble sample given the NPP observations</li>
<li>enkf.params contains the prior and posterior mean vector and covariance matrix for each time step.</li>
</ul>
</div>
<div id="sda.enkf.r-arguments" class="section level4">
<h4><span class="header-section-number">2.6.2.2</span> <strong>sda.enkf.R Arguments</strong></h4>
<ul>
<li><p>settings - (required) <a href="tutorialsdemos-and-how-tos.html#state-data-assimilation-tags-example">State Data Assimilation Tags Example</a> settings object</p></li>
<li><p>obs.mean - (required) a list of observation means named with dates in YYYY/MM/DD format</p></li>
<li><p>obs.cov - (required) a list of observation covariances names with dates in YYYY/MM/DD format</p></li>
<li><p>IC - (optional) initial condition matrix (dimensions: ensemble memeber # by state variables). Default is NULL.</p></li>
<li><p>Q - (optional) process covariance matrix (dimensions: state variable by state variables). Defualt is NULL.</p></li>
</ul>
</div>
<div id="state-data-assimilation-workflow" class="section level4">
<h4><span class="header-section-number">2.6.2.3</span> State Data Assimilation Workflow</h4>
<p>Before running sda.enkf, these tasks must be completed (in no particular order),</p>
<ul>
<li><p>Read in a <a href="tutorialsdemos-and-how-tos.html#state-data-assimilation-tags-example">State Data Assimilation Tags Example</a> settings file with tags listed below. i.e. read.settings(‘pecan.SDA.xml’)</p></li>
<li><p>Load data means (obs.mean) and covariances (obs.cov) as lists with PEcAn naming and unit conventions. Each observation must have a date in YYYY/MM/DD format (optional time) associated with it. If there are missing data, the date must still be represented in the list with an NA as the list object.</p></li>
<li><p>Create initial conditions matrix (IC) that is state variables columns by ensemble members rows in dimension. <a href="tutorialsdemos-and-how-tos.html#sample.ic.model.r">sample.IC.MODEL</a> can be used to create the IC matrix, but it is not required. This IC matrix is fed into write.configs for the initial model runs.</p></li>
</ul>
<p>The main parts of the SDA function are:</p>
<p>Setting up for initial runs:</p>
<ul>
<li><p>Set parameters</p></li>
<li><p>Load initial run inputs via <a href="tutorialsdemos-and-how-tos.html#split.inputs.model.r">split.inputs.MODEL</a></p></li>
<li><p>Open database connection</p></li>
<li><p>Get new workflow ids</p></li>
<li><p>Create ensemble ids</p></li>
</ul>
<p>Performing the initial set of runs</p>
<p>Set up for data assimilation</p>
<p>Loop over time</p>
<ul>
<li><p><a href="tutorialsdemos-and-how-tos.html#read.restart.model.r">read.restart.MODEL</a> - read model restart files corresponding to start.time and stop.time that you want to assimilate data into</p></li>
<li><p>Analysis - There are four choices based on if process variance is TRUE or FALSE and if there is data or not. <a href="tutorialsdemos-and-how-tos.html#analysis-options">See explaination below.</a></p></li>
<li><p><a href="tutorialsdemos-and-how-tos.html#write.restart.model.r">write.restart.MODEL</a> - This function has two jobs. First, to insert adjusted state back into model restart file. Second, to update start.time, stop.time, and job.sh.</p></li>
<li><p>run model</p></li>
</ul>
<p>Save outputs</p>
<p>Create diagnostics</p>
</div>
<div id="state-data-assimilation-tags-example" class="section level4">
<h4><span class="header-section-number">2.6.2.4</span> State Data Assimilation Tags Example</h4>
<pre><code>&lt;state.data.assimilation&gt;
  &lt;adjustment&gt;TRUE&lt;/adjustment&gt;
  &lt;process.variance&gt;FALSE&lt;/process.variance&gt;
  &lt;sample.parameters&gt;FALSE&lt;/sample.parameters&gt;
   &lt;state.variables&gt;
    &lt;variable&gt;
      &lt;variable.name&gt;AGB.pft&lt;/variable.name&gt;
      &lt;unit&gt;MgC/ha/yr&lt;/unit&gt;
      &lt;min_value&gt;0&lt;/min_value&gt;
      &lt;max_value&gt;100000000&lt;/max_value&gt;
    &lt;/variable&gt;
    &lt;variable&gt;
      &lt;variable.name&gt;TotSoilCarb&lt;/variable.name&gt;
      &lt;unit&gt;KgC/m^2&lt;/unit&gt;
      &lt;min_value&gt;0&lt;/min_value&gt;
      &lt;max_value&gt;100000000&lt;/max_value&gt;
    &lt;/variable&gt;
  &lt;/state.variables&gt;
  &lt;spin.up&gt;
    &lt;start.date&gt;1950/01/01&lt;/start.date&gt;
    &lt;end.date&gt;1960/12/31&lt;/end.date&gt;
  &lt;/spin.up&gt;
  &lt;forecast.time.step&gt;1&lt;/forecast.time.step&gt;
  &lt;start.date&gt;1961/01/01&lt;/start.date&gt;
  &lt;end.date&gt;2010/12/31&lt;/end.date&gt;
 &lt;/state.data.assimilation&gt;</code></pre>
</div>
<div id="state-data-assimilation-tags-descriptions" class="section level4">
<h4><span class="header-section-number">2.6.2.5</span> State Data Assimilation Tags Descriptions</h4>
<ul>
<li><strong>adjustment</strong> : [optional] TRUE/FLASE flag for if ensembles needs to be adjusted based on weights estimated given their likelihood during analysis step. The defualt is TRUE for this flag.</li>
<li><strong>process.variance</strong> : [optional] TRUE/FLASE flag for if process variance should be estimated (TRUE) or not (FALSE). If TRUE, a generalized ensemble filter will be used. If FALSE, an ensemble Kalman filter will be used. Default is FALSE.</li>
<li><strong>sample.parameters</strong> : [optional] TRUE/FLASE flag for if parameters should be sampled for each ensemble member or not. This allows for more spread in the initial conditions of the forecast.</li>
<li><strong>state.variable</strong> : [required] State variable that is to be assimilated (in PEcAn standard format).</li>
<li><strong>spin.up</strong> : [required] start.date and end.date for initial model runs.</li>
<li><strong><em>NOTE:</em></strong> start.date and end.date are distinct from values set in the run tag because initial runs can be done over a subset of the full run.</li>
<li><strong>forecast.time.step</strong> : [optional] In the future, this will be used to allow the forecast time step to vary from the data time step.</li>
<li><strong>start.date</strong> : [optional] start date of the state data assimilation (in YYYY/MM/DD format)</li>
<li><strong>end.date</strong> : [optional] end date of the state data assimilation (in YYYY/MM/DD format)</li>
<li><strong><em>NOTE:</em></strong> start.date and end.date are distinct from values set in the run tag because this analysis can be done over a subset of the run.</li>
</ul>
</div>
</div>
<div id="model-specific-functions-for-sda-workflow" class="section level3">
<h3><span class="header-section-number">2.6.3</span> Model Specific Functions for SDA Workflow</h3>
<div id="read.restart.model.r" class="section level4">
<h4><span class="header-section-number">2.6.3.1</span> read.restart.MODEL.R</h4>
<p>The purpose of read.restart is to read model restart files and return a matrix that is site rows by state variable columns. The state variables must be in PEcAn names and units. The arguments are:</p>
<ul>
<li><p>outdir - output directory</p></li>
<li><p>runid - ensemble member run ID</p></li>
<li><p>stop.time - used to determine which restart file to read (in POSIX format)</p></li>
<li><p>settings - <a href="tutorialsdemos-and-how-tos.html#state-data-assimilation-tags-example">pecan.SDA.xml</a> settings object</p></li>
<li><p>var.names - vector with state variable names with PEcAn standard naming. Example: c(‘AGB.pft’, ‘TotSoilCarb’)</p></li>
<li><p>params - parameters used by ensemble member (same format as write.configs)</p></li>
</ul>
</div>
<div id="write.restart.model.r" class="section level4">
<h4><span class="header-section-number">2.6.3.2</span> write.restart.MODEL.R</h4>
<p>This model specific function takes in new state and new parameter matrices from sda.enkf.R after the analysis step and translates new variables back to the model variables. Then, updates start.time, stop.time, and job.sh so that start.model.runs() does the correct runs with the new states. In write.restart.LINKAGES and write.restart.SIPNET, job.sh is updated by using write.configs.MODEL.</p>
<ul>
<li><p>outdir - output directory</p></li>
<li><p>runid - run ID for ensemble member</p></li>
<li><p>start.time - beginning of model run (in POSIX format)</p></li>
<li><p>stop.time - end of model run (in POSIX format)</p></li>
<li><p>settings - <a href="tutorialsdemos-and-how-tos.html#state-data-assimilation-tags-example">pecan.SDA.xml</a> settings object</p></li>
<li><p>new.state - matrix from analysis of updated state variables with PEcAn names (dimensions: site rows by state variables columns)</p></li>
<li><p>new.params - In the future, this will allow us to update parameters based on states (same format as write.configs)</p></li>
<li><p>inputs - model specific inputs from <a href="tutorialsdemos-and-how-tos.html#split.inputs.model.r">split.inputs.MODEL</a> used to run the model from start.time to stop.time</p></li>
<li><p>RENAME - [optional] Flag used in write.restart.LINKAGES.R for development.</p></li>
</ul>
</div>
<div id="split.inputs.model.r" class="section level4">
<h4><span class="header-section-number">2.6.3.3</span> split.inputs.MODEL.R</h4>
<p>This model specific function gives the correct met and/or other model inputs to settings<span class="math inline">\(run\)</span>inputs. This function returns settings<span class="math inline">\(run\)</span>inputs to an inputs argument in sda.enkf.R. But, the inputs will not need to change for all models and should return settings<span class="math inline">\(run\)</span>inputs unchanged if that is the case.</p>
<ul>
<li><p>settings - <a href="tutorialsdemos-and-how-tos.html#state-data-assimilation-tags-example">pecan.SDA.xml</a> settings object</p></li>
<li><p>start.time - start time for model run (in POSIX format)</p></li>
<li><p>stop.time - stop time for model run (in POSIX format)</p></li>
</ul>
</div>
<div id="sample.ic.model.r" class="section level4">
<h4><span class="header-section-number">2.6.3.4</span> sample.IC.MODEL.R</h4>
<p>This model specific function is optional. But, it can be used to create initial condition matrix (IC) with # state variables columns by # ensemble rows. This IC matrix is used for the initial runs in sda.enkf.R in the write.configs.MODEL function.</p>
<ul>
<li><p>ne - number of ensemble members</p></li>
<li><p>state - matrix of state variables to get initial conditions from</p></li>
<li><p>year - used to determine which year to sample initial conditions from</p></li>
</ul>
</div>
</div>
<div id="analysis-options" class="section level3">
<h3><span class="header-section-number">2.6.4</span> Analysis Options</h3>
<p>There are four options depending on whether process variance is TRUE/FALSE and whether or not there is data or not.</p>
<ul>
<li><p>If there is no data and process variance = FALSE, there is no analysis step.</p></li>
<li><p>If there is no data and process variance = TRUE, process variance is added to the forecast.</p></li>
<li><p>If there is data and process variance = TRUE, <a href="tutorialsdemos-and-how-tos.html#the-generalized-ensemble-filter">the generalized ensemble filter</a> is implemented with MCMC.</p></li>
<li><p>If there is data and process variance = FALSE, the Kalman filter is used and solved analytically.</p></li>
</ul>
</div>
<div id="the-generalized-ensemble-filter" class="section level3">
<h3><span class="header-section-number">2.6.5</span> The Generalized Ensemble Filter</h3>
<p>An ensemble filter is a sequential data assimilation algorithm with two procedures at every time step: a forecast followed by an analysis. The forecast ensembles arise from a model while the analysis makes an adjustment of the forecasts ensembles from the model towards the data. An ensemble Kalman filter is typically suggested for this type of analysis because of its computationally efficient analytical solution and its ability to update states based on an estimate of covariance structure. But, in some cases, the ensemble Kalman filter fails because of filter divergence. Filter divergence occurs when forecast variability is too small, which causes the analysis to favor the forecast and diverge from the data. Models often produce low forecast variability because there is little internal stochasticity. Our ensemble filter overcomes this problem in a Bayesian framework by including an estimation of model process variance. This methodology also maintains the benefits of the ensemble Kalman filter by updating the state vector based on the estimated covariance structure.</p>
<p>This process begins after the model is spun up to equilibrium.</p>
<p>The likelihood function uses the data vector <span class="math inline">\(\left(\boldsymbol{y_{t}}\right)\)</span> conditional on the estimated state vector <span class="math inline">\(\left(\boldsymbol{x_{t}}\right)\)</span> such that</p>
<p><span class="math inline">\(\boldsymbol{y}_{t}\sim\mathrm{multivariate\:normal}(\boldsymbol{x}_{t},\boldsymbol{R}_{t})\)</span></p>
<p>where <span class="math inline">\(\boldsymbol{R}_{t}=\boldsymbol{\sigma}_{t}^{2}\boldsymbol{I}\)</span> and <span class="math inline">\(\boldsymbol{\sigma}_{t}^{2}\)</span> is a vector of data variances. To obtain an estimate of the state vector <span class="math inline">\(\left(\boldsymbol{x}_{t}\right)\)</span>, we use a process model that incorporates a process covariance matrix <span class="math inline">\(\left(\boldsymbol{Q}_{t}\right)\)</span>. This process covariance matrix differentiates our methods from past ensemble filters. Our process model contains the following equations</p>
<p><span class="math inline">\(\boldsymbol{x}_{t} \sim \mathrm{multivariate\: normal}(\boldsymbol{x}_{model_{t}},\boldsymbol{Q}_{t})\)</span></p>
<p><span class="math inline">\(\boldsymbol{x}_{model_{t}} \sim \mathrm{multivariate\: normal}(\boldsymbol{\mu}_{forecast_{t}},\boldsymbol{P}_{forecast_{t}})\)</span></p>
<p>where <span class="math inline">\(\boldsymbol{\mu}_{forecast_{t}}\)</span> is a vector of means from the ensemble forecasts and <span class="math inline">\(\boldsymbol{P}_{forecast_{t}}\)</span> is a covariance matrix calculated from the ensemble forecasts. The prior for our process covariance matrix is <span class="math inline">\(\boldsymbol{Q}_{t}\sim\mathrm{Wishart}(\boldsymbol{V}_{t},n_{t})\)</span> where <span class="math inline">\(\boldsymbol{V}_{t}\)</span> is a scale matrix and <span class="math inline">\(n_{t}\)</span> is the degrees of freedom. The prior shape parameters are updated at each time step through moment matching such that</p>
<p><span class="math inline">\(\boldsymbol{V}_{t+1} = n_{t}\bar{\boldsymbol{Q}}_{t}\)</span></p>
<p><span class="math inline">\(n_{t+1} = \frac{\sum_{i=1}^{I}\sum_{j=1}^{J}\frac{v_{ijt}^{2}+v_{iit}v_{jjt}}{Var(\boldsymbol{\bar{Q}}_{t})}}{I\times J}\)</span></p>
<p>where we calculate the mean of the process covariance matrix <span class="math inline">\(\left(\bar{\boldsymbol{Q}_{t}}\right)\)</span> from the posterior samples at time t. Degrees of freedom for the Wishart are typically calculated element by element where <span class="math inline">\(v_{ij}\)</span> are the elements of <span class="math inline">\(\boldsymbol{V}_{t}\)</span>. <span class="math inline">\(I\)</span> and <span class="math inline">\(J\)</span> index rows and columns of <span class="math inline">\(\boldsymbol{V}\)</span>. Here, we calculate a mean number of degrees of freedom for <span class="math inline">\(t+1\)</span> by summing over all the elements of the scale matrix <span class="math inline">\(\left(\boldsymbol{V}\right)\)</span> and dividing by the count of those elements <span class="math inline">\(\left(I\times J\right)\)</span>. We fit this model sequentially through time in the R computing environment using R package ‘rjags.’</p>
</div>
<div id="multi-site-state-data-assimilation." class="section level3">
<h3><span class="header-section-number">2.6.6</span> Multi-site State data assimilation.</h3>
<p><code>sda.enkf.multisite</code> function allows for assimilation of observed data at multiple sites at the same time. In order to run a multi-site SDA, one needs to send a multisettings pecan xml file to this function. This multisettings xml file needs to contain information required for running at least two sites under <code>run</code> tag. The code will automatically run the ensembles for all the sites and reformats the outputs matching the required formats for analysis step.</p>
<p>The observed mean and cov needs to be formatted as list of different dates with observations. For each element of this list also there needs to be a list with mean and cov matrices of different sites named by their siteid. This would look like something like this:</p>
<pre><code>&gt; obs.mean

$`2010/12/31`
$`2010/12/31`$`1000000650`
   AbvGrndWood     GWBI
    111.502    1.0746

$`2010/12/31`$`1000000651`
   AbvGrndWood     GWBI
    114.302    1.574695</code></pre>
<pre><code>&gt; obs.cov

$`2010/12/31`
$`2010/12/31`$`1000000650`
           [,1]        [,2]
[1,] 19.7821691 0.213584319
[2,]  0.5135843 0.005162113

$`2010/12/31`$`1000000651`
           [,1]        [,2]
[1,] 15.2821691 0.513584319
[2,]  0.1213583 0.001162113</code></pre>
<p>An example of multi-settings pecan xml file also may look like below:</p>
<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;pecan.multi&gt;
 &lt;state.data.assimilation&gt;
   &lt;process.variance&gt;FALSE&lt;/process.variance&gt;
   &lt;adjustment&gt;TRUE&lt;/adjustment&gt;
   &lt;data&gt;
    &lt;format_id&gt;1000000040&lt;/format_id&gt;
    &lt;input.id&gt;1000013298&lt;/input.id&gt;
  &lt;/data&gt;
   &lt;state.variables&gt;
   &lt;variable&gt;
      &lt;variable.name&gt;GWBI&lt;/variable.name&gt;
   &lt;unit&gt;KgC/m^2&lt;/unit&gt;
       &lt;min_value&gt;0&lt;/min_value&gt;
       &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;variable&gt;
   &lt;variable.name&gt;AbvGrndWood&lt;/variable.name&gt;
   &lt;unit&gt;KgC/m^2&lt;/unit&gt;
   &lt;min_value&gt;0&lt;/min_value&gt;
   &lt;max_value&gt;9999&lt;/max_value&gt;
   &lt;/variable&gt;
   &lt;/state.variables&gt;
  &lt;start.date&gt;1960/01/01&lt;/start.date&gt;
  &lt;end.date&gt;2000/12/31&lt;/end.date&gt;
  &lt;/state.data.assimilation&gt;
 &lt;info&gt;
    &lt;notes&gt;&lt;/notes&gt;
    &lt;userid&gt;-1&lt;/userid&gt;
    &lt;username&gt;&lt;/username&gt;
    &lt;date&gt;2017/12/06 21:19:33 +0000&lt;/date&gt;
  &lt;/info&gt;
 &lt;outdir&gt;/fs/data3/hamzed/output/MultiSite_Sandbox/paleon_sda_SIPNET-8768&lt;/outdir&gt;
 &lt;database&gt;
    &lt;bety&gt;
      &lt;user&gt;bety&lt;/user&gt;
      &lt;password&gt;bety&lt;/password&gt;
      &lt;host&gt;128.197.168.114&lt;/host&gt;
      &lt;dbname&gt;bety&lt;/dbname&gt;
      &lt;driver&gt;PostgreSQL&lt;/driver&gt;
      &lt;write&gt;false&lt;/write&gt;
    &lt;/bety&gt;
    &lt;dbfiles&gt;/fs/data1/pecan.data/dbfiles/&lt;/dbfiles&gt;
  &lt;/database&gt;
 &lt;pfts&gt;
  &lt;pft&gt;
   &lt;name&gt;temperate.deciduous_SDA&lt;/name&gt;
   &lt;constants&gt;
    &lt;num&gt;2&lt;/num&gt;
   &lt;/constants&gt;
   &lt;outdir&gt;/fs/data2/output//PEcAn_1000008768/pft/temperate.deciduous_SDA&lt;/outdir&gt;
   &lt;posteriorid&gt;1000008552&lt;/posteriorid&gt;
  &lt;/pft&gt;
 &lt;/pfts&gt;
 &lt;meta.analysis&gt;
    &lt;iter&gt;3000&lt;/iter&gt;
    &lt;random.effects&gt;FALSE&lt;/random.effects&gt;
  &lt;/meta.analysis&gt;
 &lt;ensemble&gt;
  &lt;size&gt;20&lt;/size&gt;
  &lt;ensemble.id&gt;1000016146&lt;/ensemble.id&gt;
  &lt;start.year&gt;1995&lt;/start.year&gt;
  &lt;end.year&gt;1999&lt;/end.year&gt;
  &lt;samplingspace&gt;
  &lt;parameters&gt;
    &lt;method&gt;uniform&lt;/method&gt;
  &lt;/parameters&gt;
  &lt;met&gt;
    &lt;method&gt;sampling&lt;/method&gt;
  &lt;/met&gt;
  &lt;soil&gt;    
  &lt;parent&gt;parameters&lt;/parent&gt;
  &lt;/soil&gt;
  &lt;vegetation&gt;
  &lt;parent&gt;soil&lt;/parent&gt;
  &lt;/vegetation&gt;
  &lt;/samplingspace&gt;
 &lt;/ensemble&gt;
 &lt;model&gt;
  &lt;id&gt;1000000022&lt;/id&gt;
  &lt;default.param&gt;/fs/data3/hamzed/output/paleon_sda_SIPNET-8768/Bartlett.param&lt;/default.param&gt;
  &lt;type&gt;SIPNET&lt;/type&gt;
  &lt;revision&gt;r136&lt;/revision&gt;
  &lt;delete.raw&gt;FALSE&lt;/delete.raw&gt;
  &lt;binary&gt;/fs/data5/pecan.models/SIPNET/trunk/sipnet_ssr&lt;/binary&gt;
 &lt;/model&gt;
 &lt;workflow&gt;
    &lt;id&gt;1000008768&lt;/id&gt;
  &lt;/workflow&gt;
 &lt;run&gt;
  &lt;settings.1000000650&gt;
  &lt;site&gt;
   &lt;id&gt;1000000650&lt;/id&gt;
   &lt;met.start&gt;1960/01/01&lt;/met.start&gt;
   &lt;met.end&gt;1965/12/31&lt;/met.end&gt;
   &lt;name&gt;Harvard Forest - Lyford Plots (PalEON PHA)&lt;/name&gt;
   &lt;lat&gt;42.53&lt;/lat&gt;
   &lt;lon&gt;-72.18&lt;/lon&gt;
  &lt;/site&gt;
  &lt;inputs&gt;
   &lt;met&gt;
    &lt;source&gt;CRUNCEP&lt;/source&gt;
    &lt;output&gt;SIPNET&lt;/output&gt;
    &lt;path&gt;
    &lt;path1&gt;/fs/data1/pecan.data/dbfiles/CRUNCEP_SIPNET_site_0-758/CRUNCEP.1960-01-01.2010-12-31.clim&lt;/path1&gt;
    &lt;/path&gt;
   &lt;/met&gt;
  &lt;/inputs&gt;
  &lt;start.date&gt;1960/01/01&lt;/start.date&gt;
  &lt;end.date&gt;1980/12/31&lt;/end.date&gt;
  &lt;/settings.1000000650&gt;
  &lt;settings.1000000651&gt;
  &lt;site&gt;
   &lt;id&gt;1000000651&lt;/id&gt;
   &lt;met.start&gt;1960/01/01&lt;/met.start&gt;
   &lt;met.end&gt;1965/12/31&lt;/met.end&gt;
   &lt;name&gt;Harvard Forest - Lyford Plots (PalEON PHA)&lt;/name&gt;
   &lt;lat&gt;42.53&lt;/lat&gt;
   &lt;lon&gt;-72.18&lt;/lon&gt;
  &lt;/site&gt;
  &lt;inputs&gt;
   &lt;met&gt;
    &lt;source&gt;CRUNCEP&lt;/source&gt;
    &lt;output&gt;SIPNET&lt;/output&gt;
    &lt;path&gt;
    &lt;path1&gt;/fs/data1/pecan.data/dbfiles/CRUNCEP_SIPNET_site_0-758/CRUNCEP.1960-01-01.2010-12-31.clim&lt;/path1&gt;
    &lt;/path&gt;
   &lt;/met&gt;
  &lt;/inputs&gt;
  &lt;start.date&gt;1960/01/01&lt;/start.date&gt;
  &lt;end.date&gt;1980/12/31&lt;/end.date&gt;
  &lt;/settings.1000000651&gt;
 &lt;/run&gt;
 &lt;host&gt;
  &lt;name&gt;localhost&lt;/name&gt;
  &lt;rundir&gt;/fs/data3/hamzed/output/MultiSite_Sandbox/paleon_sda_SIPNET-8768/run&lt;/rundir&gt;
  &lt;outdir&gt;/fs/data3/hamzed/output/MultiSite_Sandbox/paleon_sda_SIPNET-8768/out&lt;/outdir&gt;
 &lt;/host&gt;
 &lt;settings.info&gt;
  &lt;deprecated.settings.fixed&gt;TRUE&lt;/deprecated.settings.fixed&gt;
  &lt;settings.updated&gt;TRUE&lt;/settings.updated&gt;
  &lt;checked&gt;TRUE&lt;/checked&gt;
 &lt;/settings.info&gt;
 &lt;rundir&gt;/fs/data3/hamzed/output/MultiSite_Sandbox/paleon_sda_SIPNET-8768/run&lt;/rundir&gt;
 &lt;modeloutdir&gt;/fs/data3/hamzed/output/MultiSite_Sandbox/paleon_sda_SIPNET-8768/out&lt;/modeloutdir&gt;
 &lt;multisettings&gt;run&lt;/multisettings&gt;
&lt;/pecan.multi&gt;</code></pre>
<p>==&gt; 03_hidden_analyses/03_sda_methods.Rmd &lt;==
## State Data Assimilation Methods</p>
<p><em>By Ann Raiho</em></p>
<p>Our goal is build a fully generalizable state data assimilation (SDA) workflow that will assimilate multiple types of data and data products into ecosystem models within PEcAn temporally and spatially. But, during development, specifically with PalEON goals in mind, we have been focusing on assimilating tree ring estimated NPP and AGB and pollen derived fractional composition into two ecosystem models, SIPNET and LINKAGES, at Harvard Forest. This methodology will soon be expanded to include the PalEON sites listed on the <a href="https://paleon.geography.wisc.edu/doku.php/working_groups;state_data_assimilation">state data assimilation wiki page</a>.</p>
</div>
<div id="data-products" class="section level3">
<h3><span class="header-section-number">2.6.7</span> Data Products</h3>
<p>During workflow development, we have been working with tree ring estimated NPP and AGB and pollen derived fractional composition data products. Both of these data products have been estimated with a full accounting of uncertainty, which provides us with state variable observation mean vector and covariance matrix at each time step. These data products are discussed in more detail below. Even though we have been working with specific data products during development, our workflow is generalizable to alternative data products as long as we can calculate a state variable observation mean vector and covariance for a time point.</p>
<div id="tree-rings" class="section level4">
<h4><span class="header-section-number">2.6.7.1</span> Tree Rings</h4>
<p>We have been primarily been working with the tree ring data product created by Andria Dawson and Chris Paciorek and the PEcAn tree ring allometry module. They have developed a Bayesian model that estimates annual aboveground biomass increment (Mg/ha/yr) and aboveground biomass (Mg/ha) for each tree in a dataset. We obtain this data and aggregate to the level appropriate for the ecosystem model. In SIPNET, we are assimilating annual gross woody increment (Mg/ha/yr) and above ground woody biomass (Mg/ha). In LINKAGES, we are assimilating annual species biomass. More information on deriving these tree ring data products can be found in Dawson et al 201?.</p>
<p>We have been working mostly with tree data collected at Harvard Forest. Tree rings and census data were collected at Lyford Plot between 1960 and 2010 in three separate plots. Other tree ring data will be added to this analysis in the future from past PEON courses (UNDERC), Kelly Heilman (Billy’s Lake and Bigwoods), and Alex Dye (Huron Mt. Club).</p>
</div>
<div id="pollen" class="section level4">
<h4><span class="header-section-number">2.6.7.2</span> Pollen</h4>
<p>STEPPS is a Bayesian model developed by Paciorek and McLachlan 2009 and Dawson et al 2016 to estimate spatially gridded fractional composition from fossil pollen. We have been working with STEPPS1 output, specifically with the grid cell that contains Harvard Forest. The temporal resolution of this data product is centennial. Our workflow currently operates at annual time steps, but does not require data at every time step. So, it is possible to assimilate fractional composition every one hundred years or to assimilate fractional composition data every year by accounting for variance inflation.</p>
<p>In the future, pollen derived biomass (ReFAB) will also be available for data assimilation. Although, we have not discussed how STEPPS and ReFAB data assimilation will work.</p>
</div>
<div id="variance-inflation" class="section level4">
<h4><span class="header-section-number">2.6.7.3</span> Variance Inflation</h4>
<p>*Side Note: Probably want to call this something else now.</p>
<p>Since the fractional composition data product has a centennial resolution, in order to use fractional composition information every year we need to change the weight the data has on the analysis. The basic idea is to downweight the likelihood relative to the prior to account for (a) the fact that we assimilate an observation multiple times and (b) the fact that the number of STEPPS observations is ‘inflated’ because of the autocorrelation. To do this, we take the likelihood and raise it to the power of (1/w) where ‘w’ is an inflation factor.</p>
<p>w = D * (N / ESS)</p>
<p>where D is the length of the time step. In our case D = 100. N is the number of time steps. In our case N = 11. and ESS is the effective sample size. The ESS is calculated with the following function where ntimes is the same as N above and sims is a matrix with the dimensions number of MCMC samples by number of state variables.</p>
<pre><code>ESS_calc &lt;- function(ntimes, sims){
        # center based on mean at each time to remove baseline temporal correlation 
        # (we want to estimate effective sample size effect from correlation of the errors)
        row.means.sims &lt;- sims - rowMeans(sims)  
        
        # compute all pairwise covariances at different times
        covars &lt;- NULL
        for(lag in 1:(ntimes-1)){
          covars &lt;- c(covars, rowMeans(row.means.sims[(lag+1):ntimes, , drop = FALSE] * row.means.sims[1:(ntimes-lag), , drop = FALSE])) 
        }
        vars &lt;- apply(row.means.sims, 1, var) # pointwise post variances at each time, might not be homoscedastic
        
        # nominal sample size scaled by ratio of variance of an average
        # under independence to variance of average of correlated values
        neff &lt;- ntimes * sum(vars) / (sum(vars) + 2 * sum(covars))
        return(neff)
      }</code></pre>
<p>The ESS for the STEPPS1 data product is 3.6, so w in our assimilation of fractional composition at Harvard Forest will be w = 305.6.</p>
</div>
</div>
<div id="current-models" class="section level3">
<h3><span class="header-section-number">2.6.8</span> Current Models</h3>
<p>SIPNET and LINKAGES are the two ecosystem models that have been used during state data assimilation development within PEcAn. SIPNET is a simple ecosystem model that was built for… LINKAGES is a forest gap model created to simulate the process of succession that occurs when a gap is opened in the forest canopy. LINKAGES has 72 species level plant functional types and the ability to simulate some below ground processes (C and N cycles).</p>
</div>
<div id="model-calibration" class="section level3">
<h3><span class="header-section-number">2.6.9</span> Model Calibration</h3>
<p>Without model calibration both SIPNET and LINKAGES make incorrect predictions about Harvard Forest. To confront this problem, SIPNET and LINKAGES will both be calibrated using data collected at the Harvard Forest flux tower. Istem has completed calibration for SIPNET using a <a href="https://github.com/PecanProject/pecan/blob/develop/modules/assim.batch/R/pda.emulator.R">parameter data assimilation emulator</a> contained within the PEcAn workflow. LINKAGES will also be calibrated using this method. This method is also generalizable to other sites assuming there is data independent of data assimilation data available to calibrate against.</p>
</div>
<div id="initial-conditions" class="section level3">
<h3><span class="header-section-number">2.6.10</span> Initial Conditions</h3>
<p>The initial conditions for SIPNET are sampled across state space based on data distributions at the time when the data assimilation will begin. We do not sample LINAKGES for initial conditions and instead perform model spin up for 100 years prior to beginning data assimilation. In the future, we would like to estimate initial conditions based on data. We achieve adequate spread in the initial conditions by allowing the parameters to vary across ensemble members.</p>
</div>
<div id="drivers" class="section level3">
<h3><span class="header-section-number">2.6.11</span> Drivers</h3>
<p>We are currently using Global Climate Model (GCM) drivers from the PaLEON model intercomparison. Christy Rollinson and John Tipton are creating MET downscaled GCM drivers for the Paleon data assimilation sites. We will use these drivers when they are available because they are a closer representation of reality.</p>
</div>
</div>
<div id="sequential-state-data-assimilation" class="section level2">
<h2><span class="header-section-number">2.7</span> Sequential State Data Assimilation</h2>
<p>We are using sequential state data assimilation methods to assimilate paleon data products into ecosystem models because less computation power is required for sequential state data assimilation than for particle filter methods.</p>
<div id="general-description" class="section level3">
<h3><span class="header-section-number">2.7.1</span> General Description</h3>
<p>The general sequential data assimilation framework consists of three steps at each time step:
1. Read the state variable output for time t from the model forecast ensembles and save the forecast mean (muf) and covariance (Pf).
2. If there are data mean (y) and covariance (R) at this time step, perform data assimilation analysis (either EnKF or generalized ensemble filter) to calculate the new mean (mua) and covariance (Pa) of the state variables.
3. Use mua and Pa to restart and run the ecosystem model ensembles with new state variables for time t+1.</p>
</div>
<div id="enkf" class="section level3">
<h3><span class="header-section-number">2.7.2</span> EnKF</h3>
<p>There are two ways to implement sequential state data assimilation at this time. The first is the Ensemble Kalman Filter (EnKF). EnKF has an analytical solution, so the kalman gain, analysis mean vector, and analysis covariance matrix can be calculated directly:</p>
<pre><code>       
        K &lt;- Pf %*% t(H) %*% solve((R + H %*% Pf %*% t(H))) ## Kalman Gain
        
        mu.a &lt;- mu.f + K %*% (Y - H %*% mu.f) # Analysis mean vector
        
        Pa   &lt;- (diag(ncol(X)) - K %*% H) %*% Pf # Analysis covariance matrix
        </code></pre>
<p>The EnKF is typically used for sequential state data assimilation, but we found that EnKF lead to filter divergence when combined with our uncertain data products. Filter divergence led us to create a generalized ensemble filter that estimates process variance.</p>
</div>
<div id="generalized-ensemble-filter" class="section level3">
<h3><span class="header-section-number">2.7.3</span> Generalized Ensemble Filter</h3>
<p>The generalized ensemble filter follows generally the three steps of sequential state data assimilation. But, in the generalized ensemble filter we add a latent state vector that accounts for added process variance. Furthermore, instead of solving the analysis analytically like the EnKF, we have to estimate the mean analysis vector and covariance matrix with MCMC.</p>
<div id="mapping-ensemble-output-to-tobit-space" class="section level4">
<h4><span class="header-section-number">2.7.3.1</span> Mapping Ensemble Output to Tobit Space</h4>
<p>There are some instances when we have right or left censored variables from the model forecast. For example, a model estimating species level biomass may have several ensemble members that produce zero biomass for a given species. We are considering this case a left censored state variable that needs to be mapped to normal space using a tobit model. We do this by creating two matrices with dimensions number of ensembles by state variable. The first matrix is a matrix of indicator variables (y.ind), and the second is a matrix of censored variables (y.censored). When the indicator variable is 0 the state variable (j) for ensemble member (i) is sampled. This allows us to impute a normal distribution for each state variable that contains ‘missing’ forecasts or forecasts of zero.</p>
<pre><code>tobit2space.model &lt;- nimbleCode({
    for(i in 1:N){
      y.censored[i,1:J] ~ dmnorm(muf[1:J], cov = pf[1:J,1:J])
      for(j in 1:J){
        y.ind[i,j] ~ dconstraint(y.censored[i,j] &gt; 0)
      }
    }
    
    muf[1:J] ~ dmnorm(mean = mu_0[1:J], cov = pf[1:J,1:J])
    
    Sigma[1:J,1:J] &lt;- lambda_0[1:J,1:J]/nu_0
    pf[1:J,1:J] ~ dinvwish(S = Sigma[1:J,1:J], df = J)
    
  })</code></pre>
</div>
<div id="generalized-ensemble-filter-model-description" class="section level4">
<h4><span class="header-section-number">2.7.3.2</span> Generalized Ensemble Filter Model Description</h4>
<p>Below is the BUGS code for the full analysis model. The forecast mean an covariance are calculated from the tobit2space model above. We use a tobit likelihood in this model because there are instances when the data may be left or right censored. Process variance is included by adding a latent model state (X) with a process precision matrix (q). We update our prior on q at each time step using our estimate of q from the previous time step.</p>
<pre><code>  tobit.model &lt;- nimbleCode({ 
    
    q[1:N,1:N]  ~ dwish(R = aq[1:N,1:N], df = bq) ## aq and bq are estimated over time
    Q[1:N,1:N] &lt;- inverse(q[1:N,1:N])
    X.mod[1:N] ~ dmnorm(muf[1:N], prec = pf[1:N,1:N]) ## Model Forecast ##muf and pf are assigned from ensembles
    
    ## add process error
    X[1:N]  ~ dmnorm(X.mod[1:N], prec = q[1:N,1:N])
    
    #agb linear
    #y_star[1:YN,1:YN] &lt;- X[1:YN,1:YN] #[choose]
    
    #f.comp non linear
    #y_star[1:YN] &lt;- X[1:YN] / sum(X[1:YN])
    
    ## Analysis
    y.censored[1:YN] ~ dmnorm(X[1:YN], prec = r[1:YN,1:YN]) #is it an okay assumpution to just have X and Y in the same order?
    
    #don&#39;t flag y.censored as data, y.censored in inits
    #remove y.censored samplers and only assign univariate samplers on NAs
    
    for(i in 1:YN){
      y.ind[i] ~ dconstraint(y.censored[i] &gt; 0)
    }
    
  })</code></pre>
</div>
</div>
<div id="ensemble-adjustment" class="section level3">
<h3><span class="header-section-number">2.7.4</span> Ensemble Adjustment</h3>
<p>Each ensemble member has a different set of species parameters. We adjust the updated state variables by using an ensemble adjustment. The ensemble adjustment weights the ensemble members based on their likelihood during the analysis step.</p>
<pre><code>      S_f  &lt;- svd(Pf)
      L_f  &lt;- S_f$d
      V_f  &lt;- S_f$v
      
      ## normalize
      Z &lt;- X*0
      for(i in seq_len(nrow(X))){
          Z[i,] &lt;- 1/sqrt(L_f) * t(V_f)%*%(X[i,]-mu.f)
      }
      Z[is.na(Z)]&lt;-0
      
      ## analysis
      S_a  &lt;- svd(Pa)
      L_a  &lt;- S_a$d
      V_a  &lt;- S_a$v
      
      ## analysis ensemble
      X_a &lt;- X*0
      for(i in seq_len(nrow(X))){
        X_a[i,] &lt;- V_a %*%diag(sqrt(L_a))%*%Z[i,] + mu.a
      }</code></pre>
</div>
<div id="diagnostics" class="section level3">
<h3><span class="header-section-number">2.7.5</span> Diagnostics</h3>
<p>There are three diagnostics we have currently implemented: time series, bias time series, and process variance. The time series diagnostics show the data, forecast, and analysis time series for each state variable. These are useful for visually assessing variance and magnitude of change of state variables through time. These time series are also updated throughout the analysis and are also created as a pdf at the end of the SDA workflow. There are two types of bias time series the first assess the bias in the update (the forecast minus the analysis) and the second assess the bias in the error (the forecast minus the data). These bias time series are useful for identifying which state variables have intrinsic bias within the model. For example, if red oak biomass in LINKAGES increases at every time step (the update and the error are always positive), this would suggest that LINKAGES has a positive growth or recruitment bias for red oak. Finally, when using the generalized ensemble filter to estimate process variance, there are two additional plots to assess estimation of process variance. The first is a correlation plot of the process covariance matrix. This tells us what correlations are incorrectly represented by the model. For example, if red oak biomass and white pine biomass are highly negatively correlated in the process covariance matrix, this means that the model either 1) has no relationship between red oak and white pine and they should affect each other negatively or 2) there is a positive relationship between red oak and white pine and there shouldn’t be any relationship. We can determine which of these is true by comparing the process covariance matrix to the model covariance matrix. The second process variance diagnostic plot shows how the degrees of freedom associated with estimating the process covariance matrix have changed through time. This plot should show increasing degrees of freedom through time.</p>
<p>==&gt; 03_hidden_analyses/04_multisettings.Rmd &lt;==
## MultiSettings</p>
<p>(TODO: Under construction…)</p>
</div>
</div>
<div id="Benchmarking" class="section level2">
<h2><span class="header-section-number">2.8</span> Benchmarking</h2>
<p>Benchmarking is the process of comparing model outputs against either experimental data or against other model outputs as a way to validate model performance.
We have a suit of statistical comparisons that provide benchmarking scores as well as visual comparisons that help in diagnosing data-model and/or model-model differences.</p>
<div id="data-preparation" class="section level3">
<h3><span class="header-section-number">2.8.1</span> Data Preparation</h3>
<p>All data that you want to compare with model runs must be registered in the database.
This is currently a step that must be done by hand either from the command line or through the online BETY interface.
The data must have three records:</p>
<ol style="list-style-type: decimal">
<li><p>An input record (Instructions <a href="tutorialsdemos-and-how-tos.html#NewInput">here</a>)</p></li>
<li><p>A database file record (Instructions <a href="tutorialsdemos-and-how-tos.html#NewInput">here</a>)</p></li>
<li><p>A format record (Instructions <a href="tutorialsdemos-and-how-tos.html#NewFormat">here</a>)</p></li>
</ol>
</div>
<div id="model-runs" class="section level3">
<h3><span class="header-section-number">2.8.2</span> Model Runs</h3>
<p>Model runs can be setup and executed
- Using the PEcAn web interface online or with a VM (<a href="#GettingStarted">see setup</a>)
- By hand using the <a href="topical.html#pecanXML">pecan.xml</a></p>
</div>
<div id="the-benchmarking-shiny-app" class="section level3">
<h3><span class="header-section-number">2.8.3</span> The Benchmarking Shiny App</h3>
<p>The entire benchmarking process can be done through the Benchmarking R Shiny app.</p>
<p>When the model run has completed, navigate to the workflow visualization Shiny app.</p>
<ul>
<li>Load model data
<ul>
<li>Select the workflow and run id</li>
<li>Make sure that your model output is loading properly (i.e. you can see plots of your data)</li>
</ul></li>
<li>Load benchmarking data
<ul>
<li>Again make sure that you can see the uploaded data plotted alongside the model output. In the future there will be more tools for double checking that your uploaded data is appropriate for benchmarking, but for now you may need to do the sanity checks by hand.</li>
</ul></li>
</ul>
<div id="create-a-reference-run-record" class="section level4">
<h4><span class="header-section-number">2.8.3.1</span> Create a reference run record</h4>
<ul>
<li>Navigate to the Benchmarking tab
<ul>
<li>The first step is to register the new model run as a reference run in the database. Benchmarking cannot be done before this step is completed. When the reference run record has been created, additional menus for benchmarking will appear.</li>
</ul></li>
</ul>
</div>
<div id="setup-benchmarks-and-metrics" class="section level4">
<h4><span class="header-section-number">2.8.3.2</span> Setup Benchmarks and metrics</h4>
<ul>
<li>From the menus select
<ul>
<li>The variables in the uploaded data that you wish to compare with model output.</li>
<li>The numerical metrics you would like to use in your comparison.</li>
<li>Additional comparison plots that you would like to see.</li>
</ul></li>
<li>Note: All these selections populate the benchmarking section of the <code>pecan.BENCH.xml</code> which is then saved in the same location as the original run output. This xml is purely for reference.</li>
</ul>
<div id="benchmarking-output" class="section level5">
<h5><span class="header-section-number">2.8.3.2.1</span> Benchmarking Output</h5>
<ul>
<li>All benchmarking results are stored in the benchmarking directory which is created in the same folder as the original model run.</li>
<li>The benchmaking directory contains subdirectories for each of the datasets compared with the model output. The names of these directories are the same as the corresponding data set’s input id in BETY.</li>
<li>Each input directory contains <code>benchmarking.output.Rdata</code>, an Rdata file contianing all the results of the benchmarking workflow. <code>load(benchmarking.output.Rdata)</code> loads a list called <code>result.out</code> which contains the following:
<ul>
<li><code>bench.results</code>: a data frame of all numeric benchmarking scores</li>
<li><code>format</code>: a data frame that can be used to see how the input data was transformed to make it comparable to the model output. This involves converting from the original variable names and units to the internal pecan standard.</li>
<li><code>aligned.dat</code>: a data frame of the final aligned model and input values.</li>
</ul></li>
<li><p>All plots are saved as pdf files with names with “benchmark_plot-type_variable_input-id.pdf”</p></li>
<li><p>To view interactive results, naviage to the Benchmarking Plots tab in the shiny app.</p></li>
</ul>
</div>
</div>
</div>
<div id="benchmarking-in-pecan.xml" class="section level3">
<h3><span class="header-section-number">2.8.4</span> Benchmarking in pecan.xml</h3>
<p>Before reading this section, it is recommended that you <a href="topical.html#pecanXML">familiarize yourself with basics of the pecan.xml file.</a></p>
<p>The <code>pecan.xml</code> has an <em>optional</em> benchmarking section. Below are all the tags in the benchmarking section explained. Many of these field are filled in automatically during the benchmarking process when using the benchmarking shiny app.</p>
<p>The only time one should edit the benchmarking section by hand is for performing clone runs. See <a href="#CloneRun">clone run documentation.</a></p>
<p><code>&lt;benchmarking&gt;</code> settings:</p>
<ul>
<li><code>ensemble_id</code>: the id of the ensemble that you will be using - the settings from this ensemble will be saved in a reference run record and then <code>ensemble_id</code> will be replaced with <code>reference_run_id</code></li>
<li><code>new_run</code>: TRUE = create new run, FALSE = use existing run (required, default FALSE)</li>
</ul>
<p>It is possible to look at more than one benchmark with a particular run.
The specific settings related to each benchmark are in a sub section called <code>benchmark</code></p>
<ul>
<li><code>input_id</code>: the id of the benchmarking data (required)</li>
<li><code>variable_id</code>: the id of the variable of interest within the data. If you leave this blank, all variables that are shared between the input and model output will be used.</li>
<li><code>metric_id</code>: the id(s) of the metric(s) to be calculated. If you leave this blank, all metrics will be used.</li>
</ul>
<p>Example:
In this example,
- we are using a pre-existing run from <code>ensemble_id = 1000010983</code> (<code>new_run = FALSE</code>)
- the output will be compared to data from <code>input_id = 1000013743</code>, specifically two variables of interest: <code>variable_id = 411, variable_id = 18</code>
- for <code>variable_id = 411</code> we will perform only one metric of comparison <code>metric_id = 1000000001</code>
- for for <code>variable_id = 18</code> we will perform two metrics of comparison <code>metric_id = 1000000001, metric_id = 1000000002</code></p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;benchmarking&gt;</span>
  <span class="kw">&lt;ensemble_id&gt;</span>1000010983<span class="kw">&lt;/ensemble_id&gt;</span>
  <span class="kw">&lt;new_run&gt;</span>FALSE<span class="kw">&lt;/new_run&gt;</span>
  <span class="kw">&lt;benchmark&gt;</span>
   <span class="kw">&lt;input_id&gt;</span>1000013743<span class="kw">&lt;/input_id&gt;</span>
   <span class="kw">&lt;variable_id&gt;</span>411<span class="kw">&lt;/variable_id&gt;</span>
   <span class="kw">&lt;site_id&gt;</span>853<span class="kw">&lt;/site_id&gt;</span>
   <span class="kw">&lt;metrics&gt;</span>
    <span class="kw">&lt;metric_id&gt;</span>1000000001<span class="kw">&lt;/metric_id&gt;</span>
   <span class="kw">&lt;/metrics&gt;</span>
  <span class="kw">&lt;/benchmark&gt;</span>
  <span class="kw">&lt;benchmark&gt;</span>
   <span class="kw">&lt;input_id&gt;</span>1000013743<span class="kw">&lt;/input_id&gt;</span>
   <span class="kw">&lt;variable_id&gt;</span>18<span class="kw">&lt;/variable_id&gt;</span>
   <span class="kw">&lt;site_id&gt;</span>853<span class="kw">&lt;/site_id&gt;</span>
   <span class="kw">&lt;metrics&gt;</span>
    <span class="kw">&lt;metric_id&gt;</span>1000000001<span class="kw">&lt;/metric_id&gt;</span>
    <span class="kw">&lt;metric_id&gt;</span>1000000002<span class="kw">&lt;/metric_id&gt;</span>
   <span class="kw">&lt;/metrics&gt;</span>
  <span class="kw">&lt;/benchmark&gt;</span>
<span class="kw">&lt;/benchmarking&gt;</span></code></pre>

</div>
<div id="pecan-remote" class="section level3">
<h3><span class="header-section-number">2.8.5</span> Remote execution with PEcAn</h3>
<p>Remote execution allows the user to leverage the power and storage of high performance computing clusters, AWS instances, or specially configured virtual machines, but without leaving their local working environment.
PEcAn uses remote execution primarily to run ecosystem models.</p>
<p>The infrastructure for remote execution lives in the <code>PEcAn.remote</code> package (<code>base/remote</code> in the PEcAn repository).</p>
<p>This section describes the following:</p>
<ol style="list-style-type: decimal">
<li>Checking capabilities to connect to the remote machine correctly:</li>
</ol>
<ul>
<li>Basics of command line SSH</li>
<li>SSH authentication with keys and passwords</li>
<li>Basics of SSH tunnels, and how they are used in PEcAn</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Description of PEcAn related tools that control remote execution</li>
</ol>
<ul>
<li>Basic remote execution R functions in <code>PEcAn.remote</code></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>SETUP- Configuration Files and settings</li>
</ol>
<ul>
<li>Remote model execution configuration in the <code>pecan.xml</code> and <code>config.php</code></li>
<li>Additional information about preparing remote servers for execution</li>
</ul>
<div id="basics-of-ssh" class="section level4">
<h4><span class="header-section-number">2.8.5.1</span> Basics of SSH</h4>
<p>All of the PEcAn remote infrastructure depends on the system <code>ssh</code> utility, so it’s important to make sure this works before attempting the advanced remote execution functionality in PEcAn.</p>
<p>To connect to a remote server interactively, the command is simply:</p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">ssh</span> <span class="op">&lt;</span>username<span class="op">&gt;</span>@<span class="op">&lt;</span>hostname<span class="op">&gt;</span></code></pre>
<p>For instance, my connection to the BU shared computing cluster looks like:</p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">ssh</span> ashiklom@geo.bu.edu</code></pre>
<p>It will prompt me for my BU password, and, if successful, will drop me into a login shell on the remote machine.</p>
<p>Alternatively to the login shell, <code>ssh</code> can be used to execute arbitrary code, whose output will be returned exactly as it would if you ran the command locally.
For example, the following:</p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">ssh</span> ashiklom@geo.bu.edu pwd</code></pre>
<p>will run the <code>pwd</code> command, and return the path to my home directory on the BU SCC.
The more advanced example below will run some simple R code on the BU SCC and return the output as if it was run locally.</p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">ssh</span> ashiklom@geo.bu.edu Rscript -e <span class="st">&quot;seq(1, 10)&quot;</span></code></pre>
</div>
<div id="ssh-authentication-password-vs.ssh-key" class="section level4">
<h4><span class="header-section-number">2.8.5.2</span> SSH authentication – password vs. SSH key</h4>
<p>Because this server uses passwords for authentication, this command will then prompt me for my password.</p>
<p>An alternative to password authentication is using SSH keys.
Under this system, the host machine (say, your laptop, or the PEcAn VM) has to generate a public and private key pair (using the <code>ssh-keygen</code> command).
The private key (by default, a file in <code>~/.ssh/id_rsa</code>) lives on the host machine, and should <strong>never</strong> be shared with anyone.
The public key will be distributed to any remote machines to which you want the host to be able to connect.
On each remote machine, the public key should be added to a list of authorized keys located in the <code>~/.ssh/authorized_keys</code> file (on the remote machine).
The authorized keys list indicates which machines (technically, which keys – a single machine, and even a single user, can have many keys) are allowed to connect to it.
This is the system used by all of the PEcAn servers (<code>pecan1</code>, <code>pecan2</code>, <code>test-pecan</code>).</p>
</div>
<div id="ssh-tunneling" class="section level4">
<h4><span class="header-section-number">2.8.5.3</span> SSH tunneling</h4>
<p>SSH authentication can be more advanced than indicated above, especially on systems that require dual authentication.
Even simple password-protection can be tricky in scripts, since (by design) it is fairly difficult to get SSH to accept a password from anything other than the raw keyboard input (i.e. SSH doesn’t let you pass passwords as input or arguments, because this exposes your password as plain text).</p>
<p>A convenient and secure way to follow SSH security protocol, but prevent having to go through the full authentication process every time, is to use SSH tunnels (or “sockets”, which are effectively synonymous).
Essentially, an SSH socket is a read- and write-protectected file that contains all of the information about an SSH connection.</p>
<p>To create an SSH tunnel, use a command like the following:</p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">ssh</span> -n -N -f -o ControlMaster=yes -S /path/to/socket/file <span class="op">&lt;</span>username<span class="op">&gt;</span>@<span class="op">&lt;</span>hostname<span class="op">&gt;</span></code></pre>
<p>If appropriate, this will prompt you for your password (if using password authentication), and then will drop you back to the command line (thanks to the <code>-N</code> flag, which runs SSH without executing a command, the <code>-f</code> flag, which pushes SSH into the background, and the <code>-n</code> flag, which prevents ssh from reading any input).
It will also create the file <code>/path/to/socket/file</code>.</p>
<p>To use this socket with another command, use the <code>-S /path/to/file</code> flag, pointing to the same tunnel file you just created.</p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">ssh</span> -S /path/to/socket/file <span class="op">&lt;</span>hostname<span class="op">&gt;</span> <span class="op">&lt;</span>optional command<span class="op">&gt;</span></code></pre>
<p>This will let you access the server without any sort of authentication step.
As before, if <code>&lt;optional command&gt;</code> is blank, you will be dropped into an interactive shell on the remote, or if it’s a command, that command will be executed and the output returned.</p>
<p>To close a socket, use the following:</p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">ssh</span> -S /path/to/socket/file <span class="op">&lt;</span>hostname<span class="op">&gt;</span> -O exit</code></pre>
<p>This will delete the socket file and close the connection.
Alternatively, a scorched earth approach to closing the SSH tunnel if you don’t remember where you put the socket file is something like the following:</p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="ex">pgrep</span> ssh   # See which processes will be killed
<span class="ex">pkill</span> ssh   # Kill those processes</code></pre>
<p>…which will kill all user processes called <code>ssh</code>.</p>
<p>To automatically create tunnels following a specific pattern, you can add the following to your
<code>~/.ssh/config</code></p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="ex">Host</span> <span class="op">&lt;</span>hostname goes here<span class="op">&gt;</span>
 <span class="ex">ControlMaster</span> auto
 <span class="ex">ControlPath</span> /tmp/%r@%h:%p</code></pre>
<p>For more information, see <code>man ssh</code>.</p>
</div>
</div>
<div id="ssh-tunnels-and-pecan" class="section level3">
<h3><span class="header-section-number">2.8.6</span> SSH tunnels and PEcAn</h3>
<p>Many of the <code>PEcAn.remote</code> functions assume that a tunnel is already open.
If working from the web interface, the tunnel will be opened for you by some under-the-hood PHP and Bash code, but if debugging or working locally, you will have to create the tunnel yourself.
The best way to do this is to create the tunnel first, outside of R, as described above.
(In the following examples, I’ll use my username <code>ashiklom</code> connecting to the <code>test-pecan</code> server with a socket stored in <code>/tmp/testpecan</code>.
To follow along, replace these with your own username and designated server, respectively).</p>
<pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">ssh</span> -nNf -o ControlMaster=yes -S /tmp/testpecan ashiklom@test-pecan.bu.edu</code></pre>
<p>Then, in R, create a <code>host</code> object, which is just a list containing the elements <code>name</code> (hostname) and <code>tunnel</code> (path to tunnel file).</p>
<pre class="sourceCode r"><code class="sourceCode r">my_host &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">name =</span> <span class="st">&quot;test-pecan.bu.edu&quot;</span>, <span class="dt">tunnel =</span> <span class="st">&quot;/tmp/testpecan&quot;</span>)</code></pre>
<p>This host object can then be used in any of the remote execution functions.</p>
</div>
<div id="basic-remote-execute-functions" class="section level3">
<h3><span class="header-section-number">2.8.7</span> Basic remote execute functions</h3>
<p>The <code>PEcAn.remote::remote.execute.cmd</code> function runs a system command on a remote server (or on the local server, if <code>host$name == &quot;localhost&quot;</code>).</p>
<pre><code>x &lt;- PEcAn.remote::remote.execute.cmd(host = my_host, cmd = &quot;echo&quot;, args = &quot;Hello world&quot;)
x</code></pre>
<p>Note that <code>remote.execute.cmd</code> is similar to base R’s <code>system2</code>, in that the base command (in this case, <code>echo</code>) is passed separately from its arguments (<code>&quot;Hello world&quot;</code>).
Note also that the output of the remote command is returned as a character.</p>
<p>For R code, there is a special wrapper around <code>remote.execute.cmd</code> – <code>PEcAn.remote::remote.execute.R</code>, which runs R code (passed as a string) on a remote and returns the output.</p>
<pre><code>code &lt;- &quot;
    x &lt;- 2:4
    y &lt;- 3:1
    x ^ y
&quot;
out &lt;- PEcAn.remote::remote.execute.R(code = code, host = my_host)</code></pre>
<p>For additional functions related to remote file operations and other stuff, see the <code>PEcAn.remote</code> package documentation.</p>
</div>
<div id="remote-model-execution-with-pecan" class="section level3">
<h3><span class="header-section-number">2.8.8</span> Remote model execution with PEcAn</h3>
<p>The workhorse of remote model execution is the <code>PEcAn.remote::start.model.runs</code> function, which distributes execution of each run in a list of runs (e.g. multiple runs in an ensemble) to the local machine or a remote based on the configuration in the PEcAn settings.</p>
<p>Broadly, there are three major types of model execution:</p>
<ul>
<li>Serialized (<code>PEcAn.remote::start_serial</code>) – This runs models one at a time, directly on the local machine or remote (i.e. same as calling the executables one at a time for each run).</li>
<li>Via a queue system, (<code>PEcAn.remote::start_qsub</code>) – This uses a queue management system, such as SGE (e.g. <code>qsub</code>, <code>qstat</code>) found on the BU SCC machines, to submit jobs.
For computationally intensive tasks, this is the recommended way to go.</li>
<li>Via a model launcher script (<code>PEcAn.remote::setup_modellauncher</code>) – This is a highly customizable approach where task submission is controlled by a user-provided script (<code>launcher.sh</code>).</li>
</ul>
</div>
<div id="xml-configuration" class="section level3">
<h3><span class="header-section-number">2.8.9</span> XML configuration</h3>
<p>The relevant section of the PEcAn XML file is the <code>&lt;host&gt;</code> block.
Here is a minimal example from one of my recent runs:</p>
<pre><code>&lt;host&gt;
    &lt;name&gt;geo.bu.edu&lt;/name&gt;
    &lt;user&gt;ashiklom&lt;/user&gt;
    &lt;tunnel&gt;/home/carya/output//PEcAn_99000000008/tunnel/tunnel&lt;/tunnel&gt;
&lt;/host&gt;</code></pre>
<p>Breaking this down:</p>
<ul>
<li><code>name</code> – The hostname of the machine where the runs will be performed.
Set it to <code>localhost</code> to run on the local machine.</li>
<li><code>user</code> – Your username on the remote machine (note that this may be different from the username on your local machine).</li>
<li><code>tunnel</code> – This is the tunnel file for the connection used by all remote execution files.
The tunnel is created automatically by the web interface, but must be created by the user for command line execution.</li>
</ul>
<p>This configuration will run in serialized mode.
To use <code>qsub</code>, the configuration is slightly more involved:</p>
<pre><code>&lt;host&gt;
  &lt;name&gt;geo.bu.edu&lt;/name&gt;
  &lt;user&gt;ashiklom&lt;/user&gt;
  &lt;qsub&gt;qsub -V -N @NAME@ -o @STDOUT@ -e @STDERR@ -S /bin/bash&lt;/qsub&gt;
  &lt;qsub.jobid&gt;Your job ([0-9]+) .*&lt;/qsub.jobid&gt;
  &lt;qstat&gt;qstat -j @JOBID@ || echo DONE&lt;/qstat&gt;
  &lt;tunnel&gt;/home/carya/output//PEcAn_99000000008/tunnel/tunnel&lt;/tunnel&gt;
&lt;/host&gt;</code></pre>
<p>The additional fields are as follows:</p>
<ul>
<li><code>qsub</code> – The command used to submit jobs to the queue system.
Despite the name, this can be any command used for any queue system.
The following variables are available to be set here:
<ul>
<li><code>@NAME@</code> – Job name to display</li>
<li><code>@STDOUT@</code> – File to which <code>stdout</code> will be redirected</li>
<li><code>@STDERR@</code> – File to which <code>stderr</code> will be redirected</li>
</ul></li>
<li><code>qsub.jobid</code> – A regular expression, from which the job ID will be determined.
This string will be parsed by R as <code>jobid &lt;- gsub(qsub.jobid, &quot;\\1&quot;, output)</code> – note that the first pattern match is taken as the job ID.</li>
<li><code>qstat</code> – The command used to check the status of a job.
Internally, PEcAn will look for the <code>DONE</code> string at the end, so a structure like <code>&lt;some command indicating if any jobs are still running&gt; || echo DONE</code> is required.
The <code>@JOBID@</code> here is the job ID determined from the <code>qsub.jobid</code> parsing.</li>
</ul>
<p>Documentation for using the model launcher is currently unavailable.</p>
</div>
<div id="configuration-for-pecan-web-interface" class="section level3">
<h3><span class="header-section-number">2.8.10</span> Configuration for PEcAn web interface</h3>
<p>The <code>config.php</code> has a few variables that will control where the web
interface can run jobs, and how to run those jobs. It is located in the <code>/web</code> directory and if you have not touched it yet it will
be named as <code>config.example.php</code>. Rename it to ’config.php` and edit by folowing the following directions.</p>
<p>These variables are <code>$hostlist</code>, <code>$qsublist</code>, <code>$qsuboptions</code>, and <code>$SSHtunnel</code>. In
the near future <code>$hostlist</code>, <code>$qsublist</code>, <code>$qsuboptions</code> will be
combined into a single list.</p>
<p><code>$SSHtunnel</code> : points to the script that creates an SSH tunnel.
The script is located in the web folder and the default value of
<code>dirname(__FILE__) . DIRECTORY_SEPARATOR . &quot;sshtunnel.sh&quot;;</code> most
likely will work.</p>
<p><code>$hostlist</code> : is an array with by default a single value, only
allowing jobs to run on the local server. Adding any other servers
to this list will show them in the pull down menu when selecting
machines, and will trigger the web page to be show to ask for a
username and password for the remote execution (make sure to use
HTTPS setup when asking for password to prevent it from being send
in the clear).</p>
<p><code>$qsublist</code> : is an array of hosts that require qsub to be used
when running the models. This list can include <code>$fqdn</code> to indicate
that jobs on the local machine should use qsub to run the models.</p>
<p><code>$qsuboptions</code> : is an array that lists options for each machine.
Currently it support the following options (see also
[Run Setup] and look at the tags)</p>
<pre><code>array(&quot;geo.bu.edu&quot; =&gt;
    array(&quot;qsub&quot;   =&gt; &quot;qsub -V -N @NAME@ -o @STDOUT@ -e @STDERR@ -S /bin/bash&quot;,
          &quot;jobid&quot;  =&gt; &quot;Your job ([0-9]+) .*&quot;,
          &quot;qstat&quot;  =&gt; &quot;qstat -j @JOBID@ || echo DONE&quot;,
          &quot;job.sh&quot; =&gt; &quot;module load udunits R/R-3.0.0_gnu-4.4.6&quot;,
          &quot;models&quot; =&gt; array(&quot;ED2&quot;    =&gt; &quot;module load hdf5&quot;))</code></pre>
<p>In this list <code>qsub</code> is the actual command line for qsub, <code>jobid</code>
is the text returned from qsub, <code>qstat</code> is the command to check
to see if the job is finished. <code>job.sh</code> and the value in models
are additional entries to add to the job.sh file generated to
run the model. This can be used to make sure modules are loaded
on the HPC cluster before running the actual model.</p>
<div id="running-pecan-code-for-remotely" class="section level4">
<h4><span class="header-section-number">2.8.10.1</span> Running PEcAn code for remotely</h4>
<p>You do not need to download PEcAn fully on your remote machine. You can compile and install the model specific code pieces of
PEcAn on the cluster easily without having to install the
full code base of PEcAn (and all OS dependencies). Use the <code>git clone</code> command to:</p>
<pre><code>devtools::install_github(&quot;pecanproject/pecan&quot;, subdir = &#39;base/utils&#39;)</code></pre>
<p>Next we need to install the model specific pieces, this is done
almost the same (example for ED2):</p>
<pre><code>devtools::install_github(&quot;pecanproject/pecan&quot;, subdir = &#39;models/ed&#39;)</code></pre>
<p>This should install dependencies required.</p>
<ul>
<li>The following are some notes on how to install the model specifics on different HPC
clusters*</li>
</ul>
</div>
<div id="geo.bu.edu" class="section level4">
<h4><span class="header-section-number">2.8.10.2</span> geo.bu.edu</h4>
<p>Following modules need to be loaded:</p>
<pre><code>module load hdf5 udunits R/R-3.0.0_gnu-4.4.6</code></pre>
<p>Next the following packages need to be installed, otherwise it
will fall back on the older versions install site-library</p>
<pre><code>install.packages(c(&#39;udunits2&#39;, &#39;lubridate&#39;), 
   configure.args=c(udunits2=&#39;--with-udunits2-lib=/project/earth/packages/udunits-2.1.24/lib --with-udunits2-include=/project/earth/packages/udunits-2.1.24/include&#39;),
   repos=&#39;http://cran.us.r-project.org&#39;)</code></pre>
<p>Finally to install support for both ED and SIPNET:</p>
<pre><code>devtools::install_github(&quot;pecanproject/pecan&quot;, subdir = &#39;base/utils&#39;)
devtools::install_github(&quot;pecanproject/pecan&quot;, subdir = &#39;models/sipnet&#39;)
devtools::install_github(&quot;pecanproject/pecan&quot;, subdir = &#39;models/ed&#39;)</code></pre>

</div>
</div>
</div>
<div id="pecan-api" class="section level2">
<h2><span class="header-section-number">2.9</span> The PEcAn Docker API</h2>
<p>If you have a running instance of Dockerized PEcAn (or other setup where PEcAn workflows are submitted via <a href="topical.html#rabbitmq">RabbitMQ</a>),
you have the option of running and managing PEcAn workflows using the <code>pecanapi</code> package.</p>
<p>For more details, see the <code>pecanapi</code> <a href="#pecanapi-vignette">package vignette</a> and function-level documentation.
What follows is a lightning introduction.</p>
<div id="installation" class="section level3">
<h3><span class="header-section-number">2.9.1</span> Installation</h3>
<p>The package can be installed directly from GitHub via <code>devtools::install_github</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">devtools<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;pecanproject/pecan/api@develop&quot;</span>)</code></pre>
</div>
<div id="creating-and-submitting-a-workflow" class="section level3">
<h3><span class="header-section-number">2.9.2</span> Creating and submitting a workflow</h3>
<p>With <code>pecanapi</code>, creating a workflow, submitting it to RabbitMQ, monitoring its progress, and processing its output can all be accomplished via an R script.</p>
<p>Start by loading the package (and the <code>magrittr</code> package, for the <code>%&gt;%</code> pipe operator).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pecanapi)
<span class="kw">library</span>(magrittr)</code></pre>
<p>Set your PEcAn database user ID, and create a database connection object, which will be used for database operations throughout the workflow.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">options</span>(<span class="dt">pecanapi.user_id =</span> <span class="dv">99000000002</span>)
con &lt;-<span class="st"> </span>DBI<span class="op">::</span><span class="kw">dbConnect</span>(
  RPostgres<span class="op">::</span><span class="kw">Postgres</span>(),
  <span class="dt">user =</span> <span class="st">&quot;bety&quot;</span>,
  <span class="dt">password =</span> <span class="st">&quot;bety&quot;</span>,
  <span class="dt">host =</span> <span class="st">&quot;localhost&quot;</span>,
  <span class="dt">port =</span> <span class="dv">5432</span>
)</code></pre>
<p>Find model and site IDs for the site and model you want to run.</p>
<pre class="sourceCode r"><code class="sourceCode r">model_id &lt;-<span class="st"> </span><span class="kw">get_model_id</span>(con, <span class="st">&quot;SIPNET&quot;</span>, <span class="st">&quot;136&quot;</span>)
all_umbs &lt;-<span class="st"> </span><span class="kw">search_sites</span>(con, <span class="st">&quot;umbs%disturbance&quot;</span>)
site_id &lt;-<span class="st"> </span><span class="kw">subset</span>(all_umbs, <span class="op">!</span><span class="kw">is.na</span>(mat))[[<span class="st">&quot;id&quot;</span>]]</code></pre>
<p>Insert a new workflow into the PEcAn database, and extract its ID.</p>
<pre class="sourceCode r"><code class="sourceCode r">workflow &lt;-<span class="st"> </span><span class="kw">insert_new_workflow</span>(con, site_id, model_id,
                                <span class="dt">start_date =</span> <span class="st">&quot;2004-01-01&quot;</span>,
                                <span class="dt">end_date =</span> <span class="st">&quot;2004-12-31&quot;</span>)
workflow_id &lt;-<span class="st"> </span>workflow[[<span class="st">&quot;id&quot;</span>]]</code></pre>
<p>Pull all of this information together into a settings list object.</p>
<pre class="sourceCode r"><code class="sourceCode r">settings &lt;-<span class="st"> </span><span class="kw">list</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_workflow</span>(workflow) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_database</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_pft</span>(<span class="st">&quot;temperate.deciduous&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_rabbitmq</span>(<span class="dt">con =</span> con) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">modifyList</span>(<span class="kw">list</span>(
    <span class="dt">meta.analysis =</span> <span class="kw">list</span>(<span class="dt">iter =</span> <span class="dv">3000</span>, <span class="dt">random.effects =</span> <span class="ot">FALSE</span>),
    <span class="dt">run =</span> <span class="kw">list</span>(<span class="dt">inputs =</span> <span class="kw">list</span>(<span class="dt">met =</span> <span class="kw">list</span>(<span class="dt">source =</span> <span class="st">&quot;CRUNCEP&quot;</span>, <span class="dt">output =</span> <span class="st">&quot;SIPNET&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;ncss&quot;</span>))),
    <span class="dt">ensemble =</span> <span class="kw">list</span>(<span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">variable =</span> <span class="st">&quot;NPP&quot;</span>)
  ))</code></pre>
<p>Submit the workflow via RabbitMQ, and monitor its progress in the R process.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">submit_workflow</span>(settings)
<span class="kw">watch_workflow</span>(workflow_id)</code></pre>
<p>Use THREDDS to access and analyze the output.</p>
<pre class="sourceCode r"><code class="sourceCode r">sipnet_out &lt;-<span class="st"> </span>ncdf4<span class="op">::</span><span class="kw">nc_open</span>(<span class="kw">run_dap</span>(workflow_id, <span class="st">&quot;2004.nc&quot;</span>))
gpp &lt;-<span class="st"> </span>ncdf4<span class="op">::</span><span class="kw">ncvar_get</span>(sipnet_out, <span class="st">&quot;GPP&quot;</span>)
time &lt;-<span class="st"> </span>ncdf4<span class="op">::</span><span class="kw">ncvar_get</span>(sipnet_out, <span class="st">&quot;time&quot;</span>)
ncdf4<span class="op">::</span><span class="kw">nc_close</span>(sipnet_out)
<span class="kw">plot</span>(time, gpp, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</code></pre>

</div>
</div>
<div id="advanced-user" class="section level2">
<h2><span class="header-section-number">2.10</span> Advanced User Guide</h2>
<ul>
<li>Adding to PEcAn as a user
<ul>
<li>Case studies
<ul>
<li>Adding a model</li>
<li>Adding new species, PFTs, and traits from a new site
<ul>
<li>Add a site</li>
<li>Add some species</li>
<li>Add PFT</li>
<li>Add trait data</li>
</ul></li>
<li>Adding a benchmark</li>
<li>Adding a met driver</li>
</ul></li>
<li>Reference (How to change tables)
<ul>
<li>Models</li>
<li>Species</li>
<li>PFTs</li>
<li>Traits</li>
<li>Inputs</li>
<li>DB files</li>
<li>Variables</li>
<li>Formats</li>
<li>(Link each section to relevant Bety tables)</li>
</ul></li>
</ul></li>
<li>Workflow curl submission</li>
</ul>

<div id="adding-to-pecan" class="section level3">
<h3><span class="header-section-number">2.10.1</span> Adding to PEcAn</h3>
<ul>
<li>Case studies
<ul>
<li><a href="tutorialsdemos-and-how-tos.html#adding-model">Adding a model</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#NewInput">Adding input data</a></li>
<li><a href="tutorialsdemos-and-how-tos.html#adding-data-web">Adding data through the web interface</a></li>
<li>Adding new species, PFTs, and traits from a new site
<ul>
<li>Add a site</li>
<li>Add some species</li>
<li>Add PFT</li>
<li>Add trait data</li>
</ul></li>
<li>Adding a benchmark</li>
<li>Adding a met driver</li>
</ul></li>
<li><a href="tutorialsdemos-and-how-tos.html#editing-records">Reference</a> (How to edit records in bety)
<ul>
<li>Models</li>
<li>Species</li>
<li>PFTs</li>
<li>Traits</li>
<li>Inputs</li>
<li>DB files</li>
<li>Variables</li>
<li>Formats</li>
<li>(Link each section to relevant Bety tables)</li>
</ul></li>
</ul>
</div>
<div id="adding-model" class="section level3">
<h3><span class="header-section-number">2.10.2</span> Adding An Ecosystem Model</h3>
<p><strong>Adding a model to PEcAn involves two activities:</strong></p>
<ol style="list-style-type: decimal">
<li>Updating the PEcAn database to register the model</li>
<li>Writing the interface modules between the model and PEcAn</li>
</ol>
<p><strong>Note that coupling a model to PEcAn should not require any changes to the model code itself</strong>. A key aspect of our design philosophy is that we want it to be easy to add models to the system and we want to using the working version of the code that is used by all other model users, not a special branch (which would rapidly end up out-of-date).</p>
</div>
<div id="pecan-database" class="section level3">
<h3><span class="header-section-number">2.10.3</span> PEcAn Database</h3>
<p>To run a model within PEcAn requires that the PEcAn database know about the model – this includes a MODEL_TYPE designation, the types of inputs the model requires, the location of the model executable, and the plant functional types used by the model. The instructions below assume that you will be specifying this information using the BETYdb web-based interface. This can be done either on your local VM (localhost:3280/bety or localhost:6480/bety) or on a server installation of BETYdb, though in either case we’d encourage you to set up your PEcAn instance to support <a href="https://github.com/PecanProject/bety/wiki/Distributed-BETYdb">database syncs</a> so that these changes can be shared and backed-up across the PEcAn network.</p>
<p>The figure below summarizes the relevant database tables that need to be updated to add a new model and the primary variables that define each table.</p>
<p><img src="https://www.lucidchart.com/publicSegments/view/54a8aea8-9360-4628-af9e-392a0a00c27b/image.png" /></p>
</div>
<div id="define-model_type" class="section level3">
<h3><span class="header-section-number">2.10.4</span> Define MODEL_TYPE</h3>
<p>The first step to adding a model is to create a new MODEL_TYPE, which defines the abstract model class which we will then use to specify input requirements, define plant functional types, and keep track of different model versions. A MODEL_TYPE is created by selecting Runs &gt; Model Type and then clicking on <em>New Model Type</em>. The MODEL_TYPE name should be identical to the MODEL package name (see Interface Module below) and is case sensitive.</p>
</div>
<div id="machine" class="section level3">
<h3><span class="header-section-number">2.10.5</span> MACHINE</h3>
<p>The PEcAn design acknowledges that the same model executables and input files may exist on multiple computers. Therefore, we need to define the machine that that we are using. If you are running on the VM then the local machine is already defined as <em>pecan</em>. Otherwise, you will need to select Runs &gt; Machines, click <em>New Machine</em>, and enter the URL of your server (e.g. pecan2.bu.edu).</p>
</div>
<div id="model" class="section level3">
<h3><span class="header-section-number">2.10.6</span> MODEL</h3>
<p>Next we are going to tell PEcAn where the model executable is. Select Runs &gt; Files, and click ADD. Use the pull down menu to specify the machine you just defined above and fill in the path and name for the executable. For example, if SIPNET is installed at /usr/local/bin/sipnet then the path is /usr/local/bin/ and the file (executable) is sipnet.</p>
<p>Now we will create the model record and associate this with the File we just registered. The first time you do this select Runs &gt; Models and click <em>New Model</em>. Specify a descriptive name of the model (which doesn’t have to be the same as MODEL_TYPE), select the MODEL_TYPE from the pull down, and provide a revision identifier for the model (e.g. v3.2.1). Once the record is created select it from the Models table and click EDIT RECORD. Click on “View Related Files” and when the search window appears search for the model executable you just added (if you are unsure which file to choose you can go back to the Files menu and look up the unique ID number). You can then associate this Model record with the File by clicking on the +/- symbol. By contrast, clicking on the name itself will take you to the File record.</p>
<p>In the future, if you set up the SAME MODEL VERSION on a different computer you can add that Machine and File to PEcAn and then associate this new File with this same Model record. A single version of a model should only be entered into PEcAn <strong>once</strong>.</p>
<p>If a new version of the model is developed that is derived from the current version you should add this as a new Model record but with the same MODEL_TYPE as the original. Furthermore, you should set the previous version of the model as Parent of this new version.</p>
</div>
<div id="formats" class="section level3">
<h3><span class="header-section-number">2.10.7</span> FORMATS</h3>
<p>The PEcAn database keep track of all the input files passed to models, as well as any data used in model validation or data assimilation. Before we start to register these files with PEcAn we need to define the format these files will be in. To create a new format see <a href="tutorialsdemos-and-how-tos.html#NewFormat">Formats Documentation</a>.</p>
</div>
<div id="model_type---formats" class="section level3">
<h3><span class="header-section-number">2.10.8</span> MODEL_TYPE -&gt; Formats</h3>
<p>For each of the input formats you specify for your model, you will need to edit your MODEL_TYPE record to add an association between the format and the MODEL_TYPE. Go to Runs &gt; Model Type, select your record and click on the Edit button. Next, click on “Edit Associated Formats” and choose the Format you just defined from the pull down menu. If the <em>Input</em> box is checked then all matching Input records will be displayed in the PEcAn site run selection page when you are defining a model run. In other words, the set of model inputs available through the PEcAn web interface is model-specific and dynamically generated from the associations between MODEL_TYPEs and Formats. If you also check the <em>Required</em> box, then the Input will be treated as required and PEcAn will not run the model if that input is not available. Furthermore, on the site selection webpage, PEcAn will filter the available sites and only display pins on the Google Map for sites that have a full set of required inputs (or where those inputs could be generated using PEcAn’s workflows). Similarly, to make a site appear on the Google Map, all you need to do is specify Inputs, as described in the next section, and the point should automatically appear on the map.</p>
</div>
<div id="inputs" class="section level3">
<h3><span class="header-section-number">2.10.9</span> INPUTS</h3>
<p>After a file Format has been created then input files can be registered with the database. Creating Inputs can be found under <a href="tutorialsdemos-and-how-tos.html#NewInput">How to insert new Input data</a>.</p>
</div>
<div id="pfts-plant-functional-types" class="section level3">
<h3><span class="header-section-number">2.10.10</span> PFTS (Plant Functional Types)</h3>
<p>Since many of the PEcAn tools are designed to keep track of parameter uncertainties and assimilate data into models, to use PEcAn with a model it is important to define Plant Functional Types for the sites or regions that you will be running the model. PFTs are MODEL_TYPE specific, so when you create a new PFT entry (Data &gt; PFTs; New PFT) you will want to choose your MODEL_TYPE from the pull down and then give the PFT a descriptive name (e.g. temperate deciduous).</p>
<div id="species" class="section level4">
<h4><span class="header-section-number">2.10.10.1</span> Species</h4>
<p>Within PEcAn there are no predefined PFTs and user can create new PFTs very easily at whatever taxonomic level is most appropriate, from PFTs for individual species up to one PFT for all plants globally. To allow PEcAn to query its trait database for information about a PFT, you will want to associate species with the PFT record by choosing Edit and then “View Related Species”. Species can be searched for by common or scientific name and then added to a PFT using the +/- button.</p>
</div>
<div id="cultivars" class="section level4">
<h4><span class="header-section-number">2.10.10.2</span> Cultivars</h4>
<p>You can also define PFTs whose members are <em>cultivars</em> instead of species. This is designed for analyses where you want to want to perform meta-analysis on within-species comparisons (e.g. cultivar evaluation in an agricultural model) but may be useful for other cases when you want to specify different priors for some member of a species. You cannot associate both species and cultivars with the same PFT, but the cultivars in a cultivar PFT may come from different species, potentially including all known cultivars from some of the species, if you wish to and have thought about how to interpret the results.</p>
<p>It is not yet possible to add a cultivar PFT through the BETYdb web interface. See <a href="https://github.com/PecanProject/pecan/pull/1826#issuecomment-360665864">this GithHub comment</a> for an example of how to define one manually in PostgreSQL.</p>
</div>
</div>
<div id="priors" class="section level3">
<h3><span class="header-section-number">2.10.11</span> PRIORS</h3>
<p>In addition to adding species, a PFT is defined in PEcAn by the list of variables associated with the PFT. PEcAn takes a fundamentally Bayesian approach to representing model parameters, so variables are not entered as fixed constants but as Prior probability distributions (see below). Once Priors are defined for each model variable then you Edit the PFT and use “View Related Priors” to search for and add Prior distributions for each model parameter. It is important to note that the priors are defined for the variable name and units as specified in the Variables table. <strong>If the variable name or units is different within the model it is the responsibility of write.configs.MODEL function to handle name and unit conversions</strong> (see Interface Modules below). This can also include common but nonlinear transformations, such as converting SLA to LMA or changing the reference temperature for respiration rates.</p>
<p>There are a wide variety of priors already defined in the PEcAn database that often range from very diffuse and generic to very informative priors for specific PFTs. If the current set of Priors for a variable are inadequate, or if a prior needs to be specified for a new variable, this can be done under Data &gt; Priors then “New Prior”. After using the pull-down menu to select the Variable you want to generate a prior for, the prior is defined by choosing a probability distribution and specifying values for that distribution’s parameters. These are labeled Parameter a &amp; b but their exact meaning depends upon the distribution chosen. For example, for the Normal distribution a and b are the mean and standard deviation while for the Uniform they are the minimum and maximum. All parameters are defined based on their standard parameterization in the R language. If the prior is based on observed data (independent of data in the PEcAn database) then you can also specify the prior sample size, <em>N</em>. The <em>Phylogeny</em> variable allows one to specify what taxonomic grouping the prior is defined for, at it is important to note that this is just for reference and doesn’t have to be specified in any standard way nor does it have to be monophyletic (i.e. it can be a functional grouping). Finally, the <em>Citation</em> is a required variable that provides a reference for how the prior was defined. That said, there are a number of unpublished Citations in current use that simply state the expert opinion of an individual.</p>
<p>Additional information on adding PFTs, Species, and Priors can be found under [[Choosing PFTs]]</p>
</div>
<div id="interface-modules" class="section level3">
<h3><span class="header-section-number">2.10.12</span> Interface Modules</h3>
<div id="setting-up-the-module-directory-required" class="section level4">
<h4><span class="header-section-number">2.10.12.1</span> Setting up the module directory (required)</h4>
<p>PEcAn assumes that the interface modules are available as an R package in the models directory named after the model in question. The simplest way to get started on that R package is to make a copy the <a href="https://github.com/PecanProject/pecan/tree/master/models/template"><em>template</em></a> directory in the pecan/models folder and re-name it to the name of your model. In the code, filenames, and examples below you will want to substitute the word <strong>MODEL</strong> for the name of your model (note: R is case-sensitive).</p>
<p>If you do not want to write the interface modules in R then it is fairly simple to set up the R functions describe below to just call the script you want to run using R’s <em>system</em> command. Scripts that are not R functions should be placed in the <em>inst</em> folder and R can look up the location of these files using the function <em>system.file</em> which takes as arguments the <em>local</em> path of the file within the package folder and the name of the package (typically PEcAn.MODEL). For example</p>
<pre><code>## Example met conversion wrapper function
met2model.MODEL &lt;- function(in.path, in.prefix, outfolder, start_date, end_date){
   myMetScript &lt;- system.file(&quot;inst/met2model.MODEL.sh&quot;, &quot;PEcAn.MODEL&quot;)
   system(paste(myMetScript, file.path(in.path, in.prefix), outfolder, start_date, end_date))
}</code></pre>
<p>would execute the following at the Linux command line</p>
<pre><code>inst/met2model.MODEL.sh in.path/in.prefix outfolder start_date end_date    `</code></pre>
</div>
<div id="description" class="section level4">
<h4><span class="header-section-number">2.10.12.2</span> DESCRIPTION</h4>
<p>Within the module folder open the <em>DESCRIPTION</em> file and change the package name to PEcAn.MODEL. Fill out other fields such as Title, Author, Maintainer, and Date.</p>
</div>
<div id="namespace" class="section level4">
<h4><span class="header-section-number">2.10.12.3</span> NAMESPACE</h4>
<p>Open the <em>NAMESPACE</em> file and change all instances of MODEL to the name of your model. If you are not going to implement one of the optional modules (described below) at this time then you will want to comment those out using the pound sign <code>#</code>. For a complete description of R NAMESPACE files <a href="http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Package-namespaces">see here</a>. If you create additional functions in your R package that you want to be used make sure you include them in the NAMESPACE as well (internal functions don’t need to be declared)</p>
</div>
<div id="building-the-package" class="section level4">
<h4><span class="header-section-number">2.10.12.4</span> Building the package</h4>
<p>Once the package is defined you will then need to add it to the PEcAn build scripts. From the root of the pecan directory, go into the <em>scripts</em> folder and open the file <em>build.sh</em>. Within the section of code that includes PACKAGES= add model/MODEL to the list of packages to compile. If, in writing your module, you add any other R packages to the system you will want to make sure those are listed in the DESCRIPTION and in the script <strong>scripts/install.dependencies.R</strong>. Next, from the root pecan directory open all/DESCRIPTION and add your model package to the <em>Suggests:</em> list.</p>
<p>At any point, if you want to check if PEcAn can build your MODEL package successfully, just go to the linux command prompt and run <strong>scripts/build.sh</strong>. You will need to do this before the system can use these packages.</p>
</div>
<div id="write.config.model-required" class="section level4">
<h4><span class="header-section-number">2.10.12.5</span> write.config.MODEL (required)</h4>
<p>This module performs two primary tasks. The first is to take the list of parameter values and model input files that it receives as inputs and write those out in whatever format(s) the MODEL reads (e.g. a settings file). The second is to write out a shell script, jobs.sh, which, when run, will start your model run and convert its output to the PEcAn standard (netCDF with metadata currently equivalent to the <a href="http://nacp.ornl.gov/MsTMIP_variables.shtml">MsTMIP standard</a>). Within the MODEL directory take a close look at inst/template.job and the example write.config.MODEL to see an example of how this is done. It is important that this script writes or moves outputs to the correct location so that PEcAn can find them. The example function also shows an example of writing a model-specific settings/config file, also by using a template.</p>
<p>You are encouraged to read the section above on defining PFTs before writing write.config.MODEL so that you understand what model parameters PEcAn will be passing you, how they will be named, and what units they will be in. Also note that the (optional) PEcAn input/driver processing scripts are called by separate workflows, so the paths to any required inputs (e.g. meteorology) will already be in the model-specific format by the time write.config.MODEL receives that info.</p>
</div>
<div id="output-conversions" class="section level4">
<h4><span class="header-section-number">2.10.12.6</span> Output Conversions</h4>
<p>The module model2netcdf.MODEL converts model output into the PEcAn standard (netCDF with metadata currently equivalent to the <a href="http://nacp.ornl.gov/MsTMIP_variables.shtml">MsTMIP standard</a>). This function was previously required, but now that the conversion is called within jobs.sh it may be easier for you to convert outputs using other approaches (or to just directly write outputs in the standard).</p>
<p>Whether you implement this function or convert outputs some other way, please note that PEcAn expects all outputs to be broken up into ANNUAL files with the year number as the file name (i.e. YEAR.nc), though these files may contain any number of scalars, vectors, matrices, or arrays of model outputs, such as time-series of each output variable at the model’s native timestep.</p>
<p>Note: PEcAn reads all variable names from the files themselves so it is possible to add additional variables that are not part of the MsTMIP standard. Similarly, there are no REQUIRED output variables, though <em>time</em> is highly encouraged. We are shortly going establish a canonical list of PEcAn variables so that if users add additional output variables they become part of the standard. <strong>We don’t want two different models to call the same output with two different names or different units</strong> as this would prohibit the multi-model syntheses and comparisons that PEcAn is designed to facilitate.</p>
</div>
<div id="met2model.model" class="section level4">
<h4><span class="header-section-number">2.10.12.7</span> met2model.MODEL</h4>
<p><code>met2model.MODEL(in.path, in.prefix, outfolder, start_date, end_date)</code></p>
<p>Converts meteorology input files from the PEcAn standard (netCDF, CF metadata) to the format required by the model. This file is optional if you want to load all of your met files into the Inputs table as described in <a href="../developers_guide/How-to-insert-new-Input-data.html">How to insert new Input data</a>, which is often the easiest way to get up and running quickly. However, this function is required if you want to benefit from PEcAn’s meteorology workflows and model run cloning. You’ll want to take a close look at [Adding-an-Input-Converter] to see the exact variable names and units that PEcAn will be providing. Also note that PEcAn splits all meteorology up into ANNUAL files, with the year number explicitly included in the file name, and thus what PEcAn will actually be providing is <strong>in.path</strong>, the input path to the folder where multiple met files may stored, and <strong>in.prefix</strong>, the start of the filename that precedes the year (i.e. an individual file will be named <code>&lt;in.prefix&gt;.YEAR.nc</code>). It is valid for in.prefix to be blank. The additional REQUIRED arguments to met2model.MODEL are <strong>outfolder</strong>, the output folder where PEcAn wants you to write your meteorology, and <strong>start_date</strong> and <strong>end_date</strong>, the time range the user has asked the meteorology to be processed for.</p>
</div>
<div id="commit-changes" class="section level4">
<h4><span class="header-section-number">2.10.12.8</span> Commit changes</h4>
<p>Once the MODEL modules are written, you should follow the <a href="Using-Git.md">Using-Git</a> instructions on how to commit your changes to your local git repository, verify that PEcAn compiles using <em>scripts/build.sh</em>, push these changes to Github, and submit a pull request so that your model module is added to the PEcAn system. It is important to note that while we encourage users to make their models open, adding the PEcAn interface module to the Github repository in no way requires that the model code itself be made public. It does, however, allow anyone who already has a copy of the model code to use PEcAn so we strongly encourage that any new model modules be committed to Github.</p>
</div>
</div>
</div>
<div id="NewInput" class="section level2">
<h2><span class="header-section-number">2.11</span> Adding input data</h2>
<div id="input-records-in-bety" class="section level3">
<h3><span class="header-section-number">2.11.1</span> Input records in BETY</h3>
<p>All model input data or data used for model calibration/validation must be registered in the BETY database.</p>
<p>Before creating a new Input record, you must make sure that the format type of your data is registered in the database. If you need to make a new format record, see <a href="tutorialsdemos-and-how-tos.html#NewFormat">Creating a new format record in BETY</a>.</p>
</div>
<div id="create-a-database-file-record-for-the-input-data" class="section level3">
<h3><span class="header-section-number">2.11.2</span> Create a database file record for the input data</h3>
<p>An input record contains all the metadata required to identify the data, however, this record does not include the location of the data file. Since the same data may be stored in multiple places, every file has its own dbfile record.</p>
<p>From your BETY interface:</p>
<ul>
<li>Create a DBFILES entry for the path to the file
<ul>
<li>From the menu click RUNS then FILES</li>
<li>Click “New File”</li>
<li>Select the machine your file is located at</li>
<li>Fill in the File Path where your file is located (aka folder or directory) NOT including the name of the file itself</li>
<li>Fill in the File Name with the name of the file itself. Note that some types of input records will refer to be ALL the files in a directory and thus File Name can be blank</li>
<li>Click Update</li>
</ul></li>
</ul>
</div>
<div id="creating-a-new-input-record-in-bety" class="section level3">
<h3><span class="header-section-number">2.11.3</span> Creating a new Input record in BETY</h3>
<p>From your BETY interface:</p>
<ul>
<li>Create an INPUT entry for your data
<ul>
<li>From the menu click RUNS then INPUTS</li>
<li>Click “New Input”</li>
<li>Select the SITE that this data is associated with the input data set</li>
<li>Other required fields are a unique name for the input, the start and end dates of the data set, and the format of the data. If the data is not in a currently known format you will need to create a NEW FORMAT and possibly a new input converter. Instructions on how to do add a converter can be found here <a href="tutorialsdemos-and-how-tos.html#InputConversions">Input conversion</a>. Instructions on how to add a format record can be found <a href="tutorialsdemos-and-how-tos.html#NewFormat">here</a></li>
<li>Parent ID is an optional variable to indicated that one dataset was derived from another.</li>
<li>Click “Create”</li>
</ul></li>
<li>Associate the DBFILE with the INPUT
<ul>
<li>In the RUNS -&gt; INPUTS table, search and find the input record you just created</li>
<li>Click on the EDIT icon</li>
<li>Select “View related Files”</li>
<li>In the Search window, search for the DBFILE you just created</li>
</ul></li>
<li>Once you have found the DBFILE, click on the “+” icon to add the file</li>
<li>Click on “Update” at the bottom when you are done.</li>
</ul>
</div>
<div id="InputConversions" class="section level3">
<h3><span class="header-section-number">2.11.4</span> Adding a new input converter</h3>
<p>Three Types of data conversions are discussed below: Meteorological data, Vegetation data, and Soil data. Each section provides instructions on how to convert data from their raw formats into a PEcAn standard format, whether it be from a database or if you have raw data in hand.</p>
<p>Also, see <a href="topical.html#pecan-standard-formats">PEcAn standard formats</a>.</p>
<div id="meterological-data" class="section level4">
<h4><span class="header-section-number">2.11.4.1</span> Meterological Data</h4>
<div id="adding-a-function-to-pecan-to-convert-a-met-data-source" class="section level5">
<h5><span class="header-section-number">2.11.4.1.1</span> Adding a function to PEcAn to convert a met data source</h5>
<p>In general, you will need to write a function to download the raw met data and one to convert it to the PEcAn standard.</p>
<p>Downloading raw data function are named <code>download.&lt;source&gt;.R</code>. These functions are stored within the PEcAn directory: <a href="https://github.com/PecanProject/pecan/tree/develop/modules/data.atmosphere/R"><code>/modules/data.atmosphere/R</code></a>.</p>
<p>Conversion function from raw to standard are named <code>met2CF.&lt;source&gt;.R</code>. These functions are stored within the PEcAn directory: <a href="https://github.com/PecanProject/pecan/tree/develop/modules/data.atmosphere/R"><code>/modules/data.atmosphere/R</code></a>.</p>
<p>Current Meteorological products that are coupled to PEcAn can be found in our <a href="topical.html#available-meteorological-drivers">Available Meteorological Drivers</a> page.</p>
<p>Note: Unless you are also adding a new model, you will not need to write a script to convert from PEcAn standard to PEcAn models. Those conversion scripts are written when a model is added and can be found within each model’s PEcAn directory.</p>
<p><em>Standards dimesion, names, nad units can be found here:</em> <a href="topical.html#input-standards">Input Standards</a></p>
</div>
<div id="adding-single-site-specific-meteorological-data" class="section level5">
<h5><span class="header-section-number">2.11.4.1.2</span> Adding Single-Site Specific Meteorological Data</h5>
<p>Perhaps you have meteorological data specific to one site, with a unique format that you would like to add to PEcAn. Your steps would be to:
1. write a script or function to convert your files into the netcdf PEcAn standard
2. insert that file as an input record for your site following these <a href="tutorialsdemos-and-how-tos.html#NewInput">instructions</a></p>
</div>
<div id="processing-met-data-outside-of-the-workflow-using-pecan-functions" class="section level5">
<h5><span class="header-section-number">2.11.4.1.3</span> Processing Met data outside of the workflow using PEcAn functions</h5>
<p>Perhaps you would like to obtain data from one of the sources coupled to PEcAn on its own. To do so you can run PEcAn functions on their own.</p>
<div id="example-1-processing-data-from-a-database" class="section level6">
<h6><span class="header-section-number">2.11.4.1.3.1</span> Example 1: Processing data from a database</h6>
<p>Download Amerifluxlbl from Niwot Ridge for the year 2004:</p>
<pre><code>raw.file &lt;-PEcAn.data.atmosphere::download.AmerifluxLBL(sitename = &quot;US-NR1&quot;, 
                                             outfolder = &quot;.&quot;, 
                                             start_date = &quot;2004-01-01&quot;, 
                                             end_date = &quot;2004-12-31&quot;)</code></pre>
<p>Using the information returned as the object <code>raw.file</code> you will then convert the raw files into a standard file.</p>
<p>Open a connection with BETY. You may need to change the host name depending on what machine you are hosting BETY. You can find the hostname listed in the machines table of BETY.</p>
<pre><code>
bety &lt;- dplyr::src_postgres(dbname   = &#39;bety&#39;, 
                            host =&#39;localhost&#39;, 
                            user     = &quot;bety&quot;, 
                            password = &quot;bety&quot;)
                            
con &lt;- bety$con</code></pre>
<p>Next you will set up the arguments for the function</p>
<pre><code>in.path &lt;- &#39;.&#39;
in.prefix &lt;- raw.file$dbfile.name
outfolder &lt;- &#39;.&#39;
format.id &lt;- 5000000002
format &lt;- PEcAn.DB::query.format.vars(format.id=format.id,bety = bety)
lon &lt;- -105.54
lat &lt;- 40.03
format$time_zone &lt;- &quot;America/Chicago&quot;</code></pre>
<p>Note: The format.id can be pulled from the BETY database if you know the format of the raw data.</p>
<p>Once these arguments are defined you can execute the <code>met2CF.csv</code> function</p>
<pre><code>PEcAn.data.atmosphere::met2CF.csv(in.path = in.path, 
                                  in.prefix =in.prefix,
                                  outfolder = &quot;.&quot;, 
                                  start_date =&quot;2004-01-01&quot;,
                                  end_date = &quot;2004-12-01&quot;,
                                  lat= lat,
                                  lon = lon,
                                  format = format) </code></pre>
</div>
<div id="example-2-processing-data-from-data-already-in-hand" class="section level6">
<h6><span class="header-section-number">2.11.4.1.3.2</span> Example 2: Processing data from data already in hand</h6>
<p>If you have Met data already in hand and you would like to convert into the PEcAn standard follow these instructions.</p>
<p>Update BETY with file record, format record and input record according to this page <a href="tutorialsdemos-and-how-tos.html#NewInput">How to Insert new Input Data</a></p>
<p>If your data is in a csv format you can use the <code>met2CF.csv</code>function to convert your data into a PEcAn standard file.</p>
<p>Open a connection with BETY. You may need to change the host name depending on what machine you are hosting BETY. You can find the hostname listed in the machines table of BETY.</p>
<pre><code>bety &lt;- dplyr::src_postgres(dbname   = &#39;bety&#39;, 
                            host =&#39;localhost&#39;, 
                            user     = &quot;bety&quot;, 
                            password = &quot;bety&quot;)
                            
con &lt;- bety$con</code></pre>
<p>Prepare the arguments you need to execute the met2CF.csv function</p>
<pre><code>in.path &lt;- &#39;path/where/the/raw/file/lives&#39;
in.prefix &lt;- &#39;prefix_of_the_raw_file&#39;
outfolder &lt;- &#39;path/to/where/you/want/to/output/thecsv/&#39;
format.id &lt;- formatid of the format your created
format &lt;- PEcAn.DB::query.format.vars(format.id=format.id,bety = bety)
lon &lt;- longitude of your site
lat &lt;- latitude of your site
format$time_zone &lt;- time zone of your site
start_date &lt;- Start date of your data in &quot;y-m-d&quot;
end_date &lt;- End date of your data in &quot;y-m-d&quot;</code></pre>
<p>Next you can execute the function:</p>
<pre><code>PEcAn.data.atmosphere::met2CF.csv(in.path = in.path, 
                                  in.prefix =in.prefix, 
                                  outfolder = &quot;.&quot;, 
                                  start_date = start_date,
                                  end_date = end_date,
                                  lat= lat,
                                  lon = lon,
                                  format = format)</code></pre>
</div>
</div>
</div>
<div id="vegetation-data" class="section level4">
<h4><span class="header-section-number">2.11.4.2</span> Vegetation Data</h4>
<p>Vegetation data will be required to parameterize your model. In these examples we will go over how to produce a standard initial condition file.</p>
<p>The main function to process cohort data is the <code>ic.process.R</code> function. As of now however, if you require pool data you will run a separate function, <code>pool_ic_list2netcdf.R</code>.</p>
<div id="example-1-processing-veg-data-from-data-in-hand." class="section level6">
<h6><span class="header-section-number">2.11.4.2.0.1</span> Example 1: Processing Veg data from data in hand.</h6>
<p>In the following example we will process vegetation data that you have in hand using PEcAn.</p>
<p>First, you’ll need to create a input record in BETY that will have a file record and format record reflecting the location and format of your file. Instructions can be found in our <a href="tutorialsdemos-and-how-tos.html#NewInput">How to Insert new Input Data</a> page.</p>
<p>Once you have created an input record you must take note of the input id of your record. An easy way to take note of this is in the URL of the BETY webpage that shows your input record. In this example we use an input record with the id <code>1000013064</code> which can be found at this url: <a href="https://psql-pecan.bu.edu/bety/inputs/1000013064#" class="uri">https://psql-pecan.bu.edu/bety/inputs/1000013064#</a> . Note that this is the Boston University BETY database. If you are on a different machine, your url will be different.</p>
<p>With the input id in hand you can now edit a pecan XML so that the PEcAn function <code>ic.process</code> will know where to look in order to process your data. The <code>inputs</code> section of your pecan XML will look like this. As of now ic.process is set up to work with the ED2 model so we will use ED2 settings and then grab the intermediary Rds data file that is created as the standard PEcAn file. For your Inputs section you will need to input your input id wherever you see the <code>useic</code> flag.</p>
<pre><code>&lt;inputs&gt;
      &lt;css&gt;
        &lt;source&gt;FFT&lt;/source&gt;
        &lt;output&gt;css&lt;/output&gt;
        &lt;username&gt;pecan&lt;/username&gt;
        &lt;id&gt;1000013064&lt;/id&gt;
        &lt;useic&gt;TRUE&lt;/useic&gt;
        &lt;metadata&gt;
          &lt;trk&gt;1&lt;/trk&gt;
          &lt;age&gt;70&lt;/age&gt;
          &lt;area&gt;400&lt;/area&gt;
        &lt;/metadata&gt;
      &lt;/css&gt;
      &lt;pss&gt;
        &lt;source&gt;FFT&lt;/source&gt;
        &lt;output&gt;pss&lt;/output&gt;
        &lt;username&gt;pecan&lt;/username&gt;
        &lt;id&gt;1000013064&lt;/id&gt;
        &lt;useic&gt;TRUE&lt;/useic&gt;
      &lt;/pss&gt;
      &lt;site&gt;
        &lt;source&gt;FFT&lt;/source&gt;
        &lt;output&gt;site&lt;/output&gt;
        &lt;username&gt;pecan&lt;/username&gt;
        &lt;id&gt;1000013064&lt;/id&gt;
        &lt;useic&gt;TRUE&lt;/useic&gt;
      &lt;/site&gt;
      &lt;met&gt;
        &lt;source&gt;CRUNCEP&lt;/source&gt;
        &lt;output&gt;ED2&lt;/output&gt;
      &lt;/met&gt;
      &lt;lu&gt;
        &lt;id&gt;294&lt;/id&gt;
      &lt;/lu&gt;
      &lt;soil&gt;
        &lt;id&gt;297&lt;/id&gt;
      &lt;/soil&gt;
      &lt;thsum&gt;
        &lt;id&gt;295&lt;/id&gt;
      &lt;/thsum&gt;
      &lt;veg&gt;
        &lt;id&gt;296&lt;/id&gt;
      &lt;/veg&gt;
    &lt;/inputs&gt;</code></pre>
<p>This IC workflow also supports generating ensembles of initial conditions from posterior estimates of DBH. To do this the tags below can be inserted to the pecan.xml:</p>
<pre><code>       &lt;css&gt;
        &lt;source&gt;PalEON&lt;/source&gt;
        &lt;output&gt;css&lt;/output&gt;
        &lt;id&gt;1000015682&lt;/id&gt;
        &lt;useic&gt;TRUE&lt;/useic&gt;
        &lt;ensemble&gt;20&lt;/ensemble&gt;
        &lt;metadata&gt;
          &lt;area&gt;1256.637&lt;/area&gt;
          &lt;n.patch&gt;3&lt;/n.patch&gt;
        &lt;/metadata&gt;
      &lt;/css&gt;</code></pre>
<p>Here the <code>id</code> should point to a file that has MCMC samples to generate the ensemble from. The number between the <code>&lt;ensemble&gt;</code> tag defines the number of ensembles requested. The workflow will populate the settings list <code>run$inputs</code> tag with ensemble member information. E.g.:</p>
<pre><code>  &lt;inputs&gt;
   &lt;css&gt;
    &lt;path1&gt;...&lt;/path1&gt;
    &lt;path2&gt;...&lt;/path2&gt;
    &lt;path3&gt;...&lt;/path3&gt;
    ...
    &lt;pathN&gt;...&lt;/pathN&gt;
   &lt;/css&gt;
   &lt;pss&gt;
    &lt;path&gt;
     &lt;path1&gt;...&lt;/path1&gt;
     &lt;path2&gt;...&lt;/path2&gt;
     &lt;path3&gt;...&lt;/path3&gt;
      ...
     &lt;pathN&gt;...&lt;/pathN&gt;
    &lt;/path&gt;
   &lt;/pss&gt;
   &lt;site&gt;
    &lt;path&gt;
     &lt;path1&gt;...&lt;/path1&gt;
     &lt;path2&gt;...&lt;/path2&gt;
     &lt;path3&gt;...&lt;/path3&gt;
      ...
     &lt;pathN&gt;...&lt;/pathN&gt;
    &lt;/path&gt;
   &lt;/site&gt;
   &lt;met&gt;...&lt;/met&gt;
   &lt;lu&gt;...&lt;/lu&gt;
   &lt;soil&gt;...&lt;/soil&gt;
   &lt;thsum&gt;...&lt;/thsum&gt;
   &lt;veg&gt;...&lt;/veg&gt;
  &lt;/inputs&gt;</code></pre>
<p>Once you edit your PEcAn.xml you can than create a settings object using PEcAn functions. Your <code>pecan.xml</code> must be in your working directory.</p>
<pre><code>settings &lt;- PEcAn.settings::read.settings(&quot;pecan.xml&quot;)
settings &lt;- PEcAn.settings::prepare.settings(settings, force=FALSE)</code></pre>
<p>You can then execute the <code>ic.process</code> function to convert data into a standard Rds file:</p>
<pre><code>input &lt;- settings$run$inputs
dir &lt;- &quot;.&quot;
ic.process(settings, input, dir, overwrite = FALSE)</code></pre>
<p>Note that the argument <code>dir</code> is set to the current directory. You will find the final ED2 file there. More importantly though you will find the <code>.Rds</code> file within the same directory.</p>
</div>
<div id="example-3-pool-initial-condition-files" class="section level6">
<h6><span class="header-section-number">2.11.4.2.0.2</span> Example 3 Pool Initial Condition files</h6>
<p>If you have pool vegetation data, you’ll need the <a href="https://github.com/PecanProject/pecan/blob/develop/modules/data.land/R/pool_ic_list2netcdf.R"><code>pool_ic_list2netcdf.R</code></a> function to convert the pool data into PEcAn
standard.</p>
<p>The function stands alone and requires that you provide a named list of netcdf dimensions and values, and a named list of variables and values. Names and units need to match the standard_vars.csv table found <a href="https://github.com/PecanProject/pecan/blob/develop/base/utils/data/standard_vars.csv">here</a>.</p>
<pre><code>#Create a list object with necessary dimensions for your site
input&lt;-list()
dims&lt;- list(lat=-115,lon=45, time= 1)
variables&lt;- list(SoilResp=8,TotLivBiom=295)
input$dims &lt;- dims
input$vals &lt;- variables</code></pre>
<p>Once this is done, set <code>outdir</code> to where you’d like the file to write out to and a siteid. Siteid in this can be used as an file name identifier. Once part of the automated workflow siteid will reflect the site id within the BET db.</p>
<pre><code>outdir  &lt;- &quot;.&quot;
siteid &lt;- 772
pool_ic_list2netcdf(input = input, outdir = outdir, siteid = siteid)</code></pre>
<p>You should now have a netcdf file with initial conditions.</p>
</div>
</div>
<div id="soil-data" class="section level4">
<h4><span class="header-section-number">2.11.4.3</span> Soil Data</h4>
<div id="example-1-converting-data-in-hand" class="section level6">
<h6><span class="header-section-number">2.11.4.3.0.1</span> Example 1: Converting Data in hand</h6>
<p>Local data that has the correct names and units can easily be written out in PEcAn standard using the function soil2netcdf.</p>
<pre><code>soil.data &lt;- list(volume_fraction_of_sand_in_soil = c(0.3,0.4,0.5),
                  volume_fraction_of_clay_in_soil = c(0.3,0.3,0.3),
                  soil_depth = c(0.2,0.5,1.0))
                         
soil2netcdf(soil.data,&quot;soil.nc&quot;)</code></pre>
<p>At the moment this file would need to be inserted into Inputs manually. By default, this function also calls soil_params, which will estimate a number of hydraulic and thermal parameters from texture. Be aware that at the moment not all model couplers are yet set up to read this file and/or convert it to model-specific formats.</p>
</div>
<div id="example-2-converting-paleon-data" class="section level6">
<h6><span class="header-section-number">2.11.4.3.0.2</span> Example 2: Converting PalEON data</h6>
<p>In addition to location-specific soil data, PEcAn can extract soil texture information from the PalEON regional soil product, which itself is a subset of the MsTMIP Unified North American Soil Map. If this product is installed on your machine, the appropriate step in the do_conversions workflow is enabled by adding the following tag under <code>&lt;inputs&gt;</code> in your pecan.xml</p>
<pre class="sourceCode xml"><code class="sourceCode xml">   <span class="kw">&lt;soil&gt;</span>
     <span class="kw">&lt;id&gt;</span>1000012896<span class="kw">&lt;/id&gt;</span>
   <span class="kw">&lt;/soil&gt;</span></code></pre>
<p>In the future we aim to extend this extraction to a wider range of soil products.</p>
</div>
<div id="example-3-extracting-soil-properties-from-gssurgo-database" class="section level6">
<h6><span class="header-section-number">2.11.4.3.0.3</span> Example 3: Extracting soil properties from gSSURGO database</h6>
<p>In addition to location-specific soil data, PEcAn can extract soil texture information from the gSSURGO data product. This product needs no installation and it extract soil proeprties for the lower 48 states in U.S. In order to let the pecan know that you’re planning to use gSSURGO, you can the following XML tag under input in your pecan xml file.</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;inputs&gt;</span>
   <span class="kw">&lt;soil&gt;</span>
     <span class="kw">&lt;source&gt;</span>gSSURGO<span class="kw">&lt;/source&gt;</span>
   <span class="kw">&lt;/soil&gt;</span>
<span class="kw">&lt;/inputs&gt;</span></code></pre>
</div>
</div>
</div>
<div id="adding-data-web" class="section level3">
<h3><span class="header-section-number">2.11.5</span> Pecan Data Ingest via Web Interface</h3>
<p>This tutorial explains the process of ingesting data into PEcAn via our Data-Ingest Application. In order to ingest data, the users must first select data that they wish to upload. Then, they enter metadata to help PEcAn parse and load the data into the main PEcAn workflow.</p>
<div id="loading-data" class="section level4">
<h4><span class="header-section-number">2.11.5.1</span> Loading Data</h4>
</div>
<div id="selecting-ingest-method" class="section level4">
<h4><span class="header-section-number">2.11.5.2</span> Selecting Ingest Method</h4>
<p>The Data-Ingest application is capable of loading data from the DataONE data federation and from the user’s local machine. The first step in the workflow is therefore to select an upload method. The application defaults to uploading from DataONE. To upload data from a local device, simply select the radio button titled <code>Local Files</code>.</p>
</div>
<div id="dataone-upload-example" class="section level4">
<h4><span class="header-section-number">2.11.5.3</span> DataONE Upload Example</h4>
<p><br></p>
<p><img src="04_advanced_user_guide/02_adding_to_pecan/01_case_studies/images/data-ingest/D1Ingest-1.gif" width="50%" height="50%" style="display: block; margin: auto;" />
<br>
The DataONE download feature allows the user to download data at a given doi or DataONE specific package id. To do so, enter the doi or identifier in the <code>Import From DataONE</code> field and select <code>download</code>. The download process may take a couple of minutes to run depending on the number of files in the dataONE package. This may be a convenient option if the user does not wish to download files directly to their local machine. Once the files have been successfully downloaded from DataONE, they are displayed in a table. Before proceeding to the next step, the user can select a file to ingest by clicking on the corresponding row in the data table.
<br></p>
</div>
<div id="local-upload-example" class="section level4">
<h4><span class="header-section-number">2.11.5.4</span> Local Upload Example</h4>
<p><br>
To upload local files, the user should first select the <code>Local Files</code> button. From there, the user can upload files from their local machines by selecting <code>Browse</code> or by dragging and dropping files into the text box. The files will begin uploading automatically. From there, the user should select a file to ingest and then select the <code>Next Step</code> button.
<br>
After this step, the workflow is identical for both methods. However, please note that if it becomes necessary to switch from loading data via <code>DataONE</code> to uploading local files after the first step, please restart the application.
<br></p>
<p><img src="04_advanced_user_guide/02_adding_to_pecan/01_case_studies/images/data-ingest/Local_loader_sm.gif" width="50%" height="50%" style="display: block; margin: auto;" />
<br>
<img src="04_advanced_user_guide/02_adding_to_pecan/01_case_studies/images/data-ingest/local_browse.gif" width="50%" height="50%" style="display: block; margin: auto;" />
#### 2. Creating an Input Record
Creating an input record requires some basic metadata about the file that is being ingested. Each entry field is briefly explained below.
<br></p>
<ul>
<li>Site: To link the selected file with a site, the user can scroll or type to search all the sites in PEcAn. See Example:
<br>
<img src="04_advanced_user_guide/02_adding_to_pecan/01_case_studies/images/data-ingest/Selectize_Input_sm.gif" width="50%" height="50%" style="display: block; margin: auto;" />
<br></li>
<li><p>Parent: To link the selected file with another dataset, type to search existing datasets in the <code>Parent</code> field.</p></li>
<li><p>Name: this field should be autofilled by selecting a file in step 1.</p></li>
<li><p>Format: If the selected file has an existing format name, the user can search and select in the <code>Format</code> field. If the selected file’s format is not already in pecan, the user can create a new format by selecting <code>Create New Format</code>. Once this new format is created, it will automatically populate the <code>Format</code> box and the <code>Current Mimetype</code> box (See Section 3).</p></li>
<li><p>Mimetype: If the format already exists, select an existing mimetype.</p></li>
<li><p>Start and End Date and Time: Inputs can be entered manually or by using the user interface. See example</p></li>
</ul>
<p><br>
<img src="04_advanced_user_guide/02_adding_to_pecan/01_case_studies/images/data-ingest/DateTime.gif" width="50%" height="50%" style="display: block; margin: auto;" /></p>
<ul>
<li>Notes: Describe the data that is being uploaded. Please include any citations or references.</li>
</ul>
</div>
<div id="creating-a-format-record" class="section level4">
<h4><span class="header-section-number">2.11.5.5</span> 3. Creating a format record</h4>
<p>If it is necessary to add a new format to PEcAn, the user should fill out the form attached to the <code>Create New Format</code> button. The inputs to this form are described below:</p>
<ul>
<li><p>Mimetype: type to search existing mimetypes. If the mimetype is not in that list, please click on the link <code>Create New Mimetype</code> and create a new mimetype via the BETY website.</p></li>
<li><p>New Format Name: Add the name of the new format. Please exclude spaces from the name. Instead please use underscores &quot;_&quot;.</p></li>
<li><p>Header: If there is space before the first line of data in the dataset, please select <code>Yes</code></p></li>
<li><p>Skip: The number of lines in the header that should be skipped before the data.</p></li>
<li><p>Please enter notes that describe the format.</p></li>
</ul>
<p>Example:
<br>
<img src="04_advanced_user_guide/02_adding_to_pecan/01_case_studies/images/data-ingest/new_format_record.gif" width="50%" height="50%" style="display: block; margin: auto;" />
#### 4. Formats_Variables Record
The final step in the ingest process is to register a formats-variables record. This record links pecan variables with variables from the selected data.</p>
<ul>
<li><p>Variable: PEcAn variable that is equivalent to variable in selected file.</p></li>
<li><p>Name: The variable name in the imported data need only be specified if it differs from the BETY variable name.</p></li>
<li><p>Unit: Should be in a format parseable by the udunits library and need only be secified if the units of the data in the file differ from the BETY standard.</p></li>
<li><p>Storage Type: Storage type need only be specified if the variable is stored in a format other than would be expected (e.g. if numeric values are stored as quoted character strings). Additionally, storage_type stores POSIX codes that are used to store any time variables (e.g. a column with a 4-digit year would be <code>%Y</code>).</p></li>
<li><p>Column Number: Vector of integers that list the column numbers associated with variables in a dataset. Required for text files that lack headers.
<br>
<img src="04_advanced_user_guide/02_adding_to_pecan/01_case_studies/images/data-ingest/D1Ingest-9_sm.gif" width="50%" height="50%" style="display: block; margin: auto;" /></p></li>
</ul>
<p>Finally, the path to the ingest data is displayed in the <code>Select Files</code> box.</p>
</div>
</div>
<div id="NewFormat" class="section level3">
<h3><span class="header-section-number">2.11.6</span> Creating a new format</h3>
<div id="formats-in-bety" class="section level4">
<h4><span class="header-section-number">2.11.6.1</span> Formats in BETY</h4>
<p>The PEcAn database keeps track of all the input files passed to models, as well as any data used in model validation or data assimilation. Before we start to register these files with PEcAn we need to define the format these files will be in.</p>
<p>The main goal is to take all the meta-data we have about a data file and create a record of it that pecan can use as a guide when parsing the data file.</p>
<p>This information is stored in a Format record in the bety database. Make sure to read through the current Formats before deciding to make a new one.</p>
</div>
<div id="creating-a-new-format-in-bety" class="section level4">
<h4><span class="header-section-number">2.11.6.2</span> Creating a new format in BETY</h4>
<p>If the Format you are looking for is not available, you will need to create a new record. Before entering information into the database, you need to be able to answer the following questions about your data:</p>
<ul>
<li>What is the file MIME type?
<ul>
<li>We have a suit of functions for loading in data in open formats such as CSV, txt, netCDF, etc.</li>
<li>PEcAn has partnered with the <a href="http://browndog.ncsa.illinois.edu/">NCSA BrownDog project</a> to create a service that can read and convert as many data formats as possible. If your file type is less common or a proprietary type, you can use the <a href="http://dap.ncsa.illinois.edu/">BrownDog DAP</a> to convert it to a format that can be used with PEcAn.</li>
<li>If BrownDog cannot convert your data, you will need to contact us about writing a data specific load function.</li>
</ul></li>
<li>What variables does the file contain?
<ul>
<li>What are the variables named?</li>
<li>What are the variable units?</li>
<li>How do the variable names and units in the data map to PEcAn variables in the BETY database? See <a href="###%20Name%20and%20Unit">below</a> for an example. It is most likely that you will NOT need to add variables to BETY. However, identifying the appropriate variables matches in the database may require some work. We are always available to help answer your questions.</li>
</ul></li>
<li>Is there a timestamp on the data?
<ul>
<li>What are the units of time?</li>
</ul></li>
</ul>
<p>Here is an example using a fake dataset:</p>
<div class="figure">
<img src="04_advanced_user_guide/images/example_data.png" alt="example_data" />
<p class="caption">example_data</p>
</div>
<p>This data started out as an excel document, but was saved as a CSV file.</p>
<p>To create a Formats record for this data, in the web interface of BETY, select Runs &gt; Formats and click <em>New Format</em>.</p>
<p>You will need to fill out the following fields:</p>
<ul>
<li>MIME type: File type (you can search for other formats in the text field)</li>
<li>Name: The name of your format (this can be whatever you want)</li>
<li>Header: Boolean that denotes whether or not your data contains a header as the first line of the data. (1 = TRUE, 0 = FALSE)</li>
<li>Skip: The number of lines above the data that should be skipped. For example, metadata that should not be included when reading in the data or blank spaces.</li>
<li>Notes: Any additional information about the data such as sources and citations.</li>
</ul>
<p>Here is the Formats record for the example data:</p>
<p><img src="04_advanced_user_guide/images/format_record_1.png" alt="format_record_1" />
When you have finished this section, hit Create. The final record will be displayed on the screen.</p>
</div>
<div id="formats---variables" class="section level4">
<h4><span class="header-section-number">2.11.6.3</span> Formats -&gt; Variables</h4>
<p>After a Format entry has been created, you are encouraged to edit the entry to add relationships between the file’s variables and the Variables table in PEcAn. Not only do these relationships provide meta-data describing the file format, but they also allow PEcAn to search and (for some MIME types) read files.</p>
<p>To enter this data, select Edit Record and on the edit screen select View Related Variable.</p>
<p>Here is the record for the example data after adding related variables:</p>
<div class="figure">
<img src="04_advanced_user_guide/images/format_record_2.png" alt="format_record_2" />
<p class="caption">format_record_2</p>
</div>
<div id="name-and-unit" class="section level5">
<h5><span class="header-section-number">2.11.6.3.1</span> Name and Unit</h5>
<p>For each variable in the file you will want at a minimum to specify the NAME of the variable within your file and match that to the equivalent Variable in the pulldown.</p>
<p>Make sure to search for your variables under Data &gt; Variables before suggesting that we create a new variable record. This may not always be a straightforward process.</p>
<p>For example bety contains a record for Net Primary Productivity:</p>
<div class="figure">
<img src="04_advanced_user_guide/images/var_record.png" alt="var_record" />
<p class="caption">var_record</p>
</div>
<p>This record does not have the same variable name or the same units as NPP in the example data.
You may have to do some reading to confirm that they are the same variable.
In this case
- Both the data and the record are for Net Primary Productivity (the notes section provides additional resources for interpreting the variable.)
- The units of the data can be converted to those of the vairiable record (this can be checked by running <code>udunits2::ud.are.convertible(&quot;g C m-2 yr-1&quot;, &quot;Mg C ha-1 yr-1&quot;)</code>)</p>
<p>Differences between the data and the variable record can be accounted for in the data Formats record.</p>
<ul>
<li>Under Variable, select the variable as it is recorded in bety.</li>
<li>Under Name, write the name the variable has in your data file.</li>
<li>Under Unit, write the units the variable has in your data file.</li>
</ul>
<p>NOTE: All units must be written in a udunits compliant format. To check that your units can be read by udunits, in R, load the udunits2 package and run <code>udunits2::is.parseable(&quot;g C m-2 yr-1&quot;)</code></p>
<p><strong>If the name or the units are the same</strong>, you can leave the Name and Unit fields blank. This is can be seen with the variable LAI.</p>
</div>
<div id="storage-type" class="section level5">
<h5><span class="header-section-number">2.11.6.3.2</span> Storage Type</h5>
<p><em>Storage Type</em> only needs to be specified if the variable is stored in a format other than what would be expected (e.g. if numeric values are stored as quoted character strings).</p>
<p>One such example is <em>time variables</em>.</p>
<p>PEcAn converts all dates into POSIX format using R functions such as <code>strptime</code>. These functions require that the user specify the format in which the date is written.</p>
<p>The default is <code>&quot;%Y-%m-%d %H:%M:%S&quot;</code> which would look like <code>&quot;2017-01-01 00:00:00&quot;</code></p>
<p>A list of date formats can be found in the <a href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/strptime.html">R documentation for the function <code>strptime</code></a></p>
<p>Below are some commonly used codes:</p>
<table>
<colgroup>
<col width="9%" />
<col width="90%" />
</colgroup>
<thead>
<tr class="header">
<th>%d</th>
<th>Day of the month as decimal number (01–31).</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>%D</td>
<td>Date format such as %m/%d/%y.</td>
</tr>
<tr class="even">
<td>%H</td>
<td>Hours as decimal number (00–23).</td>
</tr>
<tr class="odd">
<td>%m</td>
<td>Month as decimal number (01–12).</td>
</tr>
<tr class="even">
<td>%M</td>
<td>Minute as decimal number (00–59).</td>
</tr>
<tr class="odd">
<td>%S</td>
<td>Second as integer (00–61), allowing for up to two leap-seconds (but POSIX-compliant implementations will ignore leap seconds).</td>
</tr>
<tr class="even">
<td>%T</td>
<td>Equivalent to %H:%M:%S.</td>
</tr>
<tr class="odd">
<td>%y</td>
<td>Year without century (00–99). On input, values 00 to 68 are prefixed by 20 and 69 to 99 by 19 – that is the behaviour specified by the 2004 and 2008 POSIX standards, but they do also say ‘it is expected that in a future version the default century inferred from a 2-digit year will change’.</td>
</tr>
<tr class="even">
<td>%Y</td>
<td>Year with century.</td>
</tr>
</tbody>
</table>
</div>
<div id="column-number" class="section level5">
<h5><span class="header-section-number">2.11.6.3.3</span> Column Number</h5>
<p>If your data is in text format with variables in a standard order then you can specify the Column Number for the variable. This is required for text files that lack headers.</p>
</div>
</div>
<div id="retrieving-format-information" class="section level4">
<h4><span class="header-section-number">2.11.6.4</span> Retrieving Format Information</h4>
<p>To acquire Format information from a Format record, use the R function <code>query.format.vars</code></p>
<div id="inputs-1" class="section level5">
<h5><span class="header-section-number">2.11.6.4.1</span> Inputs</h5>
<ul>
<li><code>bety</code>: connection to BETY</li>
<li><code>input.id=NA</code> and/or <code>format.id=NA</code>: Input or Format record ID from BETY
<ul>
<li>At least one must be specified. Defaults to <code>format.id</code> if both provided.</li>
</ul></li>
<li><code>var.ids=NA</code>: optional vector of variable IDs. If provided, limits results to these variables.</li>
</ul>
</div>
<div id="output" class="section level5">
<h5><span class="header-section-number">2.11.6.4.2</span> Output</h5>
<ul>
<li>R list object containing many things. Fill this in.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="NewBenchmark" class="section level2">
<h2><span class="header-section-number">2.12</span> Creating a new benchmark reference run</h2>
<p>The purpose of the reference run record in BETY is to store all the settings from a run that are necessary in exactly recreating it.</p>
<p>The pecan.xml file is the home of absolutely all the settings for a particular run in pecan. However, much of the information in the pecan.xml file is server and user specific and more importantly, the pecan.xml files are stored on individual servers and may not be available to the public.</p>
<p>When a run that is performed using pecan is registered as a reference run, the settings that were used to make that run are made available to all users through the database.</p>
<p>All completed runs are not automatically registered as reference runs. To register a run, navigate to the benchmarking section of the workflow visualizations Shiny app.</p>
</div>
<div id="editing-records" class="section level2">
<h2><span class="header-section-number">2.13</span> Editing records</h2>
<ul>
<li>Models</li>
<li>Species</li>
<li>PFTs</li>
<li>Traits</li>
<li>Inputs</li>
<li>DB files</li>
<li>Variables</li>
<li>Formats</li>
<li>(Link each section to relevant Bety tables)</li>
</ul>

</div>
<div id="submitting-workflow-from-command-line" class="section level2">
<h2><span class="header-section-number">2.14</span> Submitting Workflow from Command Line</h2>
<p>This is how you can submit a workflow from the command line through the pecan web interface. This will use curl to submit all the requireed parameters to the web interface and trigger a run.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># the host where the model should run</span>
<span class="co"># never use remote sites since you will need to pass your username/password and that WILL be stored</span>
<span class="va">hostname=</span>pecan.vm
<span class="co"># the site id where to run the model (NIWOT in this case)</span>
<span class="va">siteid=</span>772
<span class="co"># start date and end date, / need to be replaced with %2F or use - (NOT TESTED)</span>
<span class="va">start=</span>2004-01-01
<span class="va">end=</span>2004-12-31

<span class="co"># if of model you want to run, rest of section parameters depend on the model selected (SIPNET 136)</span>
<span class="va">modelid=</span>5000000002
<span class="co"># PFT selected (we should just use a number here)</span>
<span class="co"># </span><span class="al">NOTE</span><span class="co">: the square brackets are needed and will need be escaped with a \ if you call this from command line</span>
<span class="ex">pft</span>[]=temperate.coniferous
<span class="co"># initial pool condition (-1 means nothing is selected)</span>
<span class="va">input_poolinitcond=</span>-1
<span class="co"># met data</span>
<span class="va">input_met=</span>99000000006

<span class="co"># variables to collect</span>
<span class="va">variables=</span>NPP,GPP
<span class="co"># ensemble size</span>
<span class="va">runs=</span>10
<span class="co"># use sensitivity analysis</span>
<span class="va">sensitivity=</span>-1,1

<span class="co"># redirect to the edit pecan.xml file</span>
<span class="va">pecan_edit=</span>on
<span class="co"># redirect to edit the model configuration files</span>
<span class="va">model_edit=</span>on
<span class="co"># use browndog</span>
<span class="va">browndog=</span>on</code></pre>
<p>For example the following will run the above workflow. Using -v in curl will show verbose output (needed) and the grep will make sure it only shows the redirect. This will show the actual workflowid:</p>
<pre><code>curl -s -v &#39;http://localhost:6480/pecan/04-runpecan.php?hostname=pecan.vm&amp;siteid=772&amp;start=2004-01-01&amp;end=2004-12-31&amp;modelid=5000000002&amp;pft\[\]=temperate.coniferous&amp;input_poolinitcond=-1&amp;input_met=99000000006&#39; 2&gt;&amp;1 | grep &#39;Location:&#39;
&lt; Location: 05-running.php?workflowid=99000000004</code></pre>
<p>In this case you can use the browser to see progress, or use the following to see the status:</p>
<pre><code>curl -s &#39;http://localhost:6480/pecan/dataset.php?workflowid=99000000004&amp;type=file&amp;name=STATUS&#39;
TRAIT   2017-12-13 08:56:56 2017-12-13 08:56:57 DONE
META    2017-12-13 08:56:57 2017-12-13 08:57:13 DONE
CONFIG  2017-12-13 08:57:13 2017-12-13 08:57:14 DONE
MODEL   2017-12-13 08:57:14 2017-12-13 08:57:15 DONE
OUTPUT  2017-12-13 08:57:15 2017-12-13 08:57:15 DONE
ENSEMBLE    2017-12-13 08:57:15 2017-12-13 08:57:16 DONE
FINISHED    2017-12-13 08:57:16 2017-12-13 08:57:16 DONE</code></pre>
<p>Or to show the output log:</p>
<pre><code>curl -s &#39;http://localhost:6480/pecan/dataset.php?workflowid=99000000004&amp;type=file&amp;name=workflow.Rout&#39;

R version 3.4.3 (2017-11-30) -- &quot;Kite-Eating Tree&quot;
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type &#39;license()&#39; or &#39;licence()&#39; for distribution details.

R is a collaborative project with many contributors.
....</code></pre>

</div>
<div id="developer-guide" class="section level2">
<h2><span class="header-section-number">2.15</span> Developer user guide</h2>

<div id="aws-setup" class="section level3">
<h3><span class="header-section-number">2.15.1</span> AWS Setup</h3>
<p>***********Mirror of earlier section in installation section?*********************</p>
</div>
<div id="porting-vm-to-aws" class="section level3">
<h3><span class="header-section-number">2.15.2</span> Porting VM to AWS</h3>
<p>The following are Mike’s rough notes from a first attempt to port the PEcAn VM to the AWS. This was done on a Mac</p>
<p>These notes are based on following the instructions <a href="http://www.rittmanmead.com/2014/09/obiee-sampleapp-in-the-cloud-importing-virtualbox-machines-to-aws-ec2/">here</a></p>
<div id="convert-pecan-vm" class="section level4">
<h4><span class="header-section-number">2.15.2.1</span> Convert PEcAn VM</h4>
<p>AWS allows upload of files as VMDK but the default PEcAn VM is in OVA format</p>
<ol style="list-style-type: decimal">
<li><p>If you haven’t done so already, download the <a href="http://isda.ncsa.illinois.edu/download/index.php?project=PEcAn&amp;sort=category">PEcAn VM</a></p></li>
<li><p>Split the OVA file into OVF and VMDK files</p></li>
</ol>
<pre><code>tar xf &lt;ovafile&gt;</code></pre>
</div>
<div id="set-up-an-account-on-aws" class="section level4">
<h4><span class="header-section-number">2.15.2.2</span> Set up an account on <a href="http://aws.amazon.com/">AWS</a></h4>
<p>After you have an account you need to set up a user and save your <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/ManagingCredentials.html">access key and secret key</a></p>
<p>In my case I created a user named ‘carya’</p>
<p>Note: the key that ended up working had to be made at <a href="https://console.aws.amazon.com/iam/home#security_credential" class="uri">https://console.aws.amazon.com/iam/home#security_credential</a>, not the link above.</p>
</div>
<div id="install-ec2-command-line-tools" class="section level4">
<h4><span class="header-section-number">2.15.2.3</span> Install <a href="http://docs.aws.amazon.com/AWSEC2/latest/CommandLineReference/set-up-ec2-cli-linux.html">EC2 command line tools</a></h4>
<pre><code>wget http://s3.amazonaws.com/ec2-downloads/ec2-api-tools.zip

sudo mkdir /usr/local/ec2

sudo unzip ec2-api-tools.zip -d /usr/local/ec2</code></pre>
<p>If need be, download and install <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">JDK</a></p>
<pre><code>export JAVA_HOME=$(/usr/libexec/java_home)

export EC2_HOME=/usr/local/ec2/ec2-api-tools-&lt;version&gt;

export PATH=$PATH:$EC2_HOME/bin</code></pre>
<p>Then set your user credentials as environment variables:</p>
<p><code>export AWS_ACCESS_KEY=xxxxxxxxxxxxxx</code></p>
<p><code>export AWS_SECRET_KEY=xxxxxxxxxxxxxxxxxxxxxx</code></p>
<p>Note: you may want to add all the variables set in the above EXPORT commands above into your .bashrc or equivalent.</p>
</div>
<div id="create-an-aws-s3-bucket-to-upload-vm-to" class="section level4">
<h4><span class="header-section-number">2.15.2.4</span> Create an AWS S3 ‘bucket’ to upload VM to</h4>
<p>Go to <a href="https://console.aws.amazon.com/s3" class="uri">https://console.aws.amazon.com/s3</a> and click “Create Bucket”</p>
<p>In my case I named the bucket ‘pecan’</p>
</div>
<div id="upload" class="section level4">
<h4><span class="header-section-number">2.15.2.5</span> Upload</h4>
<p>In the code below, make sure to change the PEcAn version, the name of the bucket, and the name of the region. Make sure that the PEcAn version matches the one you downloaded.</p>
<p>Also, you may want to choose a considerably larger instance type. The one chosen below is that corresponding to the AWS Free Tier</p>
<pre><code>ec2-import-instance PEcAn_1.2.6-disk1.vmdk --instance-type t2.micro --format VMDK --architecture x86_64 --platform Linux --bucket pecan --region us-east-1 --owner-akid $AWS_ACCESS_KEY --owner-sak $AWS_SECRET_KEY</code></pre>
<p>Make sure to note the ID of the image since you’ll need it to check the VM status. Once the image is uploaded it will take a while (typically about an hour) for Amazon to convert the image to one it can run. You can check on this progress by running</p>
<pre><code>ec2-describe-conversion-tasks &lt;image.ID&gt;</code></pre>
</div>
<div id="configuring-the-vm" class="section level4">
<h4><span class="header-section-number">2.15.2.6</span> Configuring the VM</h4>
<p>On the EC2 management webpage, <a href="https://console.aws.amazon.com/ec2" class="uri">https://console.aws.amazon.com/ec2</a>, if you select <strong>Instances</strong> on the left hand side (LHS) you should be able to see your new PEcAn image as an option under Launch Instance.</p>
<p>Before launching, you will want to update the firewall to open up additional ports that PEcAn needs – specifically port 80 for the webpage. Port 22 (ssh/sftp) should be open by default. Under “Security Groups” select “Inbound” then “Edit” and then add “HTTP”.</p>
<p>Select “Elastic IPs” on the LHS, and “Allocate New Address” in order to create a public IP for your VM.</p>
<p>Next, select “Network Interfaces” on the LHS and then under Actions select “Associate Addresses” then choose the Elastic IP you just created.</p>
<p>See also <a href="http://docs.aws.amazon.com/AmazonVPC/latest/GettingStartedGuide/GetStarted.html" class="uri">http://docs.aws.amazon.com/AmazonVPC/latest/GettingStartedGuide/GetStarted.html</a></p>
</div>
</div>
<div id="set-up-multiple-instances-optional" class="section level3">
<h3><span class="header-section-number">2.15.3</span> Set up multiple instances (optional)</h3>
<p>For info on setting up multiple instances with load balancing see: <a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/gs-ec2VPC.html" class="uri">http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/gs-ec2VPC.html</a></p>
<p>Select “Load Balancers” on the LHS, click on “Create Load Balancer”, follow Wizard keeping defaults.</p>
<p>To be able to launch multiple VMs: Under “Instances” convert VM to an Image. When done, select Launch, enable multiple instances, and associate with the previous security group. Once running, go back to “Load Balancers” and add the instances to the load balancer. Each instance can be accessed individually by it’s own public IP, but external users should access the system more generally via the Load Balancers DNS.</p>
<div id="booting-the-vm" class="section level4">
<h4><span class="header-section-number">2.15.3.1</span> Booting the VM</h4>
<p>Return to “Instances” using the menu on the LHS.</p>
<p>To boot the VM select “Actions” then “Instance State” then “Start”. In the future, once you have the VM loaded and configured this last step is the only one you will need to repeat to turn your VM on and off.</p>
<p>The menu provided should specify the Public IP where the VM has launched</p>

</div>
</div>
<div id="shiny-setup" class="section level3">
<h3><span class="header-section-number">2.15.4</span> Shiny Setup</h3>
<p>Installing and configuring Shiny for PEcAn
authors - Alexey Shiklomanov
- Rob Kooper</p>
<p><strong>NOTE: Instructions are only tested for CentOS 6.5 and Ubuntu 16.04</strong>
<strong>NOTE: Pretty much every step here requires root access.</strong></p>
<div id="install-the-shiny-r-package-and-shiny-server" class="section level4">
<h4><span class="header-section-number">2.15.4.1</span> Install the Shiny R package and Shiny server</h4>
<p>Follow the instructions on the <a href="https://www.rstudio.com/products/shiny/download-server/">Shiny download page</a> for the operating system you are using.</p>
</div>
<div id="modify-the-shiny-configuration-file" class="section level4">
<h4><span class="header-section-number">2.15.4.2</span> Modify the shiny configuration file</h4>
<p>The Shiny configuration file is located in <code>/etc/shiny-server/shiny-server.conf</code>. Comment out the entire file and add the following, replacing <code>&lt;username&gt;</code> with your user name and <code>&lt;location&gt;</code> with the URL location you want for your app. This will allow you to run Shiny apps from your web browser at <a href="https://your.server.edu/shiny/your-location" class="uri">https://your.server.edu/shiny/your-location</a></p>
<pre><code>run as shiny;
server {
    listen 3838;
    location /&lt;location&gt;/ {
        run as &lt;username&gt;;
        site_dir /path/to/your/shiny/app;
        log_dir /var/log/shiny-server;
        directory_index on;
    }
}</code></pre>
<p>For example, my configuration on the old test-pecan looks like this.</p>
<pre><code>run as shiny;
server {
    listen 3838;
    location /ashiklom/ {
        run as ashiklom;
        site_dir /home/ashiklom/fs-data/pecan/shiny/;
        log_dir /var/log/shiny-server;
        directory_index on;
    }
}</code></pre>
<p>…and I can access my Shiny apps at, for instance, <a href="https://test-pecan.bu.edu/shiny/ashiklom/workflowPlots" class="uri">https://test-pecan.bu.edu/shiny/ashiklom/workflowPlots</a>.</p>
<p>You can add as many <code>location &lt;loc&gt; { ... }</code> fields as you would like.</p>
<pre><code>run as shiny;
server {
    listen 3838;
    location /ashiklom/ {
        ...
    }
    location /bety/ {
        ...
    }
}</code></pre>
<p>If you change the configuration, for example to add a new location, you will need to restart Shiny server.
<em>If you are setting up a new instance of Shiny</em>, skip this step and continue with the guide, since there are a few more steps to get Shiny working.
<em>If there is an instance of Shiny already running</em>, you can restart it with:</p>
<pre><code>## On CentOS
sudo service shiny-server stop
sudo service shiny-server start

## On Ubuntu
sudo systemctl stop shiny-server.service
sudo systemctl start shiny-server.service</code></pre>
</div>
<div id="set-the-apache-proxy" class="section level4">
<h4><span class="header-section-number">2.15.4.3</span> Set the Apache proxy</h4>
<p>Create a file with the following name, based on the version of the operating system you are using:</p>
<ul>
<li>Ubuntu 16.04 (pecan1, pecan2, test-pecan) – <code>/etc/apache2/conf-available/shiny.conf</code></li>
<li>CentOS 6.5 (psql-pecan) – <code>/etc/httpd/conf.d/shiny.conf</code></li>
</ul>
<p>Into this file, add the following:</p>
<pre><code>ProxyPass           /shiny/ http://localhost:3838/
ProxyPassReverse    /shiny/ http://localhost:3838/
RedirectMatch permanent ^/shiny$ /shiny/</code></pre>
</div>
<div id="ubuntu-only-enable-the-new-shiny-configuration" class="section level4">
<h4><span class="header-section-number">2.15.4.4</span> <strong>Ubuntu only:</strong> Enable the new shiny configuration</h4>
<pre><code>sudo a2enconf shiny</code></pre>
<p>This will create a symbolic link to the newly created <code>shiny.conf</code> file inside the <code>/etc/apache2/conf-enabled</code> directory.
You can do <code>ls -l /etc/apache2/conf-enabled</code> to confirm that this worked.</p>
</div>
<div id="enable-and-start-the-shiny-server-and-restart-apache" class="section level4">
<h4><span class="header-section-number">2.15.4.5</span> Enable and start the shiny server, and restart apache</h4>
</div>
<div id="on-centos" class="section level4">
<h4><span class="header-section-number">2.15.4.6</span> On CentOS</h4>
<pre><code>sudo ln -s /opt/shiny-server/config/init.d/redhat/shiny-server /etc/init.d
sudo service shiny-server stop
sudo service shiny-server start
sudo service httpd restart</code></pre>
<p>You can check that Shiny is running with <code>service shiny-server status</code>.</p>
</div>
<div id="on-ubuntu" class="section level4">
<h4><span class="header-section-number">2.15.4.7</span> On Ubuntu</h4>
<p>Enable the Shiny server service.
This will make sure Shiny runs automatically on startup.</p>
<pre><code>sudo systemctl enable shiny-server.service</code></pre>
<p>Restart Apache.</p>
<pre><code>sudo apachectl restart</code></pre>
<p>Start the Shiny server.</p>
<pre><code>sudo systemctl start shiny-server.service</code></pre>
<p>If there are problems, you can stop the <code>shiny-server.service</code> with…</p>
<pre><code>sudo systemctl stop shiny-server.service</code></pre>
<p>…and then use <code>start</code> again to restart it.</p>
</div>
<div id="troubleshooting-1" class="section level4">
<h4><span class="header-section-number">2.15.4.8</span> Troubleshooting</h4>
<p>Refer to the log files for shiny (<code>/var/log/shiny-server.log</code>) and httpd (on CentOS, <code>/var/log/httpd/error-log</code>; on Ubuntu, <code>/var/log/apache2/error-log</code>).</p>
</div>
<div id="further-reading" class="section level4">
<h4><span class="header-section-number">2.15.4.9</span> Further reading</h4>
<ul>
<li><a href="http://docs.rstudio.com/shiny-server/">Shiny server configuration reference</a></li>
</ul>

</div>
</div>
<div id="thredds-setup" class="section level3">
<h3><span class="header-section-number">2.15.5</span> Thredds Setup</h3>
<p>Installing and configuring Thredds for PEcAn
authors - Rob Kooper</p>
<p><strong>NOTE: Instructions are only tested for Ubuntu 16.04 on the VM, if you have instructions for CENTOS/RedHat please update this documentation</strong>
<strong>NOTE: Pretty much every step here requires root access.</strong></p>
<div id="install-the-tomcat-8-and-thredds-webapp" class="section level4">
<h4><span class="header-section-number">2.15.5.1</span> Install the Tomcat 8 and Thredds webapp</h4>
<p>The Tomcat 8 server can be installed from the default Ubuntu repositories. The thredds webapp will be downloaded and installed from unidata.</p>
</div>
<div id="ubuntu-1" class="section level4">
<h4><span class="header-section-number">2.15.5.2</span> Ubuntu</h4>
<p>First step is to install Tomcat 8 and configure it. The flag <code>-Dtds.content.root.path</code> should point to the location of where the thredds folder is located. This needs to be writeable by the user for tomcat. <code>-Djava.security.egd</code> is a special flag to use a different random number generator for tomcat. The default would take to long to generate a random number.</p>
<pre><code>apt-get -y install tomcat8 openjdk-8-jdk
echo JAVA_OPTS=\&quot;-Dtds.content.root.path=/home/carya \${JAVA_OPTS}\&quot; &gt;&gt; /etc/default/tomcat8
echo JAVA_OPTS=\&quot;-Djava.security.egd=file:/dev/./urandom \${JAVA_OPTS}\&quot; &gt;&gt; /etc/default/tomcat8
service tomcat8 restart</code></pre>
<p>Next is to install the webapp.</p>
<pre><code>mkdir /home/carya/thredds
chmod 777 /home/carya/thredds

wget -O /var/lib/tomcat8/webapps/thredds.war ftp://ftp.unidata.ucar.edu/pub/thredds/4.6/current/thredds.war</code></pre>
<p>Finally we configure Apache to prox the thredds server</p>
<pre><code>cat &gt; /etc/apache2/conf-available/thredds.conf &lt;&lt; EOF
ProxyPass        /thredds/ http://localhost:8080/thredds/
ProxyPassReverse /thredds/ http://localhost:8080/thredds/
RedirectMatch permanent ^/thredds$ /thredds/
EOF
a2enmod proxy_http
a2enconf thredds
service apache2 reload</code></pre>
</div>
<div id="customize-the-thredds-server" class="section level4">
<h4><span class="header-section-number">2.15.5.3</span> Customize the Thredds server</h4>
<p>To customize the thredds server for your installation edit the file in /home/carya/thredds/threddsConfig.xml. For example the following file is included in the VM.</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;threddsConfig&gt;

  &lt;!-- all options are commented out in standard install - meaning use default values --&gt;
  &lt;!-- see http://www.unidata.ucar.edu/software/thredds/current/tds/reference/ThreddsConfigXMLFile.html --&gt;
  &lt;serverInformation&gt;
    &lt;name&gt;PEcAn&lt;/name&gt;
    &lt;logoUrl&gt;/pecan/images/pecan_small.jpg&lt;/logoUrl&gt;
    &lt;logoAltText&gt;PEcAn&lt;/logoAltText&gt;

    &lt;abstract&gt;Scientific Data&lt;/abstract&gt;
    &lt;keywords&gt;meteorology, atmosphere, climate, ocean, earth science&lt;/keywords&gt;
    
    &lt;contact&gt;
      &lt;name&gt;Rob Kooper&lt;/name&gt;
      &lt;organization&gt;NCSA&lt;/organization&gt;
      &lt;email&gt;kooper@illinois.edu&lt;/email&gt;
      &lt;!--phone&gt;&lt;/phone--&gt;
    &lt;/contact&gt;
    &lt;hostInstitution&gt;
      &lt;name&gt;PEcAn&lt;/name&gt;
      &lt;webSite&gt;http://www.pecanproject.org/&lt;/webSite&gt;
      &lt;logoUrl&gt;/pecan/images/pecan_small.jpg&lt;/logoUrl&gt;
      &lt;logoAltText&gt;PEcAn Project&lt;/logoAltText&gt;
    &lt;/hostInstitution&gt;
  &lt;/serverInformation&gt;

  &lt;!--
  The &lt;catalogRoot&gt; element:
  For catalogs you don&#39;t want visible from the /thredds/catalog.xml chain
  of catalogs, you can use catalogRoot elements. Each catalog root config
  catalog is crawled and used in configuring the TDS.

  &lt;catalogRoot&gt;myExtraCatalog.xml&lt;/catalogRoot&gt;
  &lt;catalogRoot&gt;myOtherExtraCatalog.xml&lt;/catalogRoot&gt;
  --&gt;

  &lt;!--
   * Setup for generated HTML pages.
   *
   * NOTE: URLs may be absolute or relative, relative URLs must be relative
   * to the webapp URL, i.e., http://server:port/thredds/.
    --&gt;
  &lt;htmlSetup&gt;
    &lt;!--
     * CSS documents used in generated HTML pages.
     * The CSS document given in the &quot;catalogCssUrl&quot; element is used for all pages
     * that are HTML catalog views. The CSS document given in the &quot;standardCssUrl&quot;
     * element is used in all other generated HTML pages.
     * --&gt;
    &lt;standardCssUrl&gt;tds.css&lt;/standardCssUrl&gt;
    &lt;catalogCssUrl&gt;tdsCat.css&lt;/catalogCssUrl&gt;
    &lt;openDapCssUrl&gt;tdsDap.css&lt;/openDapCssUrl&gt;

    &lt;!--
     * The Google Analytics Tracking code you would like to use for the
     * webpages associated with THREDDS. This will not track WMS or DAP
     * requests for data, only browsing the catalog.
    --&gt;
    &lt;googleTrackingCode&gt;&lt;/googleTrackingCode&gt;

  &lt;/htmlSetup&gt;
  
  &lt;!-- 
    The &lt;TdsUpdateConfig&gt; element controls if and how the TDS checks
    for updates. The default is for the TDS to check for the current
    stable and development release versions, and to log that information
    in the TDS serverStartup.log file as INFO entries.

  &lt;TdsUpdateConfig&gt;
     &lt;logVersionInfo&gt;true&lt;/logVersionInfo&gt;
  &lt;/TdsUpdateConfig&gt;
  --&gt;
   
  &lt;!--
   The &lt;CORS&gt; element controls Cross-Origin Resource Sharing (CORS).
   CORS is a way to allow a website (such as THREDDS) to open up access
   to resources to web pages and applications running on a different domain.
   One example would be allowing a web-application to use fonts from
   a separate host. For TDS, this can allow a javascript app running on a
   different site to access data on a THREDDS server.
   For more information see: https://en.wikipedia.org/wiki/Cross-origin_resource_sharing
   The elements below represent defaults. Only the &lt;enabled&gt; tag is required
   to enable CORS. The default allowed origin is &#39;*&#39;, which allows sharing
   to any domain.
  &lt;CORS&gt;
    &lt;enabled&gt;false&lt;/enabled&gt;
    &lt;maxAge&gt;1728000&lt;/maxAge&gt;
    &lt;allowedMethods&gt;GET&lt;/allowedMethods&gt;
    &lt;allowedHeaders&gt;Authorization&lt;/allowedHeaders&gt;
    &lt;allowedOrigin&gt;*&lt;/allowedOrigin&gt;
  &lt;/CORS&gt;
  --&gt;

  &lt;!--
   The &lt;CatalogServices&gt; element:
   - Services on local TDS served catalogs are always on.
   - Services on remote catalogs are set with the allowRemote element
   below. They are off by default (recommended).
   --&gt;
  &lt;CatalogServices&gt;
    &lt;allowRemote&gt;false&lt;/allowRemote&gt;
  &lt;/CatalogServices&gt;

  &lt;!--
  Configuring the CDM (netcdf-java library)
  see http://www.unidata.ucar.edu/software/netcdf-java/reference/RuntimeLoading.html

  &lt;nj22Config&gt;
    &lt;ioServiceProvider class=&quot;edu.univ.ny.stuff.FooFiles&quot;/&gt;
    &lt;coordSysBuilder convention=&quot;foo&quot; class=&quot;test.Foo&quot;/&gt;
    &lt;coordTransBuilder name=&quot;atmos_ln_sigma_coordinates&quot; type=&quot;vertical&quot; class=&quot;my.stuff.atmosSigmaLog&quot;/&gt;
    &lt;typedDatasetFactory datatype=&quot;Point&quot; class=&quot;gov.noaa.obscure.file.Flabulate&quot;/&gt;
  &lt;/nj22Config&gt;
  --&gt;

  &lt;!--
  CDM uses the DiskCache directory to store temporary files, like uncompressed files.
  &lt;DiskCache&gt;
    &lt;alwaysUse&gt;false&lt;/alwaysUse&gt;
    &lt;scour&gt;1 hour&lt;/scour&gt;
    &lt;maxSize&gt;1 Gb&lt;/maxSize&gt;
  &lt;/DiskCache&gt;
  --&gt;

  &lt;!--
  Caching open NetcdfFile objects.
  default is to allow 50 - 100 open files, cleanup every 11 minutes
  &lt;NetcdfFileCache&gt;
    &lt;minFiles&gt;50&lt;/minFiles&gt;
    &lt;maxFiles&gt;100&lt;/maxFiles&gt;
    &lt;scour&gt;11 min&lt;/scour&gt;
  &lt;/NetcdfFileCache&gt;
  --&gt;

  &lt;!--
  The &lt;HTTPFileCache&gt; element:
  allow 10 - 20 open datasets, cleanup every 17 minutes
  used by HTTP Range requests.
  &lt;HTTPFileCache&gt;
    &lt;minFiles&gt;10&lt;/minFiles&gt;
    &lt;maxFiles&gt;20&lt;/maxFiles&gt;
    &lt;scour&gt;17 min&lt;/scour&gt;
  &lt;/HTTPFileCache&gt;
  --&gt;

  &lt;!--
  Writing GRIB indexes.
  &lt;GribIndexing&gt;
    &lt;setExtendIndex&gt;false&lt;/setExtendIndex&gt;
    &lt;alwaysUseCache&gt;false&lt;/alwaysUseCache&gt;
  &lt;/GribIndexing&gt;
  --&gt;

  &lt;!--
  Persist joinNew aggregations to named directory. scour every 24 hours, delete stuff older than 90 days
  &lt;AggregationCache&gt;
    &lt;scour&gt;24 hours&lt;/scour&gt;
    &lt;maxAge&gt;90 days&lt;/maxAge&gt;
    &lt;cachePathPolicy&gt;NestedDirectory&lt;/cachePathPolicy&gt;
  &lt;/AggregationCache&gt;
  --&gt;

  &lt;!--
  How to choose the template dataset for an aggregation. latest, random, or penultimate
  &lt;Aggregation&gt;
    &lt;typicalDataset&gt;penultimate&lt;/typicalDataset&gt;
  &lt;/Aggregation&gt;
  --&gt;

  &lt;!--
  The Netcdf Subset Service is off by default.
  &lt;NetcdfSubsetService&gt;
    &lt;allow&gt;false&lt;/allow&gt;
    &lt;scour&gt;10 min&lt;/scour&gt;
    &lt;maxAge&gt;-1 min&lt;/maxAge&gt;
  &lt;/NetcdfSubsetService&gt;
  --&gt;

  &lt;!--
  &lt;Opendap&gt;
    &lt;ascLimit&gt;50&lt;/ascLimit&gt;
    &lt;binLimit&gt;500&lt;/binLimit&gt;
    &lt;serverVersion&gt;opendap/3.7&lt;/serverVersion&gt;
  &lt;/Opendap&gt;
    --&gt;
  
  &lt;!--
  The WCS Service is off by default.
  Also, off by default (and encouraged) is operating on a remote dataset.
  &lt;WCS&gt;
    &lt;allow&gt;false&lt;/allow&gt;
    &lt;allowRemote&gt;false&lt;/allowRemote&gt;
    &lt;scour&gt;15 min&lt;/scour&gt;
    &lt;maxAge&gt;30 min&lt;/maxAge&gt;
  &lt;/WCS&gt;
  --&gt;

  &lt;!--
  &lt;WMS&gt;
    &lt;allow&gt;false&lt;/allow&gt;
    &lt;allowRemote&gt;false&lt;/allowRemote&gt;
    &lt;maxImageWidth&gt;2048&lt;/maxImageWidth&gt;
    &lt;maxImageHeight&gt;2048&lt;/maxImageHeight&gt;
  &lt;/WMS&gt;
  --&gt;

  &lt;!--
  &lt;NCISO&gt;
    &lt;ncmlAllow&gt;false&lt;/ncmlAllow&gt;
    &lt;uddcAllow&gt;false&lt;/uddcAllow&gt;
    &lt;isoAllow&gt;false&lt;/isoAllow&gt;
  &lt;/NCISO&gt;
  --&gt;

  &lt;!-- CatalogGen service is off by default.
  &lt;CatalogGen&gt;
    &lt;allow&gt;false&lt;/allow&gt;
  &lt;/CatalogGen&gt;
   --&gt;

  &lt;!-- DLwriter service is off by default.
       As is support for operating on remote catalogs.
  &lt;DLwriter&gt;
    &lt;allow&gt;false&lt;/allow&gt;
    &lt;allowRemote&gt;false&lt;/allowRemote&gt;
  &lt;/DLwriter&gt;
   --&gt;

  &lt;!-- DqcService is off by default.
  &lt;DqcService&gt;
    &lt;allow&gt;false&lt;/allow&gt;
  &lt;/DqcService&gt;
   --&gt;

  &lt;!--
   Link to a Viewer application on the HTML page:
   &lt;Viewer&gt;my.package.MyViewer&lt;/Viewer&gt;
   --&gt;

   &lt;!--
   Add a DataSource - essentially an IOSP with access to Servlet request parameters
   &lt;datasetSource&gt;my.package.DatsetSourceImpl&lt;/datasetSource&gt;
   --&gt;

  &lt;!--
   set FeatureCollection logging
  &lt;FeatureCollection&gt;
     &lt;RollingFileAppender&gt;
       &lt;MaxFileSize&gt;1 MB&lt;/MaxFileSize&gt;
       &lt;MaxBackups&gt;5&lt;/MaxBackups&gt;
       &lt;Level&gt;INFO&lt;/Level&gt;
     &lt;/RollingFileAppender&gt;
  &lt;/FeatureCollection&gt;
  --&gt;

  &lt;!--
    Configure how the NetCDF-4 C library is discovered and used.
    libraryPath: The directory in which the native library is installed.
    libraryName: The name of the native library. This will be used to locate the proper .DLL, .SO, or .DYLIB file
      within the libraryPath directory.
    useForReading: By default, the native library is only used for writing NetCDF-4 files; a pure-Java layer is
      responsible for reading them. However, if this property is set to true, then it will be used for reading
      NetCDF-4 (and HDF5) files as well.
  --&gt;
  &lt;!--
  &lt;Netcdf4Clibrary&gt;
    &lt;libraryPath&gt;/usr/local/lib&lt;/libraryPath&gt;
    &lt;libraryName&gt;netcdf&lt;/libraryName&gt;
    &lt;useForReading&gt;false&lt;/useForReading&gt;
  &lt;/Netcdf4Clibrary&gt;
  --&gt;
&lt;/threddsConfig&gt;</code></pre>
</div>
<div id="update-the-catalog" class="section level4">
<h4><span class="header-section-number">2.15.5.4</span> Update the catalog</h4>
<p>For example to update the catalog with the latest data, run the following command from the root crontab. This cronjob will also synchronize the database with remote servers and dump your database (by default in /home/carya/dump)</p>
<pre><code>0 * * * * /home/carya/pecan/scripts/cron.sh -o /home/carya/dump</code></pre>
</div>
<div id="troubleshooting-2" class="section level4">
<h4><span class="header-section-number">2.15.5.5</span> Troubleshooting</h4>
<p>Refer to the log files for Tomcat (<code>/var/log/tomcat8/*</code>) and Thredds (<code>/home/carya/thredds/logs</code>).</p>
</div>
<div id="further-reading-1" class="section level4">
<h4><span class="header-section-number">2.15.5.6</span> Further reading</h4>
<ul>
<li><a href="http://www.unidata.ucar.edu/software/thredds/current/tds/">Thredds reference</a></li>
</ul>

</div>
</div>
</div>
<div id="updatepecan" class="section level2">
<h2><span class="header-section-number">2.16</span> Updating PEcAn Code and Bety Database</h2>
<p>Release notes for all releases can be found <a href="https://github.com/PecanProject/pecan/releases">here</a>.</p>
<p>This page will only list any steps you have to do to upgrade an existing system. When updating PEcAn it is highly encouraged to update BETY. You can find instructions on how to do this, as well on how to update the database in the <a href="https://pecan.gitbooks.io/betydb-documentation/content/updating_betydb_when_new_versions_are_released.html">Updating BETYdb</a> gitbook page.</p>
<div id="updating-pecan" class="section level3">
<h3><span class="header-section-number">2.16.1</span> Updating PEcAn</h3>
<p>The latest version of PEcAn code can be obtained from the PEcAn repository on GitHub:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">cd</span> pecan        # If you are not already in the PEcAn directory
<span class="fu">git</span> pull</code></pre>
<p>The PEcAn build system is based on GNU Make.
The simplest way to install is to run <code>make</code> from inside the PEcAn directory.
This will update the documentation for all packages and install them, as well as all required dependencies.</p>
<p>For more control, the following <code>make</code> commands are available:</p>
<ul>
<li><p><code>make document</code> – Use <code>devtools::document</code> to update the documentation for all package.
Under the hood, this uses the <code>roxygen2</code> documentation system.</p></li>
<li><p><code>make install</code> – Install all packages and their dependnencies using <code>devtools::install</code>.
By default, this only installs packages that have had their code changed and any dependent packages.</p></li>
<li><p><code>make check</code> – Perform a rigorous check of packages using <code>devtools::check</code></p></li>
<li><p><code>make test</code> – Run all unit tests (based on <code>testthat</code> package) for all packages, using <code>devtools::test</code></p></li>
<li><p><code>make clean</code> – Remove the make build cache, which is used to track which packages have changed.
Cache files are stored in the <code>.doc</code>, <code>.install</code>, <code>.check</code>, and <code>.test</code> subdirectories in the PEcAn main directory.
Running <code>make clean</code> will force the next invocation of <code>make</code> commands to operate on all PEcAn packages, regardless of changes.</p></li>
</ul>
<p>The following are some additional <code>make</code> tricks that may be useful:</p>
<ul>
<li><p>Install, check, document, or test a specific package – <code>make .&lt;cmd&gt;/&lt;pkg-dir&gt;</code>; e.g. <code>make .install/utils</code> or <code>make .check/modules/rtm</code></p></li>
<li><p>Force <code>make</code> to run, even if package has not changed – <code>make -B &lt;command&gt;</code></p></li>
<li><p>Run <code>make</code> commands in parallel – <code>make -j&lt;ncores&gt;</code>; e.g. <code>make -j4 install</code> to install packages using four parallel processes.</p></li>
</ul>
<p>All instructions for the <code>make</code> build system are contained in the <code>Makefile</code> in the PEcAn root directory.
For full documentation on <code>make</code>, see the man pages by running <code>man make</code> from a terminal.</p>
<p><em>Point of contact:
Alexey Shiklomanov
GitHub/Gitter: <span class="citation">@ashiklom</span>
email: <a href="mailto:ashiklom@bu.edu">ashiklom@bu.edu</a></em></p>

</div>
</div>
<div id="updating-bety" class="section level2">
<h2><span class="header-section-number">2.17</span> Updating BETY</h2>
<p>Moved to: <a href="https://pecan.gitbooks.io/betydb-documentation/content/updating_betydb_when_new_versions_are_released.html" class="uri">https://pecan.gitbooks.io/betydb-documentation/content/updating_betydb_when_new_versions_are_released.html</a></p>

</div>
<div id="git-and-github-workflow" class="section level2">
<h2><span class="header-section-number">2.18</span> Git and GitHub Workflow</h2>

</div>
<div id="using-git" class="section level2">
<h2><span class="header-section-number">2.19</span> Using Git</h2>
<p>This document describes the steps required to download PEcAn, make changes to code, and submit your changes.</p>
<ul>
<li>If you are new to GitHub or to PEcAn, start with the one-time set-up instructions under <a href="tutorialsdemos-and-how-tos.html#before-any-work-is-done">Before any work is done</a>. Also see the excellent tutorials and references in the <a href="tutorialsdemos-and-how-tos.html#git">Git</a>) section right below this list and at the bootom in <a href="tutorialsdemos-and-how-tos.html#references">References</a>.</li>
<li>To make trivial changes, see <a href="tutorialsdemos-and-how-tos.html#quick-and-easy">Quick and Easy</a>.</li>
<li>To make a few changes to the code, start with the <a href="tutorialsdemos-and-how-tos.html#basic-workflow">Basic Workflow</a>.</li>
<li>To make substantial changes and/or if plan to contribute over time see <a href="tutorialsdemos-and-how-tos.html#recommended-workflow-a-new-branch-for-each-change">Recommended Workflow: A new branch for each change</a>.</li>
</ul>
<div id="git" class="section level3">
<h3><span class="header-section-number">2.19.1</span> Git</h3>
<p>Git is a free &amp; open source, distributed version control system designed
to handle everything from small to very large projects with speed and
efficiency. Every Git clone is a full-fledged repository with complete
history and full revision tracking capabilities, not dependent on
network access or a central server. Branching and merging are fast and
easy to do.</p>
<p>A good place to start is the <a href="https://guides.github.com/introduction/flow/">GitHub 5 minute illustrated tutorial</a>.
In addition, there are three fun tutorials for learning git:</p>
<ul>
<li><a href="https://www.codecademy.com/learn/learn-git">Learn Git</a> is a great web-based interactive tutorial.</li>
<li><a href="https://learngitbranching.js.org/">LearnGitBranching</a></li>
<li><a href="http://try.github.com">TryGit</a>.</li>
</ul>
<p><strong>URLs</strong> In the rest of the document will use specific URL’s to clone the code.
There a few URL’s you can use to clone a project, using https, ssh and
git. You can use either https or git to clone a repository and write to
it. The git protocol is read-only.
This document describes the steps required to download PEcAn, make changes to code, and submit your changes.</p>
</div>
<div id="pecan-project-and-github" class="section level3">
<h3><span class="header-section-number">2.19.2</span> PEcAn Project and Github</h3>
<pre><code>                                                                                                                                           * Organization Repository: https://github.com/organizations/PecanProject                                                                       * PEcAn source code: https://github.com/PecanProject/pecan.git                                                                                 * BETYdb source code: https://github.com/PecanProject/bety.git</code></pre>
<p>These instructions apply to other repositories too.</p>
</div>
<div id="pecan-project-branches" class="section level3">
<h3><span class="header-section-number">2.19.3</span> PEcAn Project Branches</h3>
<pre><code>                                                                                                                                           We follow branch organization laid out on [this page](http://nvie.com/posts/a-successful-git-branching-model).</code></pre>
<p>In short, there are three main branches you must be aware of:</p>
<ul>
<li><strong>develop</strong> - Main Branch containing the latest code. This is the main branch you will make changes to.</li>
<li><strong>master</strong> - Branch containing the latest stable code. DO NOT MAKE CHANGES TO THIS BRANCH.</li>
<li><strong>release/vX.X.X</strong> - Named branches containing code specific to a release. Only make changes to this branch if you are fixing a bug on a release branch.</li>
</ul>
<div id="milestones-issues-tasks" class="section level4">
<h4><span class="header-section-number">2.19.3.1</span> Milestones, Issues, Tasks</h4>
<p>The Milestones, issues, and tasks can be used to organize specific features or research projects. In general, there is a heirarchy:</p>
<ul>
<li>milestones (Big picture, “Epic”): contains many issues, organized by release.</li>
<li>issues (Specific features / bugs, “Story”): may contain a list of tasks; represent</li>
<li>task list (to do list, “Tasks”): list of steps required to close an issue, e.g.:</li>
</ul>
<table>
<tbody>
<tr class="odd">
<td align="left">* [ ] first do this</td>
</tr>
<tr class="even">
<td align="left">* [ ] then this</td>
</tr>
<tr class="odd">
<td align="left">* [ ] completed when x and y</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="quick-and-easy" class="section level3">
<h3><span class="header-section-number">2.19.4</span> Quick and Easy</h3>
<p>The <strong>easiest</strong> approach is to use GitHub’s browser based workflow. This is useful when your change is a few lines, if you are editing a wiki, or if the edit is trivial (and won’t break the code). The <a href="https://help.github.com/articles/github-flow-in-the-browser">GitHub documentation is here</a> but it is simple: finding the page or file you want to edit, click “edit” and then the GitHub web application will automatically forking and branch, then allow you to submit a pull request. However, it should be noted that unless you are a member of the PEcAn project that the “edit” button will not be active and you’ll want to follow the workflow described below for forking and then submitting a pull request.</p>
</div>
<div id="recommended-git-workflow" class="section level3">
<h3><span class="header-section-number">2.19.5</span> Recommended Git Workflow</h3>
<p><strong>Each feature should be in its own branch</strong> (for example each issue is a branch, names of branches are often the issue in a bug tracking system).</p>
<p><strong>Commit and Push Frequency</strong> On your branch, commit <strong><em>at minimum once a day before you push changes:</em></strong> even better: every time you reach a stopping point and move to a new issue. best: any time that you have done work that you do not want to re-do. Remember, pushing changes to your branch is like saving a draft. Submit a pull request when you are done.</p>
</div>
<div id="before-any-work-is-done" class="section level3">
<h3><span class="header-section-number">2.19.6</span> Before any work is done</h3>
<p>The first step below only needs to be done once when you first start working on the PEcAn code. The steps below that need to be done to set up PEcAn on your computer, and would need to be repeated if you move to a new computer. If you are working from the PEcAn VM, you can skip the “git clone” since the PEcAn code is already installed.</p>
<p>Most people will not be able to work in the PEcAn repository directly and will need to create a fork of the PEcAn source code in their own folder. To fork PEcAn into your own github space (<a href="https://help.github.com/articles/fork-a-repo">github help: “fork a repo”</a>). This forked repository will allow you to create branches and commit changes back to GitHub and create pull requests to the develop branch of PEcAn.</p>
<p>The forked repository is the only way for external people to commit code back to PEcAn and BETY. The pull request will start a review process that will eventually result in the code being merged into the main copy of the codebase. See <a href="https://help.github.com/articles/fork-a-repo" class="uri">https://help.github.com/articles/fork-a-repo</a> for more information, especially on how to keep your fork up to date with respect to the original. (Rstudio users should also see <a href="Using-Git.md#git--rstudio">Git + Rstudio</a>, below)</p>
<p>You can setup SSH keys to make it easier to commit cod back to GitHub. This might especially be true if you are working from a cluster, see <a href="https://help.github.com/articles/generating-ssh-keys">set up ssh keys</a></p>
<ol style="list-style-type: decimal">
<li>Introduce yourself to GIT</li>
</ol>
<p><code>git config --global user.name &quot;FULLNAME&quot;</code>
<code>git config --global user.email you@yourdomain.example.com</code></p>
<ol start="2" style="list-style-type: decimal">
<li><p>Fork PEcAn on GitHub. Go to the PEcAn source code and click on the Fork button in the upper right. This will create a copy of PEcAn in your personal space.</p></li>
<li><p>Clone to your local machine via command line</p></li>
</ol>
<p><code>git clone git@github.com:&lt;username&gt;/pecan.git</code></p>
<p>If this does not work, try the https method</p>
<p><code>git clone https://github.com/PecanProject/pecan.git</code></p>
<ol start="4" style="list-style-type: decimal">
<li>Define upstream repository</li>
</ol>
<pre><code>cd pecan
git remote add upstream git@github.com:PecanProject/pecan.git</code></pre>
</div>
<div id="during-development" class="section level3">
<h3><span class="header-section-number">2.19.7</span> During development:</h3>
<ul>
<li>commit often;</li>
<li>each commit can address 0 or 1 issue; many commits can reference an issue</li>
<li>ensure that all tests are passing before anything is pushed into develop.</li>
</ul>
</div>
<div id="basic-workflow" class="section level3">
<h3><span class="header-section-number">2.19.8</span> Basic Workflow</h3>
<p>This workflow is for educational purposes only. Please use the Recommended Workflow if you plan on contributing to PEcAn. This workflow does not include creating branches, a feature we would like you to use.
1. Get the latest code from the main repository</p>
<p><code>git pull upstream develop</code></p>
<ol start="2" style="list-style-type: decimal">
<li><p>Do some coding</p></li>
<li><p>Commit after each chunk of code (multiple times a day)</p></li>
</ol>
<p><code>git commit -m &quot;&lt;some descriptive information about what was done; references/fixes gh-X&gt;&quot;</code></p>
<ol start="4" style="list-style-type: decimal">
<li>Push to YOUR Github (when a feature is working, a set of bugs are fixed, or you need to share progress with others)</li>
</ol>
<p><code>git push origin develop</code></p>
<ol start="5" style="list-style-type: decimal">
<li>Before submitting code back to the main repository, make sure that code compiles from the main directory.</li>
</ol>
<p><code>make</code></p>
<ol start="6" style="list-style-type: decimal">
<li>submit pull request with a reference to related issue;</li>
</ol>
<ul>
<li>also see <a href="https://help.github.com/articles/using-pull-requests">github documentation</a></li>
</ul>
</div>
<div id="recommended-workflow-a-new-branch-for-each-change" class="section level3">
<h3><span class="header-section-number">2.19.9</span> Recommended Workflow: A new branch for each change</h3>
<ol style="list-style-type: decimal">
<li>Make sure you start in develop</li>
</ol>
<p><code>git checkout develop</code></p>
<ol start="2" style="list-style-type: decimal">
<li>Make sure develop is up to date</li>
</ol>
<p><code>git pull upstream develop</code></p>
<ol start="3" style="list-style-type: decimal">
<li>Run the PEcAn MAKEFILE to compile code from the main directory.</li>
</ol>
<p><code>make</code></p>
<ol start="4" style="list-style-type: decimal">
<li>Create a branch and switch to it</li>
</ol>
<p><code>git checkout -b &lt;branchname&gt;</code></p>
<ol start="5" style="list-style-type: decimal">
<li>Work/commit/etc</li>
</ol>
<p><code>git add &lt;file_that_was_changed.R&gt;</code></p>
<p><code>git commit -m &quot;&lt;some descriptive information about what was done&gt;&quot;</code></p>
<ol start="6" style="list-style-type: decimal">
<li>Make sure that code compiles and documentation updated. The make document command will run roxygenise.</li>
</ol>
<p><code>make document</code>
<code>make</code></p>
<ol start="7" style="list-style-type: decimal">
<li>Push this branch to your github space</li>
</ol>
<p><code>git push origin &lt;branchname&gt;</code></p>
<ol start="8" style="list-style-type: decimal">
<li>submit pull request with [[link commits to issues|Using-Git#link-commits-to-issuess]];</li>
</ol>
<ul>
<li>also see <a href="https://github.com/PecanProject/bety/issues/57">explanation in this PecanProject/bety issue</a> and <a href="https://help.github.com/articles/using-pull-requests">github documentation</a></li>
</ul>
<div id="after-pull-request-is-merged" class="section level4">
<h4><span class="header-section-number">2.19.9.1</span> After pull request is merged</h4>
<ol style="list-style-type: decimal">
<li>Make sure you start in master</li>
</ol>
<p><code>git checkout develop</code></p>
<ol start="2" style="list-style-type: decimal">
<li>delete branch remotely</li>
</ol>
<p><code>git push origin --delete &lt;branchname&gt;</code></p>
<ol start="3" style="list-style-type: decimal">
<li>delete branch locally</li>
</ol>
<p><code>git branch -D &lt;branchname&gt;</code></p>
</div>
<div id="fixing-a-release-branch" class="section level4">
<h4><span class="header-section-number">2.19.9.2</span> Fixing a release Branch</h4>
<p>If you would like to make changes to a release branch, you must follow a different workflow, as the release branch will not contain the latest code on develop and must remain seperate.</p>
<ol style="list-style-type: decimal">
<li>Fetch upstream remote branches</li>
</ol>
<p><code>git fetch upstream</code></p>
<ol start="2" style="list-style-type: decimal">
<li>Checkout the correct release branch</li>
</ol>
<p><code>git checkout -b release/vX.Y.Z</code></p>
<ol start="4" style="list-style-type: decimal">
<li>Compile Code with make</li>
</ol>
<p><code>make</code></p>
<ol start="5" style="list-style-type: decimal">
<li>Make changes and commit them</li>
</ol>
<p><code>git add &lt;changed_file.R&gt;</code>
<code>git commit -m &quot;Describe changes&quot;</code></p>
<ol start="6" style="list-style-type: decimal">
<li><p>Compile and make roxygen changes
<code>make</code>
<code>make document</code></p></li>
<li><p>Commit and push any files that were changed by make document</p></li>
<li><p>Make a pull request. It is essential that you compare your pull request to the remote release branch, NOT the develop branch.</p></li>
</ol>
</div>
<div id="link-commits-to-issues" class="section level4">
<h4><span class="header-section-number">2.19.9.3</span> Link commits to issues</h4>
<p>You can reference and close issues from comments, pull requests, and commit messages. This should be done when you commit code that is related to or will close/fix an existing issue.</p>
<p>There are two ways to do this. One easy way is to include the following text in your commit message:</p>
<ul>
<li><a href="https://github.com/blog/1386-closing-issues-via-commit-messages"><strong>Github</strong></a></li>
<li>to close: “closes gh-xxx” (or syn. close, closed, fixes, fix, fixed)<br />
</li>
<li>to reference: just the issue number (e.g. “gh-xxx”)</li>
</ul>
</div>
<div id="other-useful-git-commands" class="section level4">
<h4><span class="header-section-number">2.19.9.4</span> Other Useful Git Commands:</h4>
<ul>
<li>GIT encourages branching “early and often”</li>
<li>First pull from develop</li>
<li>Branch before working on feature</li>
<li>One branch per feature</li>
<li>You can switch easily between branches</li>
<li>Merge feature into main line when branch done</li>
</ul>
<p>If during above process you want to work on something else, commit all
your code, create a new branch, and work on new branch.</p>
<ul>
<li>Delete a branch: <code>git branch -d &lt;name of branch&gt;</code></li>
<li>To push a branch git: <code>push -u origin</code><name of branch>`</li>
<li>To check out a branch:</li>
</ul>
<pre><code>git fetch origin
git checkout --track origin/&lt;name of branch&gt;</code></pre>
<ul>
<li>Show graph of commits:</li>
</ul>
<p><code>git log --graph --oneline --all</code></p>
</div>
<div id="tags" class="section level4">
<h4><span class="header-section-number">2.19.9.5</span> Tags</h4>
<p>Git supports two types of tags: lightweight and annotated. For more information see the <a href="http://git-scm.com/book/ch2-6.html">Tagging Chapter in the Git documentation</a>.</p>
<p>Lightweight tags are useful, but here we discuss the annotated tags that are used for marking stable versions, major releases, and versions associated with published results.</p>
<p>The basic command is <code>git tag</code>. The <code>-a</code> flag means ‘annotated’ and <code>-m</code> is used before a message. Here is an example:</p>
<p><code>git tag -a v0.6 -m &quot;stable version with foo and bar features, used in the foobar publication by Bob&quot;</code></p>
<p>Adding a tag to the a remote repository must be done explicitly with a push, e.g.</p>
<p><code>git push v0.6</code></p>
<p>To use a tagged version, just checkout:</p>
<p><code>git checkout v0.6</code></p>
<p>To tag an earlier commit, just append the commit SHA to the command, e.g.</p>
<p><code>git tag -a v0.99 -m &quot;last version before 1.0&quot; 9fceb02</code></p>
<p><strong>Using GitHub</strong> The easiest way to get working with GitHub is by installing the GitHub
client. For instructions for your specific OS and download of the
GitHub client, see <a href="https://help.github.com/articles/set-up-git" class="uri">https://help.github.com/articles/set-up-git</a>.
This will help you set up an SSH key to push code back to GitHub. To
check out a project you do not need to have an ssh key and you can use
the https or git url to check out the code.</p>
</div>
</div>
<div id="git-rstudio" class="section level3">
<h3><span class="header-section-number">2.19.10</span> Git + Rstudio</h3>
<p>Rstudio is nicely integrated with many development tools, including git and GitHub.
It is quite easy to check out source code from within the Rstudio program or browser.
The Rstudio documentation includes useful overviews of <a href="http://www.rstudio.com/ide/docs/version_control/overview">version control</a> and <a href="http://www.rstudio.com/ide/docs/packages/overview">R package development</a>.</p>
<p>Once you have git installed on your computer (see the <a href="http://www.rstudio.com/ide/docs/version_control/overview">Rstudio version control</a> documentation for instructions), you can use the following steps to install the PEcAn source code in Rstudio.</p>
<div id="creating-a-read-only-version" class="section level4">
<h4><span class="header-section-number">2.19.10.1</span> Creating a Read-only version:</h4>
<p>This is a fast way to clone the repository that does not support contributing new changes (this can be done with further modification).</p>
<ol style="list-style-type: decimal">
<li>install Rstudio (www.rstudio.com)</li>
<li>click (upper right) project</li>
</ol>
<ul>
<li>create project</li>
<li>version control</li>
<li>Git - clone a project from a Git Repository</li>
<li>paste <a href="https://www.github.com/PecanProject/pecan" class="uri">https://www.github.com/PecanProject/pecan</a></li>
<li>choose working dir. for repo</li>
</ul>
</div>
</div>
<div id="for-development" class="section level3">
<h3><span class="header-section-number">2.19.11</span> For development:</h3>
<ol style="list-style-type: decimal">
<li>create account on github</li>
<li>create a fork of the PEcAn repository to your own account <a href="https://www.github.com/pecanproject/pecan" class="uri">https://www.github.com/pecanproject/pecan</a></li>
<li>install Rstudio (www.rstudio.com)</li>
<li>generate an ssh key</li>
</ol>
<ul>
<li>in Rstudio:
<ul>
<li><code>Tools -&gt; Options -&gt; Git/SVN -&gt; &quot;create RSA key&quot;</code></li>
</ul></li>
<li><code>View public key -&gt; ctrl+C to copy</code></li>
<li>in GitHub</li>
<li>go to <a href="https://github.com/settings/ssh">ssh settings</a></li>
<li><code>-&gt; 'add ssh key' -&gt; ctrl+V to paste -&gt; 'add key'</code></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Create project in Rstudio</li>
</ol>
<ul>
<li><code>project (upper right) -&gt; create project -&gt; version control -&gt; Git - clone a project from a Git Repository</code></li>
<li>paste repository url <code>git@github.com:&lt;username&gt;/pecan.git&gt;</code></li>
<li>choose working dir. for repository</li>
</ul>
</div>
<div id="references" class="section level3">
<h3><span class="header-section-number">2.19.12</span> References</h3>
<div id="git-documentation" class="section level4">
<h4><span class="header-section-number">2.19.12.1</span> Git Documentation</h4>
<ul>
<li>Scott Chacon, ‘Pro Git book’,
<a href="http://git-scm.com/book" class="uri">http://git-scm.com/book</a></li>
<li>GitHub help pages,
<a href="https://help.github.com" class="uri">https://help.github.com</a>/</li>
<li>Main GIT page
<a href="http://git-scm.com/documentation" class="uri">http://git-scm.com/documentation</a></li>
<li>Another set of pages about branching,
<a href="http://sandofsky.com/blog/git-workflow.html" class="uri">http://sandofsky.com/blog/git-workflow.html</a></li>
<li><a href="http://stackoverflow.com/questions/tagged/git?sort=votes&amp;pagesize=50">Stackoverflow highest voted questions tagged “git”</a></li>
</ul>
</div>
<div id="github-documentation" class="section level4">
<h4><span class="header-section-number">2.19.12.2</span> GitHub Documentation</h4>
<p>When in doubt, the first step is to click the “Help” button at the top of the page.</p>
<ul>
<li><a href="http://scottchacon.com/2011/08/31/github-flow.html">GitHub Flow</a> by
Scott Chacon (Git evangelist and Ruby developer working on GitHub.com)</li>
<li><a href="https://help.github.com/">GitHub FAQ</a></li>
<li><a href="https://help.github.com/articles/using-pull-requests">Using Pull Requests</a></li>
<li><a href="https://help.github.com/articles/generating-ssh-keys">SSH Keys</a></li>
</ul>

</div>
</div>
</div>
<div id="github-use-with-pecan" class="section level2">
<h2><span class="header-section-number">2.20</span> GitHub use with PEcAn</h2>
<p>In this section, development topics are introduced and discussed. PEcAn code lives within the If you are looking for an issue to work on, take a look through issues labled <a href="https://github.com/PecanProject/pecan/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22">“good first issue”</a>. To get started you will want to review</p>
<p>We use GitHub to track development.</p>
<p>To learn about GitHub, it is worth taking some time to read through the <a href="https://help.github.com/">FAQ</a>. When in doubt, the first step is to click the “Help” button at the top of the page.</p>
<ul>
<li><strong>To address specific people</strong>, use a github feature called <span class="citation">@mentions</span> e.g. write <span class="citation">@dlebauer</span>, <span class="citation">@robkooper</span>, <span class="citation">@mdietze</span>, or <span class="citation">@serbinsh</span> … in the issue to alert the user as described in the <a href="https://help.github.com/articles/notifications">GitHub documentation on notifications</a></li>
</ul>
<div id="bugs-issues-features-etc." class="section level3">
<h3><span class="header-section-number">2.20.1</span> Bugs, Issues, Features, etc.</h3>
<div id="reporting-a-bug" class="section level4">
<h4><span class="header-section-number">2.20.1.1</span> Reporting a bug</h4>
<ol style="list-style-type: decimal">
<li>(For developers) work through debugging.</li>
<li>Once you have identified a problem, that you can not resolve, you can write a bug report</li>
<li>Write a bug report</li>
<li>submit the bug report</li>
<li>If you do find the answer, explain the resolution (in the issue) and close the issue</li>
</ol>
</div>
<div id="required-content" class="section level4">
<h4><span class="header-section-number">2.20.1.2</span> Required content</h4>
<p>Note:</p>
<ul>
<li><strong>a bug is only a bug if it is reproducible</strong></li>
<li><strong>clear bug reports save time</strong></li>
</ul>
<ol style="list-style-type: decimal">
<li>Clear, specific title</li>
<li>Description -</li>
</ol>
<ul>
<li>What you did</li>
<li>What you expected to happen</li>
<li>What actually happened</li>
<li>What does work, under what conditions does it fail?</li>
<li>Reproduction steps - minimum steps required to reproduce the bug</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>additional materials that could help identify the cause:</li>
</ol>
<ul>
<li>screen shots</li>
<li>stack traces, logs, scripts, output</li>
<li>specific code and data / settings / configuration files required to reproduce the bug</li>
<li>environment (operating system, browser, hardware)</li>
</ul>
</div>
</div>
<div id="requesting-a-feature" class="section level3">
<h3><span class="header-section-number">2.20.2</span> Requesting a feature</h3>
<p>(from The Pragmatic Programmer, available as
<a href="http://proquestcombo.safaribooksonline.com/0-201-61622-X/223">ebook</a>
through UI libraries, hardcopy on David’s bookshelf)<br />
</p>
<ul>
<li>focus on “user stories”, e.g. specific use cases</li>
<li><p>Be as specific as possible,</p></li>
<li><p>Here is an example:</p></li>
</ul>
<ol style="list-style-type: decimal">
<li>Bob is at www.mysite.edu/maps</li>
<li>map of the the region (based on user location, e.g. US, Asia, etc)</li>
<li>option to “use current location” is provided, if clicked, map zooms in to, e.g. state or county level</li>
<li>for site run:
<ol style="list-style-type: decimal">
<li>option to select existing site or specify point by lat/lon</li>
<li>option to specify a bounding box and grid resolution in
either lat/lon or polar stereographic.</li>
</ol></li>
<li>asked to specify start and end times in terms of year, month, day, hour, minute. Time is recorded in UTC not local time, this should be indicated.</li>
</ol>
</div>
<div id="closing-an-issue" class="section level3">
<h3><span class="header-section-number">2.20.3</span> Closing an issue</h3>
<ol style="list-style-type: decimal">
<li>Definition of “Done”</li>
</ol>
<ul>
<li>test</li>
<li>documentation</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>when issue is resolved:</li>
</ol>
<ul>
<li>status is changed to “resolved”</li>
<li>assignee is changed to original author</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>if original author agrees that issue has been resolved</li>
</ol>
<ul>
<li>original author changes status to “closed”</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>except for trivial issues, issues are only closed by the author</li>
</ol>
</div>
<div id="when-to-submit-an-issue" class="section level3">
<h3><span class="header-section-number">2.20.4</span> When to submit an issue?</h3>
<div id="ideally-non-trivial-code-changes-will-be-linked-to-an-issue-and-a-commit." class="section level4">
<h4><span class="header-section-number">2.20.4.1</span> Ideally, non-trivial code changes will be linked to an issue and a commit.</h4>
<p>This requires creating issues for each task, making small commits, and referencing the issue within your commit message. Issues can be created <a href="https://github.com/PecanProject/pecan/issues/new">on GitHub</a>. These issues can be linked to commits by adding text such as <code>fixes gh-5</code>).</p>
<p>Rationale: This workflow is a small upfront investment that reduces error and time spent re-creating and debugging errors. Associating issues and commits, makes it easier to identify why a change was made, and potential bugs that could arise when the code is changed. In addition, knowing which issue you are working on clarifies the scope and objectives of your current task.</p>

</div>
</div>
</div>
<div id="coding-practices" class="section level2">
<h2><span class="header-section-number">2.21</span> Coding Practices</h2>

</div>
<div id="coding-style" class="section level2">
<h2><span class="header-section-number">2.22</span> Coding Style</h2>
<p>Consistent coding style improves readability and reduces errors in
shared code.</p>
<p>R does not have an official style guide, but Hadley Wickham provides one that is well
thought out and widely adopted. <a href="http://r-pkgs.had.co.nz/style.html">Advanced R: Coding Style</a>.</p>
<p>Both the Wickham text and this page are derived from <a href="https://google.github.io/styleguide/Rguide.xml">Google’s R Style Guide</a>.</p>
<div id="use-roxygen2-documentation" class="section level3">
<h3><span class="header-section-number">2.22.1</span> Use Roxygen2 documentation</h3>
<p>This is the standard method of documentation used in PEcAn development,
it provides inline documentation similar to doxygen. Even trivial
functions should be documented.</p>
<p>See <a href="Roxygen2.md">Roxygen2</a> Wiki page</p>
</div>
<div id="write-your-name-at-the-top" class="section level3">
<h3><span class="header-section-number">2.22.2</span> Write your name at the top</h3>
<p>Any function that you create or make a meaningful contribution to should
have your name listed after the author tag in the function documentation.</p>
</div>
<div id="use-testthat-testing-package" class="section level3">
<h3><span class="header-section-number">2.22.3</span> Use testthat testing package</h3>
<p>See <a href="Testing.md">Unit_Testing</a> wiki for instructions, and <a href="http://r-pkgs.had.co.nz/tests.html">Advanced R: Tests</a>.</p>
<ul>
<li>tests provide support for documentation - they define what a function is (and is not) expected to do</li>
<li>all functions need tests to ensure basic functionality is maintained during development.</li>
<li>all bugs should have a test that reproduces the bug, and the test should pass before bug is closed</li>
</ul>
</div>
<div id="dont-use-shortcuts" class="section level3">
<h3><span class="header-section-number">2.22.4</span> Don’t use shortcuts</h3>
<p>R provides many shortcuts that are useful when coding interactively, or for writing scripts. However, these can make code more difficult to read and can cause problems when written into packages.</p>
<div id="function-names-verb.noun" class="section level4">
<h4><span class="header-section-number">2.22.4.1</span> Function Names (<code>verb.noun</code>)</h4>
<p>Following convention established in PEcAn 0.1, we use the all lowercase with periods to separate words. They should generally have a <code>verb.noun</code> format, such as <code>query.traits</code>, <code>get.samples</code>, etc.</p>
</div>
<div id="file-names" class="section level4">
<h4><span class="header-section-number">2.22.4.2</span> File Names</h4>
<p>File names should end in <code>.R</code>, <code>.Rdata</code>, <code>.Rscript</code> and should be meaningful, e.g. named after the primary functions that they contain. There should be a separate file for each major high-level function to aid in identifying the contents of files in a directory.</p>
</div>
<div id="use---as-an-assignment-operator" class="section level4">
<h4><span class="header-section-number">2.22.4.3</span> Use “&lt;-” as an assignment operator</h4>
<ul>
<li>Because most R code uses &lt;- (except where = is required), we will use &lt;-</li>
<li>“=” is used for function arguments</li>
</ul>
</div>
<div id="use-spaces" class="section level4">
<h4><span class="header-section-number">2.22.4.4</span> Use Spaces</h4>
<ul>
<li>around all binary operators (=, +, -, &lt;-, etc.).</li>
<li>after but not before a comma</li>
</ul>
</div>
<div id="use-curly-braces" class="section level4">
<h4><span class="header-section-number">2.22.4.5</span> Use curly braces</h4>
<p>The option to omit curly braces is another shortcut that makes code easier to write but harder to read and more prone to error.</p>
</div>
</div>
<div id="package-dependencies" class="section level3">
<h3><span class="header-section-number">2.22.5</span> Package Dependencies:</h3>
<div id="library-vs-require" class="section level4">
<h4><span class="header-section-number">2.22.5.1</span> library vs require</h4>
<p>When another package is required by a function or script, it can be called in the following ways:</p>
<p>(As a package dependency loads with the package, these should be the default approaches when writing functions in a package. There can be some exceptions, such as when a rarely-used or non-essential function requires an esoteric package.)
1. When using <code>library</code>,
if dependency is not met, it will print an error and stop
2. When using <code>require</code>, it
will print a warning and continue (but will throw an error when a function from the required package is called)</p>
<p>Reference: Stack Overflow <a href="http://stackoverflow.com/questions/5595512/what-is-the-difference-between-require-and-library">“What is the difference between require and library?”</a></p>
</div>
<div id="depends-suggests-imports" class="section level4">
<h4><span class="header-section-number">2.22.5.2</span> DEPENDS, SUGGESTS, IMPORTS</h4>
<p>It is considered best practice to use DEPENDS and SUGGESTS in DESCRIPTION; SUGGESTS should be used for packages that are called infrequently, or only in examples and vignettes; suggested packages are called by require inside a function.</p>
<p>Consider using IMPORTS instead of depends in the DESCRIPTION files. This will make loading packages faster by allowing it to have functions available without loading the hierarchy of dependencies, dependencies of dependencies, ad infinitum …
From p. 6 of the “R extensions manual”:<a href="http://cran.r-project.org/doc/manuals/R-exts.html" class="uri">http://cran.r-project.org/doc/manuals/R-exts.html</a></p>
<blockquote>
<p>The <code>Suggests</code> field uses the same syntax as <code>Depends</code> and lists packages that are not necessarily needed. This includes packages used only in examples, tests or vignettes (see Section 1.4 [Writing package vignettes], page 26), and packages loaded in the body of functions. E.g., suppose an example from package foo uses a dataset from package bar. Then it is not necessary to have bar use foo unless one wants to execute all the examples/tests/vignettes: it is useful to have bar, but not necessary. Version requirements can be specified, and will be used by R CMD check.</p>
</blockquote>

</div>
</div>
</div>
<div id="logging" class="section level2">
<h2><span class="header-section-number">2.23</span> Logging</h2>
<p>During development we often add many print statements to check to see how the code is doing, what is happening, what intermediate results there are etc. When done with the development it would be nice to turn this additional code off, but have the ability to quickly turn it back on if we discover a problem. This is where logging comes into play. Logging allows us to use “rules” to say what information should be shown. For example when I am working on the code to create graphs, I do not have to see any debugging information about the SQL command being sent, however trying to figure out what goes wrong during a SQL statement it would be nice to show the SQL statements without adding any additional code.</p>
<div id="pecan-logging-functions" class="section level3">
<h3><span class="header-section-number">2.23.1</span> PEcAn logging functions</h3>
<p>These <code>logger</code> family of functions are more sophisticated, and can be used in place of <code>stop</code>, <code>warn</code>, <code>print</code>, and similar functions. The <code>logger</code> functions make it easier to print to a system log file.</p>
<div id="examples" class="section level4">
<h4><span class="header-section-number">2.23.1.1</span> Examples</h4>
<ul>
<li>The file <a href="../blob/master/utils/inst/tests/test.logger.R">test.logger.R</a> provides descriptive examples</li>
<li>This query provides an current overview of <a href="https://github.com/PecanProject/pecan/search?q=logger&amp;ref=cmdform">functions that use logging</a></li>
<li>logger functions (in order of increasing level):</li>
<li><code>logger.debug</code></li>
<li><code>logger.info</code></li>
<li><code>logger.warn</code></li>
<li><code>logger.error</code></li>
<li>the <code>logger.setLevel</code> function sets the level at which a message will be printed</li>
<li><code>logger.setLevel(&quot;DEBUG&quot;)</code> will print messages from all logger functions</li>
<li><code>logger.setLevel(&quot;ERROR&quot;)</code> will only print messages from <code>logger.error</code></li>
<li><code>logger.setLevel(&quot;INFO&quot;)</code> and <code>logger.setLevel(&quot;WARN&quot;) shows messages from</code>logger.<level><code>and higher functions, e.g.</code>logger.setLevel(“WARN”)<code>shows messages from</code>logger.warn<code>and</code>logger.error`</li>
<li><code>logger.setLevel(&quot;OFF&quot;)</code> suppresses all logger messages</li>
<li>To print all messages to console, use <code>logger.setUseConsole(TRUE)</code></li>
</ul>
</div>
<div id="related-issues-requires-redmine-developer-account" class="section level4">
<h4><span class="header-section-number">2.23.1.2</span> Related Issues (requires Redmine developer account)</h4>
<ul>
<li><a href="https://ebi-forecast.igb.illinois.edu/redmine/issues/1071">#1071 How to handle errors?</a></li>
<li><a href="https://ebi-forecast.igb.illinois.edu/redmine/issues/1222">#1222 Ignore warnings</a>
You can use <span class="citation">@logger.setLevel</span>(“ERROR”)@ to only show error messages. All the code that does not use logger will not be filtered.</li>
</ul>
</div>
</div>
<div id="other-r-logging-packages" class="section level3">
<h3><span class="header-section-number">2.23.2</span> Other R logging packages</h3>
<ul>
<li><strong>This section is for reference - these functions should not be used in PEcAn, as they are redundant with the <code>logger.*</code> functions described above</strong></li>
</ul>
<p>R does provide a basic logging capability using stop, warning and message. These allow to print message (and stop execution in case of stop). However there is not an easy method to redirect the logging information to a file, or turn the logging information on and off. This is where one of the following packages comes into play. The packages themselves are very similar since they try to emulate log4j.</p>
<p>Both of the following packages use a hierarchic loggers, meaning that if you change the level of displayed level of logging at one level all levels below it will update their logging.</p>
<div id="logging-1" class="section level4">
<h4><span class="header-section-number">2.23.2.1</span> logging</h4>
The logging development is done at <a href="http://logging.r-forge.r-project.org/" class="uri">http://logging.r-forge.r-project.org/</a> and more information is located at <a href="http://cran.r-project.org/web/packages/logging/index.html" class="uri">http://cran.r-project.org/web/packages/logging/index.html</a> . To install use the following command:
<pre>
install.packages("logging", repos="http://R-Forge.R-project.org")
</pre>
<p>This has my preference pure based on documentation.</p>
</div>
<div id="futile" class="section level4">
<h4><span class="header-section-number">2.23.2.2</span> futile</h4>
<p>The second logging package is <a href="http://cran.r-project.org/web/packages/futile.logger/" class="uri">http://cran.r-project.org/web/packages/futile.logger/</a> and is eerily similar to logging (as a matter of fact logging is based on futile).</p>
</div>
</div>
<div id="example-usage" class="section level3">
<h3><span class="header-section-number">2.23.3</span> Example Usage</h3>
<p>To be able to use the loggers there needs to be some initialization done. Neither package allows to read it from a configuration file, so we might want to use the pecan.xml file to set it up. The setup will always be somewhat the same:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load library</span>
<span class="kw">library</span>(logging)
<span class="kw">logReset</span>()

<span class="co"># add handlers, responsible for actually printing/saving the messages</span>
<span class="kw">addHandler</span>(writeToConsole)
<span class="kw">addHandler</span>(writeToFile, <span class="dt">file=</span><span class="st">&quot;file.log&quot;</span>)

<span class="co"># setup root logger with INFO</span>
<span class="kw">setLevel</span>(<span class="st">&#39;INFO&#39;</span>)

<span class="co"># make all of PEcAn print debug messages</span>
<span class="kw">setLevel</span>(<span class="st">&#39;DEBUG&#39;</span>, <span class="kw">getLogger</span>(<span class="st">&#39;PEcAn&#39;</span>))

<span class="co"># only print info and above for the SQL part of PEcAn</span>
<span class="kw">setLevel</span>(<span class="st">&#39;INFO&#39;</span>, <span class="kw">getLogger</span>(<span class="st">&#39;PEcAn.SQL&#39;</span>))</code></pre>
<p>To now use logging in the code you can use the following code:</p>
<pre class="sourceCode r"><code class="sourceCode r">pl &lt;-<span class="st"> </span><span class="kw">getLogger</span>(<span class="st">&#39;PEcAn.MetaAnalysis.function1&#39;</span>)
pl<span class="op">$</span><span class="kw">info</span>(<span class="st">&quot;This is an INFO message.&quot;</span>)
pl<span class="op">$</span><span class="kw">debug</span>(<span class="st">&quot;The value for x=%d&quot;</span>, x)
pl<span class="op">$</span><span class="kw">error</span>(<span class="st">&quot;Something bad happened and I am scared now.&quot;</span>)</code></pre>
<p>or</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">loginfo</span>(<span class="st">&quot;This is an INFO message.&quot;</span>, <span class="dt">logger=</span><span class="st">&quot;PEcAn.MetaAnalysis.function1&quot;</span>)
<span class="kw">logdebug</span>(<span class="st">&quot;The value for x=%d&quot;</span>, x, <span class="dt">logger=</span><span class="st">&quot;PEcAn.MetaAnalysis.function1&quot;</span>)
<span class="kw">logerror</span>(<span class="st">&quot;Something bad happened and I am scared now.&quot;</span>, <span class="dt">logger=</span><span class="st">&quot;PEcAn.MetaAnalysis.function1&quot;</span>)</code></pre>

</div>
</div>
<div id="package-data" class="section level2">
<h2><span class="header-section-number">2.24</span> Package Data</h2>
<div id="summary" class="section level3">
<h3><span class="header-section-number">2.24.1</span> Summary:</h3>
<p>Files with the following extensions will be read by R as data:</p>
<ul>
<li>plain R code in .R and .r files are sourced using <code>source()</code></li>
<li>text tables in .tab, .txt, .csv files are read using <code>read()</code>
** objects in R image files: .RData, .rda are loaded using <code>load()</code></li>
<li>capitalization matters</li>
<li>all objects in foo.RData are loaded into environment</li>
<li>pro: easiset way to store objects in R format</li>
<li>con: format is application (R) specific (<a href="https://ebi-forecast.igb.illinois.edu/redmine/issues/318">discussed in #318</a>)</li>
</ul>
<p>Details are in <code>?data</code>, which is mostly a copy of <a href="http://cran.r-project.org/doc/manuals/R-exts.html#Data-in-packages">Data section of
Writing R
Extensions</a>.</p>
</div>
<div id="accessing-data" class="section level3">
<h3><span class="header-section-number">2.24.2</span> Accessing data</h3>
<p>Data in the [data] directory will be accessed in the following ways,</p>
<ul>
<li>efficient way: (especially for large data sets) using the <code>data</code>
function:</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(foo) <span class="co"># accesses data with, e.g. load(foo.RData), read(foo.csv), or source(foo.R) </span></code></pre>
<ul>
<li>easy way: by adding the following line to the package DESCRIPTION:
<em>note:</em> this should be used with caution or it can cause difficulty as discussed in redmine issue #1118</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">LazyData<span class="op">:</span><span class="st"> </span><span class="ot">TRUE</span></code></pre>
<p>From the R help page:</p>
<p>Currently, a limited number of data formats can be accessed using the <code>data</code> function by placing one of the following filetypes in a packages’ <code>data</code> directory:
* files ending <code>.R</code> or <code>.r</code> are <code>source()</code>d in, with the R working
directory changed temporarily to the directory containing the respective
file. (<code>data</code> ensures that the <code>utils</code> package is attached, in case it
had been run <em>via</em> <code>utils::data</code>.)
* files ending <code>.RData</code> or <code>.rda</code> are <code>load()</code>ed.
* files ending <code>.tab</code>, <code>.txt</code> or <code>.TXT</code> are read using <code>read.table(..., header = TRUE)</code>, and hence result in a data frame.
* files ending <code>.csv</code> or <code>.CSV</code> are read using <code>read.table(..., header = TRUE, sep = ';')</code>, and also result in a data frame.</p>
<p>If your data does not fall in those 4 categories, or you can use the
<code>system.file</code> function to get access to the data:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.file</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;ed.trait.dictionary.csv&quot;</span>, <span class="dt">package=</span><span class="st">&quot;PEcAn.utils&quot;</span>)
[<span class="dv">1</span>] <span class="st">&quot;/home/kooper/R/x86_64-pc-linux-gnu-library/2.15/PEcAn.utils/data/ed.trait.dictionary.csv&quot;</span></code></pre>
<p>The arguments are folder, filename(s) and then package. It will return
the fully qualified path name to a file in a package, in this case it
points to the trait data. This is almost the same as the data function,
however we can now use any function to read the file, such as read.csv
instead of read.csv2 which seems to be the default of data. This also
allows us to store arbitrary files in the data folder, such as the the
bug file and load it when we need it.</p>
<div id="examples-of-data-in-pecan-packages" class="section level5">
<h5><span class="header-section-number">2.24.2.0.1</span> Examples of data in PEcAn packages</h5>
<ul>
<li><a href="https://ebi-forecast.igb.illinois.edu/redmine/issues/1060">Redmine issue #1060</a> added time constants in <code>source:utils/data/time.constants.RData</code></li>
<li>outputs: [/modules/uncertainties/data/output.RData]</li>
<li>parameter samples [/modules/uncertainties/data/samples.RData]</li>
</ul>
</div>
</div>
</div>
<div id="packages-used-in-development" class="section level2">
<h2><span class="header-section-number">2.25</span> Packages used in development</h2>
<div id="roxygen2" class="section level4">
<h4><span class="header-section-number">2.25.0.1</span> roxygen2</h4>
<p>Used to document code. See instructions under [[R#Coding_Style|Coding
Style]]</p>
</div>
<div id="devtools" class="section level4">
<h4><span class="header-section-number">2.25.0.2</span> devtools</h4>
<p>Provides functions to simplify development</p>
<p>Documentation:
<a href="https://github.com/hadley/devtools">The R devtools packate</a></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load_all</span>(<span class="st">&quot;pkg&quot;</span>)
<span class="kw">document</span>(<span class="st">&quot;pkg&quot;</span>)
<span class="kw">test</span>(<span class="st">&quot;pkg&quot;</span>)
<span class="kw">install</span>(<span class="st">&quot;pkg&quot;</span>)
<span class="kw">build</span>(<span class="st">&quot;pkg&quot;</span>)</code></pre>
<p>other tips for devtools (from the documentation):</p>
<ul>
<li>Adding the following to your <code>~/.Rprofile</code> will load devtools when
running R in interactive mode:</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load devtools by default</span>
<span class="cf">if</span> (<span class="kw">interactive</span>()) {
  <span class="kw">suppressMessages</span>(<span class="kw">require</span>(devtools))
}</code></pre>
<ul>
<li>Adding the following to your .Rpackages will allow devtools to recognize package by folder name, rather than directory path</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># in this example, devhome is the pecan trunk directory </span>
devhome &lt;-<span class="st"> &quot;/home/dlebauer/R-dev/pecandev/&quot;</span>
<span class="kw">list</span>(
    <span class="dt">default =</span> <span class="cf">function</span>(x) {
      <span class="kw">file.path</span>(devhome, x, x)
    }, 
  <span class="st">&quot;utils&quot;</span> =<span class="st"> </span><span class="kw">paste</span>(devhome, <span class="st">&quot;pecandev/utils&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
  <span class="st">&quot;common&quot;</span> =<span class="st"> </span><span class="kw">paste</span>(devhome, <span class="st">&quot;pecandev/common&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
  <span class="st">&quot;all&quot;</span> =<span class="st"> </span><span class="kw">paste</span>(devhome, <span class="st">&quot;pecandev/all&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
  <span class="st">&quot;ed&quot;</span> =<span class="st"> </span><span class="kw">paste</span>(devhome, <span class="st">&quot;pecandev/models/ed&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
  <span class="st">&quot;uncertainty&quot;</span> =<span class="st"> </span><span class="kw">paste</span>(devhome, <span class="st">&quot;modules/uncertainty&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
  <span class="st">&quot;meta.analysis&quot;</span> =<span class="st"> </span><span class="kw">paste</span>(devhome, <span class="st">&quot;modules/meta.analysis&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
  <span class="st">&quot;db&quot;</span> =<span class="st"> </span><span class="kw">paste</span>(devhome, <span class="st">&quot;db&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
)</code></pre>
<p>Now, devtools can take <code>pkg</code> as an argument instead of <code>/path/to/pkg/</code>,
e.g. so you can use <code>build(&quot;pkg&quot;)</code> instead of <code>build(&quot;/path/to/pkg/&quot;)</code></p>

</div>
</div>
<div id="roxygen2-1" class="section level2">
<h2><span class="header-section-number">2.26</span> Roxygen2</h2>
<p>This is the standard method of documentation used in PEcAn development, it provides inline documentation similar to doxygen.</p>
<div id="canonical-references" class="section level3">
<h3><span class="header-section-number">2.26.1</span> Canonical references:</h3>
<ul>
<li>Must Read: R package development by Hadley Wickham:</li>
<li><a href="http://r-pkgs.had.co.nz/man.html"><strong>Object Documentation</strong></a><br />
</li>
<li><a href="http://r-pkgs.had.co.nz/description.html">Package Metadata</a></li>
<li>Roxygen2 Documentation</li>
<li><a href="http://cran.r-project.org/web/packages/roxygen2/roxygen2.pdf">Roxygen2 Package Documentation</a></li>
<li><a href="https://github.com/klutometis/roxygen">GitHub</a></li>
</ul>
</div>
<div id="basic-roxygen2-instructions" class="section level3">
<h3><span class="header-section-number">2.26.2</span> Basic Roxygen2 instructions:</h3>
<p>Section headers link to “Writing R extensions” which provides in-depth documentation. This is provided as an overview and quick reference.</p>
<div id="tags-1" class="section level4">
<h4><span class="header-section-number">2.26.2.1</span> <a href="http://cran.r-project.org/doc/manuals/R-exts.html#Documenting-functions">Tags</a></h4>
<ul>
<li>tags are preceeded by <code>##'</code></li>
<li>tags required by R:
** <code>title</code> tag is required, along with actual title
** <code>param</code> one for each parameter, should be defined
** <code>return</code> must state what function returns (or nothing, if something occurs as a side effect</li>
<li>tags strongly suggested for most functions:
** <code>author</code>
** <code>examples</code> can be similar to test cases.</li>
<li>optional tags:
** <code>export</code> required if function is used by another package
** <code>import</code> can import a required function from another package (if package is not loaded or other function is not exported)
** <code>seealso</code> suggests related functions. These can be linked using <code>\code{link{}}</code></li>
</ul>
</div>
<div id="text-markup" class="section level4">
<h4><span class="header-section-number">2.26.2.2</span> Text markup</h4>
<div id="formatting" class="section level5">
<h5><span class="header-section-number">2.26.2.2.1</span> <a href="http://cran.r-project.org/doc/manuals/R-exts.html#Marking-text">Formatting</a></h5>
<ul>
<li><code>\bold{}</code></li>
<li><code>\emph{}</code> italics</li>
</ul>
</div>
<div id="links" class="section level5">
<h5><span class="header-section-number">2.26.2.2.2</span> <a href="http://cran.r-project.org/doc/manuals/R-exts.html#Marking-text">Links</a></h5>
<ul>
<li><code>\url{www.url.com}</code> or <code>\href{url}{text}</code> for links</li>
<li><code>\code{\link{thisfn}}</code> links to function “thisfn” in the same package</li>
<li><code>\code{\link{foo::thatfn}}</code> links to function “thatfn” in package “foo”</li>
<li><code>\pkg{package_name}</code></li>
</ul>
</div>
<div id="math" class="section level5">
<h5><span class="header-section-number">2.26.2.2.3</span> <a href="http://cran.r-project.org/doc/manuals/R-exts.html#Mathematics">Math</a></h5>
<ul>
<li><code>\eqn{a+b=c}</code> uses LaTex to format an inline equation</li>
<li><code>\deqn{a+b=c}</code> uses LaTex to format displayed equation</li>
<li><code>\deqn{latex}{ascii}</code> and <code>\eqn{latex}{ascii}</code> can be used to provide different versions in latex and ascii.</li>
</ul>
</div>
<div id="lists" class="section level5">
<h5><span class="header-section-number">2.26.2.2.4</span> <a href="http://cran.r-project.org/doc/manuals/R-exts.html#Lists-and-tables">Lists</a></h5>
<pre><code>\enumerate{
\item A database consists of one or more records, each with one or
more named fields.
\item Regular lines start with a non-whitespace character.
\item Records are separated by one or more empty lines.
}
\itemize and \enumerate commands may be nested.</code></pre>
</div>
<div id="tableshttpcran.r-project.orgdocmanualsr-exts.htmllists-and-tables" class="section level5">
<h5><span class="header-section-number">2.26.2.2.5</span> “Tables”:<a href="http://cran.r-project.org/doc/manuals/R-exts.html#Lists-and-tables" class="uri">http://cran.r-project.org/doc/manuals/R-exts.html#Lists-and-tables</a></h5>
<pre><code>\tabular{rlll}{
[,1] \tab Ozone \tab numeric \tab Ozone (ppb)\cr
[,2] \tab Solar.R \tab numeric \tab Solar R (lang)\cr
[,3] \tab Wind \tab numeric \tab Wind (mph)\cr
[,4] \tab Temp \tab numeric \tab Temperature (degrees F)\cr
[,5] \tab Month \tab numeric \tab Month (1--12)\cr
[,6] \tab Day \tab numeric \tab Day of month (1--31)
}</code></pre>
</div>
</div>
</div>
<div id="example" class="section level3">
<h3><span class="header-section-number">2.26.3</span> Example</h3>
<p>Here is an example documented function, myfun</p>
<pre><code>##&#39; My function adds three numbers
##&#39;
##&#39; A great function for demonstrating Roxygen documentation
##&#39; @param a numeric
##&#39; @param b numeric
##&#39; @param c numeric
##&#39; @return d, numeric sum of a + b + c
##&#39; @export
##&#39; @author David LeBauer
##&#39; @examples
##&#39; myfun(1,2,3)
##&#39; \dontrun{myfun(NULL)}
myfun &lt;- function(a, b, c){
  d &lt;- a + b + c
  return(d)
}</code></pre>
<p>In emacs, with the cursor inside the function, the keybinding C-x O will generate an outline or update the Roxygen2 documentation.</p>
</div>
<div id="updating-documentation" class="section level3">
<h3><span class="header-section-number">2.26.4</span> Updating documentation</h3>
<ul>
<li>After adding documentation run the following command (replacing common with the name of the folder you want to update):
** In R using devtools to call roxygenize:</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(devtools)
<span class="kw">document</span>(<span class="st">&quot;common&quot;</span>)</code></pre>

</div>
</div>
<div id="testing" class="section level2">
<h2><span class="header-section-number">2.27</span> Testing</h2>
<p>PEcAn uses the testthat package developed by Hadley Wickham. Hadley has
written instructions for using this package in his
<a href="http://adv-r.had.co.nz/Testing.html">Testing</a> chapter.</p>
<div id="rationale" class="section level3">
<h3><span class="header-section-number">2.27.1</span> Rationale</h3>
<ul>
<li>makes development easier</li>
<li>provides working documentation of expected functionality</li>
<li>saves time by allowing computer to take over error checking once a
test has been made</li>
<li>improves code quality</li>
<li>Further reading: <a href="http://arxiv.org/pdf/1210.0530v3.pdf">Aruliah et al 2012 Best Practices for Scientific
Computing</a></li>
</ul>
</div>
<div id="tests-makes-development-easier-and-less-error-prone" class="section level3">
<h3><span class="header-section-number">2.27.2</span> Tests makes development easier and less error prone</h3>
<p>Testing makes it easier to develop by organizing everything you are
already doing anyway - but integrating it into the testing and
documentation. With a codebase like PEcAn, it is often difficult to get
started. You have to figure out</p>
<ul>
<li>what was I doing yesterday?</li>
<li>what do I want to do today?</li>
<li>what existing functions do I need to edit?</li>
<li>what are the arguments to these functions (and what are examples of
valid arguments)</li>
<li>what packages are affected</li>
<li>where is a logical place to put files used in testing</li>
</ul>
</div>
<div id="quick-start" class="section level3">
<h3><span class="header-section-number">2.27.3</span> Quick Start:</h3>
<ul>
<li>decide what you want to do today</li>
<li>identify the issue in github (if none exists, create one)</li>
<li><p>to work on issue 99, create a new branch called “github99” or some descriptive name… Today we will enable an
existing function, <code>make.cheas</code> to make <code>goat.cheddar</code>. We will know
that we are done by the color and taste.</p>
<pre><code>git branch goat-cheddar
git checkout goat-cheddar</code></pre></li>
<li>open existing (or create new) file in <code>inst/tests/</code>. If working on code in “myfunction” or a set of functions in “R/myfile.R”, the file should be named accordingly, e.g. “inst/tests/test.myfile.R”</li>
<li>if you are lucky, the function has already been tested and has some examples.</li>
<li><p>if not, you may need to create a minimal example, often requiring a settings file. The default settings file can be obtained in this way:</p>
<pre class="sourceCode r"><code class="sourceCode r">settings &lt;-<span class="st"> </span><span class="kw">read.settings</span>(<span class="kw">system.file</span>(<span class="st">&quot;extdata/test.settings.xml&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;PEcAn.utils&quot;</span>))</code></pre></li>
<li><p>write what you want to do</p>
<pre><code>test_that(&quot;make.cheas can make cheese&quot;,{
  goat.cheddar &lt;- make.cheas(source = &#39;goat&#39;, style = &#39;cheddar&#39;)
  expect_equal(color(goat.cheddar), &quot;orange&quot;)
  expect_is(object = goat.cheddar, class = &quot;cheese&quot;)
  expect_true(all(c(&quot;sharp&quot;, &quot;creamy&quot;) %in% taste(goat.cheddar)))
}</code></pre></li>
<li>now edit the goat.cheddar function until it makes savory, creamy, orange cheese.</li>
<li>commit often</li>
<li><p>update documentation and test</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(devtools)
<span class="kw">document</span>(<span class="st">&quot;mypkg&quot;</span>)
<span class="kw">test</span>(<span class="st">&quot;mypkg&quot;</span>)</code></pre></li>
<li>commit again</li>
<li><p>when complete, merge, and push</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="fu">git</span> commit -m <span class="st">&quot;make.cheas makes goat.cheddar now&quot;</span>
<span class="fu">git</span> checkout master
<span class="fu">git</span> merge goat-cheddar
<span class="fu">git</span> push</code></pre></li>
</ul>
</div>
<div id="test-files" class="section level3">
<h3><span class="header-section-number">2.27.4</span> Test files</h3>
<p>Many of PEcAn’s functions require inputs that are provided as data.
These can be in the <code>/data</code> or the <code>/inst/extdata</code> folders of a package.
Data that are not package specific should be placed in the PEcAn.all or
PEcAn.utils files.</p>
<p>Some useful conventions:</p>
<div id="settings" class="section level4">
<h4><span class="header-section-number">2.27.4.1</span> Settings</h4>
<ul>
<li>A generic settings can be found in the PEcAn.all package</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">settings.xml &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;pecan.biocro.xml&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;PEcAn.BIOCRO&quot;</span>)
settings &lt;-<span class="st"> </span><span class="kw">read.settings</span>(settings.xml)</code></pre>
<ul>
<li>database settings can be specified, and tests run only if a connection is available</li>
</ul>
<p>We currently use the following database to run tests against; tests that require access to a database should check <code>db.exists()</code> and be skipped if it returns FALSE to avoid failed tests on systems that do not have the database installed.</p>
<pre class="sourceCode r"><code class="sourceCode r">settings<span class="op">$</span>database &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">userid =</span> <span class="st">&quot;bety&quot;</span>, 
                          <span class="dt">passwd =</span> <span class="st">&quot;bety&quot;</span>, 
                          <span class="dt">name =</span> <span class="st">&quot;bety&quot;</span>,     <span class="co"># database name </span>
                          <span class="dt">host =</span> <span class="st">&quot;localhost&quot;</span> <span class="co"># server name)</span>
<span class="kw">test_that</span>(..., {
  <span class="kw">skip_if_not</span>(<span class="kw">db.exists</span>(settings<span class="op">$</span>database))
  ## write tests here
})</code></pre>
<ul>
<li>instructions for installing this are available on the <a href="VM-Creation.md">VM creation
wiki</a></li>
<li><p>examples can be found in the PEcAn.DB package (<code>base/db/tests/testthat/</code>).</p></li>
<li><p>Model specific settings can go in the model-specific module, for
example:</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">settings.xml &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata/pecan.biocro.xml&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;PEcAn.BIOCRO&quot;</span>)
settings &lt;-<span class="st"> </span><span class="kw">read.settings</span>(settings.xml)</code></pre>
<ul>
<li>test-specific settings:
<ul>
<li><p>settings text can be specified inline:</p>
<pre><code>settings.text &lt;- &quot;
  &lt;pecan&gt;
    &lt;nocheck&gt;nope&lt;/nocheck&gt; ## allows bypass of checks in the read.settings functions
    &lt;pfts&gt;
      &lt;pft&gt;
        &lt;name&gt;ebifarm.pavi&lt;/name&gt;
        &lt;outdir&gt;test/&lt;/outdir&gt;
      &lt;/pft&gt;
    &lt;/pfts&gt;
    &lt;outdir&gt;test/&lt;/outdir&gt;
    &lt;database&gt;
      &lt;userid&gt;bety&lt;/userid&gt;
      &lt;passwd&gt;bety&lt;/passwd&gt;
      &lt;location&gt;localhost&lt;/location&gt;
      &lt;name&gt;bety&lt;/name&gt;
    &lt;/database&gt;
  &lt;/pecan&gt;&quot;
settings &lt;- read.settings(settings.text)</code></pre></li>
<li><p>values in settings can be updated:</p>
<pre class="sourceCode r"><code class="sourceCode r">settings &lt;-<span class="st"> </span><span class="kw">read.settings</span>(settings.text)
settings<span class="op">$</span>outdir &lt;-<span class="st"> &quot;/tmp&quot;</span> ## or any other settings</code></pre></li>
</ul></li>
</ul>
</div>
<div id="helper-functions-created-to-make-testing-easier" class="section level4">
<h4><span class="header-section-number">2.27.4.2</span> Helper functions created to make testing easier</h4>
<ul>
<li><strong>tryl</strong> returns FALSE if function gives error</li>
<li><strong>temp.settings</strong> creates temporary settings file</li>
<li><strong>test.remote</strong> returns TRUE if remote connection is available</li>
<li><strong>db.exists</strong> returns TRUE if connection to database is available</li>
</ul>
</div>
<div id="when-should-i-test" class="section level4">
<h4><span class="header-section-number">2.27.4.3</span> When should I test?</h4>
<p>A test <em>should</em> be written for each of the following situations:</p>
<ol style="list-style-type: decimal">
<li>Each bug should get a regression test.</li>
</ol>
<ul>
<li>The first step in handling a bug is to write code that reproduces the error</li>
<li>This code becomes the test</li>
<li>most important when error could re-appear</li>
<li>essential when error silently produces invalid results</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Every time a (non-trivial) function is created or edited</li>
</ol>
<ul>
<li>Write tests that indicate how the function should perform
<ul>
<li>example: <code>expect_equal(sum(1,1), 2)</code> indicates that the sum
function should take the sum of its arguments</li>
</ul></li>
<li>Write tests for cases under which the function should throw an
error</li>
<li>example: <code>expect_error(sum(&quot;foo&quot;))</code></li>
<li>better : <code>expect_error(sum(&quot;foo&quot;), &quot;invalid 'type' (character)&quot;)</code></li>
</ul>
</div>
<div id="what-types-of-testing-are-important-to-understand" class="section level4">
<h4><span class="header-section-number">2.27.4.4</span> What types of testing are important to understand?</h4>
</div>
<div id="unit-testing-test-driven-development" class="section level4">
<h4><span class="header-section-number">2.27.4.5</span> Unit Testing / Test Driven Development</h4>
<p>Tests are only as good as the test</p>
<ol style="list-style-type: decimal">
<li>write test</li>
<li>write code</li>
</ol>
</div>
<div id="regression-testing" class="section level4">
<h4><span class="header-section-number">2.27.4.6</span> Regression Testing</h4>
<p>When a bug is found,</p>
<ol style="list-style-type: decimal">
<li>write a test that finds the bug (the minimum test required to make
the test fail)</li>
<li>fix the bug</li>
<li>bug is fixed when test passes</li>
</ol>
</div>
<div id="how-should-i-test-in-r-the-testthat-package." class="section level4">
<h4><span class="header-section-number">2.27.4.7</span> How should I test in R? The testthat package.</h4>
<p>tests are found in <code>~/pecan/&lt;packagename&gt;/inst/tests</code>, for example
<code>utils/inst/tests/</code></p>
<p>See attached file and
<a href="http://r-pkgs.had.co.nz/tests.html" class="uri">http://r-pkgs.had.co.nz/tests.html</a>
for details on how to use the testthat package.</p>
<div id="list-of-expectations" class="section level5">
<h5><span class="header-section-number">2.27.4.7.1</span> List of Expectations</h5>
<table>
<thead>
<tr class="header">
<th>Full</th>
<th>Abbreviation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>expect_that(x, is_true())</td>
<td>expect_true(x)</td>
</tr>
<tr class="even">
<td>expect_that(x, is_false())</td>
<td>expect_false(x)</td>
</tr>
<tr class="odd">
<td>expect_that(x, is_a(y))</td>
<td>expect_is(x, y)</td>
</tr>
<tr class="even">
<td>expect_that(x, equals(y))</td>
<td>expect_equal(x, y)</td>
</tr>
<tr class="odd">
<td>expect_that(x, is_equivalent_to(y))</td>
<td>expect_equivalent(x, y)</td>
</tr>
<tr class="even">
<td>expect_that(x, is_identical_to(y))</td>
<td>expect_identical(x, y)</td>
</tr>
<tr class="odd">
<td>expect_that(x, matches(y))</td>
<td>expect_matches(x, y)</td>
</tr>
<tr class="even">
<td>expect_that(x, prints_text(y))</td>
<td>expect_output(x, y)</td>
</tr>
<tr class="odd">
<td>expect_that(x, shows_message(y))</td>
<td>expect_message(x, y)</td>
</tr>
<tr class="even">
<td>expect_that(x, gives_warning(y))</td>
<td>expect_warning(x, y)</td>
</tr>
<tr class="odd">
<td>expect_that(x, throws_error(y))</td>
<td>expect_error(x, y)</td>
</tr>
</tbody>
</table>
</div>
<div id="how-to-run-tests" class="section level5">
<h5><span class="header-section-number">2.27.4.7.2</span> How to run tests</h5>
<p>add the following to “pecan/tests/testthat.R”</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(testthat)
<span class="kw">library</span>(mypackage)

<span class="kw">test_check</span>(<span class="st">&quot;mypackage&quot;</span>)</code></pre>
</div>
</div>
<div id="basic-use-of-the-testthat-package" class="section level4">
<h4><span class="header-section-number">2.27.4.8</span> basic use of the testthat package</h4>
<p>Here is an example of tests (these should be placed in
<code>&lt;packagename&gt;/tests/testthat/test-&lt;sourcefilename&gt;.R</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">test_that</span>(<span class="st">&quot;mathematical operators plus and minus work as expected&quot;</span>,{
  <span class="kw">expect_equal</span>(<span class="kw">sum</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dv">2</span>)
  <span class="kw">expect_equal</span>(<span class="kw">sum</span>(<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>), <span class="dv">-2</span>)
  <span class="kw">expect_equal</span>(<span class="kw">sum</span>(<span class="dv">1</span>,<span class="ot">NA</span>), <span class="ot">NA</span>)
  <span class="kw">expect_error</span>(<span class="kw">sum</span>(<span class="st">&quot;cat&quot;</span>))
  <span class="kw">set.seed</span>(<span class="dv">0</span>)
  <span class="kw">expect_equal</span>(<span class="kw">sum</span>(<span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>)), <span class="kw">sum</span>(<span class="kw">data.frame</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>)))
})

<span class="kw">test_that</span>(<span class="st">&quot;different testing functions work, giving excuse to demonstrate&quot;</span>,{
  <span class="kw">expect_identical</span>(<span class="dv">1</span>, <span class="dv">1</span>)
  <span class="kw">expect_identical</span>(<span class="kw">numeric</span>(<span class="dv">1</span>), <span class="kw">integer</span>(<span class="dv">1</span>))
  <span class="kw">expect_equivalent</span>(<span class="kw">numeric</span>(<span class="dv">1</span>), <span class="kw">integer</span>(<span class="dv">1</span>))
  <span class="kw">expect_warning</span>(<span class="kw">mean</span>(<span class="st">&#39;1&#39;</span>))
  <span class="kw">expect_that</span>(<span class="kw">mean</span>(<span class="st">&#39;1&#39;</span>), <span class="kw">gives_warning</span>(<span class="st">&quot;argument is not numeric or logical: returning NA&quot;</span>))
  <span class="kw">expect_warning</span>(<span class="kw">mean</span>(<span class="st">&#39;1&#39;</span>), <span class="st">&quot;argument is not numeric or logical: returning NA&quot;</span>)
  <span class="kw">expect_message</span>(<span class="kw">message</span>(<span class="st">&quot;a&quot;</span>), <span class="st">&quot;a&quot;</span>)
})</code></pre>
<div id="script-testing" class="section level5">
<h5><span class="header-section-number">2.27.4.8.1</span> Script testing</h5>
<p>It is useful to add tests to a script during development. This allows
you to test that the code is doing what you expect it to do.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="op">*</span><span class="st"> </span>here is a fake script using the iris data set

<span class="kw">test_that</span>(<span class="st">&quot;the iris data set has the same basic features as before&quot;</span>,{
  <span class="kw">expect_equal</span>(<span class="kw">dim</span>(iris), <span class="kw">c</span>(<span class="dv">150</span>,<span class="dv">5</span>))
  <span class="kw">expect_that</span>(iris<span class="op">$</span>Sepal.Length, <span class="kw">is_a</span>(<span class="st">&quot;numeric&quot;</span>))
  <span class="kw">expect_is</span>(iris<span class="op">$</span>Sepal.Length, <span class="st">&quot;numeric&quot;</span>)<span class="co">#equivalent to prev. line</span>
  <span class="kw">expect_is</span>(iris<span class="op">$</span>Species, <span class="st">&quot;factor&quot;</span>)
})

iris.color &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Species =</span> <span class="kw">c</span>(<span class="st">&quot;setosa&quot;</span>, <span class="st">&quot;versicolor&quot;</span>, <span class="st">&quot;virginica&quot;</span>),
                         <span class="dt">color =</span> <span class="kw">c</span>(<span class="st">&quot;pink&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;orange&quot;</span>))

newiris &lt;-<span class="st"> </span><span class="kw">merge</span>(iris, iris.color)
iris.model &lt;-<span class="st"> </span><span class="kw">lm</span>(Petal.Length <span class="op">~</span><span class="st"> </span>color, <span class="dt">data =</span> newiris)

<span class="kw">test_that</span>(<span class="st">&quot;changes to Iris code occurred as expected&quot;</span>,{
  <span class="kw">expect_that</span>(<span class="kw">dim</span>(newiris), <span class="kw">equals</span>(<span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">6</span>)))
  <span class="kw">expect_that</span>(<span class="kw">unique</span>(newiris<span class="op">$</span>color),
              <span class="kw">is_identical_to</span>(<span class="kw">unique</span>(iris.color<span class="op">$</span>color)))
  <span class="kw">expect_equivalent</span>(iris.model<span class="op">$</span>coefficients[<span class="st">&quot;(Intercept)&quot;</span>], <span class="fl">4.26</span>)
})</code></pre>
</div>
<div id="function-testing" class="section level5">
<h5><span class="header-section-number">2.27.4.8.2</span> Function testing</h5>
<p>Testing of a new function, <code>as.sequence</code>. The function and documentation
are in source:R/utils.R and the tests are in source:tests/test.utils.R.</p>
<p>Recently, I made the function <code>as.sequence</code> to turn any vector into a
sequence, with custom handling of NA’s:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="cf">function</span>(x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>){
  x2 &lt;-<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">factor</span>(x, <span class="kw">unique</span>(x)))
  <span class="cf">if</span>(<span class="kw">all</span>(<span class="kw">is.na</span>(x2))){
    x2 &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">length</span>(x2))
  }
  <span class="cf">if</span>(na.rm <span class="op">==</span><span class="st"> </span><span class="ot">TRUE</span>){
    x2[<span class="kw">is.na</span>(x2)] &lt;-<span class="st"> </span><span class="kw">max</span>(x2, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
  }
  <span class="kw">return</span>(x2)
}</code></pre>
<p>The next step was to add documentation and test. Many people find it
more efficient to write tests before writing the function. This is true,
but it also requires more discipline. I wrote these tests to handle the
variety of cases that I had observed.</p>
<p>As currently used, the function is exposed to a fairly restricted set of
options - results of downloads from the database and transformations.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">test_that</span>(“as.sequence works”;{
 <span class="kw">expect_identical</span>(<span class="kw">as.sequence</span>(<span class="kw">c</span>(“a”, “b”)), <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)
 <span class="kw">expect_identical</span>(<span class="kw">as.sequence</span>(<span class="kw">c</span>(“a”, <span class="ot">NA</span>)), <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)
 <span class="kw">expect_equal</span>(<span class="kw">as.sequence</span>(<span class="kw">c</span>(“a”, <span class="ot">NA</span>), <span class="dt">na.rm =</span> <span class="ot">FALSE</span>), <span class="kw">c</span>(<span class="dv">1</span>,<span class="ot">NA</span>))
 <span class="kw">expect_equal</span>(<span class="kw">as.sequence</span>(<span class="kw">c</span>(<span class="ot">NA</span>,<span class="ot">NA</span>)), <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))
})</code></pre>
</div>
</div>
</div>
<div id="testing-the-shiny-server" class="section level3">
<h3><span class="header-section-number">2.27.5</span> Testing the Shiny Server</h3>
<p>Shiny can be difficult to debug because, when run as a web service, the R output is hidden in system log files that are hard to find and read.
One useful approach to debugging is to use port forwarding, as follows.</p>
<p>First, on the remote machine (including the VM), make sure R’s working directory is set to the directory of the Shiny app (e.g., <code>setwd(/path/to/pecan/shiny/WorkflowPlots)</code>, or just open the app as an RStudio project).
Then, in the R console, run the app as:</p>
<pre><code>shiny::runApp(port = XXXX)
# E.g. shiny::runApp(port = 5638)</code></pre>
<p>Then, on your local machine, open a terminal and run the following command, matching <code>XXXX</code> to the port above and <code>YYYY</code> to any unused port on your local machine (any 4-digit number should work).</p>
<pre><code>ssh -L YYYY:localhost:XXXX &lt;remote connection&gt;
# E.g., for the PEcAn VM, given the above port:
# ssh -L 5639:localhost:5638 carya@localhost -p 6422</code></pre>
<p>Now, in a web browser on your local machine, browse to <code>localhost:YYYY</code> (e.g., <code>localhost:5639</code>) to run whatever app you started with <code>shiny::runApp</code> in the previous step.
All of the output should display in the R console where the <code>shiny::runApp</code> command was executed.
Note that this includes any <code>print</code>, <code>message</code>, <code>logger.*</code>, etc. statements in your Shiny app.</p>
<p>If the Shiny app hits an R error, the backtrace should include a line like <code>Hit error at of server.R#LXX</code> – that <code>XX</code> being a line number that you can use to track down the error.
To return from the error to a normal R prompt, hit <code>&lt;Control&gt;-C</code> (alternatively, the “Stop” button in RStudio).
To restart the app, run <code>shiny::runApp(port = XXXX)</code> again (keeping the same port).</p>
<p>Note that Shiny runs any code in the <code>pecan/shiny/&lt;app&gt;</code> directory at the moment the app is launched.
So, any changes you make to the code in <code>server.R</code> and <code>ui.R</code> or scripts loaded therein will take effect the next time the app is started.</p>
<p>If for whatever reason this doesn’t work with RStudio, you can always run R from the command line.
Also, note that the ability to forward ports (<code>ssh -L</code>) may depend on the <code>ssh</code> configuration of your remote machine.
These instructions have been tested on the PEcAn VM (v.1.5.2+).</p>

</div>
<div id="download-and-compile-pecan" class="section level3">
<h3><span class="header-section-number">2.27.6</span> Download and Compile PEcAn</h3>
<p>Set <code>R_LIBS_USER</code></p>
<p><a href="http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#Managing-libraries">CRAN Reference</a></p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># point R to personal lib folder</span>
<span class="bu">echo</span> <span class="st">&#39;export R_LIBS_USER=${HOME}/R/library&#39;</span> <span class="op">&gt;&gt;</span> ~/.profile
<span class="bu">source</span> ~/.profile
<span class="fu">mkdir</span> -p <span class="va">${R_LIBS_USER}</span></code></pre>
<div id="download-compile-and-install-pecan-from-github" class="section level4">
<h4><span class="header-section-number">2.27.6.1</span> Download, compile and install PEcAn from GitHub</h4>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># download pecan</span>
<span class="bu">cd</span>
<span class="fu">git</span> clone https://github.com/PecanProject/pecan.git

<span class="co"># compile pecan</span>
<span class="bu">cd</span> pecan
<span class="fu">make</span></code></pre>
<p>For more information on the capabilities of the PEcAn Makefile, check out our section on <a href="tutorialsdemos-and-how-tos.html#updating-pecan">Updating PEcAn</a>.</p>
<p>Following will run a small script to setup some hooks to prevent people from using the pecan demo user account to check in any code.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># prevent pecan user from checking in code</span>
<span class="ex">./scripts/create-hooks.sh</span></code></pre>
</div>
</div>
<div id="pecan-testrun" class="section level3">
<h3><span class="header-section-number">2.27.7</span> PEcAn Testrun</h3>
<p>Do the run, this assumes you have <a href="tutorialsdemos-and-how-tos.html#install-bety">installed the BETY database</a>, <a href="tutorialsdemos-and-how-tos.html#site-information">sites</a> tar file and <a href="topical.html#models-sipnet">SIPNET</a>.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># create folder</span>
<span class="bu">cd</span>
<span class="fu">mkdir</span> testrun.pecan
<span class="bu">cd</span> testrun.pecan

<span class="co"># copy example of pecan workflow and configuration file</span>
<span class="fu">cp</span> ../pecan/tests/pecan32.sipnet.xml pecan.xml
<span class="fu">cp</span> ../pecan/scripts/workflow.R workflow.R

<span class="co"># exectute workflow</span>
<span class="fu">rm</span> -rf pecan
<span class="ex">./workflow.R</span> pecan.xml</code></pre>
<p>NB: pecan.xml is configured for the virtual machine, you will need to change the <met> field from ‘/home/carya/’ to wherever you installed your ‘sites’, usually $HOME</p>

</div>
</div>
<div id="directory-structure" class="section level2">
<h2><span class="header-section-number">2.28</span> Directory structure</h2>
</div>
<div id="overview-of-pecan-repository-as-of-pecan-1.5.3" class="section level2">
<h2><span class="header-section-number">2.29</span> Overview of PEcAn repository as of PEcAn 1.5.3</h2>
<!--Should Also include a guideline to structures so that people know where to put things as they add them-->
<pre><code>pecan/
 +- base/          # Core functions
    +- all         # Dummy package to load all PEcAn R packages
    +- db          # Modules for querying the database
    +- logger      # Report warnings without killing workflows
    +- qaqc        # Model skill testing and integration testing
    +- remote      # Communicate with and execute models on local and remote hosts
    +- settings    # Functions to read and manipulate PEcAn settings files
    +- utils       # Misc. utility functions
    +- visualization # Advanced PEcAn visualization module
    +- workflow    # functions to coordinate analysis steps
 +- book_source/   # Main documentation and developer&#39;s guide
 +- CHANGELOG.md   # Running log of changes in each version of PEcAn
 +- docker/        # Experimental replacement for PEcAn virtual machine
 +- documentation  # index_vm.html, references, other misc.
 +- models/        # Wrappers to run models within PEcAn
    +- ed/         # Wrapper scripts for running ED within PEcAn
    +- sipnet/     # Wrapper scripts for running SIPNET within PEcAn
    +- ...         # Wrapper scripts for running [...] within PEcAn
    +- template/   # Sample wrappers to copy and modify when adding a new model
 +- modules        # Core modules
    +- allometry
    +- data.atmosphere
    +- data.hydrology
    +- data.land
    +- meta.analysis
    +- priors
    +- rtm
    +- uncertainty
    +- ...
 +- scripts        # R and Shell scripts for use with PEcAn
 +- shiny/         # Interactive visualization of model results
 +- tests/         # Settings files for host-specific integration tests
 +- web            # Main PEcAn website files</code></pre>
</div>
<div id="generic-r-package-structure" class="section level2">
<h2><span class="header-section-number">2.30</span> Generic R package structure:</h2>
<p>see the R development wiki for more information on writing code and adding data.</p>
<pre><code> +- DESCRIPTION    # short description of the PEcAn library
 +- R/             # location of R source code
 +- man/           # Documentation (automatically compiled by Roxygen)
 +- inst/          # files to be installed with package that aren&#39;t R functions
    +- extdata/    # misc. data files (in misc. formats)
 +- data/          # data used in testing and examples (saved as *.RData or *.rda files)
 +- NAMESPACE      # declaration of package imports and exports (automatically compiled by Roxygen)
 +- tests/         # PEcAn testing scripts
   +- testthat/    # nearly all tests should use the testthat framework and live here</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="topical.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tonygardella/pecan/edit/release/vtonydoc/book_source/02_demos_tutorials_workflows/00_tutorials_demos_workflows.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
