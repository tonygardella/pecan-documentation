<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>3 Topical Pages | The Predictive Ecosystem Analyzer</title>
  <meta name="description" content="3 Topical Pages | The Predictive Ecosystem Analyzer">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="3 Topical Pages | The Predictive Ecosystem Analyzer" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Topical Pages | The Predictive Ecosystem Analyzer" />
  
  
  

<meta name="author" content="By: PEcAn Team">


<meta name="date" content="2019-02-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="tutorialsdemos-and-how-tos.html">
<link rel="next" href="appendix.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.5/datatables.js"></script>
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
<link href="libs/dt-ext-fixedcolumns-1.10.16/css/fixedColumns.dataTables.min.css" rel="stylesheet" />
<script src="libs/dt-ext-fixedcolumns-1.10.16/js/dataTables.fixedColumns.min.js"></script>
<script src="libs/jszip-1.10.16/jszip.min.js"></script>
<script src="libs/pdfmake-1.10.16/pdfmake.min.js"></script>
<script src="libs/pdfmake-1.10.16/vfs_fonts.js"></script>
<link href="libs/dt-ext-buttons-1.10.16/css/buttons.dataTables.min.css" rel="stylesheet" />
<script src="libs/dt-ext-buttons-1.10.16/js/dataTables.buttons.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.flash.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.html5.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.colVis.min.js"></script>
<script src="libs/dt-ext-buttons-1.10.16/js/buttons.print.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#project-overview"><i class="fa fa-check"></i><b>1.1</b> Project Overview</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#contributor-covenant-code-of-conduct"><i class="fa fa-check"></i><b>1.2</b> Contributor Covenant Code of Conduct</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#about-the-pecan-book"><i class="fa fa-check"></i><b>1.3</b> About the PEcAn Book</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#general-feedbackcommentssuggestions"><i class="fa fa-check"></i><b>1.3.1</b> General Feedback/Comments/Suggestions</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#bookediting"><i class="fa fa-check"></i><b>1.4</b> Editing this book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html"><i class="fa fa-check"></i><b>2</b> Tutorials,Demos and How To’s</a><ul>
<li class="chapter" data-level="2.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-manual-setup"><i class="fa fa-check"></i><b>2.1</b> Install PEcAn</a><ul>
<li class="chapter" data-level="2.1.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecanvm"><i class="fa fa-check"></i><b>2.1.1</b> PEcAn Virtual Machine</a></li>
<li class="chapter" data-level="2.1.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#docker-index"><i class="fa fa-check"></i><b>2.1.2</b> Docker</a></li>
<li class="chapter" data-level="2.1.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#osinstall"><i class="fa fa-check"></i><b>2.1.3</b> OS Specific Installations</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#user-tut"><i class="fa fa-check"></i><b>2.2</b> User Tutorial Section</a><ul>
<li class="chapter" data-level="2.2.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#demo-table"><i class="fa fa-check"></i><b>2.2.1</b> PEcAn Demos</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#web-workflow"><i class="fa fa-check"></i><b>2.3</b> Web workflow</a><ul>
<li class="chapter" data-level="2.3.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#web-site-model"><i class="fa fa-check"></i><b>2.3.1</b> Site and model selection</a></li>
<li class="chapter" data-level="2.3.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#selecting-a-site"><i class="fa fa-check"></i><b>2.3.2</b> Selecting a site</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#web-model-config"><i class="fa fa-check"></i><b>2.4</b> Model configuration</a><ul>
<li class="chapter" data-level="2.4.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#choosing-meteorology"><i class="fa fa-check"></i><b>2.4.1</b> Choosing meteorology</a></li>
<li class="chapter" data-level="2.4.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#selecting-plant-functional-types-pfts-and-other-parameter-groupings."><i class="fa fa-check"></i><b>2.4.2</b> Selecting Plant Functional Types (PFTs) and other parameter groupings.</a></li>
<li class="chapter" data-level="2.4.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#choosing-initial-vegetation"><i class="fa fa-check"></i><b>2.4.3</b> Choosing initial vegetation</a></li>
<li class="chapter" data-level="2.4.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#spin-up"><i class="fa fa-check"></i><b>2.4.4</b> Spin up</a></li>
<li class="chapter" data-level="2.4.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#selecting-a-soils-product"><i class="fa fa-check"></i><b>2.4.5</b> Selecting a soils product</a></li>
<li class="chapter" data-level="2.4.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#other-model-inputs"><i class="fa fa-check"></i><b>2.4.6</b> Other model inputs</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#intermediate-user"><i class="fa fa-check"></i><b>2.5</b> Intermediate user guide</a><ul>
<li class="chapter" data-level="2.5.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#additional-web-configuration"><i class="fa fa-check"></i><b>2.5.1</b> Additional web configuration</a></li>
<li class="chapter" data-level="2.5.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#brown-dog"><i class="fa fa-check"></i><b>2.5.2</b> Brown Dog</a></li>
<li class="chapter" data-level="2.5.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#basic-setups"><i class="fa fa-check"></i><b>2.5.3</b> Basic Setups</a></li>
<li class="chapter" data-level="2.5.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#advanced-setup"><i class="fa fa-check"></i><b>2.5.4</b> Advanced Setup</a></li>
<li class="chapter" data-level="2.5.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#editing-model-configurations"><i class="fa fa-check"></i><b>2.5.5</b> Editing model configurations</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#settings-configured-analyses"><i class="fa fa-check"></i><b>2.6</b> Settings-configured analyses</a><ul>
<li class="chapter" data-level="2.6.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pda"><i class="fa fa-check"></i><b>2.6.1</b> Parameter data assimilation (PDA)</a></li>
<li class="chapter" data-level="2.6.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#sda"><i class="fa fa-check"></i><b>2.6.2</b> State data assimilation (SDA)</a></li>
<li class="chapter" data-level="2.6.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#model-specific-functions-for-sda-workflow"><i class="fa fa-check"></i><b>2.6.3</b> Model Specific Functions for SDA Workflow</a></li>
<li class="chapter" data-level="2.6.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#analysis-options"><i class="fa fa-check"></i><b>2.6.4</b> Analysis Options</a></li>
<li class="chapter" data-level="2.6.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#the-generalized-ensemble-filter"><i class="fa fa-check"></i><b>2.6.5</b> The Generalized Ensemble Filter</a></li>
<li class="chapter" data-level="2.6.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#multi-site-state-data-assimilation."><i class="fa fa-check"></i><b>2.6.6</b> Multi-site State data assimilation.</a></li>
<li class="chapter" data-level="2.6.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#data-products"><i class="fa fa-check"></i><b>2.6.7</b> Data Products</a></li>
<li class="chapter" data-level="2.6.8" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#current-models"><i class="fa fa-check"></i><b>2.6.8</b> Current Models</a></li>
<li class="chapter" data-level="2.6.9" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#model-calibration"><i class="fa fa-check"></i><b>2.6.9</b> Model Calibration</a></li>
<li class="chapter" data-level="2.6.10" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#initial-conditions"><i class="fa fa-check"></i><b>2.6.10</b> Initial Conditions</a></li>
<li class="chapter" data-level="2.6.11" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#drivers"><i class="fa fa-check"></i><b>2.6.11</b> Drivers</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#sequential-state-data-assimilation"><i class="fa fa-check"></i><b>2.7</b> Sequential State Data Assimilation</a><ul>
<li class="chapter" data-level="2.7.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#general-description"><i class="fa fa-check"></i><b>2.7.1</b> General Description</a></li>
<li class="chapter" data-level="2.7.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#enkf"><i class="fa fa-check"></i><b>2.7.2</b> EnKF</a></li>
<li class="chapter" data-level="2.7.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#generalized-ensemble-filter"><i class="fa fa-check"></i><b>2.7.3</b> Generalized Ensemble Filter</a></li>
<li class="chapter" data-level="2.7.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#ensemble-adjustment"><i class="fa fa-check"></i><b>2.7.4</b> Ensemble Adjustment</a></li>
<li class="chapter" data-level="2.7.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#diagnostics"><i class="fa fa-check"></i><b>2.7.5</b> Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#Benchmarking"><i class="fa fa-check"></i><b>2.8</b> Benchmarking</a><ul>
<li class="chapter" data-level="2.8.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#data-preparation"><i class="fa fa-check"></i><b>2.8.1</b> Data Preparation</a></li>
<li class="chapter" data-level="2.8.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#model-runs"><i class="fa fa-check"></i><b>2.8.2</b> Model Runs</a></li>
<li class="chapter" data-level="2.8.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#the-benchmarking-shiny-app"><i class="fa fa-check"></i><b>2.8.3</b> The Benchmarking Shiny App</a></li>
<li class="chapter" data-level="2.8.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#benchmarking-in-pecan.xml"><i class="fa fa-check"></i><b>2.8.4</b> Benchmarking in pecan.xml</a></li>
<li class="chapter" data-level="2.8.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-remote"><i class="fa fa-check"></i><b>2.8.5</b> Remote execution with PEcAn</a></li>
<li class="chapter" data-level="2.8.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#ssh-tunnels-and-pecan"><i class="fa fa-check"></i><b>2.8.6</b> SSH tunnels and PEcAn</a></li>
<li class="chapter" data-level="2.8.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#basic-remote-execute-functions"><i class="fa fa-check"></i><b>2.8.7</b> Basic remote execute functions</a></li>
<li class="chapter" data-level="2.8.8" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#remote-model-execution-with-pecan"><i class="fa fa-check"></i><b>2.8.8</b> Remote model execution with PEcAn</a></li>
<li class="chapter" data-level="2.8.9" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#xml-configuration"><i class="fa fa-check"></i><b>2.8.9</b> XML configuration</a></li>
<li class="chapter" data-level="2.8.10" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#configuration-for-pecan-web-interface"><i class="fa fa-check"></i><b>2.8.10</b> Configuration for PEcAn web interface</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-api"><i class="fa fa-check"></i><b>2.9</b> The PEcAn Docker API</a><ul>
<li class="chapter" data-level="2.9.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#installation"><i class="fa fa-check"></i><b>2.9.1</b> Installation</a></li>
<li class="chapter" data-level="2.9.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#creating-and-submitting-a-workflow"><i class="fa fa-check"></i><b>2.9.2</b> Creating and submitting a workflow</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#advanced-user"><i class="fa fa-check"></i><b>2.10</b> Advanced User Guide</a><ul>
<li class="chapter" data-level="2.10.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#adding-to-pecan"><i class="fa fa-check"></i><b>2.10.1</b> Adding to PEcAn</a></li>
<li class="chapter" data-level="2.10.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#adding-model"><i class="fa fa-check"></i><b>2.10.2</b> Adding An Ecosystem Model</a></li>
<li class="chapter" data-level="2.10.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-database"><i class="fa fa-check"></i><b>2.10.3</b> PEcAn Database</a></li>
<li class="chapter" data-level="2.10.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#define-model_type"><i class="fa fa-check"></i><b>2.10.4</b> Define MODEL_TYPE</a></li>
<li class="chapter" data-level="2.10.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#machine"><i class="fa fa-check"></i><b>2.10.5</b> MACHINE</a></li>
<li class="chapter" data-level="2.10.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#model"><i class="fa fa-check"></i><b>2.10.6</b> MODEL</a></li>
<li class="chapter" data-level="2.10.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#formats"><i class="fa fa-check"></i><b>2.10.7</b> FORMATS</a></li>
<li class="chapter" data-level="2.10.8" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#model_type---formats"><i class="fa fa-check"></i><b>2.10.8</b> MODEL_TYPE -&gt; Formats</a></li>
<li class="chapter" data-level="2.10.9" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#inputs"><i class="fa fa-check"></i><b>2.10.9</b> INPUTS</a></li>
<li class="chapter" data-level="2.10.10" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pfts-plant-functional-types"><i class="fa fa-check"></i><b>2.10.10</b> PFTS (Plant Functional Types)</a></li>
<li class="chapter" data-level="2.10.11" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#priors"><i class="fa fa-check"></i><b>2.10.11</b> PRIORS</a></li>
<li class="chapter" data-level="2.10.12" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#interface-modules"><i class="fa fa-check"></i><b>2.10.12</b> Interface Modules</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#NewInput"><i class="fa fa-check"></i><b>2.11</b> Adding input data</a><ul>
<li class="chapter" data-level="2.11.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#input-records-in-bety"><i class="fa fa-check"></i><b>2.11.1</b> Input records in BETY</a></li>
<li class="chapter" data-level="2.11.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#create-a-database-file-record-for-the-input-data"><i class="fa fa-check"></i><b>2.11.2</b> Create a database file record for the input data</a></li>
<li class="chapter" data-level="2.11.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#creating-a-new-input-record-in-bety"><i class="fa fa-check"></i><b>2.11.3</b> Creating a new Input record in BETY</a></li>
<li class="chapter" data-level="2.11.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#InputConversions"><i class="fa fa-check"></i><b>2.11.4</b> Adding a new input converter</a></li>
<li class="chapter" data-level="2.11.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#adding-data-web"><i class="fa fa-check"></i><b>2.11.5</b> Pecan Data Ingest via Web Interface</a></li>
<li class="chapter" data-level="2.11.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#NewFormat"><i class="fa fa-check"></i><b>2.11.6</b> Creating a new format</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#NewBenchmark"><i class="fa fa-check"></i><b>2.12</b> Creating a new benchmark reference run</a></li>
<li class="chapter" data-level="2.13" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#editing-records"><i class="fa fa-check"></i><b>2.13</b> Editing records</a></li>
<li class="chapter" data-level="2.14" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#submitting-workflow-from-command-line"><i class="fa fa-check"></i><b>2.14</b> Submitting Workflow from Command Line</a></li>
<li class="chapter" data-level="2.15" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#developer-guide"><i class="fa fa-check"></i><b>2.15</b> Developer user guide</a><ul>
<li class="chapter" data-level="2.15.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#aws-setup"><i class="fa fa-check"></i><b>2.15.1</b> AWS Setup</a></li>
<li class="chapter" data-level="2.15.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#porting-vm-to-aws"><i class="fa fa-check"></i><b>2.15.2</b> Porting VM to AWS</a></li>
<li class="chapter" data-level="2.15.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#set-up-multiple-instances-optional"><i class="fa fa-check"></i><b>2.15.3</b> Set up multiple instances (optional)</a></li>
<li class="chapter" data-level="2.15.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#shiny-setup"><i class="fa fa-check"></i><b>2.15.4</b> Shiny Setup</a></li>
<li class="chapter" data-level="2.15.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#thredds-setup"><i class="fa fa-check"></i><b>2.15.5</b> Thredds Setup</a></li>
</ul></li>
<li class="chapter" data-level="2.16" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#updatepecan"><i class="fa fa-check"></i><b>2.16</b> Updating PEcAn Code and Bety Database</a><ul>
<li class="chapter" data-level="2.16.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#updating-pecan"><i class="fa fa-check"></i><b>2.16.1</b> Updating PEcAn</a></li>
</ul></li>
<li class="chapter" data-level="2.17" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#updating-bety"><i class="fa fa-check"></i><b>2.17</b> Updating BETY</a></li>
<li class="chapter" data-level="2.18" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#git-and-github-workflow"><i class="fa fa-check"></i><b>2.18</b> Git and GitHub Workflow</a></li>
<li class="chapter" data-level="2.19" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#using-git"><i class="fa fa-check"></i><b>2.19</b> Using Git</a><ul>
<li class="chapter" data-level="2.19.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#git"><i class="fa fa-check"></i><b>2.19.1</b> Git</a></li>
<li class="chapter" data-level="2.19.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-project-and-github"><i class="fa fa-check"></i><b>2.19.2</b> PEcAn Project and Github</a></li>
<li class="chapter" data-level="2.19.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-project-branches"><i class="fa fa-check"></i><b>2.19.3</b> PEcAn Project Branches</a></li>
<li class="chapter" data-level="2.19.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#quick-and-easy"><i class="fa fa-check"></i><b>2.19.4</b> Quick and Easy</a></li>
<li class="chapter" data-level="2.19.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#recommended-git-workflow"><i class="fa fa-check"></i><b>2.19.5</b> Recommended Git Workflow</a></li>
<li class="chapter" data-level="2.19.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#before-any-work-is-done"><i class="fa fa-check"></i><b>2.19.6</b> Before any work is done</a></li>
<li class="chapter" data-level="2.19.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#during-development"><i class="fa fa-check"></i><b>2.19.7</b> During development:</a></li>
<li class="chapter" data-level="2.19.8" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#basic-workflow"><i class="fa fa-check"></i><b>2.19.8</b> Basic Workflow</a></li>
<li class="chapter" data-level="2.19.9" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#recommended-workflow-a-new-branch-for-each-change"><i class="fa fa-check"></i><b>2.19.9</b> Recommended Workflow: A new branch for each change</a></li>
<li class="chapter" data-level="2.19.10" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#git-rstudio"><i class="fa fa-check"></i><b>2.19.10</b> Git + Rstudio</a></li>
<li class="chapter" data-level="2.19.11" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#for-development"><i class="fa fa-check"></i><b>2.19.11</b> For development:</a></li>
<li class="chapter" data-level="2.19.12" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#references"><i class="fa fa-check"></i><b>2.19.12</b> References</a></li>
</ul></li>
<li class="chapter" data-level="2.20" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#github-use-with-pecan"><i class="fa fa-check"></i><b>2.20</b> GitHub use with PEcAn</a><ul>
<li class="chapter" data-level="2.20.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#bugs-issues-features-etc."><i class="fa fa-check"></i><b>2.20.1</b> Bugs, Issues, Features, etc.</a></li>
<li class="chapter" data-level="2.20.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#requesting-a-feature"><i class="fa fa-check"></i><b>2.20.2</b> Requesting a feature</a></li>
<li class="chapter" data-level="2.20.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#closing-an-issue"><i class="fa fa-check"></i><b>2.20.3</b> Closing an issue</a></li>
<li class="chapter" data-level="2.20.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#when-to-submit-an-issue"><i class="fa fa-check"></i><b>2.20.4</b> When to submit an issue?</a></li>
</ul></li>
<li class="chapter" data-level="2.21" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#coding-practices"><i class="fa fa-check"></i><b>2.21</b> Coding Practices</a></li>
<li class="chapter" data-level="2.22" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#coding-style"><i class="fa fa-check"></i><b>2.22</b> Coding Style</a><ul>
<li class="chapter" data-level="2.22.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#use-roxygen2-documentation"><i class="fa fa-check"></i><b>2.22.1</b> Use Roxygen2 documentation</a></li>
<li class="chapter" data-level="2.22.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#write-your-name-at-the-top"><i class="fa fa-check"></i><b>2.22.2</b> Write your name at the top</a></li>
<li class="chapter" data-level="2.22.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#use-testthat-testing-package"><i class="fa fa-check"></i><b>2.22.3</b> Use testthat testing package</a></li>
<li class="chapter" data-level="2.22.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#dont-use-shortcuts"><i class="fa fa-check"></i><b>2.22.4</b> Don’t use shortcuts</a></li>
<li class="chapter" data-level="2.22.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#package-dependencies"><i class="fa fa-check"></i><b>2.22.5</b> Package Dependencies:</a></li>
</ul></li>
<li class="chapter" data-level="2.23" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#logging"><i class="fa fa-check"></i><b>2.23</b> Logging</a><ul>
<li class="chapter" data-level="2.23.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-logging-functions"><i class="fa fa-check"></i><b>2.23.1</b> PEcAn logging functions</a></li>
<li class="chapter" data-level="2.23.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#other-r-logging-packages"><i class="fa fa-check"></i><b>2.23.2</b> Other R logging packages</a></li>
<li class="chapter" data-level="2.23.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#example-usage"><i class="fa fa-check"></i><b>2.23.3</b> Example Usage</a></li>
</ul></li>
<li class="chapter" data-level="2.24" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#package-data"><i class="fa fa-check"></i><b>2.24</b> Package Data</a><ul>
<li class="chapter" data-level="2.24.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#summary"><i class="fa fa-check"></i><b>2.24.1</b> Summary:</a></li>
<li class="chapter" data-level="2.24.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#accessing-data"><i class="fa fa-check"></i><b>2.24.2</b> Accessing data</a></li>
</ul></li>
<li class="chapter" data-level="2.25" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#packages-used-in-development"><i class="fa fa-check"></i><b>2.25</b> Packages used in development</a></li>
<li class="chapter" data-level="2.26" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#roxygen2-1"><i class="fa fa-check"></i><b>2.26</b> Roxygen2</a><ul>
<li class="chapter" data-level="2.26.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#canonical-references"><i class="fa fa-check"></i><b>2.26.1</b> Canonical references:</a></li>
<li class="chapter" data-level="2.26.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#basic-roxygen2-instructions"><i class="fa fa-check"></i><b>2.26.2</b> Basic Roxygen2 instructions:</a></li>
<li class="chapter" data-level="2.26.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#example"><i class="fa fa-check"></i><b>2.26.3</b> Example</a></li>
<li class="chapter" data-level="2.26.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#updating-documentation"><i class="fa fa-check"></i><b>2.26.4</b> Updating documentation</a></li>
</ul></li>
<li class="chapter" data-level="2.27" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#testing"><i class="fa fa-check"></i><b>2.27</b> Testing</a><ul>
<li class="chapter" data-level="2.27.1" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#rationale"><i class="fa fa-check"></i><b>2.27.1</b> Rationale</a></li>
<li class="chapter" data-level="2.27.2" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#tests-makes-development-easier-and-less-error-prone"><i class="fa fa-check"></i><b>2.27.2</b> Tests makes development easier and less error prone</a></li>
<li class="chapter" data-level="2.27.3" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#quick-start"><i class="fa fa-check"></i><b>2.27.3</b> Quick Start:</a></li>
<li class="chapter" data-level="2.27.4" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#test-files"><i class="fa fa-check"></i><b>2.27.4</b> Test files</a></li>
<li class="chapter" data-level="2.27.5" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#testing-the-shiny-server"><i class="fa fa-check"></i><b>2.27.5</b> Testing the Shiny Server</a></li>
<li class="chapter" data-level="2.27.6" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#download-and-compile-pecan"><i class="fa fa-check"></i><b>2.27.6</b> Download and Compile PEcAn</a></li>
<li class="chapter" data-level="2.27.7" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#pecan-testrun"><i class="fa fa-check"></i><b>2.27.7</b> PEcAn Testrun</a></li>
</ul></li>
<li class="chapter" data-level="2.28" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#directory-structure"><i class="fa fa-check"></i><b>2.28</b> Directory structure</a></li>
<li class="chapter" data-level="2.29" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#overview-of-pecan-repository-as-of-pecan-1.5.3"><i class="fa fa-check"></i><b>2.29</b> Overview of PEcAn repository as of PEcAn 1.5.3</a></li>
<li class="chapter" data-level="2.30" data-path="tutorialsdemos-and-how-tos.html"><a href="tutorialsdemos-and-how-tos.html#generic-r-package-structure"><i class="fa fa-check"></i><b>2.30</b> Generic R package structure:</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="topical.html"><a href="topical.html"><i class="fa fa-check"></i><b>3</b> Topical Pages</a><ul>
<li class="chapter" data-level="3.1" data-path="topical.html"><a href="topical.html#pecan-standard-formats"><i class="fa fa-check"></i><b>3.1</b> PEcAn standard formats</a><ul>
<li class="chapter" data-level="3.1.1" data-path="topical.html"><a href="topical.html#defining-new-input-formats"><i class="fa fa-check"></i><b>3.1.1</b> Defining new input formats</a></li>
<li class="chapter" data-level="3.1.2" data-path="topical.html"><a href="topical.html#input-standards"><i class="fa fa-check"></i><b>3.1.2</b> Input Standards</a></li>
<li class="chapter" data-level="3.1.3" data-path="topical.html"><a href="topical.html#output-standards"><i class="fa fa-check"></i><b>3.1.3</b> Output Standards</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="topical.html"><a href="topical.html#pecanXML"><i class="fa fa-check"></i><b>3.2</b> The PEcAn XML</a><ul>
<li class="chapter" data-level="3.2.1" data-path="topical.html"><a href="topical.html#xml-core-config"><i class="fa fa-check"></i><b>3.2.1</b> Core configuration</a></li>
<li class="chapter" data-level="3.2.2" data-path="topical.html"><a href="topical.html#xml-outdir"><i class="fa fa-check"></i><b>3.2.2</b> <code>outdir</code>: Output directory</a></li>
<li class="chapter" data-level="3.2.3" data-path="topical.html"><a href="topical.html#xml-database"><i class="fa fa-check"></i><b>3.2.3</b> <code>database</code>: PEcAn database settings</a></li>
<li class="chapter" data-level="3.2.4" data-path="topical.html"><a href="topical.html#xml-pft"><i class="fa fa-check"></i><b>3.2.4</b> <code>pft</code>: Plant functional type selection</a></li>
<li class="chapter" data-level="3.2.5" data-path="topical.html"><a href="topical.html#xml-meta-analysis"><i class="fa fa-check"></i><b>3.2.5</b> <code>meta.analysis</code>: Trait Meta Analysis</a></li>
<li class="chapter" data-level="3.2.6" data-path="topical.html"><a href="topical.html#xml-model"><i class="fa fa-check"></i><b>3.2.6</b> <code>model</code>: Model configuration</a></li>
<li class="chapter" data-level="3.2.7" data-path="topical.html"><a href="topical.html#xml-run"><i class="fa fa-check"></i><b>3.2.7</b> <code>run</code>: Run Setup</a></li>
<li class="chapter" data-level="3.2.8" data-path="topical.html"><a href="topical.html#xml-host"><i class="fa fa-check"></i><b>3.2.8</b> <code>host</code>: Host information for remote execution</a></li>
<li class="chapter" data-level="3.2.9" data-path="topical.html"><a href="topical.html#xml-advanced"><i class="fa fa-check"></i><b>3.2.9</b> Advanced features</a></li>
<li class="chapter" data-level="3.2.10" data-path="topical.html"><a href="topical.html#xml-ensemble"><i class="fa fa-check"></i><b>3.2.10</b> <code>ensemble</code>: Ensemble Runs</a></li>
<li class="chapter" data-level="3.2.11" data-path="topical.html"><a href="topical.html#xml-sensitivity-analysis"><i class="fa fa-check"></i><b>3.2.11</b> <code>sensitivity.analysis</code>: Sensitivity analysis</a></li>
<li class="chapter" data-level="3.2.12" data-path="topical.html"><a href="topical.html#xml-parameter-data-assimilation"><i class="fa fa-check"></i><b>3.2.12</b> Parameter Data Assimilation</a></li>
<li class="chapter" data-level="3.2.13" data-path="topical.html"><a href="topical.html#xml-multi-settings"><i class="fa fa-check"></i><b>3.2.13</b> Multi-Settings</a></li>
<li class="chapter" data-level="3.2.14" data-path="topical.html"><a href="topical.html#xml-state-data-assimilation"><i class="fa fa-check"></i><b>3.2.14</b> (experimental) State Data Assimilation</a></li>
<li class="chapter" data-level="3.2.15" data-path="topical.html"><a href="topical.html#xml-browndog"><i class="fa fa-check"></i><b>3.2.15</b> (experimental) Brown Dog</a></li>
<li class="chapter" data-level="3.2.16" data-path="topical.html"><a href="topical.html#xml-benchmarking"><i class="fa fa-check"></i><b>3.2.16</b> (experimental) Benchmarking</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="topical.html"><a href="topical.html#workflow"><i class="fa fa-check"></i><b>3.3</b> PEcAn workflow (web/workflow.R)</a><ul>
<li class="chapter" data-level="3.3.1" data-path="topical.html"><a href="topical.html#workflow-readsettings"><i class="fa fa-check"></i><b>3.3.1</b> Read Settings</a></li>
<li class="chapter" data-level="3.3.2" data-path="topical.html"><a href="topical.html#workflow-input"><i class="fa fa-check"></i><b>3.3.2</b> Input Conversions</a></li>
<li class="chapter" data-level="3.3.3" data-path="topical.html"><a href="topical.html#workflow-input-data"><i class="fa fa-check"></i><b>3.3.3</b> Input Data</a></li>
<li class="chapter" data-level="3.3.4" data-path="topical.html"><a href="topical.html#workflow-input-initial"><i class="fa fa-check"></i><b>3.3.4</b> Initial Conditions</a></li>
<li class="chapter" data-level="3.3.5" data-path="topical.html"><a href="topical.html#workflow-met"><i class="fa fa-check"></i><b>3.3.5</b> Meteorological Data</a></li>
<li class="chapter" data-level="3.3.6" data-path="topical.html"><a href="topical.html#workflow-met-standard"><i class="fa fa-check"></i><b>3.3.6</b> Converting raw data to PEcAn standard</a></li>
<li class="chapter" data-level="3.3.7" data-path="topical.html"><a href="topical.html#workflow-met-downscale"><i class="fa fa-check"></i><b>3.3.7</b> Downscaling and gapfilling (optional)</a></li>
<li class="chapter" data-level="3.3.8" data-path="topical.html"><a href="topical.html#workflow-met-model"><i class="fa fa-check"></i><b>3.3.8</b> Converting from PEcAn standard to model-specific format</a></li>
<li class="chapter" data-level="3.3.9" data-path="topical.html"><a href="topical.html#workflow-traits"><i class="fa fa-check"></i><b>3.3.9</b> Traits</a></li>
<li class="chapter" data-level="3.3.10" data-path="topical.html"><a href="topical.html#workflow-metaanalysis"><i class="fa fa-check"></i><b>3.3.10</b> Meta Analysis</a></li>
<li class="chapter" data-level="3.3.11" data-path="topical.html"><a href="topical.html#workflow-modelconfig"><i class="fa fa-check"></i><b>3.3.11</b> Model Configuration</a></li>
<li class="chapter" data-level="3.3.12" data-path="topical.html"><a href="topical.html#workflow-modelrun"><i class="fa fa-check"></i><b>3.3.12</b> Run Execution</a></li>
<li class="chapter" data-level="3.3.13" data-path="topical.html"><a href="topical.html#workflow-postrun"><i class="fa fa-check"></i><b>3.3.13</b> Post Run Analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="topical.html"><a href="topical.html#pecan-models"><i class="fa fa-check"></i><b>3.4</b> PEcAn Models</a><ul>
<li class="chapter" data-level="3.4.1" data-path="topical.html"><a href="topical.html#models-biocro"><i class="fa fa-check"></i><b>3.4.1</b> BioCro</a></li>
<li class="chapter" data-level="3.4.2" data-path="topical.html"><a href="topical.html#models-clm"><i class="fa fa-check"></i><b>3.4.2</b> CLM</a></li>
<li class="chapter" data-level="3.4.3" data-path="topical.html"><a href="topical.html#models-dalec"><i class="fa fa-check"></i><b>3.4.3</b> DALEC</a></li>
<li class="chapter" data-level="3.4.4" data-path="topical.html"><a href="topical.html#models-ed"><i class="fa fa-check"></i><b>3.4.4</b> ED2</a></li>
<li class="chapter" data-level="3.4.5" data-path="topical.html"><a href="topical.html#introduction-1"><i class="fa fa-check"></i><b>3.4.5</b> Introduction</a></li>
<li class="chapter" data-level="3.4.6" data-path="topical.html"><a href="topical.html#pecan-configuration-file-additions"><i class="fa fa-check"></i><b>3.4.6</b> PEcAn configuration file additions</a></li>
<li class="chapter" data-level="3.4.7" data-path="topical.html"><a href="topical.html#models-ed-pft-configuration"><i class="fa fa-check"></i><b>3.4.7</b> PFT configuration in ED2</a></li>
<li class="chapter" data-level="3.4.8" data-path="topical.html"><a href="topical.html#model-specific-input-files"><i class="fa fa-check"></i><b>3.4.8</b> Model specific input files</a></li>
<li class="chapter" data-level="3.4.9" data-path="topical.html"><a href="topical.html#model-configuration-files"><i class="fa fa-check"></i><b>3.4.9</b> Model configuration files</a></li>
<li class="chapter" data-level="3.4.10" data-path="topical.html"><a href="topical.html#installation-notes"><i class="fa fa-check"></i><b>3.4.10</b> Installation notes</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="topical.html"><a href="topical.html#models-gday"><i class="fa fa-check"></i><b>3.5</b> GDAY</a><ul>
<li class="chapter" data-level="3.5.1" data-path="topical.html"><a href="topical.html#models-linkages"><i class="fa fa-check"></i><b>3.5.1</b> LINKAGES</a></li>
<li class="chapter" data-level="3.5.2" data-path="topical.html"><a href="topical.html#models-lpjguess"><i class="fa fa-check"></i><b>3.5.2</b> LPJ-GUESS</a></li>
<li class="chapter" data-level="3.5.3" data-path="topical.html"><a href="topical.html#models-maespa"><i class="fa fa-check"></i><b>3.5.3</b> MAESPA</a></li>
<li class="chapter" data-level="3.5.4" data-path="topical.html"><a href="topical.html#models-preles"><i class="fa fa-check"></i><b>3.5.4</b> PRELES</a></li>
<li class="chapter" data-level="3.5.5" data-path="topical.html"><a href="topical.html#models-sipnet"><i class="fa fa-check"></i><b>3.5.5</b> SiPNET</a></li>
<li class="chapter" data-level="3.5.6" data-path="topical.html"><a href="topical.html#download-gfdl"><i class="fa fa-check"></i><b>3.5.6</b> Download GFDL</a></li>
<li class="chapter" data-level="3.5.7" data-path="topical.html"><a href="topical.html#cm3"><i class="fa fa-check"></i><b>3.5.7</b> CM3</a></li>
<li class="chapter" data-level="3.5.8" data-path="topical.html"><a href="topical.html#esm2m-esm2g"><i class="fa fa-check"></i><b>3.5.8</b> ESM2M &amp; ESM2G</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="topical.html"><a href="topical.html#available-meteorological-drivers"><i class="fa fa-check"></i><b>3.6</b> Available Meteorological Drivers</a><ul>
<li class="chapter" data-level="3.6.1" data-path="topical.html"><a href="topical.html#ameriflux"><i class="fa fa-check"></i><b>3.6.1</b> Ameriflux</a></li>
<li class="chapter" data-level="3.6.2" data-path="topical.html"><a href="topical.html#amerifluxlbl"><i class="fa fa-check"></i><b>3.6.2</b> AmerifluxLBL</a></li>
<li class="chapter" data-level="3.6.3" data-path="topical.html"><a href="topical.html#fluxnet2015"><i class="fa fa-check"></i><b>3.6.3</b> Fluxnet2015</a></li>
<li class="chapter" data-level="3.6.4" data-path="topical.html"><a href="topical.html#narr"><i class="fa fa-check"></i><b>3.6.4</b> NARR</a></li>
<li class="chapter" data-level="3.6.5" data-path="topical.html"><a href="topical.html#cruncep"><i class="fa fa-check"></i><b>3.6.5</b> CRUNCEP</a></li>
<li class="chapter" data-level="3.6.6" data-path="topical.html"><a href="topical.html#cmip5"><i class="fa fa-check"></i><b>3.6.6</b> CMIP5</a></li>
<li class="chapter" data-level="3.6.7" data-path="topical.html"><a href="topical.html#nldas"><i class="fa fa-check"></i><b>3.6.7</b> NLDAS</a></li>
<li class="chapter" data-level="3.6.8" data-path="topical.html"><a href="topical.html#gldas"><i class="fa fa-check"></i><b>3.6.8</b> GLDAS</a></li>
<li class="chapter" data-level="3.6.9" data-path="topical.html"><a href="topical.html#paleon"><i class="fa fa-check"></i><b>3.6.9</b> PalEON</a></li>
<li class="chapter" data-level="3.6.10" data-path="topical.html"><a href="topical.html#fluxnetlathuile"><i class="fa fa-check"></i><b>3.6.10</b> FluxnetLaThuile</a></li>
<li class="chapter" data-level="3.6.11" data-path="topical.html"><a href="topical.html#geostreams"><i class="fa fa-check"></i><b>3.6.11</b> Geostreams</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="topical.html"><a href="topical.html#database-synchronization"><i class="fa fa-check"></i><b>3.7</b> Database synchronization</a><ul>
<li class="chapter" data-level="3.7.1" data-path="topical.html"><a href="topical.html#how-does-it-work"><i class="fa fa-check"></i><b>3.7.1</b> How does it work?</a></li>
<li class="chapter" data-level="3.7.2" data-path="topical.html"><a href="topical.html#set-up"><i class="fa fa-check"></i><b>3.7.2</b> Set up</a></li>
<li class="chapter" data-level="3.7.3" data-path="topical.html"><a href="topical.html#fetch-latest-data"><i class="fa fa-check"></i><b>3.7.3</b> Fetch latest data</a></li>
<li class="chapter" data-level="3.7.4" data-path="topical.html"><a href="topical.html#sharing-data"><i class="fa fa-check"></i><b>3.7.4</b> Sharing data</a></li>
<li class="chapter" data-level="3.7.5" data-path="topical.html"><a href="topical.html#automation"><i class="fa fa-check"></i><b>3.7.5</b> Automation</a></li>
<li class="chapter" data-level="3.7.6" data-path="topical.html"><a href="topical.html#database-maintentance"><i class="fa fa-check"></i><b>3.7.6</b> Database maintentance</a></li>
<li class="chapter" data-level="3.7.7" data-path="topical.html"><a href="topical.html#troubleshooting-3"><i class="fa fa-check"></i><b>3.7.7</b> Troubleshooting</a></li>
<li class="chapter" data-level="3.7.8" data-path="topical.html"><a href="topical.html#network-status-map"><i class="fa fa-check"></i><b>3.7.8</b> Network Status Map</a></li>
<li class="chapter" data-level="3.7.9" data-path="topical.html"><a href="topical.html#tasks"><i class="fa fa-check"></i><b>3.7.9</b> Tasks</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="topical.html"><a href="topical.html#standalone-tools-modules"><i class="fa fa-check"></i><b>3.8</b> Standalone tools (modules)</a><ul>
<li class="chapter" data-level="3.8.1" data-path="topical.html"><a href="topical.html#LoadData"><i class="fa fa-check"></i><b>3.8.1</b> Loading Data in PEcAn</a></li>
<li class="chapter" data-level="3.8.2" data-path="topical.html"><a href="topical.html#function-load_data"><i class="fa fa-check"></i><b>3.8.2</b> Function <code>load_data</code></a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="topical.html"><a href="topical.html#using-the-pecan-download.file-function"><i class="fa fa-check"></i><b>3.9</b> Using the PEcAn download.file() function</a></li>
<li class="chapter" data-level="3.10" data-path="topical.html"><a href="topical.html#shiny"><i class="fa fa-check"></i><b>3.10</b> SHINY</a><ul>
<li class="chapter" data-level="3.10.1" data-path="topical.html"><a href="topical.html#debugging-shiny-apps"><i class="fa fa-check"></i><b>3.10.1</b> Debugging Shiny Apps</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="topical.html"><a href="topical.html#debugging"><i class="fa fa-check"></i><b>3.11</b> Debugging</a><ul>
<li class="chapter" data-level="3.11.1" data-path="topical.html"><a href="topical.html#using-testsworkflow.r"><i class="fa fa-check"></i><b>3.11.1</b> Using <code>tests/workflow.R</code></a></li>
<li class="chapter" data-level="3.11.2" data-path="topical.html"><a href="topical.html#useful-scripts"><i class="fa fa-check"></i><b>3.11.2</b> Useful scripts</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="topical.html"><a href="topical.html#troubleshooting-pecan"><i class="fa fa-check"></i><b>3.12</b> Troubleshooting PEcAn</a><ul>
<li class="chapter" data-level="3.12.1" data-path="topical.html"><a href="topical.html#cookies-and-pecan-web-pages"><i class="fa fa-check"></i><b>3.12.1</b> Cookies and pecan web pages</a></li>
<li class="chapter" data-level="3.12.2" data-path="topical.html"><a href="topical.html#warning-mkdir-function.mkdir-no-such-file-or-directory"><i class="fa fa-check"></i><b>3.12.2</b> <code>Warning: mkdir() [function.mkdir]: No such file or directory</code></a></li>
<li class="chapter" data-level="3.12.3" data-path="topical.html"><a href="topical.html#after-creating-a-new-pft-the-tag-for-pft-not-passed-to-config.xml-in-ed"><i class="fa fa-check"></i><b>3.12.3</b> After creating a new PFT the <num> tag for PFT not passed to config.xml in ED</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="topical.html"><a href="topical.html#pecan-project-use-to-teach-ecological-model-data-synthesis"><i class="fa fa-check"></i><b>3.13</b> PEcAn Project use to teach Ecological model-data synthesis</a><ul>
<li class="chapter" data-level="3.13.1" data-path="topical.html"><a href="topical.html#university-classes"><i class="fa fa-check"></i><b>3.13.1</b> University classes</a></li>
<li class="chapter" data-level="3.13.2" data-path="topical.html"><a href="topical.html#summer-courses-workshops"><i class="fa fa-check"></i><b>3.13.2</b> Summer Courses / Workshops</a></li>
<li class="chapter" data-level="3.13.3" data-path="topical.html"><a href="topical.html#selected-publications"><i class="fa fa-check"></i><b>3.13.3</b> Selected Publications</a></li>
</ul></li>
<li class="chapter" data-level="3.14" data-path="topical.html"><a href="topical.html#rabbitmq"><i class="fa fa-check"></i><b>3.14</b> RabbitMQ</a><ul>
<li class="chapter" data-level="3.14.1" data-path="topical.html"><a href="topical.html#rabbitmq-basics-sender"><i class="fa fa-check"></i><b>3.14.1</b> Producer – <code>sender.py</code></a></li>
<li class="chapter" data-level="3.14.2" data-path="topical.html"><a href="topical.html#rabbitmq-basics-receiver"><i class="fa fa-check"></i><b>3.14.2</b> Consumer – <code>receiver.py</code></a></li>
<li class="chapter" data-level="3.14.3" data-path="topical.html"><a href="topical.html#rabbitmq-web"><i class="fa fa-check"></i><b>3.14.3</b> RabbitMQ and the PEcAn web interface</a></li>
<li class="chapter" data-level="3.14.4" data-path="topical.html"><a href="topical.html#rabbitmq-xml"><i class="fa fa-check"></i><b>3.14.4</b> RabbitMQ in the PEcAn XML</a></li>
<li class="chapter" data-level="3.14.5" data-path="topical.html"><a href="topical.html#rabbitmq-dockerfile"><i class="fa fa-check"></i><b>3.14.5</b> RabbitMQ configuration in Dockerfiles</a></li>
<li class="chapter" data-level="3.14.6" data-path="topical.html"><a href="topical.html#rabbitmq-case-study"><i class="fa fa-check"></i><b>3.14.6</b> Case study: PEcAn web interface</a></li>
</ul></li>
<li class="chapter" data-level="3.15" data-path="topical.html"><a href="topical.html#database"><i class="fa fa-check"></i><b>3.15</b> BETY Database Administration</a><ul>
<li class="chapter" data-level="3.15.1" data-path="topical.html"><a href="topical.html#database-setup"><i class="fa fa-check"></i><b>3.15.1</b> Best practices</a></li>
<li class="chapter" data-level="3.15.2" data-path="topical.html"><a href="topical.html#backup-of-bety-database"><i class="fa fa-check"></i><b>3.15.2</b> Backup of BETY database</a></li>
<li class="chapter" data-level="3.15.3" data-path="topical.html"><a href="topical.html#restore-of-bety-database"><i class="fa fa-check"></i><b>3.15.3</b> Restore of BETY database</a></li>
</ul></li>
<li class="chapter" data-level="3.16" data-path="topical.html"><a href="topical.html#workflow-modules"><i class="fa fa-check"></i><b>3.16</b> Workflow modules</a><ul>
<li class="chapter" data-level="3.16.1" data-path="topical.html"><a href="topical.html#overview"><i class="fa fa-check"></i><b>3.16.1</b> Overview</a></li>
<li class="chapter" data-level="3.16.2" data-path="topical.html"><a href="topical.html#load-settings"><i class="fa fa-check"></i><b>3.16.2</b> Load Settings:</a></li>
<li class="chapter" data-level="3.16.3" data-path="topical.html"><a href="topical.html#query-database"><i class="fa fa-check"></i><b>3.16.3</b> Query Database:</a></li>
<li class="chapter" data-level="3.16.4" data-path="topical.html"><a href="topical.html#meta-analysis"><i class="fa fa-check"></i><b>3.16.4</b> Meta Analysis:</a></li>
<li class="chapter" data-level="3.16.5" data-path="topical.html"><a href="topical.html#write-configuration-files"><i class="fa fa-check"></i><b>3.16.5</b> Write Configuration Files</a></li>
<li class="chapter" data-level="3.16.6" data-path="topical.html"><a href="topical.html#start-runs"><i class="fa fa-check"></i><b>3.16.6</b> Start Runs:</a></li>
<li class="chapter" data-level="3.16.7" data-path="topical.html"><a href="topical.html#get-model-output"><i class="fa fa-check"></i><b>3.16.7</b> Get Model Output</a></li>
<li class="chapter" data-level="3.16.8" data-path="topical.html"><a href="topical.html#ensemble-analysis"><i class="fa fa-check"></i><b>3.16.8</b> Ensemble Analysis</a></li>
<li class="chapter" data-level="3.16.9" data-path="topical.html"><a href="topical.html#sensitivity-analysis-variance-decomposition"><i class="fa fa-check"></i><b>3.16.9</b> Sensitivity Analysis, Variance Decomposition</a></li>
<li class="chapter" data-level="3.16.10" data-path="topical.html"><a href="topical.html#glossary"><i class="fa fa-check"></i><b>3.16.10</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="3.17" data-path="topical.html"><a href="topical.html#data-assimilation-with-dart"><i class="fa fa-check"></i><b>3.17</b> Data assimilation with DART</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>4</b> Appendix</a><ul>
<li class="chapter" data-level="4.1" data-path="appendix.html"><a href="appendix.html#faq"><i class="fa fa-check"></i><b>4.1</b> FAQ</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Predictive Ecosystem Analyzer</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="topical" class="section level1">
<h1><span class="header-section-number">3</span> Topical Pages</h1>

<div id="pecan-standard-formats" class="section level2">
<h2><span class="header-section-number">3.1</span> PEcAn standard formats</h2>
<div id="defining-new-input-formats" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Defining new input formats</h3>
<ul>
<li>New formats can be defined on the <a href="http://betydb.org/formats">‘formats’ page of BETYdb</a></li>
<li>After creating a new format, the contents should be defined by specifying the BETYdb variable name and the name used in the file/</li>
</ul>
</div>
<div id="input-standards" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Input Standards</h3>
<div id="meterology-standards" class="section level4">
<h4><span class="header-section-number">3.1.2.1</span> Meterology Standards</h4>
<div id="dimensions" class="section level5">
<h5><span class="header-section-number">3.1.2.1.1</span> Dimensions:</h5>
<table>
<thead>
<tr class="header">
<th align="left">CF standard-name</th>
<th align="left">units</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">time</td>
<td align="left">days since 1700-01-01 00:00:00 UTC</td>
</tr>
<tr class="even">
<td align="left">longitude</td>
<td align="left">degrees_east</td>
</tr>
<tr class="odd">
<td align="left">latitude</td>
<td align="left">degrees_north</td>
</tr>
</tbody>
</table>
<p>General Note: dates in the database should be date-time (preferably with timezone), and datetime passed around in PEcAn should be of type POSIXct.</p>
</div>
<div id="the-variable-names-should-be-standard_name" class="section level5">
<h5><span class="header-section-number">3.1.2.1.2</span> The variable names should be <code>standard_name</code></h5>
<div id="htmlwidget-8d17729ae7d384029c08" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-8d17729ae7d384029c08">{"x":{"filter":"none","extensions":["FixedColumns","Buttons"],"data":[["&lt;b&gt;air_temperature&lt;/b&gt;","air_temperature_max","air_temperature_min","&lt;b&gt;air_pressure&lt;/b&gt;","mole_fraction_of_carbon_dioxide_in_air","moisture_content_of_soil_layer","soil_temperature ","relative_humidity","&lt;b&gt;specific_humidity&lt;/b&gt;","water_vapor_saturation_deficit","&lt;b&gt;surface_downwelling_longwave_flux_in_air&lt;/b&gt;","&lt;b&gt;surface_downwelling_shortwave_flux_in_air&lt;/b&gt;","surface_downwelling_photosynthetic_photon_flux_in_air","&lt;b&gt;precipitation_flux&lt;/b&gt;","  ","wind_speed","&lt;b&gt;eastward_wind&lt;/b&gt;","&lt;b&gt;northward_wind&lt;/b&gt;"],["K","K","K","Pa","mol/mol","kg m-2","K","%","1","Pa","W m-2","W m-2","mol m-2 s-1","kg m-2 s-1","degrees","m/s","m/s","m/s"],["airT","","","air_pressure","","","soilT","relative_humidity","specific_humidity","VPD","same","solar_radiation","PAR","cccc","wind_direction","Wspd","eastward_wind","northward_wind"],["tasAdjust","tasmaxAdjust","tasminAdjust","","","","","rhurs","NA","","rldsAdjust","rsdsAdjust","","prAdjust","","","",""],["tair","NA","NA","","","","","NA","qair","","lwdown","swdown","","rain","","","",""],["air","tmax","tmin","","","","","rhum","shum","","dlwrf","dswrf","","acpc","","","",""],["TA(C)","","","PRESS (KPa)","CO2","","TS1(NOT DONE)","RH","CALC(RH)","VPD(NOT DONE)","Rgl","Rg","PAR(NOT DONE)","PREC","WD","WS","CALC(WS+WD)","CALC(WS+WD)"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>CF standard-name<\/th>\n      <th>units<\/th>\n      <th>BETY<\/th>\n      <th>Isimip<\/th>\n      <th>CRUNCEP<\/th>\n      <th>NARR<\/th>\n      <th>Ameriflux<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"Bfrtip","scrollX":true,"fixedColumns":true,"buttons":["copy","csv","excel","pdf","print"],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<ul>
<li>preferred variables indicated in bold</li>
<li>wind_direction has no CF equivalent and should not be converted, instead the met2CF functions should convert wind_direction and wind_speed to eastward_wind and northward_wind</li>
<li>standard_name is CF-convention standard names</li>
<li>units can be converted by udunits, so these can vary (e.g. the time denominator may change with time frequency of inputs)</li>
<li>soil moisture for the full column, rather than a layer, is soil_moisture_content</li>
<li>A full list of PEcAn standard variable names, units and dimensions can be found here: <a href="https://github.com/PecanProject/pecan/blob/develop/base/utils/data/standard_vars.csv" class="uri">https://github.com/PecanProject/pecan/blob/develop/base/utils/data/standard_vars.csv</a></li>
</ul>
<p>For example, in the <a href="https://www.betydb.org/inputs/280">MsTMIP-CRUNCEP</a> data, the variable <code>rain</code> should be <code>precipitation_rate</code>.
We want to standardize the units as well as part of the <code>met2CF.&lt;product&gt;</code> step. I believe we want to use the CF “canonical” units but retain the MsTMIP units any time CF is ambiguous about the units.</p>
<p>The key is to process each type of met data (site, reanalysis, forecast, climate scenario, etc) to the exact same standard. This way every operation after that (extract, gap fill, downscale, convert to a model, etc) will always have the exact same inputs. This will make everything else much simpler to code and allow us to avoid a lot of unnecessary data checking, tests, etc being repeated in every downstream function.</p>
</div>
</div>
<div id="soils-and-vegetation-inputs" class="section level4">
<h4><span class="header-section-number">3.1.2.2</span> Soils and Vegetation Inputs</h4>
<div id="soil-data-1" class="section level5">
<h5><span class="header-section-number">3.1.2.2.1</span> Soil Data</h5>
<p>Check out the <a href="topical.html#soil-data-1">Soil Data</a> section on more into on creating a standard soil data file.</p>
</div>
<div id="vegetation-data-1" class="section level5">
<h5><span class="header-section-number">3.1.2.2.2</span> Vegetation Data</h5>
<p>Check Out the <a href="topical.html#vegetation-data-1">Vegetation Data</a> section on more info on creating a standard vegetation data file</p>
</div>
</div>
</div>
<div id="output-standards" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Output Standards</h3>
<ul>
<li>created by <code>model2netcdf</code> functions</li>
<li>based on format used by <a href="http://nacp.ornl.gov/MsTMIP_variables.shtml">MsTMIP</a></li>
<li>Can be seen at HERE</li>
</ul>
<p>We originally used the <a href="http://nacp.ornl.gov/MsTMIP_variables.shtml">MsTMIP</a> conventions. Since then, we’ve added the PaLEON variable conventions to our standard as well. If a variable isn’t in one of those two, we stick to the CF conventions.</p>
<div id="htmlwidget-6e419bf2c1d0fad1e4b7" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-6e419bf2c1d0fad1e4b7">{"x":{"filter":"none","extensions":["FixedColumns","Buttons"],"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112"],["lon","lat","depth","pft","time","rtsize","wdsize","lon_bnds","lat_bnds","time_bnds","dec_date","dec_date_bnds","cal_date_mid","cal_date_beg","cal_date_end","GPP","NEE","TotalResp","AutoResp","HeteroResp","SoilResp","DOC_flux","Fire_flux","litter_carbon_flux","surface_litter_carbon_flux","subsurface_litter_carbon_flux","leaf_litter_carbon_flux","WoodyLitter","wood_debris_carbon_flux","NPP","GWBI","CWDI","CropYield","poolname","CarbPools","TotLivBiom","AGB","LAI","leaf_carbon_content","root_carbon_content","fine_root_carbon_content","coarse_root_carbon_content","wood_carbon_content","AbvGrndWood","TotSoilCarb","litter_carbon_content","surface_litter_carbon_content","subsurface_litter_carbon_content","leaf_litter_carbon_content","reproductive_litter_carbon_content","other_litter_carbon_content","wood_debris_carbon_content","soil_carbon_content","soil_inorganic_carbon_content","soil_organic_carbon_content","slow_soil_pool_carbon_content","fast_soil_pool_carbon_content","structural_soil_pool_carbon_content","soil_nitrogen_content","soil_phosphorus_content","Qh","Qle","Qg","stomatal_conductance","Evap","TVeg","Transp","LW_albedo","SW_albedo","Lwnet","SWnet","fPAR","z_top","z_node","z_bottom","SoilMoist","SoilMoistFrac","SoilWet","Qs","Qsb","SoilTemp","Tdepth","Fdepth","Tcan","SWE","SnowDen","SnowDepth","CO2CAS","CO2air","LWdown","Psurf","Qair","Rainf","SWdown","Tair","Wind","Tmin","Tmax","Uwind","Vwind","RH","PAR","precipf","BA","Dens","DBH","DBH by PFT","Fcomp","Estab","Mort","SoilDepth","assimilation_rate"],["longitude","latitude","depth","pft","time","rtsize","wdsize",null,null,null,null,null,null,null,null,null,null,null,"plant_respiration_carbon_flux","heterotrophic_respiration_carbon_flux","soil_respiration_carbon_flux",null,null,"litter_carbon_flux","surface_litter_carbon_flux","subsurface_litter_carbon_flux","leaf_litter_carbon_flux","wood_litter_carbon_flux","wood_debris_carbon_flux",null,null,null,null,null,null,null,null,null,"leaf_carbon_content","root_carbon_content_of_size_class","fine_root_carbon_content","coarse_root_carbon_content","wood_carbon_content",null,null,"litter_carbon_content","surface_litter_carbon_content","subsurface_litter_carbon_content","leaf_litter_carbon_content","reproductive_litter_carbon_content","other_litter_carbon_content","wood_debris_carbon_content","soil_carbon_content_of_soil_layer","soil_inorganic_carbon_content_of_soil_layer","soil_organic_carbon_content_of_soil_layer","slow_soil_pool_carbon_content_of_soil_layer","fast_soil_pool_carbon_content_of_soil_layer","structural_soil_pool_carbon_content_of_soil_layer","soil_nitrogen_content_of_soil_layer","soil_phosphorus_content_of_soil_layer",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"surface_downwelling_longwave_flux_in_air","air_pressure","specific_humidity","precipitation_flux","surface_downwelling_shortwave_flux_in_air","air_temperature","wind_speed","air_temperature_max","air_temperature_min","northward_wind","eastward_wind","relative_humidity","surface_downwelling_photosynthetic_photon_flux_in_air",null,null,null,null,"",null,null,null,null,null],["degrees_east","degrees_north","m","(-)","days since 1700-01-01 00:00:00 UTC","m","m","degrees_east","degrees_north","days since 1700-01-01 00:00:00 UTC","yr","yr","yr, mon, day, hr, min, sec","yr, mon, day, hr, min, sec","yr, mon, day, hr, min, sec","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 s-1","kg C m-2 month-1","kg C m-2 month-1","kg m-2","(-)","kg C m-2","kg C m-2","kg C m-2","m2 m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg C m-2","kg N m-2","kg P m-2","W m-2","W m-2","W m-2","kg m-2 s-1","kg m-2 s-1","kg m-2 s-1","kg m-2 s-1","(-)","(-)","W m-2","W m-2","(-)","m","m","m","kg m-2","(-)","(-)","kg m-2 s-1","kg m-2 s-1","K","m","m","K","kg m-2","kg m-3","m","ppmv","micromol mol-1","W/m2","Pa","kg kg-1","kg m-2 s-1","W m-2","K","m s-1","K","K","m s-1","m s-1","%","mol m-2 s-1","kg m-2 s-1","m2 ha-1","1 ha-1","cm","","kgC kgC-1","1 ha-1","1 ha-1","m","kg C m-2 s-1"],["Longitude","Latitude","Depth","Plant Functional Type","Time middle averaging period","Root Size Class","Woody Debris Size Class","Longitude west-east bounds","Latitude south-north bounds","Time beginning-end bounds","Decimal date middle averaging period","Decimal date beginning-end bounds","Calender date middle averaging period","Calender date beginning averaging period","Calender date end averaging period","Gross Primary Productivity","Net Ecosystem Exchange","Total Respiration","Autotrophic Respiration","Heterotrophic Respiration","Soil Respiration","Dissolved Organic Carbon flux","Fire emissions","Litter Carbon Flux","Surface Litter Carbon Flux","Subsurface Litter Carbon Flux","Leaf Litter Carbon Flux","Wood Litter Carbon Flux","Wood Debris Carbon Flux","Net Primary Productivity","Gross Woody Biomass Increment","Coarse Woody Debris Increment","CropYield","Name of each Carbon Pool","Size of each carbon pool","Total living biomass","Total aboveground biomass","Leaf Area Index","Leaf Carbon Content","Root Carbon Content","Fine Root Carbon Content","Coarse Root Carbon Content","Wood Carbon Content","Above ground woody biomass","Total Soil Carbon","Litter Carbon Content","Surface Litter Carbon Content","Subsurface Litter Carbon Content","Leaf Litter Carbon Content","Reproductive Litter Carbon Content","Other Litter Carbon Content","Wood Debris Carbon Content","Soil Carbon Content by Layer","Soil Inorganic Carbon Content by Layer","Soil Organic Carbon Content by Layer","Slow Soil Pool Carbon Content by Layer","Fast Soil Pool Carbon Content by Layer","Structural Soil Pool Carbon Content by Layer","Soil Nitrogen Content by Layer","Soil Phosphorus Content by Layer","Sensible heat","Latent heat","Ground heat","Stomatal Conductance","Total Evaporation","Transpiration","Total transpiration","Longwave Albedo","Shortwave Albedo","Net Longwave Radiation","Net shortwave radiation","Absorbed fraction incoming PAR","Soil Layer Top Depth","Soil Layer Node Depth","Soil Layer Bottom Depth","Average Layer Soil Moisture","Average Layer Fraction of Saturation","Total Soil Wetness","Surface runoff","Subsurface runoff","Average Layer Soil Temperature","Active Layer Thickness","Frozen Thickness","Canopy Temperature","Snow Water Equivalent","Bulk Snow Density","Total snow depth","CO2CAS","Near surface CO2 concentration","Surface incident longwave radiation","Surface pressure","Near surface specific humidity","Rainfall rate","Surface incident shortwave radiation","Near surface air temperature","Near surface module of the wind","Daily Maximum Temperature","Daily Minimum Temperature","Northward Component of Wind","Eastward Component of Wind","Relative Humidity","Photosynthetically Active Radiation","Precipitation","Basal area","Stem Density","Diameter at Breast Height","","Aboveground Biomass Fractional Composition","New Individuals","Mortality","Soil Depth Layer","Leaf assimilation rate"],["Dimension","Dimension","Dimension","Dimension","Dimension","Dimension","Dimension","Deprecated","Deprecated","Deprecated","Deprecated","Deprecated","Deprecated","Deprecated","Deprecated","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Deprecated","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Carbon Fluxes","Deprecated","Deprecated","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Carbon Pools","Nitrogen Pools","Phosphorus Pools","Energy Fluxes","Energy Fluxes","Energy Fluxes","Energy Fluxes","Energy Fluxes","Deprecated","Energy Fluxes","Energy Fluxes","Energy Fluxes","Energy Fluxes","Energy Fluxes","Energy Fluxes","Deprecated","Deprecated","Deprecated","Physical Variables","Physical Variables","Physical Variables","Physical Variables","Physical Variables","Physical Variables","Physical Variables","Physical Variables","Physical Variables","Physical Variables","Physical Variables","Physical Variables","Physical Variables","Driver","Driver","Driver","Driver","Driver","Driver","Driver","Driver","Driver","Driver","Driver","Driver","Driver","Driver","Driver","Diversity","Diversity","Diversity","","Diversity","Diversity","Diversity","Deprecated","Carbon Fluxes"],["real","real","real","character","double","real","real","real","real","double","double","double","integer","integer","integer","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","character","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","real","","real","real","real","real","real"],[null,null,null,null,null,null,null,"nbnds","nbnds","nbnds","time","nbnds","ncal","ncal","ncal","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","nchar","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","depth","depth","depth","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","lon","","lon","lon","lon","depth","lon"],[null,null,null,null,null,null,null,"lon","lat","time",null,"time","time","time","time","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","npool","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat",null,null,null,"lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","lat","","lat","lat","lat",null,"lat"],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time",null,"npool","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time",null,null,null,"depth","depth","time","time","time","depth","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","time","","time","time","time",null,"time"],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"depth",null,null,"wdsize",null,null,null,"pft",null,"time",null,null,null,null,"rtsize","depth","depth",null,null,null,null,null,"depth",null,null,null,"wdsize","depth","depth","depth","depth","depth","depth","depth","depth",null,null,null,null,null,null,"pft",null,null,null,null,null,null,null,null,"time","time",null,null,null,"time",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"pft","pft","pft","","pft","pft","pft",null,null],["longitude at center of each grid cell","latitude at center of each grid cell","depth to bottom of soil layer","Name of each plant function type or species included in the model","julian days days since 1700-01-01 00:00:00 UTC for middle of time averaging period Proleptic_Gregorianc calendar","Minimum threshold of root size class","Minimum threshold of woody debris size class","(west boundary of grid cell, east boundary of grid cell)","(south boundary of grid cell, north boundary of grid cell)","(julian days days since 1700-01-01 beginning time ave period, julian days days since 1700-01-01 end time ave period)","decimal date in fractional years for middle of time averaging period","(decimal date beginning time ave period, decimal date end time ave period)","calender date middle of time ave period: year, month, day, hour, minute, second for UTC time zone","calender date beginning of time ave period: year, month, day, hour, minute, second for UTC time zone","calender date end of time ave period: year, month, day, hour, minute, second for UTC time zone","Rate of photosynthesis (always positive)","Net Ecosystem Exchange (NEE=HeteroResp+AutoResp-GPP, positive into atmosphere)","Total respiration (TotalResp=AutoResp+heteroResp, always positive)","Autotrophic respiration rate (always positive)","Heterotrophic respiration rate (always positive)","Sum of respiration in the soil by heterotrophs and by the roots of plants (autotrophs)","Loss of organic carbon dissolved in ground water or rivers (positive out of grid cell)","Flux of carbon due to fires (always positive)","Total carbon flux of litter, excluding coarse woody debris","Total carbon flux of surface litter","Total carbon flux of subsurface litter","Carbon flux of leaf litter","DALEC output; haven't yet resolved standard woody litter flux","Total carbon flux of woody debris, including downed woody debris and standing deadwood; excludes litter; size class defined by wdsize dimension","Net Primary Productivity (NPP=GPP-AutoResp, positive into plants)","Variable most analogous to tree-ring-derived change in stem biomass (before mortality/CWD flux)","Variable most analogous to flux of woody material material to the detrital pool resulting from mortality","Crop yield; ED2 output variable","Name of each carbon pool (i.e., wood or Coarse Woody Debris)","Total size of each carbon pool vertically integrated over the entire soil column","Total carbon content of the living biomass (leaves+roots+wood)","aboveground biomass","Area of leaves per area ground","Leaf carbon content","\nRoot carbon content, optionally by size class; alternatively specify fine_ and coarse_root_carbon_content","Carbon content of fine roots (2 mm and smaller); alternative to providing dimensions for root_carbon_content","Carbon content of coarse roots (larger than 2 mm); alternative to providing dimensions for root_carbon_content","Wood carbon content including above (AbvGrndWood) and below ground (coarse roots, shared with root_carbon_content)","Total above ground wood biomass","Total soil and litter carbon content vertically integrated over the enire soil column","Total carbon content of litter pool, excluding coarse woody debris","Carbon content of surface litter pool","Carbon content of subsurface litter pool; depth dimension optional","Carbon content of leaf litter pool","Carbon content of reproductive litter pool (e.g. seeds, flowers, cones, pollen)","Carbon content of uncategorized litter pool (e.g. insect excreta)","Carbon content of downed woody debris and standing deadwood; excludes litter; size classes defined by wdsize dimension","Total carbon content of soil layer, excluding litter","Total inorganic carbon content of soil layer (mineralized carbon such as carbonate)","Total organic carbon content of soil layer, excluding litter","Slow soil pool carbon content of soil layer","Fast soil pool carbon content of soil layer","Structural soil pool carbon content of soil layer","Total nitrogen content of soil layer","Total phosphorus content of soil layer","Sensible heat flux into the boundary layer (positive into atmosphere)","Latent heat flux into the boundary layer (positive into atmosphere)","Ground heat flux; ED2 output variable","Rate of leaf conductance of water vapor from the leaf sub-stomatal cavities to the atmosphere","Sum of all evaporation sources (positive into atmosphere)","Deprecated, to be replaced by Transp. Total Plant transpiration (always positive)","Total transpiration of each PFT within each grid cell","Longwave Albedo","Shortwave albedo","Incident longwave radiation minus simulated outgoing longwave radiation (positive into grnd)","Incident shortwave radiation minus simulated outgoing shortwave radiation (positive into grnd)","absorbed fraction incoming photosyntetically active radiation","Depth from soil surface to top of soil layer","Depth from soil surface to layer prognostic variables, typically center of soil layer","Depth from soil surface to bottom of soil layer","Soil water content in each soil layer, including liquid, vapor and ice","Fraction of saturation of soil water in each soil layer, including liquid and ice","Vertically integrated soil moisture divided by maximum allowable soil moisture above wilting point","Runoff from the landsurface and/or subsurface stormflow","Gravity soil water drainage and/or soil water lateral flow","Average soil temperature in each soil layer","Thaw depth to zero centigrade isotherm in permafrost","Freeze depth to zero centigrade isotherm in non-permafrost","Canopy or vegetation temperature (or temperature used in photosynthesis calculations)","Total water mass of snow pack, including ice and liquid water","Overall bulk density of the snow pack, including ice and liquid water","Total snow depth","CO2 in canopy air space; ED2 output variable","Near surface dry air CO2 mole fraction","Surface incident longwave radiation","Surface pressure","Near surface specific humidity","Rainfall rate","Surface incident shortwave radiation","Near surface air temperature","Near surface wind magnitude","Daily Maximum Temperature","Daily Minimum Temperature","Northward Component of Wind","Eastward Component of Wind","Relative Humidity","Photosynthetically Active Radiation","The per unit area and time precipitation representing the sum of convective rainfall, stratiform rainfall, and snowfall","Basal area by PFT","Stem Density by PFT",null,"","Aboveground biomass Fractional composition of each PFT within each grid cell","New Individuals","Individuals lost through death","Depth to the bottom of each model-defined soil layer","Rate of leaf photosynthesis / carbon assimilation"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Variable.Name<\/th>\n      <th>standard_name<\/th>\n      <th>Units<\/th>\n      <th>Long.name<\/th>\n      <th>Category<\/th>\n      <th>var_type<\/th>\n      <th>dim1<\/th>\n      <th>dim2<\/th>\n      <th>dim3<\/th>\n      <th>dim4<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"Bfrtip","scrollX":true,"fixedColumns":true,"buttons":["copy","csv","excel","pdf","print"],"order":[],"autoWidth":false,"orderClasses":false,"columnDefs":[{"orderable":false,"targets":0}]}},"evals":[],"jsHooks":[]}</script>

</div>
</div>
<div id="pecanXML" class="section level2">
<h2><span class="header-section-number">3.2</span> The PEcAn XML</h2>
<p>The PEcAn system is configured using a XML file, often called <code>pecan.xml</code>.
It contains the following major sections (“nodes”):</p>
<ul>
<li><a href="topical.html#xml-core-config">Core configuration</a>
<ul>
<li><a href="topical.html#xml-structure">Top level structure</a></li>
<li><a href="topical.html#xml-info"><code>info</code></a> – Run metadata</li>
<li><a href="topical.html#xml-outdir"><code>outdir</code></a> – Output directory</li>
<li><a href="topical.html#xml-database"><code>database</code></a> – PEcAn database settings</li>
<li><a href="topical.html#xml-pft"><code>pft</code></a> – Plant functional type selection</li>
<li><a href="topical.html#xml-meta-analysis"><code>meta.analysis</code></a> – Trait meta analysis</li>
<li><a href="topical.html#xml-model"><code>model</code></a> – Model configuration</li>
<li><a href="topical.html#xml-run"><code>run</code></a> – Run setup</li>
<li><a href="topical.html#xml-host"><code>host</code></a> – Host information for remote execution</li>
</ul></li>
<li><a href="topical.html#xml-advanced">Advanced features</a>
<ul>
<li><a href="topical.html#xml-ensemble"><code>ensemble</code></a> – Ensemble runs</li>
<li><a href="topical.html#xml-sensitivity-analysis"><code>sensitivity.analysis</code></a> – Sensitivity analysis</li>
<li><a href="topical.html#xml-parameter-data-assimilation"><code>parameter.data.assimilation</code></a> – Parameter data assimilation</li>
<li><a href="topical.html#xml-multi-settings"><code>multi.settings</code></a> – Multi Site Settings</li>
<li>(experimental) <a href="topical.html#xml-state-data-assimilation"><code>state.data.assimilation</code></a> – State data assimilation</li>
<li>(experimental) <a href="topical.html#xml-browndog"><code>browndog</code></a> – Brown Dog configuration</li>
<li>(experimental) <a href="topical.html#xml-benchmarking"><code>benchmarking</code></a> – Benchmarking</li>
</ul></li>
</ul>
<p>A basic example looks like this:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;<span class="kw">?&gt;</span>
<span class="kw">&lt;pecan&gt;</span>
  <span class="kw">&lt;info&gt;</span>
    <span class="kw">&lt;notes&gt;</span>Example run<span class="kw">&lt;/notes&gt;</span>
    <span class="kw">&lt;userid&gt;</span>-1<span class="kw">&lt;/userid&gt;</span>
    <span class="kw">&lt;username&gt;</span>guestuser<span class="kw">&lt;/username&gt;</span>
    <span class="kw">&lt;date&gt;</span>2018/09/18 19:12:28 +0000<span class="kw">&lt;/date&gt;</span>
  <span class="kw">&lt;/info&gt;</span>
  <span class="kw">&lt;outdir&gt;</span>/data/workflows/PEcAn_99000000006<span class="kw">&lt;/outdir&gt;</span>
  <span class="kw">&lt;database&gt;</span>
    <span class="kw">&lt;bety&gt;</span>
      <span class="kw">&lt;user&gt;</span>bety<span class="kw">&lt;/user&gt;</span>
      <span class="kw">&lt;password&gt;</span>bety<span class="kw">&lt;/password&gt;</span>
      <span class="kw">&lt;host&gt;</span>postgres<span class="kw">&lt;/host&gt;</span>
      <span class="kw">&lt;dbname&gt;</span>bety<span class="kw">&lt;/dbname&gt;</span>
      <span class="kw">&lt;driver&gt;</span>PostgreSQL<span class="kw">&lt;/driver&gt;</span>
      <span class="kw">&lt;write&gt;</span>true<span class="kw">&lt;/write&gt;</span>
    <span class="kw">&lt;/bety&gt;</span>
    <span class="kw">&lt;dbfiles&gt;</span>/data/dbfiles<span class="kw">&lt;/dbfiles&gt;</span>
  <span class="kw">&lt;/database&gt;</span>
  <span class="kw">&lt;pfts&gt;</span>
    <span class="kw">&lt;pft&gt;</span>
      <span class="kw">&lt;name&gt;</span>tundra.grasses<span class="kw">&lt;/name&gt;</span> 
      <span class="kw">&lt;constants&gt;</span>
        <span class="kw">&lt;num&gt;</span>1<span class="kw">&lt;/num&gt;</span>
      <span class="kw">&lt;/constants&gt;</span>
    <span class="kw">&lt;/pft&gt;</span>
  <span class="kw">&lt;/pfts&gt;</span>
  <span class="kw">&lt;meta.analysis&gt;</span>
    <span class="kw">&lt;iter&gt;</span>3000<span class="kw">&lt;/iter&gt;</span>
    <span class="kw">&lt;random.effects&gt;</span>FALSE<span class="kw">&lt;/random.effects&gt;</span>
  <span class="kw">&lt;/meta.analysis&gt;</span>
  <span class="kw">&lt;ensemble&gt;</span>
   <span class="kw">&lt;size&gt;</span>1<span class="kw">&lt;/size&gt;</span>
   <span class="kw">&lt;variable&gt;</span>NPP<span class="kw">&lt;/variable&gt;</span>
   <span class="kw">&lt;samplingspace&gt;</span>
   <span class="kw">&lt;parameters&gt;</span>
    <span class="kw">&lt;method&gt;</span>uniform<span class="kw">&lt;/method&gt;</span>
   <span class="kw">&lt;/parameters&gt;</span>
   <span class="kw">&lt;met&gt;</span>
    <span class="kw">&lt;method&gt;</span>sampling<span class="kw">&lt;/method&gt;</span>
    <span class="kw">&lt;/met&gt;</span>
   <span class="kw">&lt;/samplingspace&gt;</span>
  <span class="kw">&lt;/ensemble&gt;</span>
  <span class="kw">&lt;model&gt;</span>
    <span class="kw">&lt;id&gt;</span>5000000002<span class="kw">&lt;/id&gt;</span>
  <span class="kw">&lt;/model&gt;</span>
  <span class="kw">&lt;workflow&gt;</span>
    <span class="kw">&lt;id&gt;</span>99000000006<span class="kw">&lt;/id&gt;</span>
  <span class="kw">&lt;/workflow&gt;</span>
  <span class="kw">&lt;run&gt;</span>
    <span class="kw">&lt;site&gt;</span>
      <span class="kw">&lt;id&gt;</span>1000000098<span class="kw">&lt;/id&gt;</span>
      <span class="kw">&lt;met.start&gt;</span>2004/01/01<span class="kw">&lt;/met.start&gt;</span>
      <span class="kw">&lt;met.end&gt;</span>2004/12/31<span class="kw">&lt;/met.end&gt;</span>
    <span class="kw">&lt;/site&gt;</span>
    <span class="kw">&lt;inputs&gt;</span>
      <span class="kw">&lt;met&gt;</span>
        <span class="kw">&lt;source&gt;</span>CRUNCEP<span class="kw">&lt;/source&gt;</span>
        <span class="kw">&lt;output&gt;</span>SIPNET<span class="kw">&lt;/output&gt;</span>
      <span class="kw">&lt;/met&gt;</span>
    <span class="kw">&lt;/inputs&gt;</span>
    <span class="kw">&lt;start.date&gt;</span>2004/01/01<span class="kw">&lt;/start.date&gt;</span>
    <span class="kw">&lt;end.date&gt;</span>2004/12/31<span class="kw">&lt;/end.date&gt;</span>
  <span class="kw">&lt;/run&gt;</span>
  <span class="kw">&lt;host&gt;</span>
    <span class="kw">&lt;name&gt;</span>localhost<span class="kw">&lt;/name&gt;</span>
    <span class="kw">&lt;rabbitmq&gt;</span>
      <span class="kw">&lt;uri&gt;</span>amqp://guest:guest@rabbitmq:5672/%2F<span class="kw">&lt;/uri&gt;</span>
      <span class="kw">&lt;queue&gt;</span>SIPNET_136<span class="kw">&lt;/queue&gt;</span>
    <span class="kw">&lt;/rabbitmq&gt;</span>
  <span class="kw">&lt;/host&gt;</span>
<span class="kw">&lt;/pecan&gt;</span></code></pre>
<p>In the following sections, we step through each of these sections in detail.</p>
<div id="xml-core-config" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Core configuration</h3>
<div id="xml-structure" class="section level4">
<h4><span class="header-section-number">3.2.1.1</span> Top-level structure</h4>
<p>The first line of the XML file should contain version and encoding information.</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;<span class="kw">?&gt;</span></code></pre>
<p>The rest of the XML file should be surrounded by <code>&lt;pecan&gt;...&lt;/pecan&gt;</code> tags.</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;pecan&gt;</span>
  ...XML body here...
<span class="kw">&lt;/pecan&gt;</span></code></pre>
</div>
<div id="xml-info" class="section level4">
<h4><span class="header-section-number">3.2.1.2</span> <code>info</code>: Run metadata</h4>
<p>This section contains run metadata.
This information is not essential to a successful model run, but is useful for tracking run provenance.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;info&gt;</span>
    <span class="kw">&lt;notes&gt;</span>Example run<span class="kw">&lt;/notes&gt;</span>
    <span class="kw">&lt;userid&gt;</span>-1<span class="kw">&lt;/userid&gt;</span>
    <span class="kw">&lt;username&gt;</span>guestuser<span class="kw">&lt;/username&gt;</span>
    <span class="kw">&lt;date&gt;</span>2018/09/18 19:12:28 +0000<span class="kw">&lt;/date&gt;</span>
  <span class="kw">&lt;/info&gt;</span></code></pre>
<p>The <code>&lt;notes&gt;</code> tag will be filled in by the web GUI if you provide notes, or you can add notes yourself within these tags. We suggest adding notes that help identify your run and a brief description of what the run is for. Because these notes are searchable within the PEcAn database and web interface, they can be a useful way to distinguish between similar runs.</p>
<p>The <code>&lt;userid&gt;</code> and <code>&lt;username&gt;</code> section is filled in from the GUI if you are signed in. If you are not using the GUI, add the user name and ID you are associated with that exists within the PEcAn database.</p>
<p>The <code>&lt;date&gt;&lt;/date&gt;</code> tag is filled automatically at the time of your run from the GUI. If you are not using the GUI, add the date you execute the run. This tag is not the tag for the dates you would like to run your model simulation.</p>
</div>
</div>
<div id="xml-outdir" class="section level3">
<h3><span class="header-section-number">3.2.2</span> <code>outdir</code>: Output directory</h3>
<p>The <code>&lt;outdir&gt;</code> tag is used to configure the output folder used by PEcAn.
This is the directory where all model input and output files will be stored.
By default, the web interface names this folder <code>PEcAn_&lt;workflow ID&gt;</code>, and higher-level location is set by the <code>$output_folder$</code> variable in the <code>web/config.php</code> file.
If no <code>outdir</code> is specified, PEcAn defaults to the working directory from which it is called, which may be counterintuitive.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;outdir&gt;</span>/data/workflows/PEcAn_99000000006<span class="kw">&lt;/outdir&gt;</span></code></pre>
</div>
<div id="xml-database" class="section level3">
<h3><span class="header-section-number">3.2.3</span> <code>database</code>: PEcAn database settings</h3>
<div id="xml-bety" class="section level4">
<h4><span class="header-section-number">3.2.3.1</span> <code>bety</code>: PEcAn database (Bety) configuration</h4>
<p>The <code>bety</code> tag defines the driver to use to connect to the database (the only driver we support, and the default, is <code>PostgreSQL</code>) and parameters required to connect to the database. Note that connection parameters are passed <em>exactly</em> as entered to the underlying R database driver, and any invalid or extra parameters will result in an error.</p>
<p>In other words, this configuration…</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;database&gt;</span>
    ...
    <span class="kw">&lt;bety&gt;</span>
      <span class="kw">&lt;user&gt;</span>bety<span class="kw">&lt;/user&gt;</span>
      <span class="kw">&lt;password&gt;</span>bety<span class="kw">&lt;/password&gt;</span>
      <span class="kw">&lt;host&gt;</span>postgres<span class="kw">&lt;/host&gt;</span>
      <span class="kw">&lt;dbname&gt;</span>bety<span class="kw">&lt;/dbname&gt;</span>
      <span class="kw">&lt;driver&gt;</span>PostgreSQL<span class="kw">&lt;/driver&gt;</span>
      <span class="kw">&lt;write&gt;</span>true<span class="kw">&lt;/write&gt;</span>
    <span class="kw">&lt;/bety&gt;</span>
    ...
  <span class="kw">&lt;/database&gt;</span></code></pre>
<p>…will be translated into R code like the following:</p>
<pre class="sourceCode r"><code class="sourceCode r">con &lt;-<span class="st"> </span>DBI<span class="op">::</span><span class="kw">dbConnect</span>(
  DBI<span class="op">::</span><span class="kw">dbDriver</span>(<span class="st">&quot;PostgreSQL&quot;</span>),
  <span class="dt">user =</span> <span class="st">&quot;bety&quot;</span>,
  <span class="dt">password =</span> <span class="st">&quot;bety&quot;</span>,
  <span class="dt">dbname =</span> <span class="st">&quot;bety&quot;</span>,
  <span class="dt">host =</span> <span class="st">&quot;postgres&quot;</span>,
  <span class="dt">write =</span> <span class="ot">TRUE</span>
)</code></pre>
<p>Common parameters are described as follows:</p>
<ul>
<li><code>driver</code>: The driver to use to connect to the database. This should always be set to <code>PostgreSQL</code>, unless you absolutely know what you’re doing.</li>
<li><code>dbname</code>: The name of the database (formerly <code>name</code>), corresponding to the <code>-d</code> argument to <code>psql</code>. In most cases, this should be set to <code>bety</code>, and will only be different if you named your Bety instance something else (e.g. if you have multiple instances running at once). If unset, it will default to the user name of the current user, which is usually wrong!</li>
<li><code>user</code>: The username to connect to the database (formerly <code>userid</code>), corresponding to the <code>-U</code> argument to <code>psql</code>. default value is the username of the current user logged in (PostgreSQL uses user for this field).</li>
<li><code>password</code>: The password to connect to the database (was <code>passwd</code>), corresponding to the <code>-p</code> argument to <code>psql</code>. If unspecified, no password is used. On standard PEcAn installations, the username and password are both <code>bety</code> (all lowercase).</li>
<li><code>host</code>: The hostname of the <code>bety</code> database, corresponding to the <code>-h</code> argument to <code>psql</code>. On the VM, this will be <code>localhost</code> (the default). If using <code>docker</code>, this will be the name of the PostgreSQL container, which is <code>postgres</code> if using our standard <code>docker-compose</code>. If connecting to the PEcAn database on a remote server (e.g. <code>psql-pecan.bu.edu</code>), this should be the same as the hostname used for <code>ssh</code> access.</li>
<li><code>write</code>: Logical. If <code>true</code> (the default), write results to the database. If <code>false</code>, PEcAn will run but will not store any information to <code>bety</code>.</li>
</ul>
<p>When using the web interface, this section is configured by the <code>web/config.php</code> file.
The default <code>config.php</code> settings on any given platform (VM, Docker, etc.) or in example files (e.g. <code>config.php.example</code>) are a good place to get default values for these fields if writing <code>pecan.xml</code> by hand.</p>
<p>Key R functions using these parameters are as follows:</p>
<ul>
<li><code>PEcAn.DB::db.open</code> – Open a database connection and create a connection object, which is used by many other functions for communicating with the PEcAn database.</li>
</ul>
</div>
<div id="xml-dbfiles" class="section level4">
<h4><span class="header-section-number">3.2.3.2</span> <code>dbfiles</code>: Location of database files</h4>
<p>The <code>dbfiles</code> is a path to the local location of files needed to run models using PEcAn, including model executables and inputs.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;database&gt;</span>
    ...
    <span class="kw">&lt;dbfiles&gt;</span>/data/dbfiles<span class="kw">&lt;/dbfiles&gt;</span>
    ...
  <span class="kw">&lt;/database&gt;</span></code></pre>
</div>
<div id="xml-fia" class="section level4">
<h4><span class="header-section-number">3.2.3.3</span> (Experimental) <code>fia</code>: FIA database connection parameters</h4>
<p>If a version of the FIA database is available, it can be configured using <code>&lt;fia&gt;</code> node, whose syntax is identical to that of the <code>&lt;bety&gt;</code> node.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;database&gt;</span>
    ...
    <span class="kw">&lt;fia&gt;</span>
        <span class="kw">&lt;dbname&gt;</span>fia5data<span class="kw">&lt;/dbname&gt;</span>
        <span class="kw">&lt;username&gt;</span>bety<span class="kw">&lt;/username&gt;</span>
        <span class="kw">&lt;password&gt;</span>bety<span class="kw">&lt;/password&gt;</span>
        <span class="kw">&lt;host&gt;</span>localhost<span class="kw">&lt;/host&gt;</span>
    <span class="kw">&lt;/fia&gt;</span>
    ...
  <span class="kw">&lt;/database&gt;</span></code></pre>
<p>Currently, this is only used for extraction of specific site vegetation information (notably, for ED2 <code>css</code>, <code>pss</code>, and <code>site</code> files).
Stability not ensured as of 1.5.3.</p>
</div>
</div>
<div id="xml-pft" class="section level3">
<h3><span class="header-section-number">3.2.4</span> <code>pft</code>: Plant functional type selection</h3>
<p>The PEcAn system requires at least 1 plant functional type (PFT) to be specified inside the <code>&lt;pfts&gt;</code> section.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;pfts&gt;</span>
    <span class="kw">&lt;pft&gt;</span>
      <span class="kw">&lt;name&gt;</span>tundra.grasses<span class="kw">&lt;/name&gt;</span> 
      <span class="kw">&lt;constants&gt;</span>
        <span class="kw">&lt;num&gt;</span>1<span class="kw">&lt;/num&gt;</span>
      <span class="kw">&lt;/constants&gt;</span>
    <span class="kw">&lt;/pft&gt;</span>
  <span class="kw">&lt;/pfts&gt;</span></code></pre>
<ul>
<li><code>name</code> : (required) the name of the PFT, which must <em>exactly</em> match the name in the PEcAn database.</li>
<li><code>outdir</code>: (optional) Directory path in which PFT-specific output will be stored during meta-analysis and sensitivity analysis. If not specified (recommended), it will be written into <code>&lt;outdir&gt;/&lt;pftname&gt;</code>.</li>
<li><code>contants</code>: (optional) this section contains information that will be written directly into the model specific configuration files. For example, some models like ED2 use PFT numbers instead of names for PFTs, and those numbers can be specified here. See documentation for model-specific code for details.</li>
</ul>
<p>This information is currently used by the following PEcAn workflow function:</p>
<ul>
<li><code>get.traits</code> - ??????</li>
</ul>
</div>
<div id="xml-meta-analysis" class="section level3">
<h3><span class="header-section-number">3.2.5</span> <code>meta.analysis</code>: Trait Meta Analysis</h3>
<p>The section meta.analysis needs to exists for a meta.analysis to be executed, even though all tags inside are optional.
Conversely, if you do not want to do a trait meta-analysis (e.g. if you want to manually set all parameters), you should omit this node.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;meta.analysis&gt;</span>
    <span class="kw">&lt;iter&gt;</span>3000<span class="kw">&lt;/iter&gt;</span>
    <span class="kw">&lt;random.effects&gt;</span>FALSE<span class="kw">&lt;/random.effects&gt;</span>
  <span class="kw">&lt;/meta.analysis&gt;</span></code></pre>
<p>Some of the tags that can go in this section are:</p>
<ul>
<li><code>iter</code>: <a href="http:/en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">MCMC</a> (Markov Chain Monte Carlo) chain length, i.e. the total number of posterior samples in the meta-analysis, default is 3000. Smaller numbers will run faster but produce larger errors.</li>
<li><code>random.effects</code>: Whether to include random effects (site, treatment) in meta-analysis model. Can be set to FALSE to work around convergence problems caused by an over parameterized model (e.g. too many sites, not enough data). The default value is TRUE.</li>
<li><code>update</code>: Should previous results of meta.analysis and get.traits be re-used. If set to TRUE the meta-analysis and get.trait.data will always be executed. Setting this to FALSE will try and reuse existing results. Future versions will allow for AUTO as well which will try and reuse if the PFT/traits have not changed. The default value is FALSE.</li>
<li><code>threshold</code>: threshold for Gelman-Rubin convergence diagnostic (MGPRF); default is 1.2.</li>
</ul>
<p>This information is currently used by the following PEcAn workflow function:</p>
<ul>
<li><code>PEcAn.MA::run.meta.analysis</code> - ???</li>
</ul>
</div>
<div id="xml-model" class="section level3">
<h3><span class="header-section-number">3.2.6</span> <code>model</code>: Model configuration</h3>
<p>This section describes which model PEcAn should run and some instructions for how to run it.</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;model&gt;</span>
    <span class="kw">&lt;id&gt;</span>7<span class="kw">&lt;/id&gt;</span>
    <span class="kw">&lt;type&gt;</span>ED2<span class="kw">&lt;/type&gt;</span>
    <span class="kw">&lt;binary&gt;</span>/usr/local/bin/ed2.r82<span class="kw">&lt;/binary&gt;</span>
    <span class="kw">&lt;job.sh&gt;</span>module load hdf5<span class="kw">&lt;/job.sh&gt;</span>
    <span class="kw">&lt;config.header&gt;</span>
        <span class="co">&lt;!--...xml code passed directly to config file...--&gt;</span>
    <span class="kw">&lt;/config.header&gt;</span>
<span class="kw">&lt;/model&gt;</span></code></pre>
<p>Some important tags are as follows:</p>
<ul>
<li><code>id</code> – The unique numeric ID of the model in the PEcAn database <code>models</code> table. If this is present, then <code>type</code> and <code>binary</code> are optional since they can be determined from the PEcAn database.</li>
<li><code>type</code> – The model “type”, matching the PEcAn database <code>modeltypes</code> table <code>name</code> column. This also refers to which PEcAn model-specific package will be used. In PEcAn, a “model” refers to a specific version (e.g. release, git commit) of a specific model, and “model type” is used to link different releases of the same model. Model “types” also have specific PFT definitions and other requirements associated with them (e.g. the ED2 model “type” requires a global land cover database).</li>
<li><code>binary</code> – The file path to the model executable. If omitted, PEcAn will use whatever path is registered in the PEcAn database for the current machine.</li>
<li><code>job.sh</code> – Additional options added to the <code>job.sh</code> script, which is used to execute the model. This is useful for setting specific environment variables, load modules, etc.</li>
</ul>
<p>This information is currently used by the following PEcAn workflow function:</p>
<ul>
<li><code>PEcAn.&lt;MODEL&gt;::write.config.&lt;MODEL&gt;</code> – Write model-specific configuration files {#pecan-write-configs}</li>
<li><code>PEcAn.remote::start.model.runs</code> – Begin model run execution</li>
</ul>
<div id="xml-model-specific" class="section level4">
<h4><span class="header-section-number">3.2.6.1</span> Model-specific configuration</h4>
<p>See the following:</p>
<ul>
<li>[ED2][ED2 Configuration]</li>
<li>[SIPNET][SIPNET Configuration]</li>
<li>[BIOCRO][BioCro Configuration]</li>
</ul>
</div>
<div id="xml-ed" class="section level4">
<h4><span class="header-section-number">3.2.6.2</span> ED2 specific tags</h4>
<p>Following variables are ED specific and are used in the <a href="ED2-Configuration">ED2 Configuration</a>.</p>
<p>Starting at 1.3.7 the tags for inputs have moved to <code>&lt;run&gt;&lt;inputs&gt;</code>. This includes, veg, soil, psscss, inputs.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">    <span class="kw">&lt;edin&gt;</span>/home/carya/runs/PEcAn_4/ED2IN.template<span class="kw">&lt;/edin&gt;</span>
    <span class="kw">&lt;config.header&gt;</span>
        <span class="kw">&lt;radiation&gt;</span>
            <span class="kw">&lt;lai_min&gt;</span>0.01<span class="kw">&lt;/lai_min&gt;</span>
        <span class="kw">&lt;/radiation&gt;</span>
        <span class="kw">&lt;ed_misc&gt;</span>
            <span class="kw">&lt;output_month&gt;</span>12<span class="kw">&lt;/output_month&gt;</span>
        <span class="kw">&lt;/ed_misc&gt;</span> 
    <span class="kw">&lt;/config.header&gt;</span>
    <span class="kw">&lt;phenol.scheme&gt;</span>0<span class="kw">&lt;/phenol.scheme&gt;</span></code></pre>
<ul>
<li><strong>edin</strong> : [required] template used to write ED2IN file</li>
<li><strong>veg</strong> : <strong>OBSOLETE</strong> [required] location of VEG database, now part of <code>&lt;run&gt;&lt;inputs&gt;</code></li>
<li><strong>soil</strong> : <strong>OBSOLETE</strong> [required] location of soild database, now part of <code>&lt;run&gt;&lt;inputs&gt;</code></li>
<li><strong>psscss</strong> : <strong>OBSOLETE</strong> [required] location of site inforation, now part of <code>&lt;run&gt;&lt;inputs&gt;</code>. Should be specified as <code>&lt;pss&gt;</code>, <code>&lt;css&gt;</code> and <code>&lt;site&gt;</code>.</li>
<li><strong>inputs</strong> : <strong>OBSOLETE</strong> [required] location of additional input files (e.g. data assimilation data), now part of <code>&lt;run&gt;&lt;inputs&gt;</code>. Should be specified as <code>&lt;lu&gt;</code> and <code>&lt;thsums&gt;</code>.</li>
</ul>
</div>
</div>
<div id="xml-run" class="section level3">
<h3><span class="header-section-number">3.2.7</span> <code>run</code>: Run Setup</h3>
<p>This section provides detailed configuration for the model run, including the site and time period for the simulation and what input files will be used.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;run&gt;</span>
    <span class="kw">&lt;site&gt;</span>
      <span class="kw">&lt;id&gt;</span>1000000098<span class="kw">&lt;/id&gt;</span>
      <span class="kw">&lt;met.start&gt;</span>2004/01/01<span class="kw">&lt;/met.start&gt;</span>
      <span class="kw">&lt;met.end&gt;</span>2004/12/31<span class="kw">&lt;/met.end&gt;</span>
      <span class="kw">&lt;site.pft&gt;</span>
        <span class="kw">&lt;pft.name&gt;</span>temperate.needleleaf.evergreen<span class="kw">&lt;/pft.name&gt;</span>
        <span class="kw">&lt;pft.name&gt;</span>temperate.needleleaf.evergreen.test<span class="kw">&lt;/pft.name&gt;</span>
      <span class="kw">&lt;/site.pft&gt;</span>
    <span class="kw">&lt;/site&gt;</span>
    <span class="kw">&lt;inputs&gt;</span>
      <span class="kw">&lt;met&gt;</span>
        <span class="kw">&lt;source&gt;</span>CRUNCEP<span class="kw">&lt;/source&gt;</span>
        <span class="kw">&lt;output&gt;</span>SIPNET<span class="kw">&lt;/output&gt;</span>
      <span class="kw">&lt;/met&gt;</span>
    <span class="kw">&lt;/inputs&gt;</span>
    <span class="kw">&lt;start.date&gt;</span>2004/01/01<span class="kw">&lt;/start.date&gt;</span>
    <span class="kw">&lt;end.date&gt;</span>2004/12/31<span class="kw">&lt;/end.date&gt;</span>
  <span class="kw">&lt;/run&gt;</span></code></pre>
<div id="xml-run-site" class="section level4">
<h4><span class="header-section-number">3.2.7.1</span> <code>site</code>: Where to run the model</h4>
<p>This contains the following tags:</p>
<ul>
<li><code>id</code> – This is the numeric ID of the site in the PEcAn database (table <code>sites</code>, column <code>id</code>). PEcAn can automatically fill in other relevant information for the site (e.g. <code>name</code>, <code>lat</code>, <code>lon</code>) using the site ID, so those fields are optional if ID is provided.</li>
<li><code>name</code> – The name of the site, as a string.</li>
<li><code>lat</code>, <code>lon</code> – The latitude and longitude coordinates of the site, as decimals.</li>
<li><code>met.start</code>, <code>met.end</code> – ???</li>
<li><code>&lt;site.pft&gt;</code> (optional) If this tag is found under the site tag, then PEcAn automatically makes sure that only PFTs defined under this tag is used for generating parameter’s samples. Following shows an exmaple of how this tag can be added to the PEcAn xml :</li>
</ul>
<pre class="sourceCode xml"><code class="sourceCode xml">    <span class="kw">&lt;site.pft&gt;</span>
     <span class="kw">&lt;pft.name&gt;</span>temperate.needleleaf.evergreen<span class="kw">&lt;/pft.name&gt;</span>
     <span class="kw">&lt;pft.name&gt;</span>temperate.needleleaf.evergreen<span class="kw">&lt;/pft.name&gt;</span>
    <span class="kw">&lt;/site.pft&gt;</span></code></pre>
<p>For multi-site runs if the <code>pft.site</code> tag (see {#xml-run-inputs}) is defined under <code>input</code>, then the above process will be done automatically under prepare settings step in PEcAn main workflow and there is no need for adding the tags manually. Using the <code>pft.site</code> tag however, requires a lookup table as an input (see {#xml-run-inputs}).</p>
</div>
<div id="xml-run-inputs" class="section level4">
<h4><span class="header-section-number">3.2.7.2</span> <code>inputs</code>: Model inputs</h4>
<p>Models require several different types of inputs to run.
Exact requirements differ from model to model, but common inputs include meteorological/climate drivers, site initial conditions (e.g. vegetation composition, carbon pools), and land use drivers.</p>
<p>In general, all inputs should have the following tags:</p>
<ul>
<li><code>id</code>: Numeric ID of the input in the PEcAn database (table <code>inputs</code>, column <code>id</code>). If not specified, PEcAn will try to figure this out based on the <code>source</code> tag (described below).</li>
<li><code>path</code>: The file path of the input. Usually, PEcAn will set this automatically based on the <code>id</code> (which, in turn, is determined from the <code>source</code>). However, this can be set manually for data that PEcAn does not know about (e.g. data that you have processed yourself and have not registered with the PEcAn database).</li>
<li><code>source</code>: The input data type. This tag name needs to match the names in the corresponding conversion functions. If you are using PEcAn’s automatic input processing, this is the only field you need to set. However, this field is ignored if <code>id</code> and/or <code>path</code> are provided.</li>
<li><code>output</code>: ???</li>
</ul>
<p>The following are the most common types of inputs, along with their corresponding tags:</p>
<div id="xml-run-inputs-met" class="section level5">
<h5><span class="header-section-number">3.2.7.2.1</span> <code>met</code>: Meteorological inputs</h5>
<p>(Under construction. See the <code>PEcAn.data.atmosphere</code> package, located in <code>modules/data.atmosphere</code>, for more details.)</p>
</div>
<div id="xml-run-inputs-soil" class="section level5">
<h5><span class="header-section-number">3.2.7.2.2</span> (Experimental) <code>soil</code>: Soil inputs</h5>
<p>(Under construction. See the <code>PEcAn.data.land</code> package, located in <code>modules/data.land</code>, for more details).</p>
</div>
<div id="xml-run-inputs-veg" class="section level5">
<h5><span class="header-section-number">3.2.7.2.3</span> (Experimental) <code>veg</code>: Vegetation initial conditions</h5>
<p>(Under construction. Follow developments in the <code>PEcAn.data.land</code> package, located in <code>modules/data.land</code> in the source code).
##### <code>pft.site</code> Multi-site site / PFT mapping</p>
<p>When performing multi-site runs, it is not uncommon to find that different sites need to be run with different PFTs, rather than running all PFTs at all sites. If you’re interested to use a specific PFT for your site/sites you can use the following tag to tell PEcAn which PFT needs to be used for what site.</p>
<pre><code>&lt;pft.site&gt;
  &lt;path&gt;site_pft.csv&lt;/path&gt;
&lt;/pft.site&gt;</code></pre>
<p>For example using the above tag, user needs to have a csv file named <code>site_pft</code> stored in the pecan folder. At the moment we have functions supporting just the <code>.csv</code> and <code>.txt</code> files which are comma separated and have the following format:</p>
<pre><code>site_id, pft_name
1000025731,temperate.broadleaf.deciduous
764,temperate.broadleaf.deciduous</code></pre>
<p>Then pecan would use this lookup table to inform <code>write.ensemble.config</code> function about what PFTs need to be used for what sites.</p>
</div>
</div>
<div id="start.date-and-end.date" class="section level4">
<h4><span class="header-section-number">3.2.7.3</span> <code>start.date</code> and <code>end.date</code></h4>
<p>The start and end date for the run, in a format parseable by R (e.g. <code>YYYY/MM/DD</code> or <code>YYYY-MM-DD</code>).
These dates are inclusive; in other words, they refer to the first and last days of the run, respectively.</p>
<p>NOTE: Any time-series inputs (e.g. meteorology drivers) must contain all of these dates.
PEcAn tries to detect and throw informative errors when dates are out of bounds inputs, but it may not know about some edge cases.</p>
</div>
<div id="other-tags" class="section level4">
<h4><span class="header-section-number">3.2.7.4</span> Other tags</h4>
<p>The following tags are optional run settings that apply to any model:</p>
<ul>
<li><code>jobtemplate</code>: the template used when creating a <code>job.sh</code> file, which is used to launch the actual model. Each model has its own default template in the <code>inst</code> folder of the corresponding R package (for instance, here is the one for <a href="https://github.com/PecanProject/pecan/blob/master/models/ed/inst/template.job">ED2</a>). The following variables can be used: <code>@SITE_LAT@</code>, <code>@SITE_LON@</code>, <code>@SITE_MET@</code>, <code>@START_DATE@</code>, <code>@END_DATE@</code>, <code>@OUTDIR@</code>, <code>@RUNDIR@</code> which all come variables in the <code>pecan.xml</code> file. The following two command can be used to copy and clean the results from a scratch folder (specified as scratch in the run section below, for example local disk vs network disk) : <code>@SCRATCH_COPY@</code>, <code>@SCRATCH_CLEAR@</code>.</li>
</ul>
<p>Some models also have model-specific tags, which are described in the <a href="topical.html#pecan-models">PEcAn Models</a> section.</p>
</div>
</div>
<div id="xml-host" class="section level3">
<h3><span class="header-section-number">3.2.8</span> <code>host</code>: Host information for remote execution</h3>
<p>This section provides settings for remote model execution, i.e. any execution that happens on a machine (including “virtual” machines, like Docker containers) different from the one on which the main PEcAn workflow is running.
A common use case for this section is to submit model runs as jobs to a high-performance computing cluster.
If no <code>host</code> tag is provided, PEcAn assumes models are run on <code>localhost</code>, a.k.a. the same machine as PEcAn itself.</p>
<p>For detailed instructions on remote execution, see the <a href="tutorialsdemos-and-how-tos.html#pecan-remote">Remote Execution</a> page.
For detailed information on configuring this for RabbitMQ, see the <a href="topical.html#rabbitmq-xml">RabbitMQ</a> page.
The following provides a quick overview of XML tags related to remote execution.</p>
<p><strong>NOTE</strong>: Any paths specified in the <code>pecan.xml</code> refer to paths on the <code>host</code> specified in this section, /not/ the machine on which PEcAn is running (unless models are running on <code>localhost</code> or this section is omitted).</p>
<pre class="sourceCode xml"><code class="sourceCode xml">    <span class="kw">&lt;host&gt;</span>
        <span class="kw">&lt;name&gt;</span>pecan2.bu.edu<span class="kw">&lt;/name&gt;</span>
        <span class="kw">&lt;rundir&gt;</span>/fs/data3/guestuser/pecan/testworkflow/run<span class="kw">&lt;/rundir&gt;</span>
        <span class="kw">&lt;outdir&gt;</span>/fs/data3/guestuser/pecan/testworkflow/out<span class="kw">&lt;/outdir&gt;</span>
        <span class="kw">&lt;scratchdir&gt;</span>/tmp/carya<span class="kw">&lt;/scratchdir&gt;</span>
        <span class="kw">&lt;clearscratch&gt;</span>TRUE<span class="kw">&lt;/clearscratch&gt;</span>
        <span class="kw">&lt;qsub&gt;</span>qsub -N @NAME@ -o @STDOUT@ -e @STDERR@ -S /bin/bash<span class="kw">&lt;/qsub&gt;</span>
        <span class="kw">&lt;qsub.jobid&gt;</span>Your job ([0-9]+) .*<span class="kw">&lt;/qsub.jobid&gt;</span>
        <span class="kw">&lt;qstat&gt;</span>qstat -j @JOBID@ <span class="er">&amp;</span>&gt; /dev/null || echo DONE<span class="kw">&lt;/qstat&gt;</span>
        <span class="kw">&lt;job.sh&gt;</span>module load udunits R/R-3.0.0_gnu-4.4.6<span class="kw">&lt;/job.sh&gt;</span>
    <span class="kw">&lt;/host&gt;</span></code></pre>
<p>The <code>host</code> section has the following tags:</p>
<ul>
<li><code>name</code>: [optional] name of host server where model is located and executed, if not specified localhost is assumed.</li>
<li><code>rundir</code>: [optional/required] location where all the configuration files are written. For localhost this is optional (<code>&lt;outdir&gt;/run</code> is the default), for any other host this is required.</li>
<li><code>outdir</code>: [optional/required] location where all the outputs of the model are written. For localhost this is optional (<code>&lt;outdir&gt;/out</code> is the default), for any other host this is required.</li>
<li><code>scratchdir</code>: [optional] location where output is written. If specified the output from the model is written to this folder and copied to the outdir when the model is finished, this could significantly speed up the model execution (by using local or ram disk).</li>
<li><code>clearscratch</code>: [optional] if set to TRUE the scratchfolder is cleaned up after copying the results to the outdir, otherwise the folder will be left. The default is to clean up after copying.</li>
<li><code>qsub</code>: [optional] the command to submit a job to the queuing system. There are 3 parameters you can use when specifying the qsub command, you can add additional values for your specific setup (for example -l walltime to specify the walltime, etc). You can specify <span class="citation">@NAME</span>@ the pretty name, <span class="citation">@STDOUT</span>@ where to write stdout and <span class="citation">@STDERR</span>@, where to write stderr. You can specify an empty element (<code>&lt;qsub/&gt;</code>) in which case it will use the default value is <code>qsub -V -N @NAME@ -o @STDOUT@ -e @STDERR@ -s /bin/bash</code>.</li>
<li><code>qsub.jobid</code>: [optional] the regular expression used to find the <code>jobid</code> returned from <code>qsub</code>. If not specified (and <code>qsub</code> is) it will use the default value is <code>Your job ([0-9]+) .*</code></li>
<li><code>qstat</code>: [optional] the command to execute to check if a job is finished, this should return DONE if the job is finished. There is one parameter this command should take <code>@JOBID@</code> which is the ID of the job as returned by <code>qsub.jobid</code>. If not specified (and qsub is) it will use the default value is <code>qstat -j @JOBID@ || echo DONE</code></li>
<li><code>job.sh</code>: [optional] additional options to add to the job.sh at the top.</li>
</ul>
</div>
<div id="xml-advanced" class="section level3">
<h3><span class="header-section-number">3.2.9</span> Advanced features</h3>
</div>
<div id="xml-ensemble" class="section level3">
<h3><span class="header-section-number">3.2.10</span> <code>ensemble</code>: Ensemble Runs</h3>
<p>As with <code>meta.analysis</code>, if this section is missing, then PEcAn will not do an ensemble analysis.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;ensemble&gt;</span>
    <span class="kw">&lt;size&gt;</span>1<span class="kw">&lt;/size&gt;</span>
    <span class="kw">&lt;variable&gt;</span>NPP<span class="kw">&lt;/variable&gt;</span>
    <span class="kw">&lt;samplingspace&gt;</span>
      <span class="kw">&lt;parameters&gt;</span>
        <span class="kw">&lt;method&gt;</span>uniform<span class="kw">&lt;/method&gt;</span>
      <span class="kw">&lt;/parameters&gt;</span>
      <span class="kw">&lt;met&gt;</span>
        <span class="kw">&lt;method&gt;</span>sampling<span class="kw">&lt;/method&gt;</span>
      <span class="kw">&lt;/met&gt;</span>
    <span class="kw">&lt;/samplingspace&gt;</span>
  <span class="kw">&lt;/ensemble&gt;</span></code></pre>
<p>An alternative configuration is as follows:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;ensemble&gt;</span>
  <span class="kw">&lt;size&gt;</span>5<span class="kw">&lt;/size&gt;</span>
  <span class="kw">&lt;variable&gt;</span>GPP<span class="kw">&lt;/variable&gt;</span>
  <span class="kw">&lt;start.year&gt;</span>1995<span class="kw">&lt;/start.year&gt;</span>
  <span class="kw">&lt;end.year&gt;</span>1999<span class="kw">&lt;/end.year&gt;</span>
  <span class="kw">&lt;samplingspace&gt;</span>
  <span class="kw">&lt;parameters&gt;</span>
    <span class="kw">&lt;method&gt;</span>lhc<span class="kw">&lt;/method&gt;</span>
  <span class="kw">&lt;/parameters&gt;</span>
  <span class="kw">&lt;met&gt;</span>
    <span class="kw">&lt;method&gt;</span>sampling<span class="kw">&lt;/method&gt;</span>
  <span class="kw">&lt;/met&gt;</span>
  <span class="kw">&lt;/samplingspace&gt;</span>
<span class="kw">&lt;/ensemble&gt;</span></code></pre>
<p>Tags in this block can be broken down into two categories: Those used for setup (which determine how the ensemble analysis runs) and those used for post-hoc analysis and visualization (i.e. which do not affect how the ensemble is generated).</p>
<p>Tags related to ensemble setup are:</p>
<ul>
<li><code>size</code> : (required) the number of runs in the ensemble.</li>
<li><code>samplingspace</code>: (optional) Contains tags for defining how the ensembles will be generated.</li>
</ul>
<p>Each piece in the sampling space can potentially have a method tag and a parent tag. Method refers to the sampling method and parent refers to the cases where we need to link the samples of two components. When no tag is defined for one component, one sample will be generated and used for all the ensembles. This allows for partitioning/studying different sources of uncertainties. For example, if no met tag is defined then, one met path will be used for all the ensembles and as a result the output uncertainty will come from the variability in the parameters. At the moment no sampling method is implemented for soil and vegetation.
Available sampling methods for <code>parameters</code> can be found in the documentation of the <code>PEcAn.utils::get.ensemble.samples</code> function.
For the cases where we need simulations with a predefined set of parameters, met and initial condition we can use the restart argument. Restart needs to be a list with name tags of <code>runid</code>, <code>inputs</code>, <code>new.params</code> (parameters), <code>new.state</code> (initial condition), <code>ensemble.id</code> (ensemble ids), <code>start.time</code>, and <code>stop.time</code>.</p>
<p>The restart functionality is developed using model specific functions by called <code>write_restart.modelname</code>. You need to make sure first that this function is already exist for your desired model.</p>
<p>Note: if the ensemble size is set to 1, PEcAn will select the <strong>posterior median</strong> parameter values rather than taking a single random draw from the posterior</p>
<p>Tags related to post-hoc analysis and visualization are:</p>
<ul>
<li><code>variable</code>: (optional) name of one (or more) variables the analysis should be run for. If not specified, <code>sensitivity.analysis</code> variable is used, otherwise default is GPP (Gross Primary Productivity).</li>
</ul>
<p>(NOTE: This static visualization functionality will soon be deprecated as PEcAn moves towards interactive visualization tools based on Shiny and htmlwidgets).</p>
<p>This information is currently used by the following PEcAn workflow functions:</p>
<ul>
<li><code>PEcAn.&lt;MODEL&gt;::write.config.&lt;MODEL&gt;</code> - See <a href="#pecan-write-configs">above</a>.</li>
<li><code>PEcAn.uncertainty::write.ensemble.configs</code> - Write configuration files for ensemble analysis</li>
<li><code>PEcAn.uncertainty::run.ensemble.analysis</code> - Run ensemble analysis</li>
</ul>
</div>
<div id="xml-sensitivity-analysis" class="section level3">
<h3><span class="header-section-number">3.2.11</span> <code>sensitivity.analysis</code>: Sensitivity analysis</h3>
<p>Only if this section is defined a sensitivity analysis is done. This section will have <code>&lt;quantile&gt;</code> or <code>&lt;sigma&gt;</code> nodes. If neither are given, the default is to use the median +/- [1 2 3] x sigma (e.g. the 0.00135 0.0228 0.159 0.5 0.841 0.977 0.999 quantiles); If the 0.5 (median) quantile is omitted, it will be added in the code.</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;sensitivity.analysis&gt;</span>
    <span class="kw">&lt;quantiles&gt;</span>
        <span class="kw">&lt;sigma&gt;</span>-3<span class="kw">&lt;/sigma&gt;</span>
        <span class="kw">&lt;sigma&gt;</span>-2<span class="kw">&lt;/sigma&gt;</span>
        <span class="kw">&lt;sigma&gt;</span>-1<span class="kw">&lt;/sigma&gt;</span>
        <span class="kw">&lt;sigma&gt;</span>1<span class="kw">&lt;/sigma&gt;</span>
        <span class="kw">&lt;sigma&gt;</span>2<span class="kw">&lt;/sigma&gt;</span>
        <span class="kw">&lt;sigma&gt;</span>3<span class="kw">&lt;/sigma&gt;</span>
    <span class="kw">&lt;/quantiles&gt;</span>
  <span class="kw">&lt;variable&gt;</span>GPP<span class="kw">&lt;/variable&gt;</span>
  <span class="kw">&lt;perpft&gt;</span>TRUE<span class="kw">&lt;/perpft&gt;</span>
    <span class="kw">&lt;start.year&gt;</span>2004<span class="kw">&lt;/start.year&gt;</span>
    <span class="kw">&lt;end.year&gt;</span>2006<span class="kw">&lt;/end.year&gt;</span>
<span class="kw">&lt;/sensitivity.analysis&gt;</span></code></pre>
<ul>
<li><code>quantiles/sigma</code> : [optional] The number of standard deviations relative to the standard normal (i.e. “Z-score”) for which to perform the ensemble analysis. For instance, <code>&lt;sigma&gt;1&lt;/sigma&gt;</code> corresponds to the quantile associated with 1 standard deviation greater than the mean (i.e. 0.681). Use a separate <code>&lt;sigma&gt;</code> tag, all under the <code>&lt;quantiles&gt;</code> tag, to specify multiple quantiles. Note that we <em>do not automatically add the quantile associated with <code>-sigma</code></em> – i.e. if you want +/- 1 standard deviation, then you must include both <code>&lt;sigma&gt;1&lt;/sigma&gt;</code> <em>and</em> <code>&lt;sigma&gt;-1&lt;/sigma&gt;</code>.</li>
<li><code>start.date</code> : [required?] start date of the sensitivity analysis (in YYYY/MM/DD format)</li>
<li><code>end.date</code> : [required?] end date of the sensitivity analysis (in YYYY/MM/DD format)
<ul>
<li><strong><em>NOTE:</em></strong> <code>start.date</code> and <code>end.date</code> are distinct from values set in the run tag because this analysis can be done over a subset of the run.</li>
</ul></li>
<li><code>variable</code> : [optional] name of one (or more) variables the analysis should be run for. If not specified, sensitivity.analysis variable is used, otherwise default is GPP.</li>
<li><code>perpft</code> : [optional] if <code>TRUE</code> a sensitivity analysis on PFT-specific outputs will be run. This is only possible if your model provides PFT-specific outputs for the <code>variable</code> requested. This tag only affects the output processing, not the number of samples proposed for the analysis nor the model execution.</li>
</ul>
<p>This information is currently used by the following PEcAn workflow functions:</p>
<ul>
<li><code>PEcAn.&lt;MODEL&gt;::write.configs.&lt;MODEL&gt;</code> – See <a href="#pecan-write-configs">above</a></li>
<li><code>PEcAn.uncertainty::run.sensitivity.analysis</code> – Executes the uncertainty analysis</li>
</ul>
</div>
<div id="xml-parameter-data-assimilation" class="section level3">
<h3><span class="header-section-number">3.2.12</span> Parameter Data Assimilation</h3>
<p>The following tags can be used for parameter data assimilation. More detailed information can be found here: <a href="tutorialsdemos-and-how-tos.html#pda">Parameter Data Assimilation Documentation</a></p>
</div>
<div id="xml-multi-settings" class="section level3">
<h3><span class="header-section-number">3.2.13</span> Multi-Settings</h3>
<p>Multi-settings allows you to do multiple runs across different sites. This customization can also leverage site group distinctions to expedite the customization. It takes your settings and applies the same settings, changing only the site level tags across sites.</p>
<p>To start, add the multisettings tag within the <code>&lt;run&gt;&lt;/run&gt;</code> section of your xml</p>
<pre><code>&lt;multisettings&gt;
  &lt;multisettings&gt;run&lt;/multisettings&gt;
&lt;multisettings&gt; </code></pre>
<p>Additional tags for this section exist and can fully be seen here:</p>
<pre><code> &lt;multisettings&gt;
  &lt;multisettings&gt;assim.batch&lt;/multisettings&gt;
  &lt;multisettings&gt;ensemble&lt;/multisettings&gt;
  &lt;multisettings&gt;sensitivity.analysis&lt;/multisettings&gt;
  &lt;multisettings&gt;run&lt;/multisettings&gt;
 &lt;/multisettings&gt;</code></pre>
<p>These tags correspond to different pecan analysis that need to know that there will be multiple settings read in.</p>
<p>Next you’ll want to add the following tags to denote the group of sites you want to use. It leverages site groups, which are defined in BETY.</p>
<pre class="sourceCode xml"><code class="sourceCode xml"> <span class="kw">&lt;sitegroup&gt;</span>
   <span class="kw">&lt;id&gt;</span>1000000022<span class="kw">&lt;/id&gt;</span>
 <span class="kw">&lt;/sitegroup&gt;</span></code></pre>
<p>If you add this tag, you must remove the <code>&lt;site&gt; &lt;/site&gt;</code> tags from the <code>&lt;run&gt;</code> tag portion of your xml.
The id of your sitegroup can be found by lookig up your site group within BETY.</p>
<p>You do not have to use the sitegroup tag. You can manually add multiple sites using the structure in the example below.</p>
<p>Lastly change the top level tag to <code>&lt;pecan.multi&gt;</code>, meaning the top and bootom of your xml should look like this:</p>
<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;pecan.multi&gt;
...
&lt;/pecan.multi&gt;</code></pre>
<p>Once you have defined these tags, you can run PEcAn, but there may be further specifications needed if you know that different data sources have different dates available.</p>
<p>Run workflow.R up until</p>
<pre><code># Write pecan.CHECKED.xml
PEcAn.settings::write.settings(settings, outputfile = &quot;pecan.CHECKED.xml&quot;)</code></pre>
<p>Once this section is run, you’ll need to open <code>pecan.CHECKED.xml</code>. You will notice that it has expanded from your original <code>pecan.xml</code>.</p>
<pre class="sourceCode xml"><code class="sourceCode xml"> <span class="kw">&lt;run&gt;</span>
  <span class="kw">&lt;settings.1&gt;</span>
   <span class="kw">&lt;site&gt;</span>
    <span class="kw">&lt;id&gt;</span>796<span class="kw">&lt;/id&gt;</span>
    <span class="kw">&lt;met.start&gt;</span>2005/01/01<span class="kw">&lt;/met.start&gt;</span>
    <span class="kw">&lt;met.end&gt;</span>2011/12/31<span class="kw">&lt;/met.end&gt;</span>
    <span class="kw">&lt;name&gt;</span>Bartlett Experimental Forest (US-Bar)<span class="kw">&lt;/name&gt;</span>
    <span class="kw">&lt;lat&gt;</span>44.06464<span class="kw">&lt;/lat&gt;</span>
    <span class="kw">&lt;lon&gt;</span>-71.288077<span class="kw">&lt;/lon&gt;</span>
   <span class="kw">&lt;/site&gt;</span>
   <span class="kw">&lt;start.date&gt;</span>2005/01/01<span class="kw">&lt;/start.date&gt;</span>
   <span class="kw">&lt;end.date&gt;</span>2011/12/31<span class="kw">&lt;/end.date&gt;</span>
   <span class="kw">&lt;inputs&gt;</span>
    <span class="kw">&lt;met&gt;</span>
     <span class="kw">&lt;path&gt;</span>/fs/data1/pecan.data/dbfiles/AmerifluxLBL_SIPNET_site_0-796/AMF_US-Bar_BASE_HH_4-1.2005-01-01.2011-12-31.clim<span class="kw">&lt;/path&gt;</span>
    <span class="kw">&lt;/met&gt;</span>
   <span class="kw">&lt;/inputs&gt;</span>
  <span class="kw">&lt;/settings.1&gt;</span>
  <span class="kw">&lt;settings.2&gt;</span>
   <span class="kw">&lt;site&gt;</span>
    <span class="kw">&lt;id&gt;</span>767<span class="kw">&lt;/id&gt;</span>
    <span class="kw">&lt;met.start&gt;</span>2001/01/01<span class="kw">&lt;/met.start&gt;</span>
    <span class="kw">&lt;met.end&gt;</span>2014/12/31<span class="kw">&lt;/met.end&gt;</span>
    <span class="kw">&lt;name&gt;</span>Morgan Monroe State Forest (US-MMS)<span class="kw">&lt;/name&gt;</span>
    <span class="kw">&lt;lat&gt;</span>39.3231<span class="kw">&lt;/lat&gt;</span>
    <span class="kw">&lt;lon&gt;</span>-86.4131<span class="kw">&lt;/lon&gt;</span>
   <span class="kw">&lt;/site&gt;</span>
   <span class="kw">&lt;start.date&gt;</span>2001/01/01<span class="kw">&lt;/start.date&gt;</span>
   <span class="kw">&lt;end.date&gt;</span>2014/12/31<span class="kw">&lt;/end.date&gt;</span>
   <span class="kw">&lt;inputs&gt;</span>
    <span class="kw">&lt;met&gt;</span>
     <span class="kw">&lt;path&gt;</span>/fs/data1/pecan.data/dbfiles/AmerifluxLBL_SIPNET_site_0-767/AMF_US-MMS_BASE_HR_8-1.2001-01-01.2014-12-31.clim<span class="kw">&lt;/path&gt;</span>
    <span class="kw">&lt;/met&gt;</span>
   <span class="kw">&lt;/inputs&gt;</span>
  <span class="kw">&lt;/settings.2&gt;</span>
....
<span class="kw">&lt;/run&gt;</span></code></pre>
<ul>
<li>The <code>...</code> replaces the rest of the site settings for however many sites are within the site group.</li>
</ul>
<p>Looking at the example above, take a close look at the <code>&lt;met.start&gt;&lt;/met.start&gt;</code> and <code>&lt;met.end&gt;&lt;/met.end&gt;</code>. You will notice that for both sites, the dates are different. In this example they were edited by hand to include the dates that are available for that site and source. You must know your source prior. Only the source CRUNCEP has a check that will tell you if your dates are outside the range available. PEcAn will automatically populate these dates across sites according the original setting of start and end dates.</p>
<p>In addition, you will notice that the <code>&lt;path&gt;&lt;/path&gt;</code> section contains the model specific meteorological data file. You can add that in by hand or you can you can leave the normal tags that met process workflow will use to process the data into your model specific format:</p>
<pre><code>&lt;met&gt;
  &lt;source&gt;AmerifluxLBL&lt;/source&gt;
  &lt;output&gt;SIPNET&lt;/output&gt;
  &lt;username&gt;pecan&lt;/username&gt;
&lt;/met&gt;</code></pre>
</div>
<div id="xml-state-data-assimilation" class="section level3">
<h3><span class="header-section-number">3.2.14</span> (experimental) State Data Assimilation</h3>
<p>The following tags can be used for state data assimilation. More detailed information can be found here: <a href="tutorialsdemos-and-how-tos.html#sda">State Data Assimilation Documentation</a></p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;state.data.assimilation&gt;</span>
    <span class="kw">&lt;process.variance&gt;</span>FALSE<span class="kw">&lt;/process.variance&gt;</span>
  <span class="kw">&lt;sample.parameters&gt;</span>FALSE<span class="kw">&lt;/sample.parameters&gt;</span>
  <span class="kw">&lt;state.variables&gt;</span>
   <span class="kw">&lt;variable&gt;</span>AGB.pft<span class="kw">&lt;/variable&gt;</span>
   <span class="kw">&lt;variable&gt;</span>TotSoilCarb<span class="kw">&lt;/variable&gt;</span>
  <span class="kw">&lt;/state.variables&gt;</span>
  <span class="kw">&lt;spin.up&gt;</span>
    <span class="kw">&lt;start.date&gt;</span>2004/01/01<span class="kw">&lt;/start.date&gt;</span>
      <span class="kw">&lt;end.date&gt;</span>2006/12/31<span class="kw">&lt;/end.date&gt;</span>
  <span class="kw">&lt;/spin.up&gt;</span>
  <span class="kw">&lt;forecast.time.step&gt;</span>1<span class="kw">&lt;/forecast.time.step&gt;</span>
    <span class="kw">&lt;start.date&gt;</span>2004/01/01<span class="kw">&lt;/start.date&gt;</span>
    <span class="kw">&lt;end.date&gt;</span>2006/12/31<span class="kw">&lt;/end.date&gt;</span>
<span class="kw">&lt;/state.data.assimilation&gt;</span></code></pre>
<ul>
<li><strong>process.variance</strong> : [optional] TRUE/FLASE flag for if process variance should be estimated (TRUE) or not (FALSE). If TRUE, a generalized ensemble filter will be used. If FALSE, an ensemble Kalman filter will be used. Default is FALSE.</li>
<li><strong>sample.parameters</strong> : [optional] TRUE/FLASE flag for if parameters should be sampled for each ensemble member or not. This allows for more spread in the intial conditions of the forecast.</li>
<li><strong><em>NOTE:</em></strong> If TRUE, you must also assign a vector of trait names to pick.trait.params within the sda.enkf function.</li>
<li><strong>state.variable</strong> : [required] State variable that is to be assimilated (in PEcAn standard format). Default is “AGB” - Above Ground Biomass.</li>
<li><strong>spin.up</strong> : [required] start.date and end.date for model spin up.</li>
<li><strong><em>NOTE:</em></strong> start.date and end.date are distinct from values set in the run tag because spin up can be done over a subset of the run.</li>
<li><strong>forecast.time.step</strong> : [optional] start.date and end.date for model spin up.</li>
<li><strong>start.date</strong> : [required?] start date of the state data assimilation (in YYYY/MM/DD format)</li>
<li><strong>end.date</strong> : [required?] end date of the state data assimilation (in YYYY/MM/DD format)</li>
<li><strong><em>NOTE:</em></strong> start.date and end.date are distinct from values set in the run tag because this analysis can be done over a subset of the run.</li>
</ul>
</div>
<div id="xml-browndog" class="section level3">
<h3><span class="header-section-number">3.2.15</span> (experimental) Brown Dog</h3>
<p>This section describes how to connect to <a href="http://browndog.ncsa.illinois.edu">Brown Dog</a>. This facilitates processing and conversions of data.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;browndog&gt;</span>
    <span class="kw">&lt;url&gt;</span>...<span class="kw">&lt;/url&gt;</span>
    <span class="kw">&lt;username&gt;</span>...<span class="kw">&lt;/username&gt;</span>
    <span class="kw">&lt;password&gt;</span>...<span class="kw">&lt;/password&gt;</span>
  <span class="kw">&lt;/browndog&gt;</span></code></pre>
<ul>
<li><code>url</code>: (required) endpoint for Brown Dog to be used.</li>
<li><code>username</code>: (optional) username to be used with the endpoint for Brown Dog.</li>
<li><code>password</code>: (optional) password to be used with the endpoint for Brown Dog.</li>
</ul>
<p>This information is currently used by the following R functions:</p>
<ul>
<li><code>PEcAn.data.atmosphere::met.process</code> – Generic function for processing meteorological input data.</li>
<li><code>PEcAn.benchmark::load_data</code> – Generic, versatile function for loading data in various formats.</li>
</ul>
</div>
<div id="xml-benchmarking" class="section level3">
<h3><span class="header-section-number">3.2.16</span> (experimental) Benchmarking</h3>
<p>Coming soon…</p>

</div>
</div>
<div id="workflow" class="section level2">
<h2><span class="header-section-number">3.3</span> PEcAn workflow (web/workflow.R)</h2>
<ul>
<li>How the workflow works</li>
<li>How each module is called</li>
<li>How to do outside of web interface</li>
<li>Link to “folder structure” section below for detailed descriptions</li>
</ul>
<div style="width: 640px; height: 960px; margin: 10px; position: relative;">
<iframe allowfullscreen frameborder="0" style="width:640px; height:480px" src="https://www.lucidchart.com/documents/embeddedchart/93dca2c6-63cb-4df4-b68c-29590d1836fc" id="uAv44V~qLSWE">
</iframe>
</div>
<div id="workflow-readsettings" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Read Settings</h3>
<p>(TODO: Under construction…)</p>
</div>
<div id="workflow-input" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Input Conversions</h3>
</div>
<div id="workflow-input-data" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Input Data</h3>
<p>Models require input data as drivers, parameters, and boundary conditions. In order to make a variety of data sources that have unique formats compatible with models, conversion scripts are written to convert them into a PEcAn standard format. That format is a netcdf file with variables names and specified to our standard variable table.</p>
<p>Within the PEcAn repository, code pertaining to input conversion is in the MODULES directory under the data.atmosphere and data.land directories.</p>
</div>
<div id="workflow-input-initial" class="section level3">
<h3><span class="header-section-number">3.3.4</span> Initial Conditions</h3>
<p>(TODO: Under construction)</p>
</div>
<div id="workflow-met" class="section level3">
<h3><span class="header-section-number">3.3.5</span> Meteorological Data</h3>
<p>To convert meterological data into the PEcAn Standard and then into model formats we follow four main steps:</p>
<ol style="list-style-type: decimal">
<li>Downloading raw data
- <a href="">Currently supported products</a>
- Example Code</li>
<li>Converting raw data into a CF standard
- Example Code</li>
<li>Downscaling and gapfilling
- Example Code</li>
<li>Coverting to Model Specific format
- Example Code</li>
</ol>
<p>Common Questions regarding Met Data:</p>
<p>How do I add my Meterological data product to PEcAn?
How do I use PEcAn to convert Met data outide the workflow?</p>
<p>The main script that handles Met Processing, is <a href="https://github.com/PecanProject/pecan/blob/develop/modules/data.atmosphere/R/met.process.R"><code>met.process</code></a>. It acts as a wrapper function that calls individual modules to facilitate the processing of meteorological data from it’s original form to a pecan standard, and then from that standard to model specific formats. It also handles recording these processes in the BETY database.</p>
<ol style="list-style-type: decimal">
<li>Downloading raw data
- <a href="topical.html#available-meteorological-drivers">Available Meteorological Drivers</a>
- Example Code to download <a href="https://github.com/PecanProject/pecan/blob/develop/modules/data.atmosphere/R/download.AmerifluxLBL.R">Ameriflux data</a></li>
<li>Converting raw data into a CF standard (if needed)
- Example Code to <a href="https://github.com/PecanProject/pecan/blob/develop/modules/data.atmosphere/R/met2CF.csv.R">convert from raw csv to CF standard</a></li>
<li>Downscaling and gapfilling(if needed)
- Example Code to <a href="https://github.com/PecanProject/pecan/blob/develop/modules/data.atmosphere/R/metgapfill.R">gapfill</a></li>
<li>Coverting to Model Specific format
- Example Code to <a href="https://github.com/PecanProject/pecan/blob/develop/models/sipnet/R/met2model.SIPNET.R">convert Standard into Sipnet format</a></li>
</ol>
<div id="workflow-met-download" class="section level4">
<h4><span class="header-section-number">3.3.5.1</span> Downloading Raw data (Description of Process)</h4>
<p>Given the information passed from the pecan.xml met.process will call the <code>download.raw.met.module</code> to facilitate the execution of the necessary functions to download raw data.</p>
<pre class="sourceCode xml"><code class="sourceCode xml">  <span class="kw">&lt;met&gt;</span>
    <span class="kw">&lt;source&gt;</span>AmerifluxLBL<span class="kw">&lt;/source&gt;</span>
    <span class="kw">&lt;output&gt;</span>SIPNET<span class="kw">&lt;/output&gt;</span>
    <span class="kw">&lt;username&gt;</span>pecan<span class="kw">&lt;/username&gt;</span>
  <span class="kw">&lt;/met&gt;</span></code></pre>
</div>
</div>
<div id="workflow-met-standard" class="section level3">
<h3><span class="header-section-number">3.3.6</span> Converting raw data to PEcAn standard</h3>
</div>
<div id="workflow-met-downscale" class="section level3">
<h3><span class="header-section-number">3.3.7</span> Downscaling and gapfilling (optional)</h3>
</div>
<div id="workflow-met-model" class="section level3">
<h3><span class="header-section-number">3.3.8</span> Converting from PEcAn standard to model-specific format</h3>
</div>
<div id="workflow-traits" class="section level3">
<h3><span class="header-section-number">3.3.9</span> Traits</h3>
<p>(TODO: Under construction)</p>
</div>
<div id="workflow-metaanalysis" class="section level3">
<h3><span class="header-section-number">3.3.10</span> Meta Analysis</h3>
<p>(TODO: Under construction)</p>
</div>
<div id="workflow-modelconfig" class="section level3">
<h3><span class="header-section-number">3.3.11</span> Model Configuration</h3>
<p>(TODO: Under construction)</p>
</div>
<div id="workflow-modelrun" class="section level3">
<h3><span class="header-section-number">3.3.12</span> Run Execution</h3>
<p>(TODO: Under construction)</p>
</div>
<div id="workflow-postrun" class="section level3">
<h3><span class="header-section-number">3.3.13</span> Post Run Analysis</h3>
<p>(TODO: Under construction)
### Advanced Analysis {#workflow-advanced}</p>
<p>(TODO: Under construction)</p>

</div>
</div>
<div id="pecan-models" class="section level2">
<h2><span class="header-section-number">3.4</span> PEcAn Models</h2>
<p>This section will contain information about all models and output variables that are supported by PEcAn.</p>
<table>
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th>Model Name</th>
<th>Available in the VM</th>
<th>Prescribed Inputs</th>
<th>Input Functions/Values</th>
<th>Restart Function</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="topical.html#models-biocro">BioCro</a></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="even">
<td><a href="topical.html#models-clm">CLM</a></td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="odd">
<td><a href="topical.html#models-dalec">DALEC</a></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="even">
<td><a href="topical.html#models-ed">ED2</a></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>FATES</td>
<td>No</td>
<td>Yes</td>
<td></td>
<td>No</td>
</tr>
<tr class="even">
<td><a href="topical.html#models-gday">GDAY</a></td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="odd">
<td><a href="topical.html#models-linkages">LINKAGES</a></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<td><a href="topical.html#models-lpjguess">LPJ-GUESS</a></td>
<td>No</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="odd">
<td><a href="topical.html#models-maespa">MAESPA</a></td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="even">
<td><a href="topical.html#models-preles">PRELES</a></td>
<td>Yes</td>
<td>Yes</td>
<td>Partially</td>
<td>No</td>
</tr>
<tr class="odd">
<td><a href="topical.html#models-sipnet">SiPNET</a></td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<p><em>Available in the VM</em> - Denotes if a model is publicly available with PEcAn.
<em>Prescribed Inputs</em> - Denotes whether or not PEcAn can prescribe inputs.
<em>Input Functions/Values</em> - Denotes whether or not PEcAn has functions to fully produce a model’s Input values
<em>Restart Function</em> - Denotes status of model data assimilation capabilities.</p>
<p><strong>Output Variables</strong></p>
<p>PEcAn converts all model outputs to a single <a href="topical.html#output-standards">Output Standards</a>. This standard evolved out of MsTMIP project, which is itself based on NACP, LBA, and other model-intercomparison projects. This standard was expanded for the PalEON MIP and the needs of the PEcAn modeling community to support variables not in these standards.</p>
<p><em>Model developers</em>: do not add variables to your PEcAn output without first adding them to the PEcAn standard table! Also, do not create new variables equivalent to existing variables but just with different names or units.</p>

<!---
These HTML comments are here to make sure this file doesn't get rendered.
Make sure you remove them from the top and bottom of the file when adding real model documenation.
## Template MODEL page

| Model Information ||
| -- | -- |
| Home Page | |
| Source Code | |
| License |  |
| Authors | |
| PEcAn Integration | |

**Introduction**

Introduction about model

**PEcAn configuration file additions**

Should list the model specific additions to the PEcAn file here

**Model specific input files**

List of inputs required by model, such as met, etc.

**Model configuration files**

MODEL is configured using 3 files which are placed in the run folder, as well as a symbolic link to the met file.

* **file1** : template for this file is located at models/MODEL/inst/file1 and is not modified.  
* **file2** : template for this file is located at models/MODEL/inst/file2 and is not modified.  
* **file3** : template for this file is in models/MODEL/inst/file3 or it is specified in the \<model\> section as \<template\>. The values in this template are replaced by those computed in the earlier stages of PEcAN.

**Installation notes**

This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.

**VM**

-->

<div id="models-biocro" class="section level3">
<h3><span class="header-section-number">3.4.1</span> BioCro</h3>
<table>
<thead>
<tr class="header">
<th>Model Information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Home Page</td>
<td></td>
</tr>
<tr class="even">
<td>Source Code</td>
<td></td>
</tr>
<tr class="odd">
<td>License</td>
<td></td>
</tr>
<tr class="even">
<td>Authors</td>
<td></td>
</tr>
<tr class="odd">
<td>PEcAn Integration</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Introduction</strong></p>
<p>Introduction about model</p>
<p><strong>PEcAn configuration file additions</strong></p>
<p>Should list the model specific additions to the PEcAn file here</p>
<p><strong>Model specific input files</strong></p>
<p>List of inputs required by model, such as met, etc.</p>
<p><strong>Model configuration files</strong></p>
<p>BioCro uses a config.xml file similar to ED2. At this time, no other template files are required.</p>
<p><strong>Installation notes</strong></p>
<p>This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.</p>
<p><strong>VM</strong></p>

</div>
<div id="models-clm" class="section level3">
<h3><span class="header-section-number">3.4.2</span> CLM</h3>
<table>
<thead>
<tr class="header">
<th>Model Information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Home Page</td>
<td></td>
</tr>
<tr class="even">
<td>Source Code</td>
<td></td>
</tr>
<tr class="odd">
<td>License</td>
<td></td>
</tr>
<tr class="even">
<td>Authors</td>
<td></td>
</tr>
<tr class="odd">
<td>PEcAn Integration</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Introduction</strong></p>
<p>Introduction about model</p>
<p><strong>PEcAn configuration file additions</strong></p>
<p>Should list the model specific additions to the PEcAn file here</p>
<p><strong>Model specific input files</strong>
List of inputs required by model, such as met, etc.</p>
<p><strong>Model configuration files</strong></p>
<p>MODEL is configured using 3 files which are placed in the run folder, as well as a symbolic link to the met file.</p>
<ul>
<li><strong>file1</strong> : template for this file is located at models/MODEL/inst/file1 and is not modified.<br />
</li>
<li><strong>file2</strong> : template for this file is located at models/MODEL/inst/file2 and is not modified.<br />
</li>
<li><strong>file3</strong> : template for this file is in models/MODEL/inst/file3 or it is specified in the &lt;model&gt; section as &lt;template&gt;. The values in this template are replaced by those computed in the earlier stages of PEcAN.</li>
</ul>
<p><strong>Installation notes</strong></p>
<p>This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.</p>
<p><strong>VM</strong></p>

</div>
<div id="models-dalec" class="section level3">
<h3><span class="header-section-number">3.4.3</span> DALEC</h3>
<table>
<thead>
<tr class="header">
<th>Model Information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Home Page</td>
<td></td>
</tr>
<tr class="even">
<td>Source Code</td>
<td></td>
</tr>
<tr class="odd">
<td>License</td>
<td></td>
</tr>
<tr class="even">
<td>Authors</td>
<td></td>
</tr>
<tr class="odd">
<td>PEcAn Integration</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Introduction</strong></p>
<p>Introduction about model</p>
<p><strong>PEcAn configuration file additions</strong></p>
<p>Should list the model specific additions to the PEcAn file here</p>
<p><strong>Model specific input files</strong></p>
<p>List of inputs required by model, such as met, etc.</p>
<p><strong>Model configuration files</strong></p>
<p>MODEL is configured using 3 files which are placed in the run folder, as well as a symbolic link to the met file.</p>
<ul>
<li><strong>file1</strong> : template for this file is located at models/MODEL/inst/file1 and is not modified.<br />
</li>
<li><strong>file2</strong> : template for this file is located at models/MODEL/inst/file2 and is not modified.<br />
</li>
<li><strong>file3</strong> : template for this file is in models/MODEL/inst/file3 or it is specified in the &lt;model&gt; section as &lt;template&gt;. The values in this template are replaced by those computed in the earlier stages of PEcAN.</li>
</ul>
<p><strong>Installation notes</strong></p>
<p>This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.</p>
<p><strong>VM</strong></p>

</div>
<div id="models-ed" class="section level3">
<h3><span class="header-section-number">3.4.4</span> ED2</h3>
<table>
<thead>
<tr class="header">
<th>Model Information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Home Page</td>
<td><a href="http://moorcroftlab.oeb.harvard.edu/" class="uri">http://moorcroftlab.oeb.harvard.edu/</a></td>
</tr>
<tr class="even">
<td>Source Code</td>
<td><a href="https://github.com/EDmodel/ED2" class="uri">https://github.com/EDmodel/ED2</a></td>
</tr>
<tr class="odd">
<td>License</td>
<td></td>
</tr>
<tr class="even">
<td>Authors</td>
<td>Paul Moorcroft, …</td>
</tr>
<tr class="odd">
<td>PEcAn Integration</td>
<td>Michael Dietze, Rob Kooper</td>
</tr>
</tbody>
</table>
</div>
<div id="introduction-1" class="section level3">
<h3><span class="header-section-number">3.4.5</span> Introduction</h3>
<p>Introduction about ED model</p>
</div>
<div id="pecan-configuration-file-additions" class="section level3">
<h3><span class="header-section-number">3.4.6</span> PEcAn configuration file additions</h3>
<p>The following sections of the PEcAn XML are relevant to the ED model:</p>
<ul>
<li><code>model</code>
<ul>
<li><code>id</code> – BETY model ID. Each ID corresponds to a different revision of ED (see below)</li>
<li><code>revision</code> – The revision (a.k.a. release) number of ED (e.g. “r82”). “rgit” indicates the latest code on the ED repository.</li>
<li><code>edin</code> – Name of the template ED2IN configuration file. If this is a functional path that points to a specific file, that file is used. If no file is found following the path literally, the workflow will try the path relative to the <code>PEcAn.ED2</code> package using <code>system.file</code> (recall that files in <code>inst</code> are moved in the package root, but all other directory structure is preserved). If this is omitted, <code>PEcAn.ED2::write.configs.ED2</code> will look for a file called <code>ED2IN.&lt;revision&gt;</code> (e.g. <code>ED2IN.rgit</code>, <code>ED2IN.r86</code>) in the <code>PEcAn.ED2</code> package.
<ul>
<li><strong>Example</strong>: <code>&lt;edin&gt;ED2IN.rgit&lt;/edin&gt;</code> will use the <code>ED2IN.rgit</code> file shipped with <code>PEcAn.ED2</code> <em>regardless of the revision of ED used</em>. (Note however that if a file called <code>ED2IN.rgit</code> exists in the workflow runtime directory, that file will be used instead).</li>
</ul></li>
<li><code>start.date</code>, <code>end.date</code> – Run start and end date, respectively</li>
<li><code>met.start</code>, <code>met.end</code> – Start and end year of meteorology inputs. By default (if omitted), these are set to the years of <code>start.date</code> and <code>end.date</code>, respectively. Setting these values to a shorter interval than <code>start.date</code> and <code>end.date</code> will cause ED to loop the meteorology input over the specified years. This may be useful for, for example, spinning up ED under a set of constant climate conditions.</li>
<li><code>phenol.scheme</code></li>
<li><code>phenol</code></li>
<li><code>phenol.start</code></li>
<li><code>phenol.end</code></li>
<li><code>all_pfts</code> – (Logical) If false or missing (default), only run ED2 with the PFTs configured via PEcAn (i.e. in the <code>&lt;pfts&gt;</code> section of the XML). If <code>true</code>, run with all 17 of ED2’s PFTs, using ED2’s internal default parameters for all PFTs not configured through PEcAn. See <a href="topical.html#models-ed-pft-configuration">below</a> for more details.</li>
<li><p><code>ed2in_tags</code> – Named list of additional tags in the ED2IN to be modified. These modifications override any of those set by other parts of the PEcAn workflow. These tags must be in all caps. Any tags that are not already in the ED2IN file will be added; this makes this an effective way to run newer versions of ED2 that have new ED2IN parameters without having to provide an entire new ED2IN. For example:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;model&gt;</span>
  <span class="kw">&lt;ed2in_tags&gt;</span>
    <span class="kw">&lt;IOOUTPUT&gt;</span>0<span class="kw">&lt;/IOOUTPUT&gt;</span>
    <span class="kw">&lt;PLANT_HYDRO_SCHEME&gt;</span>0<span class="kw">&lt;/PLANT_HYDRO_SCHEME&gt;</span>
    <span class="kw">&lt;ISTOMATA_SCHEME&gt;</span>0<span class="kw">&lt;/ISTOMATA_SCHEME&gt;</span>
    <span class="kw">&lt;ISTRUCT_GROWTH_SCHEME&gt;</span>0<span class="kw">&lt;/ISTRUCT_GROWTH_SCHEME&gt;</span>
    <span class="kw">&lt;TRAIT_PLASTICITY_SCHEME&gt;</span>0<span class="kw">&lt;/TRAIT_PLASTICITY_SCHEME&gt;</span>
  <span class="kw">&lt;/ed2in_tags&gt;</span>
<span class="kw">&lt;/model&gt;</span></code></pre></li>
<li><code>barebones_ed2in</code> – Whether or not to try to annotate the ED2IN file with comments. If “true”, skip all comments and only write the tags themselves. If “false” (default), try to transfer comments from the template file into the target file.</li>
<li><code>jobtemplate</code></li>
<li><code>prerun</code> – String of commands to be added to the <code>job.sh</code> model execution script before the model is run. Multiple commands should be separated by proper <code>bash</code> syntax – i.e. either with <code>&amp;&amp;</code> or <code>;</code>.
<ul>
<li><p>One common use of this argument is to load modules on some HPC systems – for instance:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;prerun&gt;</span>module load git hdf5<span class="kw">&lt;/prerun&gt;</span></code></pre></li>
<li><p>If your particular version of ED is failing early during execution with a mysterious “Segmentation fault”, that may indicate that its process is exceeding its stack limit. In this case, you may need to remove the stack limit restriction with a <code>prerun</code> command like the following:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;prerun&gt;</span>ulimit -s unlimited<span class="kw">&lt;/prerun&gt;</span></code></pre></li>
</ul></li>
<li><code>postrun</code> – Same as <code>&lt;prerun&gt;</code>, but for commands to be run <em>after</em> model execution.</li>
<li><code>binary</code> – The full path to the ED2 binary on the target machine.</li>
<li><code>binary_args</code> – Additional arguments to be passed to the ED2 binary. Some common arguments are:
<ul>
<li><code>-s</code> – Delay OpenMPI initialization until the last possible moment. This is needed when running ED2 in a Docker container. It is included by default when the host is <code>rabbitmq</code>.</li>
<li><code>-f /path/to/ED2IN</code> – Full path to a specific ED2IN namelist file. Typically, this is not needed because, by default, ED searches for the ED2IN in the current directory and the PEcAn workflow places the ED2IN file and a symbolic link to the ED executable in the same (run) directory for you.</li>
</ul></li>
</ul></li>
<li><code>run/site</code>
<ul>
<li><code>lat</code> – Latitude coordinate of site</li>
<li><code>lon</code> – Longitude coordinate of site</li>
</ul></li>
<li><code>inputs</code>
<ul>
<li><code>met/path</code> – Path to <code>ED_MET_DRIVER_HEADER</code> file</li>
<li><code>pss</code>: [required] location of patch file</li>
<li><code>css</code>: [required] location of cohort file</li>
<li><code>site</code>: [optional] location of site file</li>
<li><code>lu</code>: [required] location of land use file</li>
<li><code>thsums</code>: [required] location of thermal sums file</li>
<li><code>veg</code>: [required] location of vegetation data</li>
<li><code>soil</code>: [required] location of soil data</li>
</ul></li>
</ul>
</div>
<div id="models-ed-pft-configuration" class="section level3">
<h3><span class="header-section-number">3.4.7</span> PFT configuration in ED2</h3>
<p>ED2 has more detailed PFTs than many models, and a more complex system for configuring these PFTs.
ED2 has 17 PFTs, based roughly on growth form (e.g. tree vs. grass), biome (tropical vs. temperate), leaf morphology (broad vs. needleleaf), leaf phenology (evergreen vs. deciduous), and successional status (e.g. early, mid, or late).
Each PFT is assigned an integer (1-17), which is used by the ED model to assign default model parameters.
The mappings of these integers onto PFT definitions are not absolute, and may change as the ED2 source code evolves.
Unfortunately, <em>the only authoritative source for these PFT definitions for any given ED2 version is the Fortran source code of that version</em>.
The following is the mapping as of ED2 commit <a href="https://github.com/EDmodel/ED2/blob/24e6df6a75702337c5f29cbd3f3fad90467c9a51/ED/run/ED2IN#L1320-L1327">24e6df6a</a> (October 2018):</p>
<ol style="list-style-type: decimal">
<li>C4 grass</li>
<li>Early-successional tropical</li>
<li>Mid-successional tropical</li>
<li>Late-successional tropical</li>
<li>Temperate C3 grass</li>
<li>Northern pine</li>
<li>Southern pine</li>
<li>Late-successional conifer</li>
<li>Early-successional temperate deciduous</li>
<li>Mid-successional temperate deciduous</li>
<li>Late-successional temperate deciduous</li>
<li>Agricultural (crop) 1</li>
<li>Agricultural (crop) 2</li>
<li>Agricultural (crop) 3</li>
<li>Agricultural (crop) 4</li>
<li>Subtropical C3 grass (C4 grass with C3 photosynthesis)</li>
<li>“Araucaria” (non-optimized southern pine), or liana</li>
</ol>
<p>ED2 parameter defaults are hard-coded in its Fortran source code.
However, most parameters can be modified via an XML file (determined by the <code>ED2IN</code> <code>IEDCNFGF</code> field; usually <code>config.xml</code> in the same directory as the <code>ED2IN</code> file).
The complete record of all parameters (defaults and user overrides) used by a given ED2 run is stored in a <code>history.xml</code> file (usually in the same directory as the <code>ED2IN</code>) – this is the file to check to make sure that an ED2 run is parameterized as you expect.</p>
<p>As with other models, PEcAn can set ED2 parameters using its built-in trait meta analysis.
The function specifically responsible for writing the <code>config.xml</code> is <a href="https://pecanproject.github.io/models/ed/docs/reference/write.config.xml.ED2.html"><code>PEcAn.ED2::write.config.xml.ED2</code></a> (which is called as part of the more general <a href="https://pecanproject.github.io/models/ed/docs/reference/write.config.ED2.html"><code>PEcAn.ED2::write.config.ED2</code></a>).
The configuration process proceeds as follows:</p>
<p>First, the mappings between PEcAn PFT names and ED2 PFT numbers are determined according to the following logic:</p>
<ul>
<li><p>If the PFT has a <code>&lt;ed2_pft_number&gt;</code> XML tag, that number is used. For example:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;pft&gt;</span>
  <span class="kw">&lt;name&gt;</span>umbs.early_hardwood<span class="kw">&lt;/name&gt;</span>
  <span class="kw">&lt;ed2_pft_number&gt;</span>9<span class="kw">&lt;/ed2_pft_number&gt;</span>
<span class="kw">&lt;/pft&gt;</span></code></pre></li>
<li><p>If <code>&lt;ed2_pft_number&gt;</code> is not provided, the code tries to cross-reference the PFT <code>name</code> against the <code>pftmapping.csv</code> data provided with the <code>PEcAn.ED2</code> package. If the name is not matched (perfectly!), the function will exit with an error.</p></li>
</ul>
<p>Second, the PFT number from the previous step is used to write that PFT’s parameters to the <code>config.xml</code>.
The order of precedence for parameters is as follows (from highest to lowest):</p>
<ol style="list-style-type: decimal">
<li><p><strong>Explicit user overrides</strong>.
These are specified via a <code>&lt;constants&gt;</code> tag in the PFT definition in the <code>pecan.xml</code>.
For example:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;pft&gt;</span>
  <span class="kw">&lt;name&gt;</span>umbs.early_hardwood<span class="kw">&lt;/name&gt;</span>
  <span class="kw">&lt;constants&gt;</span>
     <span class="kw">&lt;sla&gt;</span>36.3<span class="kw">&lt;/sla&gt;</span>
  <span class="kw">&lt;/constants&gt;</span>
<span class="kw">&lt;/pft&gt;</span></code></pre>
Note that these values are passed through <a href="https://pecanproject.github.io/models/ed/docs/reference/convert.samples.ED.html"><code>PEcAn.ED2::convert.samples.ED</code></a>, so they should generally be given in PEcAn’s default units rather than ED2’s.</li>
<li><strong>Samples from the PEcAn meta analysis</strong>.
These are also converted via <a href="https://pecanproject.github.io/models/ed/docs/reference/convert.samples.ED.html"><code>PEcAn.ED2::convert.samples.ED</code></a>.</li>
<li><strong>ED2 defaults that PEcAn knows about</strong>.
These are stored in the <code>edhistory.csv</code> file inside of <code>PEcAn.ED2</code>
This file is re-generated manually whenever there is a new version of ED2, so while we try our best to keep it up to date, there is no guarantee that it is.</li>
<li><p>(Implicitly) <strong>Defaults in the ED2 Fortran source code</strong>.
In general, our goal is to set all parameters through PEcAn (via steps 1-3), but if you are running PEcAn with new or experimental versions of ED2, you should be extra careful to make sure ED2 is running with the parameters you intend.
Again, the best way to know which parameters ED2 is actually using is to check the <code>history.xml</code> file produced once the run starts.</p></li>
</ol>
<p>The <code>ED2IN</code> field <code>INCLUDE_THESE_PFT</code> controls which of these PFTs are included in a given ED2 run.
By default, PEcAn will set this field to only include the PFTs specified by the user.
This is the recommended behavior because it ensures that all PFTs in ED2 were parameterized (one way or another, at least partially) through PEcAn.
However, if you would like ED2 to run with all 17 PFTs (NOTE: using ED2’s internal defaults for all PFTs not specified by the user!), you can set the <code>&lt;all_pfts&gt;</code> XML tag (in the <code>&lt;model&gt;</code> section) to <code>true</code>:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;model&gt;</span>
    <span class="kw">&lt;all_pfts&gt;</span>true<span class="kw">&lt;/all_pfts&gt;</span>
<span class="kw">&lt;/model&gt;</span></code></pre>
</div>
<div id="model-specific-input-files" class="section level3">
<h3><span class="header-section-number">3.4.8</span> Model specific input files</h3>
<p>List of inputs required by model, such as met, etc.</p>
</div>
<div id="model-configuration-files" class="section level3">
<h3><span class="header-section-number">3.4.9</span> Model configuration files</h3>
<p>ED2 is configured using 2 files which are placed in the run folder.</p>
<ul>
<li><strong>ED2IN</strong> : template for this file is located at models/ed/inst/ED2IN.&lt;revision&gt;. The values in this template that need to be modified are described below and are surrounded with @ symbols.</li>
<li><strong>config.xml</strong> : this file is generated by PEcAn. Some values are stored in the pecan.xml in &lt;pfts&gt;&lt;pft&gt;&lt;constants&gt; section as well as in &lt;model&gt; section.</li>
</ul>
<p>An example of the template can be found in <a href="https://github.com/PecanProject/pecan/blob/master/models/ed/inst/ED2IN.r82">ED2IN.r82</a></p>
<p>The ED2IN template can contain the following variables. These will be replaced with actual values when the model configuration is written.</p>
<ul>
<li><p>**<span class="citation">@ENSNAME</span><span class="citation">@*</span>* : run id of the simulation, used in template for NL%EXPNME</p></li>
<li>**<span class="citation">@START_MONTH</span><span class="citation">@*</span>* : start of simulation UTC time, from &lt;run&gt;&lt;start.date&gt;, used in template for NL%IMONTHA<br />
</li>
<li>**<span class="citation">@START_DAY</span><span class="citation">@*</span>* : start of simulation UTC time, from &lt;run&gt;&lt;start.date&gt;, used in template for NL%IDATEA<br />
</li>
<li>**<span class="citation">@START_YEAR</span><span class="citation">@*</span>* : start of simulation UTC time, from &lt;run&gt;&lt;start.date&gt;, used in template for NL%IYEARA<br />
</li>
<li>**<span class="citation">@END_MONTH</span><span class="citation">@*</span>* : end of simulation UTC time, from &lt;run&gt;&lt;end.date&gt;, used in template for NL%IMONTHZ<br />
</li>
<li>**<span class="citation">@END_DAY</span><span class="citation">@*</span>* : end of simulation UTC time, from &lt;run&gt;&lt;end.date&gt;, used in template for NL%IDATEZ<br />
</li>
<li><p>**<span class="citation">@END_YEAR</span><span class="citation">@*</span>* : end of simulation UTC time, from &lt;run&gt;&lt;end.date&gt;, used in template for NL%IYEARZ</p></li>
<li>**<span class="citation">@SITE_LAT</span><span class="citation">@*</span>* : site latitude location, from &lt;run&gt;&lt;site&gt;&lt;lat&gt;, used in template for NL%POI_LAT<br />
</li>
<li><p>**<span class="citation">@SITE_LON</span><span class="citation">@*</span>* : site longitude location, from &lt;run&gt;&lt;site&gt;&lt;lon&gt;, used in template for NL%POI_LON</p></li>
<li>**<span class="citation">@SITE_MET</span><span class="citation">@*</span>* : met header location, from &lt;run&gt;&lt;site&gt;&lt;met&gt;, used in template for NL%ED_MET_DRIVER_DB<br />
</li>
<li>**<span class="citation">@MET_START</span><span class="citation">@*</span>* : first year of met data, from &lt;run&gt;&lt;site&gt;&lt;met.start&gt;, used in template for NL%METCYC1<br />
</li>
<li><p>**<span class="citation">@MET_END</span><span class="citation">@*</span>* : last year of met data, from &lt;run&gt;&lt;site&gt;&lt;met.end&gt;, used in template for NL%METCYCF</p></li>
<li>**<span class="citation">@PHENOL_SCHEME</span><span class="citation">@*</span>* : phenology scheme, if this variabe is 1 the following 3 fields will be used, otherwise they will be set to empty strings, from &lt;model&gt;&lt;phenol.scheme&gt;, used in template for NL%IPHEN_SCHEME<br />
</li>
<li>**<span class="citation">@PHENOL_START</span><span class="citation">@*</span>* : first year for phenology, from &lt;model&gt;&lt;phenol.start&gt;, used in template for NL%IPHENYS1 and NL%IPHENYF1<br />
</li>
<li><p><strong><span class="citation">@PHENOL_END</span><span class="citation">@*</span>* : last year for phenology, from &lt;model&gt;&lt;phenol.end&gt;, used in template for NL%IPHENYSF and NL%IPHENYFF<br />
</strong>@PHENOL<span class="citation">@*</span>* : path and prefix of the prescribed phenology data, from * &lt;model&gt;&lt;phenol&gt;, used in template for NL%PHENPATH</p></li>
<li>**<span class="citation">@SITE_PSSCSS</span><span class="citation">@*</span>* : path and prefix of the previous ecosystem state, from &lt;model&gt;&lt;psscss&gt;, used in template for NL%SFILIN<br />
</li>
<li>**<span class="citation">@ED_VEG</span><span class="citation">@*</span>* : path and prefix of the vegetation database, used only to determine the land/water mask, from &lt;model&gt;&lt;veg&gt;, used in template for NL%VEG_DATABASE<br />
</li>
<li>**<span class="citation">@ED_SOIL</span><span class="citation">@*</span>* : path and prefix of the soil database, used to determine the soil type, from &lt;model&gt;&lt;soil&gt;, used in template for NL%SOIL_DATABASE<br />
</li>
<li><p>**<span class="citation">@ED_INPUTS</span><span class="citation">@*</span>* : input directory with dataset to initialise chilling degrees and growing degree days, which is used to drive the cold-deciduous phenology, from &lt;model&gt;&lt;inputs&gt;, used in template for NL%THSUMS_DATABASE</p></li>
<li>**<span class="citation">@FFILOUT</span><span class="citation">@*</span>* : path and prefix for analysis files, generated from &lt;run&gt;&lt;host&gt;&lt;outdir&gt;/run.id/analysis, used in template for NL%FFILOUT<br />
</li>
<li><p>**<span class="citation">@SFILOUT</span><span class="citation">@*</span>* : path and prefix for history files, generated from &lt;run&gt;&lt;host&gt;&lt;outdir&gt;/run.id/history, used in template for NL%SFILOUT</p></li>
<li><p>**<span class="citation">@CONFIGFILE</span><span class="citation">@*</span>* : XML file containing additional parameter settings, this is always “config.xml”, used in template for NL%IEDCNFGF</p></li>
<li><strong><span class="citation">@OUTDIR</span><span class="citation">@*</span>* : location where output files are written (</strong>without the runid**), from &lt;run&gt;&lt;host&gt;&lt;outdir&gt;, should not be used.<br />
</li>
<li><p>**<span class="citation">@SCRATCH</span><span class="citation">@*</span>* : local scratch space for outputs, generated /scratch/&lt;username&gt;/run$scratch, should not be used right now since it only works on ebi-cluster</p></li>
</ul>
</div>
<div id="installation-notes" class="section level3">
<h3><span class="header-section-number">3.4.10</span> Installation notes</h3>
<p>This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.</p>
<div id="vm" class="section level4">
<h4><span class="header-section-number">3.4.10.1</span> VM</h4>
</div>
<div id="bu-geo" class="section level4">
<h4><span class="header-section-number">3.4.10.2</span> BU geo</h4>
</div>
<div id="tacc-lonestar" class="section level4">
<h4><span class="header-section-number">3.4.10.3</span> TACC lonestar</h4>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">module</span> load hdf5
<span class="ex">curl</span> -o ED.r82.tgz http://isda.ncsa.illinois.edu/~kooper/EBI/ED.r82.tgz
<span class="fu">tar</span> zxf ED.r82.tgz
<span class="fu">rm</span> ED.r82.tgz
<span class="bu">cd</span> ED.r82/ED/build/bin
<span class="ex">curl</span> -o include.mk.lonestar http://isda.ncsa.illinois.edu/~kooper/EBI/include.mk.lonestar
<span class="fu">make</span> OPT=lonestar</code></pre>
</div>
<div id="tacc-stampede" class="section level4">
<h4><span class="header-section-number">3.4.10.4</span> TACC stampede</h4>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">module</span> load hdf5
<span class="ex">curl</span> -o ED.r82.tgz http://isda.ncsa.illinois.edu/~kooper/EBI/ED.r82.tgz
<span class="fu">tar</span> zxf ED.r82.tgz
<span class="fu">rm</span> ED.r82.tgz
<span class="bu">cd</span> ED.r82/ED/build/bin
<span class="ex">curl</span> -o include.mk.stampede http://isda.ncsa.illinois.edu/~kooper/EBI/include.mk.stampede
<span class="fu">make</span> OPT=stampede</code></pre>

</div>
</div>
</div>
<div id="models-gday" class="section level2">
<h2><span class="header-section-number">3.5</span> GDAY</h2>
<table>
<thead>
<tr class="header">
<th>Model Information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Home Page</td>
<td></td>
</tr>
<tr class="even">
<td>Source Code</td>
<td></td>
</tr>
<tr class="odd">
<td>License</td>
<td></td>
</tr>
<tr class="even">
<td>Authors</td>
<td></td>
</tr>
<tr class="odd">
<td>PEcAn Integration</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Introduction</strong></p>
<p>Introduction about model</p>
<p><strong>PEcAn configuration file additions</strong></p>
<p>Should list the model specific additions to the PEcAn file here</p>
<p><strong>Model specific input files</strong></p>
<p>List of inputs required by model, such as met, etc.</p>
<p><strong>Model configuration files</strong></p>
<p>MODEL is configured using 3 files which are placed in the run folder, as well as a symbolic link to the met file.</p>
<ul>
<li><strong>file1</strong> : template for this file is located at models/MODEL/inst/file1 and is not modified.<br />
</li>
<li><strong>file2</strong> : template for this file is located at models/MODEL/inst/file2 and is not modified.<br />
</li>
<li><strong>file3</strong> : template for this file is in models/MODEL/inst/file3 or it is specified in the &lt;model&gt; section as &lt;template&gt;. The values in this template are replaced by those computed in the earlier stages of PEcAN.</li>
</ul>
<p><strong>Installation notes</strong></p>
<p>This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.</p>
<p><strong>VM</strong></p>

<div id="models-linkages" class="section level3">
<h3><span class="header-section-number">3.5.1</span> LINKAGES</h3>
<table>
<thead>
<tr class="header">
<th>Model Information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Home Page</td>
<td></td>
</tr>
<tr class="even">
<td>Source Code</td>
<td></td>
</tr>
<tr class="odd">
<td>License</td>
<td></td>
</tr>
<tr class="even">
<td>Authors</td>
<td></td>
</tr>
<tr class="odd">
<td>PEcAn Integration</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Introduction</strong></p>
<p>Introduction about model</p>
<p><strong>PEcAn configuration file additions</strong></p>
<p>Should list the model specific additions to the PEcAn file here</p>
<p><strong>Model specific input files</strong></p>
<p>List of inputs required by model, such as met, etc.</p>
<p><strong>Model configuration files</strong></p>
<p>MODEL is configured using 3 files which are placed in the run folder, as well as a symbolic link to the met file.</p>
<ul>
<li><strong>file1</strong> : template for this file is located at models/MODEL/inst/file1 and is not modified.<br />
</li>
<li><strong>file2</strong> : template for this file is located at models/MODEL/inst/file2 and is not modified.<br />
</li>
<li><strong>file3</strong> : template for this file is in models/MODEL/inst/file3 or it is specified in the &lt;model&gt; section as &lt;template&gt;. The values in this template are replaced by those computed in the earlier stages of PEcAN.</li>
</ul>
<p><strong>Installation notes</strong></p>
<p>This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.</p>
<p><strong>VM</strong></p>

</div>
<div id="models-lpjguess" class="section level3">
<h3><span class="header-section-number">3.5.2</span> LPJ-GUESS</h3>
<table>
<thead>
<tr class="header">
<th>Model Information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Home Page</td>
<td></td>
</tr>
<tr class="even">
<td>Source Code</td>
<td></td>
</tr>
<tr class="odd">
<td>License</td>
<td></td>
</tr>
<tr class="even">
<td>Authors</td>
<td></td>
</tr>
<tr class="odd">
<td>PEcAn Integration</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Introduction</strong></p>
<p>Introduction about model</p>
<p><strong>PEcAn configuration file additions</strong></p>
<p>Should list the model specific additions to the PEcAn file here</p>
<p><strong>Model specific input files</strong></p>
<p>List of inputs required by model, such as met, etc.</p>
<p><strong>Model configuration files</strong></p>
<p>MODEL is configured using 3 files which are placed in the run folder, as well as a symbolic link to the met file.</p>
<ul>
<li><strong>file1</strong> : template for this file is located at models/MODEL/inst/file1 and is not modified.<br />
</li>
<li><strong>file2</strong> : template for this file is located at models/MODEL/inst/file2 and is not modified.<br />
</li>
<li><strong>file3</strong> : template for this file is in models/MODEL/inst/file3 or it is specified in the &lt;model&gt; section as &lt;template&gt;. The values in this template are replaced by those computed in the earlier stages of PEcAN.</li>
</ul>
<p><strong>Installation notes</strong></p>
<p>This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.</p>
<p><strong>VM</strong></p>

</div>
<div id="models-maespa" class="section level3">
<h3><span class="header-section-number">3.5.3</span> MAESPA</h3>
<table>
<thead>
<tr class="header">
<th>Model Information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Home Page</td>
<td><a href="http://maespa.github.io/" class="uri">http://maespa.github.io/</a></td>
</tr>
<tr class="even">
<td>Source Code</td>
<td><a href="http://maespa.github.io/download.html" class="uri">http://maespa.github.io/download.html</a></td>
</tr>
<tr class="odd">
<td>License</td>
<td></td>
</tr>
<tr class="even">
<td>Authors</td>
<td>Belinda Medlyn and Remko Duursma</td>
</tr>
<tr class="odd">
<td>PEcAn Integration</td>
<td>Tony Gardella, Martim DeKauwe, Remki Duursma</td>
</tr>
</tbody>
</table>
<p><strong>Introduction</strong></p>
<p><strong>PEcAn configuration file additions</strong></p>
<p><strong>Model specific input files</strong></p>
<p><strong>Model configuration files</strong></p>
<p>MODEL is configured using 3 files which are placed in the run folder, as well as a symbolic link to the met file.</p>
<ul>
<li><strong>file1</strong> : template for this file is located at models/MODEL/inst/file1 and is not modified.<br />
</li>
<li><strong>file2</strong> : template for this file is located at models/MODEL/inst/file2 and is not modified.<br />
</li>
<li><strong>file3</strong> : template for this file is in models/MODEL/inst/file3 or it is specified in the &lt;model&gt; section as &lt;template&gt;. The values in this template are replaced by those computed in the earlier stages of PEcAN.</li>
</ul>
<p><strong>Installation notes</strong></p>
<p>Installing the MAESPA model requires cloning the MAESPA Bitbucket Repository, executing the makefile, and ensuring that the Maeswarp R package is correctly installed.</p>
<p>To clone and compile the model, execute this code at the command line</p>
<pre><code>git clone https://bitbucket.org/remkoduursma/maespa.git

cd maespa

make clean

make</code></pre>
<p><code>maespa.out</code> is your executable. Example input files can be found in the inputfiles directory. Executing measpa.out from within one of the example directories will produce output.</p>
<p>MAESPA developers have also developed a wrapper package called <code>Maeswrap</code>. The usual R package installation method <code>install.packages</code> may present issues with downloading an unpacking a dependency package called <code>rgl</code>. Here are a couple of solutions:</p>
<p>Solution 1</p>
<p><strong>From the Command Line</strong></p>
<pre><code>sudo apt-get install r-cran-rgl

then from within R

install.packages(&quot;Maeswrap&quot;)</code></pre>
<p>Solution 2</p>
<p><strong>From the Command line</strong></p>
<pre><code>sudo apt-get install libglu1-mesa-dev

then from within R

install.packages(&quot;Maeswrap&quot;)

</code></pre>
<p>This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.</p>
<p><strong>VM</strong></p>

</div>
<div id="models-preles" class="section level3">
<h3><span class="header-section-number">3.5.4</span> PRELES</h3>
<table>
<thead>
<tr class="header">
<th>Model Information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Home Page</td>
<td></td>
</tr>
<tr class="even">
<td>Source Code</td>
<td></td>
</tr>
<tr class="odd">
<td>License</td>
<td></td>
</tr>
<tr class="even">
<td>Authors</td>
<td></td>
</tr>
<tr class="odd">
<td>PEcAn Integration</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Introduction</strong></p>
<p>Introduction about model</p>
<p><strong>PEcAn configuration file additions</strong></p>
<p>Should list the model specific additions to the PEcAn file here</p>
<p><strong>Model specific input files</strong></p>
<p>List of inputs required by model, such as met, etc.</p>
<p><strong>Model configuration files</strong></p>
<p>MODEL is configured using 3 files which are placed in the run folder, as well as a symbolic link to the met file.</p>
<ul>
<li><strong>file1</strong> : template for this file is located at models/MODEL/inst/file1 and is not modified.<br />
</li>
<li><strong>file2</strong> : template for this file is located at models/MODEL/inst/file2 and is not modified.<br />
</li>
<li><strong>file3</strong> : template for this file is in models/MODEL/inst/file3 or it is specified in the &lt;model&gt; section as &lt;template&gt;. The values in this template are replaced by those computed in the earlier stages of PEcAN.</li>
</ul>
<p><strong>Installation notes</strong></p>
<p>This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.</p>
<p><strong>VM</strong></p>

</div>
<div id="models-sipnet" class="section level3">
<h3><span class="header-section-number">3.5.5</span> SiPNET</h3>
<table>
<thead>
<tr class="header">
<th>Model Information</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Home Page</td>
<td></td>
</tr>
<tr class="even">
<td>Source Code</td>
<td></td>
</tr>
<tr class="odd">
<td>License</td>
<td></td>
</tr>
<tr class="even">
<td>Authors</td>
<td></td>
</tr>
<tr class="odd">
<td>PEcAn Integration</td>
<td>Michael Dietze, Rob Kooper</td>
</tr>
</tbody>
</table>
<p><strong>Introduction</strong></p>
<p>Introduction about model</p>
<p><strong>PEcAn configuration file additions</strong></p>
<p>Should list the model specific additions to the PEcAn file here</p>
<p><strong>Model specific input files</strong></p>
<p>List of inputs required by model, such as met, etc.</p>
<p><strong>Model configuration files</strong></p>
<p>SIPNET is configured using 3 files which are placed in the run folder, as well as a symbolic link to the met file.</p>
<ul>
<li><strong>sipnet.in</strong> : template for this file is located at models/sipnet/inst/sipnet.in and is not modified.<br />
</li>
<li><strong>sipnet.param-spatial</strong> : template for this file is located at models/sipnet/inst/template.param-spatial and is not modified.<br />
</li>
<li><strong>sipnet.param</strong> : template for this file is in models/sipnet/inst/template.param or it is specified in the &lt;model&gt; section as &lt;default.param&gt;. The values in this template are replaced by those computed in the earlier stages of PEcAN.</li>
</ul>
<p><strong>Installation notes</strong></p>
<p>This section contains notes on how to compile the model. The notes for the VM might work on other machines or configurations as well.</p>
<p>SIPNET version unk:</p>
<pre><code>if [ ! -e ${HOME}/sipnet_unk ]; then
  cd
  curl -o sipnet_unk.tar.gz http://isda.ncsa.illinois.edu/~kooper/PEcAn/models/sipnet_unk.tar.gz
  tar zxf sipnet_unk.tar.gz
  rm sipnet_unk.tar.gz
fi
cd ${HOME}/sipnet_unk/
make clean
make
sudo cp sipnet /usr/local/bin/sipnet.runk
make clean</code></pre>
<p>SIPNET version 136:</p>
<pre><code>if [ ! -e ${HOME}/sipnet_r136 ]; then
  cd
  curl -o sipnet_r136.tar.gz http://isda.ncsa.illinois.edu/~kooper/EBI/sipnet_r136.tar.gz
  tar zxf sipnet_r136.tar.gz
  rm sipnet_r136.tar.gz
  sed -i &#39;s#$(LD) $(LIBLINKS) \(.*\)#$(LD) \1 $(LIBLINKS)#&#39; ${HOME}/sipnet_r136/Makefile
fi
cd ${HOME}/sipnet_r136/
make clean
make
sudo cp sipnet /usr/local/bin/sipnet.r136
make clean</code></pre>
<p><strong>VM</strong></p>

</div>
<div id="download-gfdl" class="section level3">
<h3><span class="header-section-number">3.5.6</span> Download GFDL</h3>
<p>The Downlad.GFDL function assimilates 3 hour frequency CMIP5 outputs generated by multiple GFDL models. GFDL developed several distinct modeling streams on the timescale of CMIP5 and AR5. These models include CM3, ESM2M and ESM2G with a spatial resolution of 2 degrees latitude by 2.5 degrees longitude. Each model has future outputs for the AR5 Representative Concentration Pathways ranging from 2006-2100.</p>
</div>
<div id="cm3" class="section level3">
<h3><span class="header-section-number">3.5.7</span> CM3</h3>
<p>GFDL’s CMIP5 experiments with CM3 included many of the integrations found in the long-term CMIP5 experimental design. The focus of this physical climate model is on the role of aerosols, aerosol-cloud interactions, and atmospheric chemistry in climate variability and climate change.</p>
</div>
<div id="esm2m-esm2g" class="section level3">
<h3><span class="header-section-number">3.5.8</span> ESM2M &amp; ESM2G</h3>
<p>Two new models representing ocean physics with alternative numerical frameworks to explore the implications of some of the fundamental assumptions embedded in these models. Both ESM2M and ESM2G utilize a more advanced land model, LM3, than was available in ESM2.1 including a variety of enhancements (Milly et al., in prep). GFDL’s CMIP5 experiments with Earth System Models included many of the integrations found in the long-term CMIP5 experimental design. The ESMs, by design, close the carbon cycle and are used to study the impact of climate change on ecosystems, ecosystem changes on climate and human activities on ecosystems.</p>
<p>For more information please navigate <a href="https://gfdl.noaa.gov/cmip">here</a></p>
<table width=100%>
<th>
</th>
<th>
CM#
</th>
<th>
ESM2M
</th>
<th>
ESM2G
</th>
<tr>
<td>
rcp26
</td>
<td>
</td>
<td>
r1i1p1
</td>
<td>
r1i1p1
</td>
</tr>
<tr>
<td>
rcp45
</td>
<td>
r1i1p1, r3i1p1,r5i1p1
</td>
<td>
r1i1p1
</td>
<td>
r1i1p1
</td>
</tr>
<tr>
<td>
rcp60
</td>
<td>
</td>
<td>
r1i1p1
</td>
<td>
r1i1p1
</td>
</tr>
<tr>
<td>
rcp85
</td>
<td>
r1i1p1
</td>
<td>
r1i1p1
</td>
<td>
r1i1p1
</td>
</tr>

</div>
</div>
<div id="available-meteorological-drivers" class="section level2">
<h2><span class="header-section-number">3.6</span> Available Meteorological Drivers</h2>
<div id="ameriflux" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Ameriflux</h3>
<p>Scale: site</p>
<p>Resolution: 30 or 60 min</p>
<p>Availability: varies by site <a href="http:\/\/ameriflux.lbl.gov\/data\/data-availability\/" class="uri">http:\/\/ameriflux.lbl.gov\/data\/data-availability\/</a></p>
<p>Notes: Old ORNL server, use is deprecated</p>
</div>
<div id="amerifluxlbl" class="section level3">
<h3><span class="header-section-number">3.6.2</span> AmerifluxLBL</h3>
<p>Scale: site</p>
<p>Resolution: 30 or 60 min</p>
<p>Availability: varies by site <a href="http:\/\/ameriflux.lbl.gov\/data\/data-availability\/" class="uri">http:\/\/ameriflux.lbl.gov\/data\/data-availability\/</a></p>
<p>Notes: new Lawrence Berkeley Lab server</p>
</div>
<div id="fluxnet2015" class="section level3">
<h3><span class="header-section-number">3.6.3</span> Fluxnet2015</h3>
<p>Scale: site</p>
<p>Resolution: 30 or 60 min</p>
<p>Availability: varies by site <a href="http://fluxnet.fluxdata.org/sites/site-list-and-pages/">http://fluxnet.fluxdata.org/sites/site-list-and-pages</a></p>
<p>Notes: Fluxnet 2015 synthesis product. Does not cover all FLUXNET sites</p>
</div>
<div id="narr" class="section level3">
<h3><span class="header-section-number">3.6.4</span> NARR</h3>
<p>Scale: North America</p>
<p>Resolution: 3 hr, approx. 32km <span class="math inline">\(Lambert conical projection\)</span></p>
<p>Availability: 1979-present</p>
</div>
<div id="cruncep" class="section level3">
<h3><span class="header-section-number">3.6.5</span> CRUNCEP</h3>
<p>Scale: global</p>
<p>Resolution: 6hr, 0.5 degree</p>
<p>Availability: 1901-2010</p>
</div>
<div id="cmip5" class="section level3">
<h3><span class="header-section-number">3.6.6</span> CMIP5</h3>
<p>Scale: varies by model</p>
<p>Resolution: 3 hr</p>
<p>Availability: 2006-2100</p>
<p>Currently only GFDL available. Different scenerios and ensemble members can be set via Advanced Edit.</p>
</div>
<div id="nldas" class="section level3">
<h3><span class="header-section-number">3.6.7</span> NLDAS</h3>
<p>Scale: Lower 48 + buffer,</p>
<p>Resolution: 1 hour, .125 degree</p>
<p>Availability: 1980-present</p>
</div>
<div id="gldas" class="section level3">
<h3><span class="header-section-number">3.6.8</span> GLDAS</h3>
<p>Scale: Global</p>
<p>Resolution: 3hr, 1 degree</p>
<p>Availability: 1948-2010</p>
</div>
<div id="paleon" class="section level3">
<h3><span class="header-section-number">3.6.9</span> PalEON</h3>
<p>Scale: -100 to -60 W Lon, 35 to 50 N Latitude <span class="math inline">\(US northern hardwoods + buffer\)</span></p>
<p>Resolution: 6hr, 0.5 degree</p>
<p>Availability: 850-2010</p>
</div>
<div id="fluxnetlathuile" class="section level3">
<h3><span class="header-section-number">3.6.10</span> FluxnetLaThuile</h3>
<p>Scale: site</p>
<p>Resolution: 30 or 60 min</p>
<p>Availability: varies by site <a href="http:\/\/www.fluxdata.org\/DataInfo\/Dataset%20Doc%20Lib\/SynthDataSummary.aspx">http:\/\/www.fluxdata.org\/DataInfo\/Dataset%20Doc%20Lib\/SynthDataSummary.aspx</a></p>
<p>Notes: 2007 synthesis. Fluxnet2015 supercedes this for sites that have been updated</p>
</div>
<div id="geostreams" class="section level3">
<h3><span class="header-section-number">3.6.11</span> Geostreams</h3>
<p>Scale: site</p>
<p>Resolution: varies</p>
<p>Availability: varies by site</p>
<p>Notes: This is a protocol, not a single archive. The PEcAn functions currently default to querying [<a href="https://terraref.ncsa.illinois.edu/clowder/api/geostreams" class="uri">https://terraref.ncsa.illinois.edu/clowder/api/geostreams</a>], which requires login and contains data from only two sites (Urbana IL and Maricopa AZ). However the interface can be used with any server that supports the <a href="https://opensource.ncsa.illinois.edu/confluence/display/CATS/Geostreams+API">Geostreams API</a>.</p>

</div>
</div>
<div id="database-synchronization" class="section level2">
<h2><span class="header-section-number">3.7</span> Database synchronization</h2>
<p>The database synchronization consists of 2 parts:
- Getting the data from the remote servers to your server
- Sharing your data with everybody else</p>
<div id="how-does-it-work" class="section level3">
<h3><span class="header-section-number">3.7.1</span> How does it work?</h3>
<p>Each server that runs the BETY database will have a unique machine_id and a sequence of ID’s associated. Whenever the user creates a new row in BETY it will receive an ID in the sequence. This allows us to uniquely identify where a row came from. This is information is crucial for the code that works with the synchronization since we can now copy those rows that have an ID in the sequence specified. If you have not asked for a unique ID your ID will be 99.</p>
<p>The synchronization code itself is split into two parts, loading data with the <code>load.bety.sh</code> script and exporting data using <code>dump.bety.sh</code>. If you do not plan to share data, you only need to use <code>load.bety.sh</code> to update your database.</p>
</div>
<div id="set-up" class="section level3">
<h3><span class="header-section-number">3.7.2</span> Set up</h3>
<p>Requests for new machine ID’s is currently handled manually. To request a machine ID contact Rob Kooper <a href="mailto:kooper@illinois.edu">kooper@illinois.edu</a>. In the examples below this ID is referred to as ‘my siteid’.</p>
<p>To setup the database to use this ID you need to call load.bety in ‘CREATE’ mode (replacing <my siteid> with the ID if your site)</p>
<pre><code>sudo -u postgres {$PECAN}/scripts/load.bety.sh -c -u -m &lt;my siteid&gt; </code></pre>
<p>WARNING: At the moment running CREATE deletes all current records in the database. If you are running from the VM this includes both all runs you have done and all information that the database is prepopulated with (e.g. input and model records). Remote records can be fetched (see below), but local records will be lost (we’re working on improving this!)</p>
</div>
<div id="fetch-latest-data" class="section level3">
<h3><span class="header-section-number">3.7.3</span> Fetch latest data</h3>
<p>When logged into the machine you can fetch the latest data using the load.bety.sh script. The script will check what site you want to get the data for and will remove all data in the database associated with that id. It will then reinsert all the data from the remote database.</p>
<p>The script is configured using environment variables. The following variables are recognized:
- DATABASE: the database where the script should write the results. The default is <code>bety</code>.
- OWNER: the owner of the database (if it is to be created). The default is <code>bety</code>.
- PG_OPT: additional options to be added to psql (default is nothing).
- MYSITE: the (numerical) ID of your site. If you have not requested an ID, use 99; this is used for all sites that do not want to share their data (i.e. VM). 99 is in fact the default.
- REMOTESITE: the ID of the site you want to fetch the data from. The default is 0 (EBI).
- CREATE: If ‘YES’, this indicates that the existing database (<code>bety</code>, or the one specified by DATABASE) should be removed. Set to YES (in caps) to remove the database. <strong>THIS WILL REMOVE ALL DATA</strong> in DATABASE. The default is NO.
- KEEPTMP: indicates whether the downloaded file should be preserved. Set to YES (in caps) to keep downloaded files; the default is NO.
- USERS: determines if default users should be created. Set to YES (in caps) to create default users with default passwords. The default is NO.</p>
<p>All of these variables can be specified as command line arguments as well, to see the options use -h.</p>
<pre><code>load.bety.sh -h
./scripts/load.bety.sh [-c YES|NO] [-d database] [-h] [-m my siteid] [-o owner] [-p psql options] [-r remote siteid] [-t YES|NO] [-u YES|NO]
 -c create database, THIS WILL ERASE THE CURRENT DATABASE, default is NO
 -d database, default is bety
 -h this help page
 -m site id, default is 99 (VM)
 -o owner of the database, default is bety
 -p additional psql command line options, default is empty
 -r remote site id, default is 0 (EBI)
 -t keep temp folder, default is NO
 -u create carya users, this will create some default users

dump.bety.sh -h
./scripts/dump.bety.sh [-a YES|NO] [-d database] [-h] [-l 0,1,2,3,4] [-m my siteid] [-o folder] [-p psql options] [-u YES|NO]
 -a use anonymous user, default is YES
 -d database, default is bety
 -h this help page
 -l level of data that can be dumped, default is 3
 -m site id, default is 99 (VM)
 -o output folder where dumped data is written, default is dump
 -p additional psql command line options, default is -U bety
 -u should unchecked data be dumped, default is NO</code></pre>
</div>
<div id="sharing-data" class="section level3">
<h3><span class="header-section-number">3.7.4</span> Sharing data</h3>
<p>Sharing your data requires a few steps. First, before entering any data, you will need to request an ID from the PEcAn developers. Simply open an issue at github and we will generate an ID for you. If possible, add the URL of your data host.</p>
<p>You will now need to synchronize the database again and use your ID. For example if you are given ID=42 you can use the following command: <code>MYID=42 REMOTEID=0 ./scripts/load.bety.sh</code>. This will load the EBI database and set the ID’s such that any data you insert will have the right ID.</p>
<p>To share your data you can now run the dump.bey.sh. The script is configured using environment variables, the following variables are recognized:
- DATABASE: the database where the script should write the results. The default is <code>bety</code>.
- PG_OPT: additional options to be added to psql (default is nothing).
- MYSITE: the ID of your site. If you have not requested an ID, use 99, which is used for all sites that do not want to share their data (i.e. VM). 99 is the default.
- LEVEL: the minimum access-protection level of the data to be dumped (0=private, 1=restricted, 2=internal collaborators, 3=external collaborators, 4=public). The default level for exported data is level 3.
- note that currently only the traits and yields tables have restrictions on sharing. If you share data, records from other (meta-data) tables will be shared. If you wish to extend the access_level to other tables please <a href="https://github.com/pecanproject/bety/issues/new">submit a feature request</a>.
- UNCHECKED: specifies whether unchecked traits and yields be dumped. Set to YES (all caps) to dump unchecked data. The default is NO.
- ANONYMOUS: specifies whether all users be anonymized. Set to YES (all caps) to keep the original users (<strong>INCLUDING PASSWORD</strong>) in the dump file. The default is NO.
- OUTPUT: the location of where on disk to write the result file. The default is <code>${PWD}/dump</code>.</p>
<p>NOTE: If you want your dumps to be accessible to other PEcAn servers you need to perform the following additional steps</p>
<ol style="list-style-type: decimal">
<li>Open pecan/scripts/load.bety.sh</li>
<li>In the DUMPURL section of the code add a new record indicating where you are dumping your data. Below is the example for SITE number 1 (Boston University)</li>
</ol>
<pre><code> elif [ &quot;${REMOTESITE}&quot; == &quot;1&quot; ]; then
 DUMPURL=&quot;http://psql-pecan.bu.edu/sync/dump/bety.tar.gz&quot;</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Check your Apache settings to make sure this location is public</li>
<li>Commit this code and submit a Pull Request</li>
<li>From the URL in the Pull Request, PEcAn administrators will update the machines table, the status map, and notify other users to update their cron jobs (see Automation below)</li>
</ol>
<p>Plans to simplify this process are in the works</p>
</div>
<div id="automation" class="section level3">
<h3><span class="header-section-number">3.7.5</span> Automation</h3>
<p>Below is an example of a script to synchronize PEcAn database instances across the network.</p>
<p>db.sync.sh</p>
<pre><code>#!/bin/bash 
## make sure psql is in PATH
export PATH=/usr/pgsql-9.3/bin/:$PATH 
## move to export directory
cd /fs/data3/sync 
## Dump Data
MYSITE=1 /home/dietze/pecan/scripts/dump.bety.sh 
## Load Data from other sites
MYSITE=1 REMOTESITE=2 /home/dietze/pecan/scripts/load.bety.sh 
MYSITE=1 REMOTESITE=5 /home/dietze/pecan/scripts/load.bety.sh 
MYSITE=1 REMOTESITE=0 /home/dietze/pecan/scripts/load.bety.sh 
## Timestamp sync log
echo $(date +%c) &gt;&gt; /home/dietze/db.sync.log</code></pre>
<p>Typically such a script is set up to run as a cron job. Make sure to schedule this job (<code>crontab -e</code>) as the user that has database privileges (typically postgres). The example below is a cron table that runs the sync every hour at 12 min after the hour.</p>
<pre><code>MAILTO=user@yourUniversity.edu
12 * * * * /home/dietze/db.sync.sh</code></pre>
</div>
<div id="database-maintentance" class="section level3">
<h3><span class="header-section-number">3.7.6</span> Database maintentance</h3>
<p>All databases need maintenance performed on them. Depending upon the database type this can happen automatically, or it needs to be run through a scheduler or manually. The BETYdb database is Postgresql and it needs to be reindexed and vacuumed on a regular basis. Reindexing introduces efficiencies back into the database by reorganizing the indexes. Vacuuming the database frees up resources to the database by rearranging and compacting the database. Both of these operations are necessary and safe. As always if there’s a concern, a backup of the database should be made ahead of time. While running the reindexing and vacuuming commands, users will notice a slowdown at times. Therefore it’s better to run these maintenance tasks during off hours.</p>
<div id="reindexing-the-database" class="section level4">
<h4><span class="header-section-number">3.7.6.1</span> Reindexing the database</h4>
<p>As mentioned above, reindexing allows the database to become more efficient. Over time as data gets updated and deleted, the indexes become less efficient. This has a negative inpact on executed statements. Reindexing makes the indexes efficient again (at least for a while) allowing faster statement execution and reducing the overall load on the database.</p>
<p>The reindex.bety.sh script is provided to simplify reindexing the database.</p>
<pre><code>reindex.bety.sh -h
./reindex.bety.sh [-c datalog] [-d database] [-h] [-i table names] [-p psql options] [-q] [-s] [-t tablename]
 -c catalog, database catalog name used to search for tables, default is bety
 -d database, default is bety
 -h this help page
 -i table names, list of space-separated table names to skip over when reindexing
 -p additional psql command line options, default is -U bety
 -q the reindexing should be quiet
 -s reindex the database after reindexing the tables (this should be done sparingly)
 -t tablename, the name of the one table to reindex</code></pre>
<p>If the database is small enough it’s reasonable to reindex the entire database at one time. To do this manually run or schedule the REINDEX statement. For example:</p>
<pre><code>reindex.bety.sh -s</code></pre>
<p>For larger databases it may be desireable to reindex entire tables at a time. An efficient way to do this is to reindex the larger tables and then the entire database. For example:</p>
<pre><code>reindex.bety.sh -t traits; reindex.bety.sh -t yields;
reindex.bety.sh -s</code></pre>
<p>For very large databases it may be desirable to reindex one or more individual indexes before reindexing tables and the databases. In this case running specific psql commands to reindex those specific indexes, followed by reindexing the table is a possible approach. For example:</p>
<pre><code>psql -U bety -c &quot;REINDEX INDEX index_yields_on_citation_id; REINDEX INDEX index_yields_on_cultivar_id;&quot;
reindex.bety.sh -t yields;</code></pre>
<p>Splitting up the indexing commands over time allows the database to operate efficiently with minimal impact on users. One approach is to schedule the reindexing of large, complex tables at a spcific off-time during the week, followed by a general reindexing and excluding those large tables on a weekend night.</p>
<p>Please refere to the Automation section above for information on using cron to schedule reindexing commands.</p>
</div>
<div id="vacuuming-the-database" class="section level4">
<h4><span class="header-section-number">3.7.6.2</span> Vacuuming the database</h4>
<p>Vacuuming the BETYdb Postgresql database reduces the amount of resources it uses and introduces its own efficiencies.</p>
<p>Over time, modified and deleted records leave ‘holes’ in the storage of the database. This is a common feature for most databases. Each database has its own way of handing this, in Postgresql it’s the VACUUM command. The VACUUM command performs two main operations: cleaning up tables to make memory use more efficient, and analyze tables for optimum statement execution. The use of the keyword ANALYZE indicates the second operation should take place.</p>
<p>The vacuum.bety.sh script is provided to simplify vacuuming the database.</p>
<pre><code>vacuum.bety.db -h
./vacuum.bety.sh [-c datalog] [-d database] [-f] [-h] [-i table names] [-n] [-p psql options] [-q] [-s] [-t tablename] [-z]
 -c catalog, database catalog name used to search for tables, default is bety
 -d database, default is bety
 -f perform a full vacuum to return resources to the system. Specify rarely, if ever
 -h this help page
 -i table names, list of space-separated table names to skip over when vacuuming
 -n only vacuum the tables and do not analyze, default is to first vacuum and then analyze
 -p additional psql command line options, default is -U bety
 -q the export should be quiet
 -s skip vacuuming the database after vacuuming the tables
 -t tablename, the name of the one table to vacuum
 -z only perform analyze, do not perform a regular vacuum, overrides -n and -f, sets -s</code></pre>
<p>For small databases with light loads it may be possible to set aside a time for a complete vacuum. During this time, commands executed against the database might fail (a temporary condition as the database gets cleaned up). The following commands can be used to perform all the vaccum operations in one go.</p>
<pre><code>vacuum.bety.sh -f</code></pre>
<p>Generally it’s not desireable to have down time. If the system running the database doesn’t need resources that the database is using returned to it, a FULL vacuum can be avoided. This is the default behavior of the script</p>
<pre><code>vacuum.bety.sh</code></pre>
<p>In larger databases, vacuuming the entire database can take a long time causing a negative impact on users. This means that individual tables need to be vacuumed. How often a vacuum needs to be performed is dependent upon a table’s activity. The more frequently updates and deletes occur on a table, the more frequent the vaccum should be. For large tables it may be desireable to separate the table cleanup from the analysis. An example for completely vacuuming and analyzing a table is:</p>
<pre><code>psql -U bety -c &quot;VACUUM traits; VACUUM ANALYZE traits;&quot;</code></pre>
<p>Similar to indexes, vacuuming the most active tables followed by general database vacuuming and vacuum analyze may be a desireable approach.</p>
<p>Also note that it isn’t necessary to run VACUUM ANALYZE for each vacuum performed. Separating the commands and performing a VACUUM ANALYZE after several regular vacuums may be sufficient, with less load on the database.</p>
<p>If the BETYdb database is running on a system with limited resources, or with resources that have become limited, the VACCUM command can return resources to the system from the database. The normal vacuuming process releases resources back to the database for reuse, but not to the system; generally this isn’t a problem. Postgresql has a VACUUM keyword FULL that returns resources back to the system. Requesting a FULL vacuum will lock the table being vacuumed while it is being re-written preventing any statements from being executed against it. If performing VECUUM FULL against the entire database, only the table being actively worked on is locked.</p>
<p>To minimize the impact a VACUUM FULL has on users, it’s best to perform a normal vacuum before a FULL vacuum. If this approach is taken, there sould be a minimal time gap between the normal VACUUM and the VACUUM FULL commands. A normal vacuum allows changes to be made thus requiring the full vacuum to handle those changes, extending it’s run time. Reducing the time between the two commands lessens the work VACUUM FULL needs to do.</p>
<pre><code>psql -U bety -c &quot;VACUUM yields; VACUUM FULL yields; VACUUM ANALYZE yields;&quot;</code></pre>
<p>Give its impact, it’s typically not desireable to perform a VACUUM FULL after every normal vacuum; it should be done on an “as needed” basis or infrequently.</p>
</div>
</div>
<div id="troubleshooting-3" class="section level3">
<h3><span class="header-section-number">3.7.7</span> Troubleshooting</h3>
<p>There are several possibilities if a scheduled cron job apepars to be running but isn’t producing the expected results. The following are suggestions on what to try to resolve the issue.</p>
<div id="username-and-password" class="section level5">
<h5><span class="header-section-number">3.7.7.0.1</span> Username and password</h5>
<p>The user that scheduled a cron job may not have access permissions to the database. This can be easily confirmed by running the command line from the cron job while logged in as the user that scheduled the job. An error message will be shown if the user doesn’t have permissions.</p>
<p>To resolve this, be sure to include a valid database user (not a BETYdb user) with their credentials on the command in crontab.</p>
</div>
<div id="db_hba.conf-file" class="section level5">
<h5><span class="header-section-number">3.7.7.0.2</span> db_hba.conf file</h5>
<p>Iit’s possible that the machine hosting the docker image of the database doesn’t have permissions to access the database. This may due to the cron job running on a machine that is not the docker instance of the database.</p>
<p>It may be necessary to look at the loga on the hosting machine to determine if database access permissions are causing a problem. Logs are stored in different locations depending upon the Operating System of the host and upon other environmental factors. This document doesn’t provide information on where to find the logs.</p>
<p>To begin, it’s best to look at the contents of the relevent database configuration file. The following command will display the contents of the db_hba.conf file.</p>
<pre><code>psql -U postgres -qAt -c &quot;show hba_file&quot; | xargs grep -v -E &#39;^[[:space:]]*#&#39;</code></pre>
<p>This command should return a series of text lines. For each row except those begining with ‘local’, the fourth item describes the machines that can access the database. In some cases an IP mask is specified in the fifth that further restricts the machines that have access. The special work ‘all’ in the fourth column grants permissions to all machines. The last column on each line contains the authentication option for the machine(s) specified in the fourth column (with a possible fifth column IP mask modifier).</p>
<p>Ensure that the host machine is listed under the fourth column (machine addresse range, or ‘all’), is also included in the IP mask if one was specified, and finally that any authentication option are not set to ‘reject’. If the host machine is not included the db_hba.conf file will need to be updated to allow access.</p>
</div>
</div>
<div id="network-status-map" class="section level3">
<h3><span class="header-section-number">3.7.8</span> Network Status Map</h3>
<p><a href="https://pecan2.bu.edu/pecan/status.php" class="uri">https://pecan2.bu.edu/pecan/status.php</a></p>
<p>Nodes: red = down, yellow = out-of-date schema, green = good</p>
<p>Edges: red = fail, yellow = out-of-date sync, green = good</p>
</div>
<div id="tasks" class="section level3">
<h3><span class="header-section-number">3.7.9</span> Tasks</h3>
<p>Following is a list of tasks we plan on working on to improve these scripts:
- <a href="https://github.com/PecanProject/bety/issues/368">pecanproject/bety#368</a> allow site-specific customization of information and UI elements including title, contacts, logo, color scheme.</p>

</div>
</div>
<div id="standalone-tools-modules" class="section level2">
<h2><span class="header-section-number">3.8</span> Standalone tools (modules)</h2>
<ul>
<li>Radiative transfer modeling and remote sensing (<a href="https://pecanproject.github.io/modules/rtm/docs/index.html"><code>modules/rtm</code></a>); <a href="https://pecanproject.github.io/modules/rtm/docs/articles/pecanrtm.vignette.html">vignette</a></li>
<li>Photosynthesis (<a href="https://pecanproject.github.io/modules/photosynthesis/docs/index.html"><code>modules/photosynthesis</code></a>); <a href="https://pecanproject.github.io/modules/photosynthesis/docs/articles/ResponseCurves.html">vignette</a></li>
<li>Allometry (<a href="https://pecanproject.github.io/modules/allometry/docs/index.html"><code>modules/allometry</code></a>); <a href="https://pecanproject.github.io/modules/allometry/docs/articles/AllomVignette.html">vignette</a></li>
<li>Load data (<a href="https://pecanproject.github.io/modules/benchmark/docs/index.html"><code>modules/benchmark</code></a> – <code>PEcAn.benchmark::load_data</code>)</li>
</ul>
<div id="LoadData" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Loading Data in PEcAn</h3>
<p>If you are loading data in to PEcAn for benchmarking, using the Benchmarking shiny app [provide link?] is recommended.</p>
<p>Data can be loaded manually using the <code>load_data</code> function which in turn requires providing data format information using <code>query.format.vars</code> and the path to the data using <code>query.file.path</code>.</p>
<p>Below is a description of the <code>load_data</code> function an a simple example of loading data manually.</p>
</div>
<div id="function-load_data" class="section level3">
<h3><span class="header-section-number">3.8.2</span> Function <code>load_data</code></h3>
<div id="inputs-2" class="section level4">
<h4><span class="header-section-number">3.8.2.1</span> Inputs</h4>
<p>Required</p>
<ul>
<li><code>data.path</code>: path to the data that is the output of the function <code>query.file.path</code> (see example below)</li>
<li><code>format</code>: R list object that is the output of the function <code>query.format.vars</code> (see example below)</li>
</ul>
<p>Optional</p>
<ul>
<li><code>start_year = NA</code>:</li>
<li><code>end_year = NA</code>:</li>
<li><code>site = NA</code></li>
<li><p><code>vars.used.index=NULL</code>
### Output</p></li>
<li><p>R data frame containing the requested variables converted in to PEcAn standard name and units and time steps in <code>POSIX</code> format.</p></li>
</ul>
</div>
<div id="example-1" class="section level4">
<h4><span class="header-section-number">3.8.2.2</span> Example</h4>
<p>The data for this example has already been entered in to the database. To add new data go to <a href="tutorialsdemos-and-how-tos.html#NewInput">new data documentation</a>.</p>
<p>To load the Ameriflux data for the Harvard Forest (US-Ha1) site.</p>
<ol style="list-style-type: decimal">
<li>Create a connection to the BETY database. This can be done using R function</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">bety =<span class="st"> </span>PEcAn.DB<span class="op">::</span><span class="kw">betyConnect</span>(<span class="dt">php.config =</span> <span class="st">&quot;pecan/web/config.php&quot;</span>)</code></pre>
<p>where the complete path to the <code>config.php</code> is specified. See <a href="https://github.com/PecanProject/pecan/blob/master/web/config.example.php">here</a> for an example <code>config.php</code> file.</p>
<ol start="2" style="list-style-type: decimal">
<li>Look up the inputs record for the data in BETY.</li>
</ol>
<p><img src="04_advanced_user_guide/images/Input_ID_name.png" width="50%" height="50%" style="display: block; margin: auto;" /></p>
<p>To find the input ID, either look at</p>
<ul>
<li><p>The url of the record (see image above)</p>
<ul>
<li>In R run</li>
</ul></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
input_name =<span class="st"> &quot;AmerifluxLBL_site_0-758&quot;</span> <span class="co">#copied directly from online</span>
input.id =<span class="st"> </span><span class="kw">tbl</span>(bety,<span class="st">&quot;inputs&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(name <span class="op">==</span><span class="st"> </span>input_name) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(id)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>Additional arguments to <code>query.format.vars</code> are optional</p>
<ol style="list-style-type: decimal">
<li>If you only want to load a subset of dates in the data, specify start and end year, otherwise all data will be loaded.</li>
<li>If you only want to load a select list of variables from the data, look up their IDs in BETY, otherwise all variables will be loaded.</li>
</ol></li>
<li><p>In R run</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">   format =<span class="st"> </span>PEcAn.DB<span class="op">::</span><span class="kw">query.format.vars</span>(bety, input.id)</code></pre>
<p>Examine the resulting R list object to make sure it returned the correct information.</p>
<p>The example format contains the following objects:</p>
<pre class="sourceCode r"><code class="sourceCode r">   <span class="op">$</span>file_name
   [<span class="dv">1</span>] <span class="st">&quot;AMERIFLUX_BASE_HH&quot;</span>

   <span class="op">$</span>mimetype
   [<span class="dv">1</span>] <span class="st">&quot;csv&quot;</span>

   <span class="op">$</span>skip
   [<span class="dv">1</span>] <span class="dv">2</span>

   <span class="op">$</span>header
   [<span class="dv">1</span>] <span class="dv">1</span>

   <span class="op">$</span>na.strings
   [<span class="dv">1</span>] <span class="st">&quot;-9999&quot;</span> <span class="st">&quot;-6999&quot;</span> <span class="st">&quot;9999&quot;</span>  <span class="st">&quot;NA&quot;</span>   

   <span class="op">$</span>time.row
   [<span class="dv">1</span>] <span class="dv">4</span>

   <span class="op">$</span>site
   [<span class="dv">1</span>] <span class="dv">758</span>

   <span class="op">$</span>lat
   [<span class="dv">1</span>] <span class="fl">42.5378</span>

   <span class="op">$</span>lon
   [<span class="dv">1</span>] <span class="fl">-72.1715</span>

   <span class="op">$</span>time_zone
   [<span class="dv">1</span>] <span class="st">&quot;America/New_York&quot;</span></code></pre>
<p>The first 4 rows of the table <code>format$vars</code> looks like this:</p>
<table style="width:100%;">
<colgroup>
<col width="9%" />
<col width="8%" />
<col width="11%" />
<col width="8%" />
<col width="9%" />
<col width="9%" />
<col width="7%" />
<col width="8%" />
<col width="10%" />
<col width="7%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th>bety_name</th>
<th>variable_id</th>
<th>input_name</th>
<th>input_units</th>
<th>storage_type</th>
<th>column_number</th>
<th>bety_units</th>
<th>mstmip_name</th>
<th>mstmip_units</th>
<th>pecan_name</th>
<th>pecan_units</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>air_pressure</td>
<td>554</td>
<td>PA</td>
<td>kPa</td>
<td></td>
<td>19</td>
<td>Pa</td>
<td>Psurf</td>
<td>Pa</td>
<td>Psurf</td>
<td>Pa</td>
</tr>
<tr class="even">
<td>airT</td>
<td>86</td>
<td>TA</td>
<td>celsius</td>
<td></td>
<td>4</td>
<td>degrees C</td>
<td>Tair</td>
<td>K</td>
<td>Tair</td>
<td>K</td>
</tr>
<tr class="odd">
<td>co2atm</td>
<td>135</td>
<td>CO2_1</td>
<td>umol mol-1</td>
<td></td>
<td>20</td>
<td>umol mol-1</td>
<td>CO2air</td>
<td>micromol mol-1</td>
<td>CO2air</td>
<td>micromol mol-1</td>
</tr>
<tr class="even">
<td>datetime</td>
<td>5000000001</td>
<td>TIMESTAMP_START</td>
<td>ymd_hms</td>
<td>%Y%m%d%H%M</td>
<td>1</td>
<td>ymd_hms</td>
<td>NA</td>
<td>NA</td>
<td>datetime</td>
<td>ymd_hms</td>
</tr>
</tbody>
</table>
<ol start="5" style="list-style-type: decimal">
<li>Get the path to the data</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">   data.path =<span class="st"> </span>PEcAn.DB<span class="op">::</span><span class="kw">query.file.path</span>(
     <span class="dt">input.id =</span> input.id, 
     <span class="dt">host_name =</span> PEcAn.remote<span class="op">::</span><span class="kw">fqdn</span>(), 
     <span class="dt">con =</span> bety<span class="op">$</span>con)</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>Load the data</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">   data =<span class="st"> </span>PEcAn.benchmark<span class="op">::</span><span class="kw">load_data</span>(<span class="dt">data.path =</span> data.path, <span class="dt">format =</span> format)</code></pre>

</div>
</div>
</div>
<div id="using-the-pecan-download.file-function" class="section level2">
<h2><span class="header-section-number">3.9</span> Using the PEcAn download.file() function</h2>
<p>download.file(url, destination_file, method) <br>
<br></p>
<p>This custom PEcAn function works together with the base R function download.file (<a href="https://stat.ethz.ch/R-manual/R-devel/library/utils/html/download.file.html" class="uri">https://stat.ethz.ch/R-manual/R-devel/library/utils/html/download.file.html</a>). However, it provides expanded functionality to generalize the use for a broad range of environments. This is because some computing environments are behind a firewall or proxy, including FTP firewalls. This may require the use of a custom FTP program and/or initial proxy server authentication to retrieve the files needed by PEcAn (e.g. meteorology drivers, other inputs) to run certain model simulations or tools. For example, the Brookhaven National Laboratory (BNL) requires an initial connection to a FTP proxy before downloading files via FTP protocol. As a result, the computers running PEcAn behind the BNL firewall (e.g. <a href="https://modex.bnl.gov" class="uri">https://modex.bnl.gov</a>) use the ncftp cleint (<a href="http://www.ncftp.com/" class="uri">http://www.ncftp.com/</a>) to download files for PEcAn because the base options with R::base download.file() such as curl, libcurl which don’t have the functionality to provide credentials for a proxy or even those such as wget which do but don’t easily allow for connecting through a proxy server before downloading files. The current option for use in these instances is <strong>ncftp</strong>, specifically <strong>ncftpget</strong></p>
<p><br></p>
<p>Examples: <br>
<em>HTTP</em> <br></p>
<pre><code>download.file(&quot;http://lib.stat.cmu.edu/datasets/csb/ch11b.txt&quot;,&quot;~/test.download.txt&quot;) </code></pre>
<p><em>FTP</em></p>
<pre><code>download.file(&quot;ftp://ftp.cdc.noaa.gov/Datasets/NARR/monolevel/pres.sfc.2000.nc&quot;, &quot;~/pres.sfc.2000.nc&quot;)</code></pre>
<p><em>customizing to use ncftp when running behind an FTP firewall (requires ncftp to be installed and availible)</em> <br></p>
<pre><code>download.file(&quot;ftp://ftp.cdc.noaa.gov/Datasets/NARR/monolevel/pres.sfc.2000.nc&quot;, &quot;~/pres.sfc.2000.nc&quot;, method=&quot;&quot;ncftpget&quot;)</code></pre>
<p><br></p>
<p>On modex.bnl.gov, the ncftp firewall configuration file (e.g. ~/.ncftp/firewall) is configured as:
firewall-type=1
firewall-host=ftpgateway.sec.bnl.local
firewall-port=21</p>
<p>which then allows for direct connection through the firewall using a command like:</p>
<pre><code>ncftpget ftp://ftp.unidata.ucar.edu/pub/netcdf/netcdf-fortran-4.4.4.tar.gz</code></pre>
<p>To allow the use of ncftpget from within the download.file() function you need to set your R profile download.ftp.method option in your options list. To see your current R options run options() from R cmd, which should look something like this:</p>
<pre><code>&gt; options()
$add.smooth
[1] TRUE

$bitmapType
[1] &quot;cairo&quot;

$browser
[1] &quot;/usr/bin/xdg-open&quot;

$browserNLdisabled
[1] FALSE

$CBoundsCheck
[1] FALSE

$check.bounds
[1] FALSE

$citation.bibtex.max
[1] 1

$continue
[1] &quot;+ &quot;

$contrasts
        unordered           ordered
&quot;contr.treatment&quot;      &quot;contr.poly&quot;</code></pre>
<p>In order to set your download.ftp.method option you need to add a line such as</p>
<pre><code># set default FTP
options(download.ftp.method = &quot;ncftpget&quot;)</code></pre>
<p>In your ~/.Rprofile. On modex at BNL we have set the global option in /usr/lib64/R/etc/Rprofile.site.</p>
<p>Once this is done you should be able to see the option set using this command in R:</p>
<pre><code>&gt; options(&quot;download.ftp.method&quot;)
$download.ftp.method
[1] &quot;ncftpget&quot;</code></pre>

</div>
<div id="shiny" class="section level2">
<h2><span class="header-section-number">3.10</span> SHINY</h2>
<div id="debugging-shiny-apps" class="section level3">
<h3><span class="header-section-number">3.10.1</span> Debugging Shiny Apps</h3>
<p>When developing shiny apps you can run the application from rstudio and place breakpoints int he code. To do this you will need to do the following steps first (already done on the VM) before starting rstudio:
- echo “options(shiny.port = 6438)” &gt;&gt; ${HOME}/.Rprofile
- echo “options(shiny.launch.browser = ‘FALSE’)” &gt;&gt; ${HOME}/.Rprofile</p>
<p>Next you will need to create a tunnel for port 6438 to the VM, which will be used to open the shiny app, the following command will creat this tunnel: <code>ssh -l carya -p 6422 -L 6438:localhost:6438 localhost</code>.</p>
<p>Now you can from rstudio run your application using <code>shiny::runApp()</code> and it will show the output from the application in your console. You can now place breakpoints and evaluate the output.</p>
<div id="checking-log-files" class="section level4">
<h4><span class="header-section-number">3.10.1.1</span> Checking Log Files</h4>
<p>To create Log files on the VM, execute the following:</p>
<pre><code>sudo -s
echo &quot;preserve_logs true;&quot; &gt;&gt; /etc/shiny-server/shiny-server.conf
service shiny-server restart</code></pre>
<p>Then within the directory <code>/var/log/shiny-server</code> you will see log files for your specific shiny apps.</p>

</div>
</div>
</div>
<div id="debugging" class="section level2">
<h2><span class="header-section-number">3.11</span> Debugging</h2>
<p>How to identify the source of a problem.</p>
<div id="using-testsworkflow.r" class="section level3">
<h3><span class="header-section-number">3.11.1</span> Using <code>tests/workflow.R</code></h3>
<p>This script, along with model-specific settings files in the <code>tests</code> folder, provide a working example. From inside the tests folder, <code>R CMD --vanilla -- --settings pecan.&lt;model&gt;.xml &lt; workflow.R</code> should work.</p>
<p>The next step is to add <code>debugonce(&lt;broken.function.name&gt;)</code> before running the test workflow.</p>
<p>This allows you can step through the function and evaluate the different objects as they are created and/or transformed.</p>
<p>See <a href="https://github.com/PecanProject/pecan/blob/master/tests/README.md">tests README</a> for more information.</p>
</div>
<div id="useful-scripts" class="section level3">
<h3><span class="header-section-number">3.11.2</span> Useful scripts</h3>
<p>The following scripts (in <code>qaqc/vignettes</code> identify, respectively:</p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/PecanProject/pecan/blob/master/qaqc/vignettes/function_relationships.Rmd">relationships among functions across packages</a></li>
<li><a href="https://github.com/PecanProject/pecan/blob/master/qaqc/vignettes/module_output.Rmd">function inputs and outputs</a> (e.g. that will identify which functions and outputs are used in a workflow).</li>
</ol>

</div>
</div>
<div id="troubleshooting-pecan" class="section level2">
<h2><span class="header-section-number">3.12</span> Troubleshooting PEcAn</h2>
<div id="cookies-and-pecan-web-pages" class="section level3">
<h3><span class="header-section-number">3.12.1</span> Cookies and pecan web pages</h3>
<p>You may need to disable cookies specifically for the pecan webserver in your browser. This shouldn’t be a problem running from the virtual machine, but your installation of php can include a ‘PHPSESSID’ that is quite long, and this can overflow the params field of the workflows table, depending on how long your hostname, model name, site name, etc are.</p>
</div>
<div id="warning-mkdir-function.mkdir-no-such-file-or-directory" class="section level3">
<h3><span class="header-section-number">3.12.2</span> <code>Warning: mkdir() [function.mkdir]: No such file or directory</code></h3>
<p>If you are seeing: <code>Warning: mkdir() [function.mkdir]: No such file or directory in /path/to/pecan/web/runpecan.php at line 169</code> it is because you have used a relative path for $output_folder in system.php.</p>
</div>
<div id="after-creating-a-new-pft-the-tag-for-pft-not-passed-to-config.xml-in-ed" class="section level3">
<h3><span class="header-section-number">3.12.3</span> After creating a new PFT the <num> tag for PFT not passed to config.xml in ED</h3>
<p>This is a result of the rather clunky way we currently have adding PFTs to PEcAn. This is happening because you need to edit the ./pecan/models/ed/data/pftmapping.csv file to include your new PFTs.</p>
<p>This is what the file looks like:</p>
<pre><code>PEcAn;ED
ebifarm.acru;11
ebifarm.acsa3;11
...</code></pre>
<p>You just need to edit this file (in a text editor, no Excel) and add your PFT names and associated number to the end of the file. Once you do this, recompile PEcAn and it should then work for you. We currently need to reference this file in order to properly set the PFT number and maintain internal consistency between PEcAn and ED2.</p>

</div>
</div>
<div id="pecan-project-use-to-teach-ecological-model-data-synthesis" class="section level2">
<h2><span class="header-section-number">3.13</span> PEcAn Project use to teach Ecological model-data synthesis</h2>
<div id="university-classes" class="section level3">
<h3><span class="header-section-number">3.13.1</span> University classes</h3>
<div id="ge-375---environmental-modeling---spring-2013-2014-mike-dietze-boston-university" class="section level4">
<h4><span class="header-section-number">3.13.1.1</span> GE 375 - Environmental Modeling - Spring 2013, 2014 (Mike Dietze, Boston University)</h4>
<p>The final “Case Study: Terrestrial Ecosystem Models” is a PEcAn-based hands-on activity. Each class has been 25 students.</p>
<p>GE 585 - Ecological forecasting Fall 2013 (Mike Dietze, Boston University)</p>
</div>
</div>
<div id="summer-courses-workshops" class="section level3">
<h3><span class="header-section-number">3.13.2</span> Summer Courses / Workshops</h3>
<div id="annual-summer-course-in-flux-measurement-and-advanced-modeling-mike-dietze-ankur-desai-niwot-ridge-co" class="section level4">
<h4><span class="header-section-number">3.13.2.1</span> Annual summer course in flux measurement and advanced modeling (Mike Dietze, Ankur Desai) Niwot Ridge, CO</h4>
<p>About 1/3 lecture, 2/3 hands-on (the syllabus is actually wrong as it list the other way around). Each class has 24 students.</p>
<p><a href="http://www.fluxcourse.org/files/SyllabusFluxcourse_2013.pdf">2013 Syllabus</a> see Tuesday Week 2 Data Assimilation lectures and PEcAn demo and the Class projects and presentations on Thursday and Friday. (Most students use PEcAn for their group projects. 2014 will be the third year that PEcAn has been used for this course.</p>
</div>
<div id="assimilating-long-term-data-into-ecosystem-models-paleo-ecological-observatory-network-paleon-project" class="section level4">
<h4><span class="header-section-number">3.13.2.2</span> Assimilating Long-Term Data into Ecosystem Models: Paleo-Ecological Observatory Network (PalEON) Project</h4>
<p>Here is a link to the course: <a href="https://www3.nd.edu/~paleolab/paleonproject/summer-course/" class="uri">https://www3.nd.edu/~paleolab/paleonproject/summer-course/</a></p>
<p>This course uses the same demo as above, including collecting data in the field and assimilating it (part 3)</p>
</div>
<div id="integrating-evidence-on-forest-response-to-climate-change-physiology-to-regional-abundance" class="section level4">
<h4><span class="header-section-number">3.13.2.3</span> Integrating Evidence on Forest Response to Climate Change: Physiology to Regional Abundance</h4>
<p><a href="http://blue.for.msu.edu/macrosystems/workshop" class="uri">http://blue.for.msu.edu/macrosystems/workshop</a></p>
<p>May 13-14, 2013</p>
<p>Session 4: Integrating Forest Data Into Ecosystem Models</p>
</div>
<div id="ecological-society-of-america-meetings" class="section level4">
<h4><span class="header-section-number">3.13.2.4</span> Ecological Society of America meetings</h4>
<p><a href="http://eco.confex.com/eco/2013/webprogram/Session9007.html">Workshop: Combining Field Measurements and Ecosystem Models</a></p>
</div>
</div>
<div id="selected-publications" class="section level3">
<h3><span class="header-section-number">3.13.3</span> Selected Publications</h3>
<ol style="list-style-type: decimal">
<li>Dietze, M.C., D.S LeBauer, R. Kooper (2013) <a href="https://github.com/PecanProject/pecan/blob/master/documentation/dietze2013oic.pdf?raw=true">On improving the communication between models and data</a>. Plant, Cell, &amp; Environment <a href="doi:10.1111/pce.12043" class="uri">doi:10.1111/pce.12043</a></li>
<li>LeBauer, D.S., D. Wang, K. Richter, C. Davidson, &amp; M.C. Dietze. (2013). <a href="https://github.com/PecanProject/pecan/blob/master/documentation/lebauer2013ffb.pdf?raw=true">Facilitating feedbacks between field measurements and ecosystem models</a>. Ecological Monographs. <a href="doi:10.1890/12-0137.1" class="uri">doi:10.1890/12-0137.1</a></li>
</ol>

</div>
</div>
<div id="rabbitmq" class="section level2">
<h2><span class="header-section-number">3.14</span> RabbitMQ</h2>
<p>This section provides additional details about how PEcAn uses RabbitMQ to manage communication between its Docker containers.</p>
<p>In PEcAn, we use the Python <a href="http://www.rabbitmq.com/tutorials/tutorial-one-python.html"><code>pika</code></a> client to post and retrieve messages from RabbitMQ.
As such, every Docker container that communicates with RabbitMQ contains two Python scripts: <code>sender.py</code> and <code>reciever.py</code>.
Both are located in the <code>docker</code> directory in the PEcAn source code root.</p>
<div id="rabbitmq-basics-sender" class="section level3">
<h3><span class="header-section-number">3.14.1</span> Producer – <code>sender.py</code></h3>
<p>The <code>sender.py</code> script is in charge of posting messages to RabbitMQ.
In the RabbitMQ documentation, it is known as a “producer”.
It runs once for every message posted to RabbitMQ, and then immediately exits (unlike the <code>receiver.py</code>, which runs continuously – see <a href="topical.html#rabbitmq-basics-receiver">below</a>).</p>
<p>Its usage is as follows:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">python3</span> sender.py <span class="op">&lt;</span>URI<span class="op">&gt;</span> <span class="op">&lt;</span>queue<span class="op">&gt;</span> <span class="op">&lt;</span>message<span class="op">&gt;</span></code></pre>
<p>The arguments are:</p>
<ul>
<li><p><code>&lt;URI&gt;</code> – The unique identifier of the RabbitMQ instance, similar to a URL.
The format is <code>amqp://username:password@host/vhost</code>.
By default, this is <code>amqp://guest:guest@rabbitmq/%2F</code> (the <code>%2F</code> here is the hexadecimal encoding for the <code>/</code> character).</p></li>
<li><p><code>&lt;queue&gt;</code> – The name of the queue on which to post the message.</p></li>
<li><p><code>&lt;message&gt;</code> – The contents of the message to post, in JSON format.
A typical message posted by PEcAn looks like the following:</p>
<pre class="sourceCode json"><code class="sourceCode json"><span class="fu">{</span> <span class="dt">&quot;folder&quot;</span> <span class="fu">:</span> <span class="st">&quot;/path/to/PEcAn_WORKFLOWID&quot;</span><span class="fu">,</span> <span class="dt">&quot;workflow&quot;</span> <span class="fu">:</span> <span class="st">&quot;WORKFLOWID&quot;</span> <span class="fu">}</span></code></pre></li>
</ul>
<p>The <code>PEcAn.remote::start_rabbitmq</code> function is a wrapper for this script that provides an easy way to post a <code>folder</code> message to RabbitMQ from R.</p>
</div>
<div id="rabbitmq-basics-receiver" class="section level3">
<h3><span class="header-section-number">3.14.2</span> Consumer – <code>receiver.py</code></h3>
<p>Unlike <code>sender.py</code>, <code>receiver.py</code> runs like a daemon, constantly listening for messages.
In the RabbitMQ documentation, it is known as a “consumer”.
In PEcAn, you can tell that it is ready to receive messages if the corresponding logs (e.g. <code>docker-compose logs executor</code>) show the following message:</p>
<pre><code>[*] Waiting for messages. To exit press CTRL+C.</code></pre>
<p>Our <code>reciever</code> is configured by three environment variables:</p>
<ul>
<li><p><code>RABBITMQ_URI</code> – This defines the URI where RabbitMQ is running.
See corresponding argument in the <a href="topical.html#rabbitmq-basics-sender">producer</a></p></li>
<li><p><code>RABBITMQ_QUEUE</code> – This is the name of the queue on which the consumer will listen for messages, just as in the <a href="topical.html#rabbitmq-basics-sender">producer</a>.</p></li>
<li><p><code>APPLICATION</code> – This specifies the name (including the path) of the default executable to run when receiving a message.
At the moment, it should be an executable that runs in the directory specified by the message’s <code>folder</code> variable.
In the case of PEcAn models, this is usually <code>./job.sh</code>, such that the <code>folder</code> corresponds to the <code>run</code> directory associated with a particular <code>runID</code> (i.e. where the <code>job.sh</code> is located).
For the PEcAn workflow itself, this is set to <code>R CMD BATCH workflow.R</code>, such that the <code>folder</code> is the root directory of the workflow (in the <code>executor</code> Docker container, something like <code>/data/workflows/PEcAn_&lt;workflowID&gt;</code>).
This default executable is <em>overridden</em> if the message contains a <code>custom_application</code> key.
If included, the string specified by the <code>custom_application</code> key will be run as a command exactly as is on the container, from the directory specified by <code>folder</code>.
For instance, in the example below, the container will print “Hello there!” instead of running its default application.</p>
<pre class="sourceCode json"><code class="sourceCode json"><span class="fu">{</span><span class="dt">&quot;custom_application&quot;</span><span class="fu">:</span> <span class="st">&quot;echo &#39;Hello there!&#39;&quot;</span><span class="fu">,</span> <span class="dt">&quot;folder&quot;</span><span class="fu">:</span> <span class="st">&quot;/path/to/my/dir&quot;</span><span class="fu">}</span></code></pre>
<p>NOTE that in RabbitMQ messages, the <code>folder</code> key is always required.</p></li>
</ul>
</div>
<div id="rabbitmq-web" class="section level3">
<h3><span class="header-section-number">3.14.3</span> RabbitMQ and the PEcAn web interface</h3>
<p>RabbitMQ is configured by the following variables in <code>config.php</code>:</p>
<ul>
<li><code>$rabbitmq_host</code> – The RabbitMQ server hostname (default: <code>rabbitmq</code>, because that is the name of the <code>rabbitmq</code> service in <code>docker-compose.yml</code>)</li>
<li><code>$rabbitmq_port</code> – The port on which RabbitMQ listens for messages (default: 5672)</li>
<li><code>$rabbitmq_vhost</code> – The path of the RabbitMQ <a href="https://www.rabbitmq.com/vhosts.html">Virtual Host</a> (default: <code>/</code>).</li>
<li><code>$rabbitmq_queue</code> – The name of the RabbitMQ queue associated with the PEcAn workflow (default: <code>pecan</code>)</li>
<li><code>$rabbitmq_username</code> – The RabbitMQ username (default: <code>guest</code>)</li>
<li><code>$rabbitmq_password</code> – The RabbitMQ password (default: <code>guest</code>)</li>
</ul>
<p>In addition, for running models via RabbitMQ, you will also need to add an entry like the following to the <code>config.php</code> <code>$hostlist</code>:</p>
<pre class="sourceCode php"><code class="sourceCode php"><span class="kw">$hostlist</span>=<span class="kw">array</span><span class="ot">(</span><span class="kw">$fqdn</span> =&gt; <span class="kw">array</span><span class="ot">(</span><span class="st">&quot;rabbitmq&quot;</span> =&gt; <span class="st">&quot;amqp://guest:guest@rabbitmq/%2F&quot;</span><span class="ot">),</span> <span class="st">...</span><span class="ot">)</span></code></pre>
<p>This will set the hostname to the name of the current machine (defined by the <code>$fqdn</code> variable earlier in the <code>config.php</code> file) to an array with one entry, whose key is <code>rabbitmq</code> and whose value is the RabbitMQ URI (<code>amqp://...</code>).</p>
<p>These values are converted into the appropriate entries in the <code>pecan.xml</code> in <code>web/04-runpecan.php</code>.</p>
</div>
<div id="rabbitmq-xml" class="section level3">
<h3><span class="header-section-number">3.14.4</span> RabbitMQ in the PEcAn XML</h3>
<p>RabbitMQ is a special case of remote execution, so it is configured by the <code>host</code> node.
An example RabbitMQ configuration is as follows:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;host&gt;</span>
  <span class="kw">&lt;rabbitmq&gt;</span>
    <span class="kw">&lt;uri&gt;</span>amqp://guest:guest@rabbitmq/%2F<span class="kw">&lt;/uri&gt;</span>
    <span class="kw">&lt;queue&gt;</span>sipnet_136<span class="kw">&lt;/queue&gt;</span>
  <span class="kw">&lt;/rabbitmq&gt;</span>
<span class="kw">&lt;/host&gt;</span></code></pre>
<p>Here, <code>uri</code> and <code>queue</code> have the same general meanings as described in <a href="topical.html#rabbitmq-basics-sender">“producer”</a>.
Note that <code>queue</code> here refers to the target model.
In PEcAn, RabbitMQ model queues are named as <code>MODELTYPE_REVISION</code>,
so the example above refers to the SIPNET model version 136.
Another example is <code>ED2_git</code>, referring to the latest <code>git</code> version of the ED2 model.</p>
</div>
<div id="rabbitmq-dockerfile" class="section level3">
<h3><span class="header-section-number">3.14.5</span> RabbitMQ configuration in Dockerfiles</h3>
<p>As described in the <a href="topical.html#rabbitmq-basics-receiver">“consumer”</a> section, our standard RabbitMQ receiver script is configured using three environment variables: <code>RABBITMQ_URI</code>, <code>RABBITMQ_QUEUE</code>, and <code>APPLICATION</code>.
Therefore, configuring a container to work with PEcAn’s RabbitMQ instance requires setting these three variables in the Dockerfile using an <a href="https://docs.docker.com/engine/reference/builder/#env"><code>ENV</code></a> statement.</p>
<p>For example, this excerpt from <code>docker/base/Dockerfile.executor</code> (for the <code>pecan/executor</code> image responsible for the PEcAn workflow) sets these variables as follows:</p>
<pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span class="kw">ENV</span> RABBITMQ_URI=<span class="st">&quot;amqp://guest:guest@rabbitmq/%2F&quot;</span> \
    RABBITMQ_QUEUE=<span class="st">&quot;pecan&quot;</span> \
    APPLICATION=<span class="st">&quot;R CMD BATCH workflow.R&quot;</span></code></pre>
<p>Similarly, this excerpt from <code>docker/models/Dockerfile.sipnet</code> (which builds the SIPNET model image) is a typical example for a model image.
Note the use of <a href="https://docs.docker.com/engine/reference/builder/#arg"><code>ARG</code></a> here to specify a default version model version of 136 while allowing this to be configurable (via <code>--build-arg MODEL_VERSION=X</code>) at build time:</p>
<pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span class="kw">ARG</span> MODEL_VERSION=136

<span class="kw">ENV</span> APPLICATION=<span class="st">&quot;./job.sh&quot;</span> \
    MODEL_TYPE=<span class="st">&quot;SIPNET&quot;</span> \
    MODEL_VERSION=<span class="st">&quot;${MODEL_VERSION}&quot;</span>

<span class="kw">ENV</span> RABBITMQ_QUEUE=<span class="st">&quot;${MODEL_TYPE}_${MODEL_VERSION}&quot;</span></code></pre>
<p><strong>WARNING</strong>: Dockerfile environment variables set via <code>ENV</code> are assigned <em>all at once</em>; <em>they do not evaluate successively, left to right</em>.
Consider the following block:</p>
<pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span class="co"># Don&#39;t do this!</span>
<span class="kw">ENV</span> MODEL_TYPE=<span class="st">&quot;SIPNET&quot;</span> \
    MODEL_VERSION=136 \
    RABBITMQ_QUEUE=${MODEL_TYPE}_${MODEL_VERSION}   <span class="co"># &lt;- Doesn&#39;t know about MODEL_TYPE or MODEL_VERSION!</span></code></pre>
<p>In this block, the expansion for setting <code>RABBITMQ_QUEUE</code> <em>is not aware</em> of the current values of <code>MODEL_TYPE</code> or <code>MODEL_VERSION</code>, and will therefore be set incorrectly to just <code>_</code> (unless they have been set previously, in which case it will be aware only of their earlier values).
As such, <strong>variables depending on other variables must be set in a separate, subsequent <code>ENV</code> statement than the variables they depend on</strong>.</p>
</div>
<div id="rabbitmq-case-study" class="section level3">
<h3><span class="header-section-number">3.14.6</span> Case study: PEcAn web interface</h3>
<p>The following describes in general terms what happens during a typical run of the PEcAn web interface with RabbitMQ.</p>
<ol style="list-style-type: decimal">
<li><p>The user initializes all containers with <code>docker-compose up</code>.
All the services that interact with RabbitMQ (<code>executor</code> and all models) run <code>receiver.py</code> in the foreground, waiting for messages to tell them what to do.</p></li>
<li><p>The user browses to <a href="http://localhost:8000/pecan/" class="uri">http://localhost:8000/pecan/</a> and steps through the web interface.
All the pages up to the <code>04-runpecan.php</code> run on the <code>web</code> container, and are primarily for setting up the <code>pecan.xml</code> file.</p></li>
<li><p>Once the user starts the PEcAn workflow at <code>04-runpecan.php</code>, the underlying PHP code connects to RabbitMQ (based on the URI provided in <code>config.php</code>) and posts the following message to the <code>pecan</code> queue:</p></li>
</ol>
<pre class="sourceCode json"><code class="sourceCode json">  <span class="fu">{</span><span class="dt">&quot;folder&quot;</span><span class="fu">:</span> <span class="st">&quot;/workflows/PEcAn_WORKFLOWID&quot;</span><span class="fu">,</span> <span class="dt">&quot;workflowid&quot;</span><span class="fu">:</span> <span class="st">&quot;WORKFLOWID&quot;</span><span class="fu">}</span></code></pre>
<ol start="4" style="list-style-type: decimal">
<li>The <code>executor</code> service, which is listening on the <code>pecan</code> queue, hears this message and executes its <code>APPLICATION</code> (<code>R CMD BATCH workflow.R</code>) in the working directory specified in the message’s <code>folder</code>.
The <code>executor</code> service then performs the pre-execution steps (e.g. trait meta-analysis, conversions) itself.
Then, to actually execute the model, <code>executor</code> posts the following message to the target model’s queue:</li>
</ol>
<pre class="sourceCode json"><code class="sourceCode json">  <span class="fu">{</span><span class="dt">&quot;folder&quot;</span><span class="fu">:</span> <span class="st">&quot;/workflows/PEcAn_WORKFLOWID/run/RUNID&quot;</span><span class="fu">}</span></code></pre>
<ol start="5" style="list-style-type: decimal">
<li><p>The target model service, which is listening on its dedicated queue, hears this message and runs its <code>APPLICATION</code>, which is <code>job.sh</code>, in the directory indicated by the message.
Upon exiting (normally), the model service writes its status into a file called <code>rabbitmq.out</code> in the same directory.</p></li>
<li><p>The <code>executor</code> container continuously looks for the <code>rabbitmq.out</code> file as an indication of the model run’s status.
Once it sees this file, it reads the status and proceeds with the post-execution parts of the workflow.
(NOTE that this isn’t perfect. If the model running process exits abnormally, the <code>rabbitmq.out</code> file may not be created, which can cause the <code>executor</code> container to hang. If this happens, the solution is to restart the <code>executor</code> container with <code>docker-compose restart executor</code>).</p></li>
</ol>

</div>
</div>
<div id="database" class="section level2">
<h2><span class="header-section-number">3.15</span> BETY Database Administration</h2>
<p>This section provides additional details about the BETY database used by PEcAn. It will discuss best practices for setting up the BETY database, how to backup the database and how to restore the database.</p>
<div id="database-setup" class="section level3">
<h3><span class="header-section-number">3.15.1</span> Best practices</h3>
<p>When using the BETY database in non testing mode, it is best not to use the default users. This is accomplished when running the initialize of the database. When the database is initally created the database will be created with some default users (best known is the carya user) as well as the guestuser that can be used in the BETY web application. To disable these users you will either need to disable the users from the web interface, or you can reinitialize the database and remove the <code>-u</code> flag from the command line (the <code>-u</code> flag will create the default users). To disable the guestuser as well you can remove the <code>-g</code> flag from the command line, or disable the account from BETY.</p>
<p>The default installation of BETY and PEcAn will assume there is a database called bety with a default username and password. The default installation will setup the database account to not have any superuser abilities. It is also best to limit access to the postgres database from trusted hosts, either by using firewalls, or configuring postgresql to only accept connections from a limited set of hosts.</p>
</div>
<div id="backup-of-bety-database" class="section level3">
<h3><span class="header-section-number">3.15.2</span> Backup of BETY database</h3>
<p>It is good practice to make sure you backup the BETY database. Just creating a copy of the files on disk is not enough to ensure you have a valid backup. Most likely if you do this you will end up with a corrupted backup of the database.</p>
<p>To backup the database you can use the <code>pg_dump</code> command, which will make sure the database id backed up in a consistent state. You can run <code>sudo -u postgres pg_dump -d bety -Z 9 -f bety.sql.gz</code>, this will create a compressed file that can be used to resotore the database.</p>
<p>In the PEcAn distribution in scripts folder there is a script called <code>backup.bety.sh</code>. This script will create the backup of the database. It will create multiple backups allowing you to restore the database from one of these copies. The database will be backed up to one of the following files:
- bety-d-X, daily backup, where X is the day of the month.
- bety-w-X, weekly backup, where X is the week number in the year
- bety-m-X, montly backup, where X is the month of the year
- bety-y-X, yearly backup, where X is the actual year.
Using this scheme, we can restore the database using any of the files generated.</p>
<p>It is recommeneded to run this script using a cronjob at midnight such that you have a daily backup of the database and do not have to remember to create these backups. When running this script (either cron or by hand) make sure to place the backups on a different machine than the machine that holds the database in case of a larger system failure.</p>
</div>
<div id="restore-of-bety-database" class="section level3">
<h3><span class="header-section-number">3.15.3</span> Restore of BETY database</h3>
<p>Hopefully this section will never need to be used. Following are 5 steps that have been used to restore the database. Before you start it is worth it to read up online a bit on restoring the database as well as join the slack channel and ask any of the people there for help.</p>
<ol style="list-style-type: decimal">
<li>stop apache (BETY/PEcAn web apps) <code>service httpd stop</code> or <code>service apache2 stop</code></li>
<li>backup database (you know just incase) <code>pg_dump -d bety &gt; baddb.sql</code></li>
<li>drop database <code>sudo -u postgres psql -c 'drop database bety'</code></li>
<li>create database <code>sudo -u postgres psql -c 'create database bety with owner bety'</code></li>
<li>load database (assuming dump is called bety.sql.gz) <code>zcat bety.sql.gz | grep -v  search_path |  sudo -u postgres psql -d bety</code></li>
<li>start apache again <code>service httpd start</code> or <code>service apache2 start</code></li>
</ol>
<p>If during step 5 there is a lot of errors, it is helpful to add <code>-v ON_ERROR_STOP=1</code> to the end of the command. This will stop the restore at the first error and will help with debugging the issue.</p>

</div>
</div>
<div id="workflow-modules" class="section level2">
<h2><span class="header-section-number">3.16</span> Workflow modules</h2>
<p>NOTE: As of PEcAn 1.2.6 – needs to be updated significantly</p>
<!--NEEDS TO BE UPDATED SIGNIFICANTLY-->
<div id="overview" class="section level3">
<h3><span class="header-section-number">3.16.1</span> Overview</h3>
<p>Workflow inputs and outputs (click to open in new page, then zoom). Code used to generate this image is provided in <a href="https://github.com/PecanProject/pecan/blob/master/qaqc/vignettes/module_output.Rmd">qaqc/vignettes/module_output.Rmd</a></p>
<p><a href="http://isda.ncsa.illinois.edu/~kooper/EBI/workflow.svg"><img src="http://isda.ncsa.illinois.edu/~kooper/EBI/workflow.svg" alt="PEcAn Workflow" /></a></p>
</div>
<div id="load-settings" class="section level3">
<h3><span class="header-section-number">3.16.2</span> Load Settings:</h3>
<div id="read.settingshomepecanpecan.xml" class="section level4">
<h4><span class="header-section-number">3.16.2.1</span> <code>read.settings(&quot;/home/pecan/pecan.xml&quot;)</code></h4>
<ul>
<li>loads settings</li>
<li>create directories</li>
<li>generates new xml, put in output folder</li>
</ul>
</div>
</div>
<div id="query-database" class="section level3">
<h3><span class="header-section-number">3.16.3</span> Query Database:</h3>
<div id="get.trait.data" class="section level4">
<h4><span class="header-section-number">3.16.3.1</span> <code>get.trait.data()</code></h4>
<p>Queries the database for both the trait data and prior distributions associated with the PFTs specified in the settings file. The list of variables that are queried is determined by what variables have priors associated with them in the definition of the pft. Likewise, the list of species that are associated with a PFT determines what subset of data is extracted out of all data matching a given variable name.</p>
</div>
</div>
<div id="meta-analysis" class="section level3">
<h3><span class="header-section-number">3.16.4</span> Meta Analysis:</h3>
<div id="run.meta.analysis" class="section level4">
<h4><span class="header-section-number">3.16.4.1</span> <code>run.meta.analysis()</code></h4>
<p>The meta-analysis code begins by distilling the trait.data to just the values needed for the meta-analysis statistical model, with this being stored in <code>madata.Rdata</code>. This reduced form includes the conversion of all error statistics into precision (1/variance), and the indexing of sites, treatments, and greenhouse. In reality, the core meta-analysis code can be run independent of the trait database as long as input data is correctly formatted into the form shown in <code>madata</code>.</p>
<p>The evaluation of the meta-analysis is done using a Bayesian statistical software package called JAGS that is called by the R code. For each trait, the R code will generate a [trait].model.bug file that is the JAGS code for the meta-analysis itself. This code is generated on the fly, with PEcAn adding or subtracting the site, treatment, and greenhouse terms depending upon the presence of these effects in the data itself.</p>
<p>Meta-analyses are run, and summary plots are produced.</p>
</div>
</div>
<div id="write-configuration-files" class="section level3">
<h3><span class="header-section-number">3.16.5</span> Write Configuration Files</h3>
<div id="write.configsmodel" class="section level4">
<h4><span class="header-section-number">3.16.5.1</span> <code>write.configs(model)</code></h4>
<ul>
<li>writes out a configuration file for each model run
** writes 500 configuration files for a 500 member ensemble
** for <em>n</em> traits, writes <code>6 * n + 1</code> files for running default Sensitivity Analysis (number can be changed in the pecan settings file)</li>
</ul>
</div>
</div>
<div id="start-runs" class="section level3">
<h3><span class="header-section-number">3.16.6</span> Start Runs:</h3>
<div id="start.runsmodel" class="section level4">
<h4><span class="header-section-number">3.16.6.1</span> <code>start.runs(model)</code></h4>
<p>This code starts the model runs using a model specific run function named start.runs.<a href="tutorialsdemos-and-how-tos.html#model">model</a>. If the ecosystem model is running on a remote server, this module also takes care of all of the communication with the remote server and its run queue. Each of your subdirectories should now have a [run.id].out file in it. One instance of the model is run for each configuration file generated by the previous write configs module.</p>
</div>
</div>
<div id="get-model-output" class="section level3">
<h3><span class="header-section-number">3.16.7</span> Get Model Output</h3>
<div id="get.model.outputmodel" class="section level4">
<h4><span class="header-section-number">3.16.7.1</span> <code>get.model.output(model)</code></h4>
<p>This code first uses a model-specific model2netcdf.<a href="tutorialsdemos-and-how-tos.html#model">model</a> function to convert the model output into a standard output format (<a href="http://nacp.ornl.gov/MsTMIP_variables.shtml">MsTMIP</a>). Then it extracts the data for requested variables specified in the settings file as <code>settings$ensemble$variable</code>, averages over the time-period specified as <code>start.date</code> and <code>end.date</code>, and stores the output in a file <code>output.Rdata</code>. The <code>output.Rdata</code> file contains two objects, <code>sensitivity.output</code> and <code>ensemble.output</code>, that is the model prediction for the parameter sets specified in <code>sa.samples</code> and <code>ensemble.samples</code>. In order to save bandwidth, if the model output is stored on a remote system PEcAn will perform these operations on the remote host and only return the <code>output.Rdata</code> object.</p>
</div>
</div>
<div id="ensemble-analysis" class="section level3">
<h3><span class="header-section-number">3.16.8</span> Ensemble Analysis</h3>
<div id="run.ensemble.analysis" class="section level4">
<h4><span class="header-section-number">3.16.8.1</span> <code>run.ensemble.analysis()</code></h4>
<p>This module makes some simple graphs of the ensemble output. Open ensemble.analysis.pdf to view the ensemble prediction as both a histogram and a boxplot. ensemble.ts.pdf provides a timeseries plot of the ensemble mean, meadian, and 95% CI</p>
</div>
</div>
<div id="sensitivity-analysis-variance-decomposition" class="section level3">
<h3><span class="header-section-number">3.16.9</span> Sensitivity Analysis, Variance Decomposition</h3>
<div id="run.sensitivity.analysis" class="section level4">
<h4><span class="header-section-number">3.16.9.1</span> <code>run.sensitivity.analysis()</code></h4>
<p>This function processes the output of the previous module into sensitivity analysis plots, <code>sensitivityanalysis.pdf</code>, and a variance decomposition plot, <code>variancedecomposition.pdf</code> . In the sensitivity plots you will see the parameter values on the x-axis, the model output on the Y, with the dots being the model evaluations and the line being the spline fit.</p>
<p>The variance decomposition plot is discussed more below. For your reference, the R list object, sensitivity.results, stored in sensitivity.results.Rdata, contains all the components of the variance decomposition table, as well as the the input parameter space and splines from the sensitivity analysis (reminder: the output parameter space from the sensitivity analysis was in outputs.R).</p>
<p>The variance decomposition plot contains three columns, the coefficient of variation (normalized posterior variance), the elasticity (normalized sensitivity), and the partial standard deviation of each model parameter. This graph is sorted by the variable explaining the largest amount of variability in the model output (right hand column). From this graph identify the top-tier parameters that you would target for future constraint.</p>
</div>
</div>
<div id="glossary" class="section level3">
<h3><span class="header-section-number">3.16.10</span> Glossary</h3>
<ul>
<li>Inputs: data sets that are used, and file paths leading to them</li>
<li>Parameters: e.g. info set in settings file</li>
<li>Outputs: data sets that are dropped, and the file paths leading to them</li>
</ul>

</div>
</div>
<div id="data-assimilation-with-dart" class="section level2">
<h2><span class="header-section-number">3.17</span> Data assimilation with DART</h2>
<p>In addition to the state assimilation routines found in the assim.sequential module, another approach for state data assimilation in PEcAn is through the DART workflow created by the DARES group in NCAR.</p>
<p>This section gives a straight-forward explanation how to implement DART, focused on the technical aspects of the implementation. If there are any questions, feel free to send @Viskari an email (<code>tt.viskari@gmail.com</code>) or contacting DART support as they are quite awesome in helping people with problems. Also, if there are any suggestions on how to improve the wiki, please let me know.</p>
<p><strong>Running with current folders in PEcAn</strong></p>
<p>Currently the DART folders in PEcAn are that you can simply copy the structure there over a downloaded DART workflow and it should replace/add relevant files and folders. The most important step after that is to check and change the run paths in the following files:
Path_name files in the work folders
T_ED2IN file, as it indicates where the run results be written.
advance_model.csh, as it indicates where to copy files from/to.</p>
<p>Second thing is setting the state vector size. This is explained in more detail below, but essentially this is governed by the variable model_size in model_mod.f90. In addition to this, it should be changed in utils/F2R.f90 and R2F.f90 programs, which are responsible for reading and writing state variable information for the different ensembles. This also will be expanded below. Finally, the new state vector size should be updated for any other executable that runs it.</p>
<p>Third thing needed are the initial condition and observation sequence files. They will always follow the same format and are explained in more detail below.</p>
<p>Finally the ensemble size, which is the easiest to change. In the work subfolder, there is a file named input.nml. Simply changing the ensemble size there will set it for the run itself. Also remember that initial conditions file should have the equal amount of state vectors as there are ensemble members.</p>
<p><strong>Adjusting the workflow</strong></p>
<p>The central file for the actual workflow is advance_model.csh. It is a script DART calls to determine how the state vector changes between the two observation times and is essentially the only file one needs to change when changing state models or observations operators. The file itself should be commented to give a good idea of the flow, but beneath is a crude order of events.
1. Create a temporary folder to run the model in and copy/link required files in to it.
2. Read in the state vector values and times from DART. Here it is important to note that the values will be in binary format, which need to be read in by a Fortran program. In my system, there is a program called F2R which reads in the binary values and writes out in ascii form the state vector values as well as which ED2 history files it needs to copy based on the time stamps.
3. Run the observation operator, which writes the state vector state in to the history files and adjusts them if necessary.
4. Run the program.
5. Read the new state vector values from output files.
6. Convert the state vector values to the binary. In my system, this is done by the program R2F.</p>
<p><strong>Initial conditions file</strong></p>
<p>The initial conditions file, commonly named filter_ics although you can set it to something else in input.nml, is relatively simple in structure. It has one sequence repeating over the number of ensemble members.
First line contains two times: Seconds and days. Just use one of them in this situation, but it has to match the starting time given in input.nml.
After that each line should contain a value from the state vector in the order you want to treat them.
R functions filter_ics.R and B_filter_ics.R in the R folder give good examples of how to create these.</p>
<p><strong>Observations files</strong></p>
<p>The file which contains the observations is commonly known as obs_seq.out, although again the name of the file can be changed in input.nml. The structure of the file is relatively straight-forward and the R function ObsSeq.R in the R subfolder has the write structure for this. Instead of writing it out here, I want to focus on a few really important details in this file.
Each observations will have a time, a value, an uncertainty, a location and a kind. The first four are self-explanatory, but the kind is really important, but also unfortunately really easy to misunderstand. In this file, the kind does not refer to a unit or a type of observation, but which member of the state vector is this observation of. So if the kind was, for example, 5, it would mean that it was of the fifth member of the state vector. However, if the kind value is positive, the system assumes that there is some sort of an operator change in comparing the observation and state vector value which is specified in a subprogram in model_mod.f90.</p>
<p>So for an direct identity comparison between the observation and the state vector value, the kind needs to be negative number of the state vector component. Thus, again if the observation is of the fifth state vector value, the kind should be set as -5. Thus it is recommendable that the state vector values have already been altered to be comparable with the observations.</p>
<p>As for location, there are many ways to set in DART and the method needs to be chosen when compiling the code by giving the program which of the location mods it is to use. In our examples we used a 1-dimensional location vector with scaled values between 0 and 1. For future it makes sense to switch to a 2 dimensional long- and lat-scale, but for the time being the location does not impact the system a lot. The main impact will be if the covariances will be localized, as that will be decided on their locations.</p>
<p><strong>State variable vector in DART</strong></p>
<p>Creating/adjusting a state variable vector in DART is relatively straight-forward. Below are listed the steps to specify a state variable vector in DART.</p>
<p>I. For each specific model, there should be an own folder within the DART root models folder. In this folder there is a model_mod.f90, which contains the model specific subroutines necessary for a DART run.</p>
<p>At the beginning of this file there should be the following line:</p>
<p>integer, parameter :: model_size = [number]</p>
<p>The number here should be the number of variables in the vector. So for example if there were three state variables, then the line should look like this:</p>
<p>integer, parameter :: model_size = 3</p>
<p>This number should also be changed to match with any of the other executables called during the run as indicated by the list above.</p>
<ol start="2" style="list-style-type: upper-roman">
<li>In the DART root, there should be a folder named obs_kind, which contains a file called DEFAULT_obs_kind_mod.F90. It is important to note that all changes should be done to this file instead of obs_kind_mod.f90, as during compilation DART creates obs_kind_mod.f90 from DEFAULT_obs_kind_mod.F90.
This program file contains all the defined observation types used by DART and numbers them for easier reference later. Different types are classified according to observation instrument or relevant observation phenomenon. Adding a new type only requires finding an unused number and starting a new identifying line with the following:</li>
</ol>
<p>integer, parameter, public :: &amp;
KIND_…</p>
<p>Note that the observation kind should always be easy to understand, so avoid using unnecessary acronyms. For example, when adding an observation type for Leaf Area Index, it would look like below:</p>
<p>integer, parameter, public :: &amp;
KIND_LEAF_AREA_INDEX = [number]</p>
<ol start="3" style="list-style-type: upper-roman">
<li>In the DART root, there should be a folder named obs_def, which contains several files starting with obs_def_. There files contain the different available observation kinds classified either according to observation instrument or observable system. Each file starts with the line</li>
</ol>
<p>! BEGIN DART PREPROCESS KIND LIST</p>
<p>And end with line</p>
<p>! END DART PREPROCESS KIND LIST</p>
<p>The lines between these two should contain</p>
<p>! The desired observation reference, the observation type, COMMON_CODE.</p>
<p>For example, for observations relating to phenology, I have created a file called obs_def_phen_mod.f90. In this file I define the Leaf Area Index observations in the following way.</p>
<p>! BEGIN DART PREPROCESS KIND LIST
! LAI, TYPE_LEAF_AREA_INDEX, COMMON_CODE
! END DART PREPROCESS KIND LIST</p>
<p>Note that the exclamation marks are necessary for the file.</p>
<ol start="4" style="list-style-type: upper-roman">
<li>In the model specific folder, in the work subfolder there is a namelist file input.nml. This contains all the run specific information for DART. In it, there is a subtitle &amp;preprocess, under which there is a line</li>
</ol>
<p>input_files = ‘….’</p>
<p>This input_files sections must be set to refer to the obs_def file created in step III. The input files can contain references to multiple obs_def files if necessary.</p>
<p>As an example, the reference to the obs_def_phen_mod.f90 would look like
input_files = ‘../../../obs_def/obs_def_phen_mod.f90’</p>
<p>V. Finally, as an optional step, the different values in state vector can be typed. In model_mod, referred to in step I, there is a subroutine get_state_meta_data. In it, there is an input variable index_in, which refers to the vector component. So for instance for the second component of the vector index_in would be 2. If this is done, the variable kind has to be also included at the beginning of the model_mod.f90 file, at the section which begins</p>
<p>use obs_kind_mod, only ::</p>
<p>The location of the variable can be set, but for a 0-dimensional model we are discussing here, this is not necessary.</p>
<p>Here, though, it is possible to set the variable types by including the following line</p>
<p>if(index_in .eq. [number]) var_type = [One of the variable kinds set in step II]</p>
<ol start="6" style="list-style-type: upper-roman">
<li>If the length of the state vector is changed, it is important that the script ran with DART produces a vector of that length. Change appropriately if necessary.</li>
</ol>
<p>After these steps, DART should be able to run with the state vector of interest.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tutorialsdemos-and-how-tos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="appendix.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tonygardella/pecan/edit/release/vtonydoc/book_source/03_topical_pages/00_topicalpages.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
